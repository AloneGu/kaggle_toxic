{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate', 'num_words', 'num_unique_words', 'num_chars',\n",
      "       'num_stopwords', 'num_punctuations', 'num_words_upper',\n",
      "       'num_words_title', 'mean_word_len', 'unique_r', 'w_p', 'w_p_r',\n",
      "       'stop_r', 'w_p_stop', 'w_p_stop_r', 'num_words_upper_r',\n",
      "       'num_words_title_r'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "test_df['comment_text'] =test_df['comment_text'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "\n",
    "## Number of words in the comment_text ##\n",
    "train_df[\"num_words\"] = train_df[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "test_df[\"num_words\"] = test_df[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "## Number of unique words in the comment_text ##\n",
    "train_df[\"num_unique_words\"] = train_df[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "test_df[\"num_unique_words\"] = test_df[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "## Number of characters in the comment_text ##\n",
    "train_df[\"num_chars\"] = train_df[\"comment_text\"].apply(lambda x: len(str(x)))\n",
    "test_df[\"num_chars\"] = test_df[\"comment_text\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "## Number of stopwords in the comment_text ##\n",
    "eng_stopwords = [\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"]\n",
    "train_df[\"num_stopwords\"] = train_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "test_df[\"num_stopwords\"] = test_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "\n",
    "## Number of punctuations in the comment_text ##\n",
    "import string\n",
    "train_df[\"num_punctuations\"] =train_df['comment_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "test_df[\"num_punctuations\"] =test_df['comment_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "\n",
    "## Number of title case words in the comment_text ##\n",
    "train_df[\"num_words_upper\"] = train_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "test_df[\"num_words_upper\"] = test_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "## Number of title case words in the comment_text ##\n",
    "train_df[\"num_words_title\"] = train_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "test_df[\"num_words_title\"] = test_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "## Average length of the words in the comment_text ##\n",
    "train_df[\"mean_word_len\"] = train_df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test_df[\"mean_word_len\"] = test_df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "## Average length of the words in the comment_text ##\n",
    "train_df[\"mean_word_len\"] = train_df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test_df[\"mean_word_len\"] = test_df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "# add features\n",
    "def add_feat(df):\n",
    "    df['unique_r'] = df['num_unique_words'] / df['num_words']\n",
    "    df['w_p'] = df['num_words'] - df['num_punctuations']\n",
    "    df['w_p_r'] = df['w_p'] / df['num_words']\n",
    "    df['stop_r'] = df['num_stopwords'] / df['num_words']\n",
    "    df['w_p_stop'] = df['w_p'] - df['num_stopwords']\n",
    "    df['w_p_stop_r'] = df['w_p_stop'] / df['num_words']\n",
    "    df['num_words_upper_r'] = df['num_words_upper'] / df['num_words']\n",
    "    df['num_words_title_r'] = df['num_words_title'] / df['num_words']\n",
    "\n",
    "add_feat(train_df)\n",
    "add_feat(test_df)\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_words  num_unique_words  num_chars  num_stopwords  num_punctuations  \\\n",
      "0         15                14         83              7                 0   \n",
      "1         27                23        142             17                 0   \n",
      "2         70                54        411             37                 0   \n",
      "3         26                25        148             13                 0   \n",
      "4         49                43        266             25                 0   \n",
      "\n",
      "   num_words_upper  num_words_title  mean_word_len  unique_r  w_p  w_p_r  \\\n",
      "0                2                3       4.133333  0.933333   15    1.0   \n",
      "1                2                5       3.740741  0.851852   27    1.0   \n",
      "2                2                6       4.428571  0.771429   70    1.0   \n",
      "3                0                5       4.576923  0.961538   26    1.0   \n",
      "4                1                6       4.387755  0.877551   49    1.0   \n",
      "\n",
      "     stop_r  w_p_stop  w_p_stop_r  num_words_upper_r  num_words_title_r  \n",
      "0  0.466667         8    0.533333           0.133333           0.200000  \n",
      "1  0.629630        10    0.370370           0.074074           0.185185  \n",
      "2  0.528571        33    0.471429           0.028571           0.085714  \n",
      "3  0.500000        13    0.500000           0.000000           0.192308  \n",
      "4  0.510204        24    0.489796           0.020408           0.122449  \n"
     ]
    }
   ],
   "source": [
    "train_df=train_df.drop(['id','comment_text','toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate'],axis=1)\n",
    "print(train_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_words  num_unique_words  num_chars  num_stopwords  num_punctuations  \\\n",
      "0          8                 8         59              0                 0   \n",
      "1        103                73        649             55                 0   \n",
      "2        100                73        635             37                 0   \n",
      "3         12                12         65              2                 0   \n",
      "4          4                 4         29              0                 0   \n",
      "\n",
      "   num_words_upper  num_words_title  mean_word_len  unique_r  w_p  w_p_r  \\\n",
      "0                1                2       5.500000  1.000000    8    1.0   \n",
      "1                2               15       5.009709  0.708738  103    1.0   \n",
      "2               10               15       4.960000  0.730000  100    1.0   \n",
      "3                1                5       4.000000  1.000000   12    1.0   \n",
      "4                2                2       4.250000  1.000000    4    1.0   \n",
      "\n",
      "     stop_r  w_p_stop  w_p_stop_r  num_words_upper_r  num_words_title_r  \n",
      "0  0.000000         8    1.000000           0.125000           0.250000  \n",
      "1  0.533981        48    0.466019           0.019417           0.145631  \n",
      "2  0.370000        63    0.630000           0.100000           0.150000  \n",
      "3  0.166667        10    0.833333           0.083333           0.416667  \n",
      "4  0.000000         4    1.000000           0.500000           0.500000  \n"
     ]
    }
   ],
   "source": [
    "test_df = test_df.drop(['id','comment_text'],axis=1)\n",
    "print(test_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/other_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_df.values,test_df.values],fout)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
