{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jac/.local/lib/python3.5/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
      "       'insult', 'identity_hate', 'num_words', 'num_unique_words', 'num_chars',\n",
      "       'num_stopwords', 'num_punctuations', 'num_words_upper',\n",
      "       'num_words_title', 'mean_word_len', 'unique_r', 'w_p', 'w_p_r',\n",
      "       'stop_r', 'w_p_stop', 'w_p_stop_r', 'num_words_upper_r',\n",
      "       'num_words_title_r'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "train_df = pd.read_csv(\"../input/train.csv\")\n",
    "test_df = pd.read_csv(\"../input/test.csv\")\n",
    "\n",
    "train_df['comment_text'] = train_df['comment_text'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "test_df['comment_text'] =test_df['comment_text'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "\n",
    "## Number of words in the comment_text ##\n",
    "train_df[\"num_words\"] = train_df[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "test_df[\"num_words\"] = test_df[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "## Number of unique words in the comment_text ##\n",
    "train_df[\"num_unique_words\"] = train_df[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "test_df[\"num_unique_words\"] = test_df[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "\n",
    "## Number of characters in the comment_text ##\n",
    "train_df[\"num_chars\"] = train_df[\"comment_text\"].apply(lambda x: len(str(x)))\n",
    "test_df[\"num_chars\"] = test_df[\"comment_text\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "## Number of stopwords in the comment_text ##\n",
    "eng_stopwords = [\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"]\n",
    "train_df[\"num_stopwords\"] = train_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "test_df[\"num_stopwords\"] = test_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).lower().split() if w in eng_stopwords]))\n",
    "\n",
    "## Number of punctuations in the comment_text ##\n",
    "import string\n",
    "train_df[\"num_punctuations\"] =train_df['comment_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "test_df[\"num_punctuations\"] =test_df['comment_text'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]) )\n",
    "\n",
    "## Number of title case words in the comment_text ##\n",
    "train_df[\"num_words_upper\"] = train_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "test_df[\"num_words_upper\"] = test_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.isupper()]))\n",
    "\n",
    "## Number of title case words in the comment_text ##\n",
    "train_df[\"num_words_title\"] = train_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "test_df[\"num_words_title\"] = test_df[\"comment_text\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n",
    "\n",
    "## Average length of the words in the comment_text ##\n",
    "train_df[\"mean_word_len\"] = train_df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test_df[\"mean_word_len\"] = test_df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "## Average length of the words in the comment_text ##\n",
    "train_df[\"mean_word_len\"] = train_df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "test_df[\"mean_word_len\"] = test_df[\"comment_text\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n",
    "\n",
    "# add features\n",
    "def add_feat(df):\n",
    "    df['unique_r'] = df['num_unique_words'] / df['num_words']\n",
    "    df['w_p'] = df['num_words'] - df['num_punctuations']\n",
    "    df['w_p_r'] = df['w_p'] / df['num_words']\n",
    "    df['stop_r'] = df['num_stopwords'] / df['num_words']\n",
    "    df['w_p_stop'] = df['w_p'] - df['num_stopwords']\n",
    "    df['w_p_stop_r'] = df['w_p_stop'] / df['num_words']\n",
    "    df['num_words_upper_r'] = df['num_words_upper'] / df['num_words']\n",
    "    df['num_words_title_r'] = df['num_words_title'] / df['num_words']\n",
    "\n",
    "add_feat(train_df)\n",
    "add_feat(test_df)\n",
    "print(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_words  num_unique_words  num_chars  num_stopwords  num_punctuations  \\\n",
      "0         50                46        264             20                 0   \n",
      "1         20                20        112              4                 0   \n",
      "2         44                41        233             21                 0   \n",
      "3        116                84        622             70                 0   \n",
      "4         14                14         67              8                 0   \n",
      "\n",
      "   num_words_upper  num_words_title  mean_word_len  unique_r  w_p  w_p_r  \\\n",
      "0                3               12       4.240000  0.920000   50    1.0   \n",
      "1                3                5       4.150000  1.000000   20    1.0   \n",
      "2                1                4       4.227273  0.931818   44    1.0   \n",
      "3                5               11       4.189655  0.724138  116    1.0   \n",
      "4                0                2       3.571429  1.000000   14    1.0   \n",
      "\n",
      "     stop_r  w_p_stop  w_p_stop_r  num_words_upper_r  num_words_title_r  \n",
      "0  0.400000        30    0.600000           0.060000           0.240000  \n",
      "1  0.200000        16    0.800000           0.150000           0.250000  \n",
      "2  0.477273        23    0.522727           0.022727           0.090909  \n",
      "3  0.603448        46    0.396552           0.043103           0.094828  \n",
      "4  0.571429         6    0.428571           0.000000           0.142857  \n"
     ]
    }
   ],
   "source": [
    "train_df=train_df.drop(['id','comment_text','toxic', 'severe_toxic', 'obscene', 'threat',\n",
    "       'insult', 'identity_hate'],axis=1)\n",
    "print(train_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   num_words  num_unique_words  num_chars  num_stopwords  num_punctuations  \\\n",
      "0         75                63        367             34                 0   \n",
      "1         10                 9         50              6                 0   \n",
      "2          5                 5         54              1                 0   \n",
      "3         39                29        205             23                 0   \n",
      "4          8                 8         41              3                 0   \n",
      "\n",
      "   num_words_upper  num_words_title  mean_word_len  unique_r  w_p  w_p_r  \\\n",
      "0                0                4       3.786667   0.84000   75    1.0   \n",
      "1                1                2       3.000000   0.90000   10    1.0   \n",
      "2                0                4       5.200000   1.00000    5    1.0   \n",
      "3                3                4       4.153846   0.74359   39    1.0   \n",
      "4                1                1       4.125000   1.00000    8    1.0   \n",
      "\n",
      "     stop_r  w_p_stop  w_p_stop_r  num_words_upper_r  num_words_title_r  \n",
      "0  0.453333        41    0.546667           0.000000           0.053333  \n",
      "1  0.600000         4    0.400000           0.100000           0.200000  \n",
      "2  0.200000         4    0.800000           0.000000           0.800000  \n",
      "3  0.589744        16    0.410256           0.076923           0.102564  \n",
      "4  0.375000         5    0.625000           0.125000           0.125000  \n"
     ]
    }
   ],
   "source": [
    "test_df = test_df.drop(['id','comment_text'],axis=1)\n",
    "print(test_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/other_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_df.values,test_df.values],fout)\n",
    "print('done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
