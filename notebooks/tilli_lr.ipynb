{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaning ...\n"
     ]
    }
   ],
   "source": [
    "# ref: https://www.kaggle.com/tilii7/tuned-logreg-oof-files\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import log_loss, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('../input/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../input/test.csv').fillna(' ')\n",
    "tr_ids = train[['id']]\n",
    "train[class_names] = train[class_names].astype(np.int8)\n",
    "target = train[class_names]\n",
    "\n",
    "print(' Cleaning ...')\n",
    "# PREPROCESSING PART\n",
    "repl = {\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" frown \",\n",
    "    \":(\": \" frown \",\n",
    "    \":s\": \" frown \",\n",
    "    \":-s\": \" frown \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "    r\"\\bi'm\\b\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"r\": \"are\",\n",
    "    \"u\": \"you\",\n",
    "    \"haha\": \"ha\",\n",
    "    \"hahaha\": \"ha\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"i'll\" : \"i will\",\n",
    "    \"its\" : \"it is\",\n",
    "    \"it's\" : \"it is\",\n",
    "    \"'s\" : \" is\",\n",
    "    \"that's\" : \"that is\",\n",
    "    \"weren't\" : \"were not\",\n",
    "}\n",
    "\n",
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "lte = test[\"comment_text\"].tolist()\n",
    "for i in ltr:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_train_data.append(xx)\n",
    "for i in lte:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_test_data.append(xx)\n",
    "train[\"new_comment_text\"] = new_train_data\n",
    "test[\"new_comment_text\"] = new_test_data\n",
    "\n",
    "trate = train[\"new_comment_text\"].tolist()\n",
    "tete = test[\"new_comment_text\"].tolist()\n",
    "for i, c in enumerate(trate):\n",
    "    trate[i] = re.sub('[^a-zA-Z ?!]+', '', str(trate[i]).lower())\n",
    "for i, c in enumerate(tete):\n",
    "    tete[i] = re.sub('[^a-zA-Z ?!]+', '', tete[i])\n",
    "train[\"comment_text\"] = trate\n",
    "test[\"comment_text\"] = tete\n",
    "del trate, tete\n",
    "train.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "test.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>daww! he matches this background colour i am s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man i am really not trying to edit war it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>more i can not make any real suggestions on i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation why the edits made under my userna...      0   \n",
       "1  000103f0d9cfb60f  daww! he matches this background colour i am s...      0   \n",
       "2  000113f07ec002fd  hey man i am really not trying to edit war it ...      0   \n",
       "3  0001b41b1c6bb37e   more i can not make any real suggestions on i...      0   \n",
       "4  0001d958c54c6e35  you sir are my hero any chance you remember wh...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>yo bitch ja rule is more succesful then youll ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>from rfc  the title is fine as it is imo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>sources   zawe ashton on lapland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>if you have a look back at the source the info...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>i do not anonymously edit articles at all</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text\n",
       "0  00001cee341fdb12  yo bitch ja rule is more succesful then youll ...\n",
       "1  0000247867823ef7          from rfc  the title is fine as it is imo \n",
       "2  00013b17ad220c46               sources   zawe ashton on lapland    \n",
       "3  00017563c3f7919a  if you have a look back at the source the info...\n",
       "4  00017695ad8997eb         i do not anonymously edit articles at all "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Part 1/2 of vectorizing ...\n",
      " Part 2/2 of vectorizing ...\n",
      "(159571, 60000) (153164, 60000)\n"
     ]
    }
   ],
   "source": [
    "print(' Part 1/2 of vectorizing ...')\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=10000)\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "print(' Part 2/2 of vectorizing ...')\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(2, 6),\n",
    "    max_features=50000)\n",
    "char_vectorizer.fit(all_text)\n",
    "train_char_features = char_vectorizer.transform(train_text)\n",
    "test_char_features = char_vectorizer.transform(test_text)\n",
    "\n",
    "train_features = hstack([train_char_features, train_word_features]).tocsr()\n",
    "test_features = hstack([test_char_features, test_word_features]).tocsr()\n",
    "print(train_features.shape,test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "target = target.values\n",
    "print(target[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.10421944051444547 0.07736698901708022\n",
      "1 0.10094516374483271 0.07768756315928728\n",
      "2 0.09689469756724278 0.07806437054899934\n",
      "3 0.09863308331991873 0.07785983306094772\n",
      "4 0.10200903756054049 0.07746123913080742\n",
      "5 0.09928556346338296 0.07778067034807377\n",
      "6 0.10035638549797365 0.07772664411163223\n",
      "7 0.09699550067162133 0.07807298499142155\n",
      "8 0.09727854776595017 0.077957548997523\n",
      "9 0.09894633549179196 0.07788655447932341\n",
      "========= toxic\n",
      "0 0.09432299978965594 0.09105163845294309\n",
      "1 0.09404911480539416 0.09225918670048783\n",
      "2 0.09150205475862452 0.09317590636753048\n",
      "3 0.09802411240684075 0.09169241190021024\n",
      "4 0.09031785302741922 0.09219540682696005\n",
      "5 0.0989825810352689 0.09226142402206906\n",
      "6 0.10043048350952256 0.09245957370430298\n",
      "7 0.09407353583345726 0.09202573660552242\n",
      "8 0.10018145114161303 0.09083473035890431\n",
      "9 0.09717285384762389 0.09232136011437317\n",
      "========= severe_toxic\n",
      "0 0.09970445825599546 0.08304722684407272\n",
      "1 0.09437409076292244 0.08339776929584362\n",
      "2 0.09976100561542844 0.08364914309262475\n",
      "3 0.09063598612616848 0.08402869796344857\n",
      "4 0.09508769014857586 0.08394379394664159\n",
      "5 0.09278600210885392 0.08335367655150448\n",
      "6 0.09780168872097944 0.08333750598530996\n",
      "7 0.09411154855232301 0.08345625978779758\n",
      "8 0.09425262078196354 0.08348103126998228\n",
      "9 0.09489703991624404 0.08402638626372087\n",
      "========= obscene\n",
      "0 0.039765678450082484 0.03569433717562511\n",
      "1 0.038637219935600244 0.03547044948605474\n",
      "2 0.0410508814329429 0.03581423340455231\n",
      "3 0.04022012524782764 0.036019738186165315\n",
      "4 0.037242680757599095 0.0362300899599757\n",
      "5 0.034119369577161655 0.03643648132097848\n",
      "6 0.04133722380159807 0.03577934607410481\n",
      "7 0.03748488388795066 0.035906146592589096\n",
      "8 0.0369133741196193 0.03584224882318025\n",
      "9 0.035539350338777566 0.03585767575506614\n",
      "========= threat\n",
      "0 0.13811333397109662 0.12424820946133175\n",
      "1 0.13781303112607007 0.12473107944355773\n",
      "2 0.14347219291182894 0.12435525859317452\n",
      "3 0.13349159556983772 0.12455233445540116\n",
      "4 0.14105847880746966 0.12325544955457345\n",
      "5 0.14297446863164723 0.12458388463310686\n",
      "6 0.13357339632089504 0.12425898648604461\n",
      "7 0.13362647011404447 0.12415244994865698\n",
      "8 0.1339469223257388 0.12406655046599863\n",
      "9 0.1384415440442596 0.12488217849798502\n",
      "========= insult\n",
      "0 0.0913104117713976 0.08447910629278582\n",
      "1 0.09443646972611934 0.08314484467666203\n",
      "2 0.08977167541554128 0.08326867260701895\n",
      "3 0.09295753590361412 0.08387238549530401\n",
      "4 0.08709972711923598 0.08382283897892892\n",
      "5 0.08388919211372496 0.08450452586602288\n",
      "6 0.08363983130036545 0.08462152921048127\n",
      "7 0.09238627370533316 0.08313449111634175\n",
      "8 0.09113773812423087 0.08449360476274385\n",
      "9 0.08943176141403751 0.08448934323979825\n",
      "========= identity_hate\n"
     ]
    }
   ],
   "source": [
    "def kf_train(k=5):\n",
    "    all_parameters = {\n",
    "                  'C'             : [1.048113, 0.1930, 0.596362, 0.25595, 0.449843, 0.25595],\n",
    "                  'tol'           : [0.1, 0.1, 0.046416, 0.0215443, 0.1, 0.01],\n",
    "                  'solver'        : ['lbfgs', 'newton-cg', 'lbfgs', 'newton-cg', 'newton-cg', 'lbfgs'],\n",
    "                  'fit_intercept' : [True, True, True, True, True, True],\n",
    "                  'penalty'       : ['l2', 'l2', 'l2', 'l2', 'l2', 'l2'],\n",
    "                  'class_weight'  : [None, 'balanced', 'balanced', 'balanced', 'balanced', 'balanced'],\n",
    "    }\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=1001)\n",
    "    train_pred, test_pred = np.zeros((159571,6)),np.zeros((153164,6))\n",
    "    for j in range(6):\n",
    "        fold_idx = 0\n",
    "        for train_index, test_index in skf.split(train_features,target[:,j]):\n",
    "            # model\n",
    "            model = LogisticRegression(\n",
    "                C=all_parameters['C'][j],\n",
    "                max_iter=200,\n",
    "                tol=all_parameters['tol'][j],\n",
    "                solver=all_parameters['solver'][j],\n",
    "                fit_intercept=all_parameters['fit_intercept'][j],\n",
    "                penalty=all_parameters['penalty'][j],\n",
    "                dual=False,\n",
    "                class_weight=all_parameters['class_weight'][j],\n",
    "                verbose=0)\n",
    "            \n",
    "            # data\n",
    "            curr_x,curr_y = train_features[train_index],target[train_index]\n",
    "            hold_out_x,hold_out_y = train_features[test_index],target[test_index]\n",
    "            \n",
    "            # train\n",
    "            model.fit(curr_x, curr_y[:,j])\n",
    "            hold_out_pred = model.predict_proba(hold_out_x)\n",
    "            curr_train_pred = model.predict_proba(curr_x)\n",
    "            print(fold_idx,log_loss(hold_out_y[:,j],hold_out_pred),log_loss(curr_y[:,j],curr_train_pred))\n",
    "            fold_idx += 1\n",
    "            \n",
    "            train_pred[test_index,j] = list(hold_out_pred[:,1].flatten())\n",
    "            y_test = model.predict_proba(test_features)[:,1]\n",
    "            test_pred[:,j] += y_test\n",
    "        print('=========',class_names[j])\n",
    "    test_pred = test_pred/k\n",
    "    return train_pred, test_pred\n",
    "\n",
    "train_pred,test_pred = kf_train(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99982861 0.94638479 0.99998611 0.58520974 0.99886107 0.94219621]\n",
      " [0.00392937 0.01838111 0.00370642 0.00385484 0.03252907 0.03356666]\n",
      " [0.00698681 0.01141339 0.019616   0.00381293 0.02736875 0.02219025]\n",
      " [0.00260546 0.01794668 0.0056303  0.00566862 0.00931623 0.00319148]\n",
      " [0.0132848  0.01632966 0.03347964 0.00568871 0.02679658 0.01133338]]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('../features/tilli_lr_feat.pkl','wb') as fout:\n",
    "    pickle.dump([train_pred,test_pred],fout)\n",
    "print(test_pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
