{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import re\n",
    "  \n",
    "\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values\n",
    "train['comment_text'] = train['comment_text'].fillna('nan')\n",
    "test['comment_text'] = test['comment_text'].fillna('nan')\n",
    "print('load done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 15000)\n"
     ]
    }
   ],
   "source": [
    "tf_vec1 = TfidfVectorizer(sublinear_tf=True,\n",
    "                            strip_accents='unicode',\n",
    "                            analyzer='word',\n",
    "                            token_pattern=r'\\w{1,}',\n",
    "                            ngram_range=(1, 1),\n",
    "                            max_features=15000)\n",
    "train_tfidf1 = tf_vec1.fit_transform(train['comment_text'].values)\n",
    "test_tfidf1 = tf_vec1.transform(test['comment_text'].values)\n",
    "\n",
    "print(train_tfidf1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (159571, 30)\n",
      "dump done\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "n_comp = 30\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "train_svd1 = svd_obj.fit_transform(train_tfidf1)\n",
    "test_svd1 = svd_obj.transform(test_tfidf1)\n",
    "\n",
    "print(type(train_svd1),train_svd1.shape)\n",
    "with open('../features/tfidf_feat1.pkl','wb') as fout:\n",
    "    pickle.dump([train_svd1,test_svd1],fout)\n",
    "print('dump done')\n",
    "#simple_eval(train_svd1,train_y,XGBClassifier)\n",
    "print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_eval(train_tfidf1,train_y,LogisticRegression)\n",
    "#print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 20000)\n"
     ]
    }
   ],
   "source": [
    "tf_vec2 = TfidfVectorizer(sublinear_tf=True,\n",
    "                        strip_accents='unicode',\n",
    "                        analyzer='char',\n",
    "                        ngram_range=(1, 5),\n",
    "                        max_features=20000\n",
    "                         )\n",
    "train_tfidf2 = tf_vec2.fit_transform(train['comment_text'].values)\n",
    "test_tfidf2 = tf_vec2.transform(test['comment_text'].values)\n",
    "print(train_tfidf2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (159571, 30)\n",
      "dump done\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "train_svd2 = svd_obj.fit_transform(train_tfidf2)\n",
    "test_svd2 = svd_obj.transform(test_tfidf2)\n",
    "\n",
    "print(type(train_svd2),train_svd2.shape)\n",
    "with open('../features/tfidf_feat2.pkl','wb') as fout:\n",
    "    pickle.dump([train_svd2,test_svd2],fout)\n",
    "print('dump done')\n",
    "#simple_eval(train_svd2,train_y,XGBClassifier)\n",
    "print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.93791465e-01   6.20853525e-03]\n",
      " [  9.80035544e-01   1.99644562e-02]\n",
      " [  9.78047041e-01   2.19529591e-02]\n",
      " [  9.98319365e-01   1.68063457e-03]\n",
      " [  9.29023406e-01   7.09765939e-02]\n",
      " [  9.93445038e-01   6.55496179e-03]\n",
      " [  7.24703146e-02   9.27529685e-01]\n",
      " [  9.41548506e-01   5.84514941e-02]\n",
      " [  9.68103493e-01   3.18965074e-02]\n",
      " [  9.72104652e-01   2.78953476e-02]\n",
      " [  9.99899362e-01   1.00637849e-04]\n",
      " [  9.44155988e-01   5.58440124e-02]\n",
      " [  9.45490459e-01   5.45095412e-02]\n",
      " [  9.77286823e-01   2.27131766e-02]\n",
      " [  9.65986600e-01   3.40134002e-02]\n",
      " [  9.39576365e-01   6.04236353e-02]\n",
      " [  8.59454509e-01   1.40545491e-01]\n",
      " [  9.97199600e-01   2.80039959e-03]\n",
      " [  9.95466470e-01   4.53352967e-03]\n",
      " [  9.87808196e-01   1.21918045e-02]]\n"
     ]
    }
   ],
   "source": [
    "test_m = LogisticRegression()\n",
    "test_m.fit(train_tfidf1,train_y[:,0])\n",
    "res = test_m.predict_proba(train_tfidf1)\n",
    "print(res[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.11637841408 0.101470700629\n",
      "value 5073.67347141\n",
      "1 0.0268814841569 0.0235481118326\n",
      "value 527.776488528\n",
      "2 0.0654412597451 0.0551604984025\n",
      "value 2797.97919431\n",
      "3 0.0116117976142 0.00877895441786\n",
      "value 147.773767381\n",
      "4 0.0780919918992 0.0672385638957\n",
      "value 2626.93713451\n",
      "5 0.0268349189501 0.0237007081884\n",
      "value 462.355246289\n",
      "===========this fold done\n",
      "0 0.115710924201 0.101490724417\n",
      "value 10089.3685007\n",
      "1 0.0271496944531 0.023369197004\n",
      "value 1046.27653183\n",
      "2 0.064373301468 0.0564090474947\n",
      "value 5553.39412903\n",
      "3 0.0104784711549 0.00880192538104\n",
      "value 308.332413507\n",
      "4 0.078593140831 0.0675666935586\n",
      "value 5177.39871435\n",
      "5 0.0267509200719 0.0233423897831\n",
      "value 930.882672714\n",
      "===========this fold done\n",
      "0 0.115965060406 0.101505392757\n",
      "value 15105.6093417\n",
      "1 0.0272824824149 0.0232743753467\n",
      "value 1567.99001146\n",
      "2 0.0646862020847 0.0560259446838\n",
      "value 8315.94218415\n",
      "3 0.00986511031698 0.00923503781117\n",
      "value 463.357855318\n",
      "4 0.0769433286852 0.0679915506206\n",
      "value 7749.74417713\n",
      "5 0.0285649653593 0.0229594146864\n",
      "value 1370.07957545\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def gen_base_lr_feat(train_x,train_y,test_x,fold_cnt=3,rnd=1):\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=False, random_state=233*rnd)\n",
    "    train_pred, test_pred = np.zeros((159571,6)),np.zeros((153164,6))\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        \n",
    "        for i in range(6):\n",
    "            model = LogisticRegression(solver='sag')\n",
    "            # train and pred\n",
    "            # fit for i\n",
    "            model.fit(curr_x, curr_y[:,i])\n",
    "            \n",
    "            # prepare for i on this fold\n",
    "            hold_out_pred = model.predict_proba(hold_out_x)\n",
    "            #print(hold_out_pred[:10])\n",
    "            curr_train_pred = model.predict_proba(curr_x)\n",
    "            print(i,log_loss(hold_out_y[:,i],hold_out_pred),log_loss(curr_y[:,i],curr_train_pred))\n",
    "            train_pred[test_index,i] = list(hold_out_pred[:,1].flatten())\n",
    "            print('value', np.sum(train_pred[:,i]))\n",
    "            \n",
    "            # prepare test\n",
    "            y_test = model.predict_proba(test_x)[:,1]\n",
    "            test_pred[:,i] += y_test\n",
    "        print('===========this fold done')\n",
    "    test_pred = test_pred / fold_cnt\n",
    "    #print(train_pred[:10])\n",
    "    return [train_pred, test_pred]\n",
    "\n",
    "with open('../features/lr_feat1.pkl','wb') as fout:\n",
    "    lr_feat1 = gen_base_lr_feat(train_tfidf1,train_y,test_tfidf1,3,rnd=3)\n",
    "    pickle.dump(lr_feat1,fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (159571, 20000)\n",
      "<class 'scipy.sparse.csr.csr_matrix'> (159571, 35000)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del tf_vec2,tf_vec1,svd_obj\n",
    "except:\n",
    "    pass\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "print(type(train_tfidf2),train_tfidf2.shape)\n",
    "comb_train = csr_matrix(hstack((train_tfidf2,train_tfidf1)))\n",
    "print(type(comb_train),comb_train.shape)\n",
    "comb_test = csr_matrix(hstack((test_tfidf2,test_tfidf1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.102239095102 0.0800917061043\n",
      "value 5059.15848823\n",
      "1 0.0246358045399 0.0192438107933\n",
      "value 524.575923679\n",
      "2 0.0563597855779 0.0418893867255\n",
      "value 2785.90493243\n",
      "3 0.0102722342089 0.00660976936988\n",
      "value 145.555880004\n",
      "4 0.0701651831552 0.0548051232883\n",
      "value 2612.02234374\n",
      "5 0.023418342449 0.017993678117\n",
      "value 459.831726417\n",
      "===========this fold done\n",
      "0 0.101350251021 0.0804011873994\n",
      "value 10034.6520956\n",
      "1 0.0252152057843 0.0189389976528\n",
      "value 1038.586226\n",
      "2 0.0550991442584 0.0432158878634\n",
      "value 5504.46980357\n",
      "3 0.00934594512366 0.00666309066274\n",
      "value 301.799106406\n",
      "4 0.0714712989318 0.0546115190144\n",
      "value 5141.74630297\n",
      "5 0.0238734233266 0.0175308764241\n",
      "value 914.550030731\n",
      "===========this fold done\n",
      "0 0.101944315215 0.0801712996994\n",
      "value 15042.1865961\n",
      "1 0.0252180298612 0.0188807253836\n",
      "value 1550.77476294\n",
      "2 0.0557122351597 0.0427630890005\n",
      "value 8252.99794711\n",
      "3 0.00871845630187 0.00707120488699\n",
      "value 447.497172205\n",
      "4 0.0697444725026 0.0550089569535\n",
      "value 7691.56770793\n",
      "5 0.0247529883182 0.0175928125275\n",
      "value 1344.11624097\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "with open('../features/lr_feat2.pkl','wb') as fout:\n",
    "    lr_feat2 = gen_base_lr_feat(comb_train,\n",
    "                                train_y,\n",
    "                                comb_test,3,rnd=11)\n",
    "    pickle.dump(lr_feat2,fout)\n",
    "\n",
    "# pre first fold\n",
    "# 0 0.102241368889 0.0801105597102\n",
    "# value 5060.86889559\n",
    "# 1 0.0246173591039 0.0192587631549\n",
    "# value 526.726637916\n",
    "# 2 0.056389939991 0.0419326132626\n",
    "# value 2788.22846853\n",
    "# 3 0.0102994295764 0.00665408777849\n",
    "# value 148.649550485\n",
    "# 4 0.0701977896968 0.0548491407929\n",
    "# value 2614.47061102\n",
    "# 5 0.0234527531648 0.0180436061952\n",
    "# value 462.585903392\n",
    "# ===========this fold done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.135064637786 0.119426880993\n",
      "1 0.0280498515944 0.022540605607\n",
      "2 0.0822088496144 0.070409846418\n",
      "3 0.0174418668927 0.0114750738812\n",
      "4 0.0859010193469 0.0748272828438\n",
      "5 0.0292018964185 0.0244956319078\n",
      "===========this fold done\n",
      "0 0.136402005569 0.119277291188\n",
      "1 0.0278692392234 0.0225375090818\n",
      "2 0.0831849543181 0.0708722878025\n",
      "3 0.0140445220646 0.0120016718168\n",
      "4 0.0884407651275 0.0742108440618\n",
      "5 0.0303573563701 0.0239013261819\n",
      "===========this fold done\n",
      "0 0.135258956974 0.119395227808\n",
      "1 0.0278011896406 0.0227454464303\n",
      "2 0.0829899448268 0.0708068473162\n",
      "3 0.0142391699087 0.0119526680429\n",
      "4 0.087647809208 0.0748190278716\n",
      "5 0.0322763447175 0.0235071268866\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def gen_base_mnb_feat(train_x,train_y,test_x,fold_cnt=3,rnd=1):\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=False, random_state=233*rnd)\n",
    "    train_pred, test_pred = np.zeros((159571,6)),np.zeros((153164,6))\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        \n",
    "        for i in range(6):\n",
    "            model = MultinomialNB(alpha=0.2)\n",
    "            # train and pred\n",
    "            # fit for i\n",
    "            model.fit(curr_x, curr_y[:,i])\n",
    "            \n",
    "            # prepare for i on this fold\n",
    "            hold_out_pred = model.predict_proba(hold_out_x)\n",
    "            curr_train_pred = model.predict_proba(curr_x)\n",
    "            print(i,log_loss(hold_out_y[:,i],hold_out_pred),log_loss(curr_y[:,i],curr_train_pred))\n",
    "            train_pred[test_index,i] = hold_out_pred[:,1]\n",
    "            \n",
    "            # prepare test\n",
    "            y_test = model.predict_proba(test_x)[:,1]\n",
    "            test_pred[:,i] += y_test\n",
    "        print('===========this fold done')\n",
    "    test_pred = test_pred / fold_cnt\n",
    "    #print(train_pred[:10])\n",
    "    return [train_pred, test_pred]\n",
    "\n",
    "with open('../features/mnb_feat1.pkl','wb') as fout:\n",
    "    _feat1 = gen_base_mnb_feat(train_tfidf1,train_y,test_tfidf1,3)\n",
    "    pickle.dump(_feat1,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.186172501784 0.17796216859\n",
      "1 0.138356732746 0.139951829086\n",
      "2 0.156714015863 0.143592378619\n",
      "3 0.0372164529446 0.0324088537377\n",
      "4 0.180579797164 0.167767305069\n",
      "5 0.121608716466 0.117026055627\n",
      "===========this fold done\n",
      "0 0.19673424959 0.176980401368\n",
      "1 0.152391556595 0.138566231187\n",
      "2 0.149583943395 0.143122222898\n",
      "3 0.0420097037746 0.0370923417515\n",
      "4 0.176807723136 0.165516545156\n",
      "5 0.1301960023 0.11808540472\n",
      "===========this fold done\n",
      "0 0.196710879649 0.178708104766\n",
      "1 0.141026969453 0.14040481386\n",
      "2 0.158906866955 0.144656850901\n",
      "3 0.0454890042183 0.0409103477265\n",
      "4 0.181096771759 0.16944895783\n",
      "5 0.117908591271 0.112924617458\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "with open('../features/mnb_feat2.pkl','wb') as fout:\n",
    "    _feat2 = gen_base_mnb_feat(comb_train,\n",
    "                                train_y,\n",
    "                                comb_test,3,rnd=29)\n",
    "    pickle.dump(_feat2,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
