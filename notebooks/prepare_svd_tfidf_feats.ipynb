{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import re\n",
    "  \n",
    "\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values\n",
    "train['comment_text'] = train['comment_text'].fillna('nan')\n",
    "test['comment_text'] = test['comment_text'].fillna('nan')\n",
    "print('load done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 15000)\n"
     ]
    }
   ],
   "source": [
    "tf_vec1 = TfidfVectorizer(sublinear_tf=True,\n",
    "                            strip_accents='unicode',\n",
    "                            analyzer='word',\n",
    "                            token_pattern=r'\\w{1,}',\n",
    "                            ngram_range=(1, 1),\n",
    "                            max_features=15000)\n",
    "train_tfidf1 = tf_vec1.fit_transform(train['comment_text'].values)\n",
    "test_tfidf1 = tf_vec1.transform(test['comment_text'].values)\n",
    "\n",
    "print(train_tfidf1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (159571, 30)\n",
      "dump done\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "n_comp = 30\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "train_svd1 = svd_obj.fit_transform(train_tfidf1)\n",
    "test_svd1 = svd_obj.transform(test_tfidf1)\n",
    "\n",
    "print(type(train_svd1),train_svd1.shape)\n",
    "with open('../features/tfidf_feat1.pkl','wb') as fout:\n",
    "    pickle.dump([train_svd1,test_svd1],fout)\n",
    "print('dump done')\n",
    "#simple_eval(train_svd1,train_y,XGBClassifier)\n",
    "print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_eval(train_tfidf1,train_y,LogisticRegression)\n",
    "#print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 20000)\n"
     ]
    }
   ],
   "source": [
    "tf_vec2 = TfidfVectorizer(sublinear_tf=True,\n",
    "                        strip_accents='unicode',\n",
    "                        analyzer='char',\n",
    "                        ngram_range=(1, 5),\n",
    "                        max_features=20000\n",
    "                         )\n",
    "train_tfidf2 = tf_vec2.fit_transform(train['comment_text'].values)\n",
    "test_tfidf2 = tf_vec2.transform(test['comment_text'].values)\n",
    "print(train_tfidf2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (159571, 30)\n",
      "dump done\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "train_svd2 = svd_obj.fit_transform(train_tfidf2)\n",
    "test_svd2 = svd_obj.transform(test_tfidf2)\n",
    "\n",
    "print(type(train_svd2),train_svd2.shape)\n",
    "with open('../features/tfidf_feat2.pkl','wb') as fout:\n",
    "    pickle.dump([train_svd2,test_svd2],fout)\n",
    "print('dump done')\n",
    "#simple_eval(train_svd2,train_y,XGBClassifier)\n",
    "print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.93791465e-01   6.20853525e-03]\n",
      " [  9.80035544e-01   1.99644562e-02]\n",
      " [  9.78047041e-01   2.19529591e-02]\n",
      " [  9.98319365e-01   1.68063457e-03]\n",
      " [  9.29023406e-01   7.09765939e-02]\n",
      " [  9.93445038e-01   6.55496179e-03]\n",
      " [  7.24703146e-02   9.27529685e-01]\n",
      " [  9.41548506e-01   5.84514941e-02]\n",
      " [  9.68103493e-01   3.18965074e-02]\n",
      " [  9.72104652e-01   2.78953476e-02]\n",
      " [  9.99899362e-01   1.00637849e-04]\n",
      " [  9.44155988e-01   5.58440124e-02]\n",
      " [  9.45490459e-01   5.45095412e-02]\n",
      " [  9.77286823e-01   2.27131766e-02]\n",
      " [  9.65986600e-01   3.40134002e-02]\n",
      " [  9.39576365e-01   6.04236353e-02]\n",
      " [  8.59454509e-01   1.40545491e-01]\n",
      " [  9.97199600e-01   2.80039959e-03]\n",
      " [  9.95466470e-01   4.53352967e-03]\n",
      " [  9.87808196e-01   1.21918045e-02]]\n"
     ]
    }
   ],
   "source": [
    "test_m = LogisticRegression()\n",
    "test_m.fit(train_tfidf1,train_y[:,0])\n",
    "res = test_m.predict_proba(train_tfidf1)\n",
    "print(res[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.116384088302 0.101482820947\n",
      "value 5075.21203005\n",
      "1 0.0268826085073 0.0235620319907\n",
      "value 530.08836994\n",
      "2 0.0654563051945 0.0551811376693\n",
      "value 2799.9523342\n",
      "3 0.011626509413 0.00880569132737\n",
      "value 150.85418302\n",
      "4 0.0781025411574 0.0672601955517\n",
      "value 2628.96653389\n",
      "5 0.0268439722249 0.0237216332192\n",
      "value 464.804110171\n",
      "===========this fold done\n",
      "0 0.11572313302 0.10150259587\n",
      "value 10092.4437629\n",
      "1 0.0271613106961 0.0233816389652\n",
      "value 1051.08754105\n",
      "2 0.0643928970435 0.0564350109428\n",
      "value 5557.40135751\n",
      "3 0.0105003678193 0.00883133575316\n",
      "value 314.530206973\n",
      "4 0.0786079311691 0.0675855178469\n",
      "value 5181.41206089\n",
      "5 0.0267731474314 0.0233628307555\n",
      "value 935.816747437\n",
      "===========this fold done\n",
      "0 0.11597592706 0.10152805768\n",
      "value 15110.1583416\n",
      "1 0.027288950596 0.0232874378838\n",
      "value 1575.20882431\n",
      "2 0.0646987787613 0.056046521607\n",
      "value 8321.9239402\n",
      "3 0.00989523203243 0.00926211488746\n",
      "value 472.52580499\n",
      "4 0.0769600187191 0.0680101814068\n",
      "value 7755.71244678\n",
      "5 0.02857696181 0.0229811719919\n",
      "value 1377.45621541\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def gen_base_lr_feat(train_x,train_y,test_x,fold_cnt=3,rnd=1):\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=False, random_state=233*rnd)\n",
    "    train_pred, test_pred = np.zeros((159571,6)),np.zeros((153164,6))\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        \n",
    "        for i in range(6):\n",
    "            model = LogisticRegression()\n",
    "            # train and pred\n",
    "            # fit for i\n",
    "            model.fit(curr_x, curr_y[:,i])\n",
    "            \n",
    "            # prepare for i on this fold\n",
    "            hold_out_pred = model.predict_proba(hold_out_x)\n",
    "            #print(hold_out_pred[:10])\n",
    "            curr_train_pred = model.predict_proba(curr_x)\n",
    "            print(i,log_loss(hold_out_y[:,i],hold_out_pred),log_loss(curr_y[:,i],curr_train_pred))\n",
    "            train_pred[test_index,i] = list(hold_out_pred[:,1].flatten())\n",
    "            print('value', np.sum(train_pred[:,i]))\n",
    "            \n",
    "            # prepare test\n",
    "            y_test = model.predict_proba(test_x)[:,1]\n",
    "            test_pred[:,i] += y_test\n",
    "        print('===========this fold done')\n",
    "    test_pred = test_pred / fold_cnt\n",
    "    #print(train_pred[:10])\n",
    "    return [train_pred, test_pred]\n",
    "\n",
    "with open('../features/lr_feat1.pkl','wb') as fout:\n",
    "    lr_feat1 = gen_base_lr_feat(train_tfidf1,train_y,test_tfidf1,3,rnd=3)\n",
    "    pickle.dump(lr_feat1,fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (159571, 20000)\n",
      "<class 'scipy.sparse.csr.csr_matrix'> (159571, 35000)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del tf_vec2,tf_vec1,svd_obj\n",
    "except:\n",
    "    pass\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "print(type(train_tfidf2),train_tfidf2.shape)\n",
    "comb_train = csr_matrix(hstack((train_tfidf2,train_tfidf1)))\n",
    "print(type(comb_train),comb_train.shape)\n",
    "comb_test = csr_matrix(hstack((test_tfidf2,test_tfidf1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.102241368889 0.0801105597102\n",
      "value 5060.86889559\n",
      "1 0.0246173591039 0.0192587631549\n",
      "value 526.726637916\n",
      "2 0.056389939991 0.0419326132626\n",
      "value 2788.22846853\n",
      "3 0.0102994295764 0.00665408777849\n",
      "value 148.649550485\n",
      "4 0.0701977896968 0.0548491407929\n",
      "value 2614.47061102\n",
      "5 0.0234527531648 0.0180436061952\n",
      "value 462.585903392\n",
      "===========this fold done\n",
      "0 0.10136985833 0.080415887666\n",
      "value 10038.1756267\n",
      "1 0.0252233257442 0.018949473646\n",
      "value 1043.39458345\n",
      "2 0.0551359317843 0.0432470185548\n",
      "value 5509.11006496\n",
      "3 0.00938403602261 0.00670760995522\n",
      "value 308.202739151\n",
      "4 0.0715143483368 0.0546542406887\n",
      "value 5146.86209884\n",
      "5 0.0239251877493 0.0175806382771\n",
      "value 920.281007185\n",
      "===========this fold done\n",
      "0 0.10195112328 0.0801885522765\n",
      "value 15047.5779806\n",
      "1 0.0252177777601 0.0188944735427\n",
      "value 1558.15478185\n",
      "2 0.0557356525351 0.0428063797512\n",
      "value 8260.09545158\n",
      "3 0.00875962543946 0.00711652538281\n",
      "value 457.050587866\n",
      "4 0.0697786563356 0.0550544375666\n",
      "value 7699.14804546\n",
      "5 0.0247902528441 0.017645077146\n",
      "value 1352.7800417\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "with open('../features/lr_feat2.pkl','wb') as fout:\n",
    "    lr_feat2 = gen_base_lr_feat(comb_train,\n",
    "                                train_y,\n",
    "                                comb_test,3,rnd=11)\n",
    "    pickle.dump(lr_feat2,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.135064637786 0.119426880993\n",
      "1 0.0280498515944 0.022540605607\n",
      "2 0.0822088496144 0.070409846418\n",
      "3 0.0174418668927 0.0114750738812\n",
      "4 0.0859010193469 0.0748272828438\n",
      "5 0.0292018964185 0.0244956319078\n",
      "===========this fold done\n",
      "0 0.136402005569 0.119277291188\n",
      "1 0.0278692392234 0.0225375090818\n",
      "2 0.0831849543181 0.0708722878025\n",
      "3 0.0140445220646 0.0120016718168\n",
      "4 0.0884407651275 0.0742108440618\n",
      "5 0.0303573563701 0.0239013261819\n",
      "===========this fold done\n",
      "0 0.135258956974 0.119395227808\n",
      "1 0.0278011896406 0.0227454464303\n",
      "2 0.0829899448268 0.0708068473162\n",
      "3 0.0142391699087 0.0119526680429\n",
      "4 0.087647809208 0.0748190278716\n",
      "5 0.0322763447175 0.0235071268866\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def gen_base_mnb_feat(train_x,train_y,test_x,fold_cnt=3,rnd=1):\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=False, random_state=233*rnd)\n",
    "    train_pred, test_pred = np.zeros((159571,6)),np.zeros((153164,6))\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        \n",
    "        for i in range(6):\n",
    "            model = MultinomialNB(alpha=0.2)\n",
    "            # train and pred\n",
    "            # fit for i\n",
    "            model.fit(curr_x, curr_y[:,i])\n",
    "            \n",
    "            # prepare for i on this fold\n",
    "            hold_out_pred = model.predict_proba(hold_out_x)\n",
    "            curr_train_pred = model.predict_proba(curr_x)\n",
    "            print(i,log_loss(hold_out_y[:,i],hold_out_pred),log_loss(curr_y[:,i],curr_train_pred))\n",
    "            train_pred[test_index,i] = hold_out_pred[:,1]\n",
    "            \n",
    "            # prepare test\n",
    "            y_test = model.predict_proba(test_x)[:,1]\n",
    "            test_pred[:,i] += y_test\n",
    "        print('===========this fold done')\n",
    "    test_pred = test_pred / fold_cnt\n",
    "    #print(train_pred[:10])\n",
    "    return [train_pred, test_pred]\n",
    "\n",
    "with open('../features/mnb_feat1.pkl','wb') as fout:\n",
    "    _feat1 = gen_base_mnb_feat(train_tfidf1,train_y,test_tfidf1,3)\n",
    "    pickle.dump(_feat1,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.186172501784 0.17796216859\n",
      "1 0.138356732746 0.139951829086\n",
      "2 0.156714015863 0.143592378619\n",
      "3 0.0372164529446 0.0324088537377\n",
      "4 0.180579797164 0.167767305069\n",
      "5 0.121608716466 0.117026055627\n",
      "===========this fold done\n",
      "0 0.19673424959 0.176980401368\n",
      "1 0.152391556595 0.138566231187\n",
      "2 0.149583943395 0.143122222898\n",
      "3 0.0420097037746 0.0370923417515\n",
      "4 0.176807723136 0.165516545156\n",
      "5 0.1301960023 0.11808540472\n",
      "===========this fold done\n",
      "0 0.196710879649 0.178708104766\n",
      "1 0.141026969453 0.14040481386\n",
      "2 0.158906866955 0.144656850901\n",
      "3 0.0454890042183 0.0409103477265\n",
      "4 0.181096771759 0.16944895783\n",
      "5 0.117908591271 0.112924617458\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "with open('../features/mnb_feat2.pkl','wb') as fout:\n",
    "    _feat2 = gen_base_mnb_feat(comb_train,\n",
    "                                train_y,\n",
    "                                comb_test,3,rnd=29)\n",
    "    pickle.dump(_feat2,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
