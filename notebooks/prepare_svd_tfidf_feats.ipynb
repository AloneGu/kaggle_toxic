{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import re\n",
    "  \n",
    "\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "test = pd.read_csv(\"../input/test.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values\n",
    "train['comment_text'] = train['comment_text'].fillna('nan')\n",
    "test['comment_text'] = test['comment_text'].fillna('nan')\n",
    "print('load done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 15000)\n"
     ]
    }
   ],
   "source": [
    "tf_vec1 = TfidfVectorizer(sublinear_tf=True,\n",
    "                            strip_accents='unicode',\n",
    "                            analyzer='word',\n",
    "                            token_pattern=r'\\w{1,}',\n",
    "                            ngram_range=(1, 1),\n",
    "                            max_features=15000)\n",
    "train_tfidf1 = tf_vec1.fit_transform(train['comment_text'].values)\n",
    "test_tfidf1 = tf_vec1.transform(test['comment_text'].values)\n",
    "\n",
    "print(train_tfidf1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (159571, 30)\n",
      "dump done\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "n_comp = 30\n",
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "train_svd1 = svd_obj.fit_transform(train_tfidf1)\n",
    "test_svd1 = svd_obj.transform(test_tfidf1)\n",
    "\n",
    "print(type(train_svd1),train_svd1.shape)\n",
    "with open('../features/tfidf_feat1.pkl','wb') as fout:\n",
    "    pickle.dump([train_svd1,test_svd1],fout)\n",
    "print('dump done')\n",
    "#simple_eval(train_svd1,train_y,XGBClassifier)\n",
    "print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simple_eval(train_tfidf1,train_y,LogisticRegression)\n",
    "#print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 20000)\n"
     ]
    }
   ],
   "source": [
    "tf_vec2 = TfidfVectorizer(sublinear_tf=True,\n",
    "                        strip_accents='unicode',\n",
    "                        analyzer='char',\n",
    "                        ngram_range=(1, 5),\n",
    "                        max_features=20000\n",
    "                         )\n",
    "train_tfidf2 = tf_vec2.fit_transform(train['comment_text'].values)\n",
    "test_tfidf2 = tf_vec2.transform(test['comment_text'].values)\n",
    "print(train_tfidf2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (159571, 30)\n",
      "dump done\n",
      "-----------\n"
     ]
    }
   ],
   "source": [
    "svd_obj = TruncatedSVD(n_components=n_comp, algorithm='arpack')\n",
    "train_svd2 = svd_obj.fit_transform(train_tfidf2)\n",
    "test_svd2 = svd_obj.transform(test_tfidf2)\n",
    "\n",
    "print(type(train_svd2),train_svd2.shape)\n",
    "with open('../features/tfidf_feat2.pkl','wb') as fout:\n",
    "    pickle.dump([train_svd2,test_svd2],fout)\n",
    "print('dump done')\n",
    "#simple_eval(train_svd2,train_y,XGBClassifier)\n",
    "print('-----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.93791465e-01   6.20853525e-03]\n",
      " [  9.80035544e-01   1.99644562e-02]\n",
      " [  9.78047041e-01   2.19529591e-02]\n",
      " [  9.98319365e-01   1.68063457e-03]\n",
      " [  9.29023406e-01   7.09765939e-02]\n",
      " [  9.93445038e-01   6.55496179e-03]\n",
      " [  7.24703146e-02   9.27529685e-01]\n",
      " [  9.41548506e-01   5.84514941e-02]\n",
      " [  9.68103493e-01   3.18965074e-02]\n",
      " [  9.72104652e-01   2.78953476e-02]\n",
      " [  9.99899362e-01   1.00637849e-04]\n",
      " [  9.44155988e-01   5.58440124e-02]\n",
      " [  9.45490459e-01   5.45095412e-02]\n",
      " [  9.77286823e-01   2.27131766e-02]\n",
      " [  9.65986600e-01   3.40134002e-02]\n",
      " [  9.39576365e-01   6.04236353e-02]\n",
      " [  8.59454509e-01   1.40545491e-01]\n",
      " [  9.97199600e-01   2.80039959e-03]\n",
      " [  9.95466470e-01   4.53352967e-03]\n",
      " [  9.87808196e-01   1.21918045e-02]]\n"
     ]
    }
   ],
   "source": [
    "test_m = LogisticRegression()\n",
    "test_m.fit(train_tfidf1,train_y[:,0])\n",
    "res = test_m.predict_proba(train_tfidf1)\n",
    "print(res[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.113500936706 0.0997201092397\n",
      "value 3070.23470695\n",
      "1 0.027854372592 0.0230948716027\n",
      "value 317.312680365\n",
      "2 0.065036301593 0.0542706814096\n",
      "value 1682.08147824\n",
      "3 0.0108139809824 0.00861309387776\n",
      "value 88.9334318053\n",
      "4 0.077999343874 0.0666086895257\n",
      "value 1572.06659916\n",
      "5 0.0264100739872 0.0230796532461\n",
      "value 281.054554301\n",
      "===========this fold done\n",
      "0 0.11439927879 0.099658336191\n",
      "value 6083.80900341\n",
      "1 0.0253598449757 0.0235929350643\n",
      "value 631.932505451\n",
      "2 0.0645951141862 0.0544715772649\n",
      "value 3338.62690625\n",
      "3 0.0115849282023 0.00854300985482\n",
      "value 183.746771638\n",
      "4 0.0777074218487 0.0666025749871\n",
      "value 3120.98202178\n",
      "5 0.0268064066618 0.0229512961132\n",
      "value 550.891430024\n",
      "===========this fold done\n",
      "0 0.112739435006 0.0999176214636\n",
      "value 9095.78106546\n",
      "1 0.0282918074964 0.0229714119392\n",
      "value 933.470925428\n",
      "2 0.0615502443829 0.0554807114092\n",
      "value 5002.63757765\n",
      "3 0.0104156330202 0.00856162549939\n",
      "value 276.584465503\n",
      "4 0.0764465228709 0.0671635609432\n",
      "value 4663.0051079\n",
      "5 0.0249729952424 0.0231745660625\n",
      "value 830.044642046\n",
      "===========this fold done\n",
      "0 0.113641711347 0.0997819002181\n",
      "value 12127.1053563\n",
      "1 0.0272975835999 0.0231192504451\n",
      "value 1257.84282671\n",
      "2 0.0621233108446 0.0551034001407\n",
      "value 6678.30024205\n",
      "3 0.00899459806088 0.00889729022871\n",
      "value 371.966776474\n",
      "4 0.0744922102939 0.0673166892195\n",
      "value 6230.88702096\n",
      "5 0.0273510650805 0.0228156602274\n",
      "value 1113.33774197\n",
      "===========this fold done\n",
      "0 0.113371744082 0.0997382156866\n",
      "value 15122.814018\n",
      "1 0.0261625353251 0.0234265383974\n",
      "value 1568.03545446\n",
      "2 0.0628239380929 0.0550323415677\n",
      "value 8324.29069652\n",
      "3 0.0096726070351 0.00884140716012\n",
      "value 463.550237039\n",
      "4 0.0764366250199 0.067097475645\n",
      "value 7763.51118514\n",
      "5 0.028879555853 0.0225949440858\n",
      "value 1370.71187717\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def gen_base_lr_feat(train_x,train_y,test_x,fold_cnt=3,rnd=1):\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=False, random_state=233*rnd)\n",
    "    train_pred, test_pred = np.zeros((159571,6)),np.zeros((153164,6))\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        \n",
    "        for i in range(6):\n",
    "            model = LogisticRegression(solver='sag')\n",
    "            # train and pred\n",
    "            # fit for i\n",
    "            model.fit(curr_x, curr_y[:,i])\n",
    "            \n",
    "            # prepare for i on this fold\n",
    "            hold_out_pred = model.predict_proba(hold_out_x)\n",
    "            #print(hold_out_pred[:10])\n",
    "            curr_train_pred = model.predict_proba(curr_x)\n",
    "            print(i,log_loss(hold_out_y[:,i],hold_out_pred),log_loss(curr_y[:,i],curr_train_pred))\n",
    "            train_pred[test_index,i] = list(hold_out_pred[:,1].flatten())\n",
    "            print('value', np.sum(train_pred[:,i]))\n",
    "            \n",
    "            # prepare test\n",
    "            y_test = model.predict_proba(test_x)[:,1]\n",
    "            test_pred[:,i] += y_test\n",
    "        print('===========this fold done')\n",
    "    test_pred = test_pred / fold_cnt\n",
    "    #print(train_pred[:10])\n",
    "    return [train_pred, test_pred]\n",
    "\n",
    "with open('../features/lr_feat1.pkl','wb') as fout:\n",
    "    lr_feat1 = gen_base_lr_feat(train_tfidf1,train_y,test_tfidf1,5,rnd=3)\n",
    "    pickle.dump(lr_feat1,fout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse.csr.csr_matrix'> (159571, 20000)\n",
      "<class 'scipy.sparse.csr.csr_matrix'> (159571, 35000)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del tf_vec2,tf_vec1,svd_obj\n",
    "except:\n",
    "    pass\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import csr_matrix\n",
    "print(type(train_tfidf2),train_tfidf2.shape)\n",
    "comb_train = csr_matrix(hstack((train_tfidf2,train_tfidf1)))\n",
    "print(type(comb_train),comb_train.shape)\n",
    "comb_test = csr_matrix(hstack((test_tfidf2,test_tfidf1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.100909333581 0.0792918252609\n",
      "value 3055.79384114\n",
      "1 0.0256903892666 0.0189550739087\n",
      "value 311.623999626\n",
      "2 0.0567181414043 0.0416830494684\n",
      "value 1673.41401602\n",
      "3 0.00973549825632 0.00655675910027\n",
      "value 85.9183936085\n",
      "4 0.0710422582748 0.0545085947835\n",
      "value 1560.10435426\n",
      "5 0.0230226349176 0.0176918303664\n",
      "value 279.129508035\n",
      "===========this fold done\n",
      "0 0.0995092612664 0.0797156589489\n",
      "value 6067.76645727\n",
      "1 0.0234275681011 0.0193487649282\n",
      "value 626.256200702\n",
      "2 0.0557114316353 0.0419808369082\n",
      "value 3322.6244022\n",
      "3 0.0100271951409 0.00654935882583\n",
      "value 182.565448673\n",
      "4 0.0700607930895 0.0545855634658\n",
      "value 3103.41796912\n",
      "5 0.0236178503061 0.017558769134\n",
      "value 547.272097833\n",
      "===========this fold done\n",
      "0 0.0992456314304 0.0796425627958\n",
      "value 9060.08304168\n",
      "1 0.0262452664987 0.0188093657365\n",
      "value 927.816878596\n",
      "2 0.0525593342791 0.0429490025332\n",
      "value 4966.84040274\n",
      "3 0.00931181420069 0.00655116696845\n",
      "value 272.682226478\n",
      "4 0.0695901096694 0.0548669630779\n",
      "value 4634.37512834\n",
      "5 0.0224933798031 0.0176295318077\n",
      "value 818.027040023\n",
      "===========this fold done\n",
      "0 0.0998843314895 0.0796770424201\n",
      "value 12079.3454964\n",
      "1 0.0254914112621 0.0188453834163\n",
      "value 1246.23517134\n",
      "2 0.0544878084514 0.0423000171229\n",
      "value 6623.6549447\n",
      "3 0.00806123365987 0.00678279314796\n",
      "value 362.724390751\n",
      "4 0.0684687720147 0.0548833570726\n",
      "value 6191.31812176\n",
      "5 0.0240105086399 0.0174739558429\n",
      "value 1094.38739015\n",
      "===========this fold done\n",
      "0 0.100154566176 0.0794014877946\n",
      "value 15066.5600118\n",
      "1 0.0242146005602 0.0191954865943\n",
      "value 1551.17666706\n",
      "2 0.0537634965572 0.0425951961907\n",
      "value 8266.32877754\n",
      "3 0.00840348250014 0.00684725432545\n",
      "value 450.819034363\n",
      "4 0.0695938462244 0.0547945247547\n",
      "value 7710.70691569\n",
      "5 0.0250151197468 0.0174282142699\n",
      "value 1348.05521858\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "with open('../features/lr_feat2.pkl','wb') as fout:\n",
    "    lr_feat2 = gen_base_lr_feat(comb_train,\n",
    "                                train_y,\n",
    "                                comb_test,5,rnd=11)\n",
    "    pickle.dump(lr_feat2,fout)\n",
    "\n",
    "# pre first fold\n",
    "# 0 0.102241368889 0.0801105597102\n",
    "# value 5060.86889559\n",
    "# 1 0.0246173591039 0.0192587631549\n",
    "# value 526.726637916\n",
    "# 2 0.056389939991 0.0419326132626\n",
    "# value 2788.22846853\n",
    "# 3 0.0102994295764 0.00665408777849\n",
    "# value 148.649550485\n",
    "# 4 0.0701977896968 0.0548491407929\n",
    "# value 2614.47061102\n",
    "# 5 0.0234527531648 0.0180436061952\n",
    "# value 462.585903392\n",
    "# ===========this fold done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.135560194604 0.120561737325\n",
      "1 0.0285371306379 0.0225454062507\n",
      "2 0.0828095122556 0.0713272756591\n",
      "3 0.0159182001159 0.0111174353636\n",
      "4 0.0868404344073 0.075368922452\n",
      "5 0.0284919697058 0.0241334099091\n",
      "===========this fold done\n",
      "0 0.134681292656 0.120682101916\n",
      "1 0.0262086478194 0.023074774629\n",
      "2 0.082826070923 0.0712227363663\n",
      "3 0.0160457490121 0.0111798574498\n",
      "4 0.086302657742 0.0753838108457\n",
      "5 0.0302236033733 0.0239395433961\n",
      "===========this fold done\n",
      "0 0.134863559081 0.120979069189\n",
      "1 0.0300368652994 0.0223379177587\n",
      "2 0.0820201599427 0.071903712272\n",
      "3 0.0132530406987 0.0113145750311\n",
      "4 0.0876037696284 0.0753846702295\n",
      "5 0.0284297870312 0.0240878173892\n",
      "===========this fold done\n",
      "0 0.136029159734 0.120535369571\n",
      "1 0.0273814556392 0.0227063001572\n",
      "2 0.0838548806382 0.0713355021028\n",
      "3 0.0132462985369 0.0113342075519\n",
      "4 0.0859986921885 0.0757095382946\n",
      "5 0.03100268325 0.0237016180376\n",
      "===========this fold done\n",
      "0 0.134140192152 0.120918320737\n",
      "1 0.0263620168356 0.0231601929502\n",
      "2 0.0807105921087 0.0720705335873\n",
      "3 0.0133729149718 0.0114124332105\n",
      "4 0.0879463804368 0.075507778038\n",
      "5 0.0323003703458 0.0235720425882\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import Na\n",
    "def gen_base_mnb_feat(train_x,train_y,test_x,fold_cnt=3,rnd=1):\n",
    "    kf = KFold(n_splits=fold_cnt, shuffle=False, random_state=233*rnd)\n",
    "    train_pred, test_pred = np.zeros((159571,6)),np.zeros((153164,6))\n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        \n",
    "        for i in range(6):\n",
    "            model = MultinomialNB(alpha=0.2)\n",
    "            # train and pred\n",
    "            # fit for i\n",
    "            model.fit(curr_x, curr_y[:,i])\n",
    "            \n",
    "            # prepare for i on this fold\n",
    "            hold_out_pred = model.predict_proba(hold_out_x)\n",
    "            curr_train_pred = model.predict_proba(curr_x)\n",
    "            print(i,log_loss(hold_out_y[:,i],hold_out_pred),log_loss(curr_y[:,i],curr_train_pred))\n",
    "            train_pred[test_index,i] = hold_out_pred[:,1]\n",
    "            \n",
    "            # prepare test\n",
    "            y_test = model.predict_proba(test_x)[:,1]\n",
    "            test_pred[:,i] += y_test\n",
    "        print('===========this fold done')\n",
    "    test_pred = test_pred / fold_cnt\n",
    "    #print(train_pred[:10])\n",
    "    return [train_pred, test_pred]\n",
    "\n",
    "with open('../features/mnb_feat1.pkl','wb') as fout:\n",
    "    _feat1 = gen_base_mnb_feat(train_tfidf1,train_y,test_tfidf1,5)\n",
    "    pickle.dump(_feat1,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.190397770417 0.180842323448\n",
      "1 0.147501960311 0.148863045449\n",
      "2 0.160540684057 0.147071636004\n",
      "3 0.0482392675088 0.0449910588575\n",
      "4 0.182377847089 0.171305140377\n",
      "5 0.130924882777 0.125953991006\n",
      "===========this fold done\n",
      "0 0.190274425559 0.180812565856\n",
      "1 0.155720714552 0.149726896419\n",
      "2 0.157758170819 0.146289166808\n",
      "3 0.0445484575551 0.0407295580431\n",
      "4 0.181941901975 0.170843030741\n",
      "5 0.13309407156 0.127351070285\n",
      "===========this fold done\n",
      "0 0.196184953701 0.181175591931\n",
      "1 0.156670586422 0.147950345781\n",
      "2 0.149266858669 0.148003993169\n",
      "3 0.0516411361469 0.0457793850572\n",
      "4 0.179008681533 0.170796406869\n",
      "5 0.137809170834 0.127432185804\n",
      "===========this fold done\n",
      "0 0.201146962246 0.180772669862\n",
      "1 0.154966644169 0.147148695958\n",
      "2 0.163447989425 0.146932593976\n",
      "3 0.0553869180086 0.0484173499772\n",
      "4 0.184527404689 0.171530667595\n",
      "5 0.135948761598 0.125357156666\n",
      "===========this fold done\n",
      "0 0.193657966576 0.181765482802\n",
      "1 0.150211085784 0.151211454609\n",
      "2 0.155403110581 0.148273353903\n",
      "3 0.0476132332553 0.0464999292976\n",
      "4 0.181570932743 0.17260405909\n",
      "5 0.124960369999 0.124681675638\n",
      "===========this fold done\n"
     ]
    }
   ],
   "source": [
    "with open('../features/mnb_feat2.pkl','wb') as fout:\n",
    "    _feat2 = gen_base_mnb_feat(comb_train,\n",
    "                                train_y,\n",
    "                                comb_test,5,rnd=29)\n",
    "    pickle.dump(_feat2,fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
