{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaning ...\n",
      " Part 1/2 of vectorizing ...\n",
      " Part 2/2 of vectorizing ...\n",
      "(159571, 100000) (153164, 100000)\n",
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "# ref: https://www.kaggle.com/tilii7/tuned-logreg-oof-files\n",
    "# https://www.kaggle.com/peterhurford/lightgbm-with-select-k-best-on-tfidf/code\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.metrics import log_loss, matthews_corrcoef, roc_auc_score\n",
    "\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train = pd.read_csv('../input/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../input/test.csv').fillna(' ')\n",
    "tr_ids = train[['id']]\n",
    "train[class_names] = train[class_names].astype(np.int8)\n",
    "target = train[class_names]\n",
    "\n",
    "print(' Cleaning ...')\n",
    "# PREPROCESSING PART\n",
    "repl = {\n",
    "    \"yay!\": \" good \",\n",
    "    \"yay\": \" good \",\n",
    "    \"yaay\": \" good \",\n",
    "    \"yaaay\": \" good \",\n",
    "    \"yaaaay\": \" good \",\n",
    "    \"yaaaaay\": \" good \",\n",
    "    \":/\": \" bad \",\n",
    "    \":&gt;\": \" sad \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" frown \",\n",
    "    \":(\": \" frown \",\n",
    "    \":s\": \" frown \",\n",
    "    \":-s\": \" frown \",\n",
    "    \"&lt;3\": \" heart \",\n",
    "    \":d\": \" smile \",\n",
    "    \":p\": \" smile \",\n",
    "    \":dd\": \" smile \",\n",
    "    \"8)\": \" smile \",\n",
    "    \":-)\": \" smile \",\n",
    "    \":)\": \" smile \",\n",
    "    \";)\": \" smile \",\n",
    "    \"(-:\": \" smile \",\n",
    "    \"(:\": \" smile \",\n",
    "    \":/\": \" worry \",\n",
    "    \":&gt;\": \" angry \",\n",
    "    \":')\": \" sad \",\n",
    "    \":-(\": \" sad \",\n",
    "    \":(\": \" sad \",\n",
    "    \":s\": \" sad \",\n",
    "    \":-s\": \" sad \",\n",
    "    r\"\\br\\b\": \"are\",\n",
    "    r\"\\bu\\b\": \"you\",\n",
    "    r\"\\bhaha\\b\": \"ha\",\n",
    "    r\"\\bhahaha\\b\": \"ha\",\n",
    "    r\"\\bdon't\\b\": \"do not\",\n",
    "    r\"\\bdoesn't\\b\": \"does not\",\n",
    "    r\"\\bdidn't\\b\": \"did not\",\n",
    "    r\"\\bhasn't\\b\": \"has not\",\n",
    "    r\"\\bhaven't\\b\": \"have not\",\n",
    "    r\"\\bhadn't\\b\": \"had not\",\n",
    "    r\"\\bwon't\\b\": \"will not\",\n",
    "    r\"\\bwouldn't\\b\": \"would not\",\n",
    "    r\"\\bcan't\\b\": \"can not\",\n",
    "    r\"\\bcannot\\b\": \"can not\",\n",
    "    r\"\\bi'm\\b\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"r\": \"are\",\n",
    "    \"u\": \"you\",\n",
    "    \"haha\": \"ha\",\n",
    "    \"hahaha\": \"ha\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"cannot\": \"can not\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"m\": \"am\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"its\": \"it is\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"'s\": \" is\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"weren't\": \"were not\",\n",
    "}\n",
    "\n",
    "keys = [i for i in repl.keys()]\n",
    "\n",
    "new_train_data = []\n",
    "new_test_data = []\n",
    "ltr = train[\"comment_text\"].tolist()\n",
    "lte = test[\"comment_text\"].tolist()\n",
    "for i in ltr:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_train_data.append(xx)\n",
    "for i in lte:\n",
    "    arr = str(i).split()\n",
    "    xx = \"\"\n",
    "    for j in arr:\n",
    "        j = str(j).lower()\n",
    "        if j[:4] == 'http' or j[:3] == 'www':\n",
    "            continue\n",
    "        if j in keys:\n",
    "            # print(\"inn\")\n",
    "            j = repl[j]\n",
    "        xx += j + \" \"\n",
    "    new_test_data.append(xx)\n",
    "train[\"new_comment_text\"] = new_train_data\n",
    "test[\"new_comment_text\"] = new_test_data\n",
    "\n",
    "trate = train[\"new_comment_text\"].tolist()\n",
    "tete = test[\"new_comment_text\"].tolist()\n",
    "for i, c in enumerate(trate):\n",
    "    trate[i] = re.sub('[^a-zA-Z ?!]+', '', str(trate[i]).lower())\n",
    "for i, c in enumerate(tete):\n",
    "    tete[i] = re.sub('[^a-zA-Z ?!]+', '', tete[i])\n",
    "train[\"comment_text\"] = trate\n",
    "test[\"comment_text\"] = tete\n",
    "del trate, tete\n",
    "train.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "test.drop([\"new_comment_text\"], axis=1, inplace=True)\n",
    "\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "train.head()\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "test.head()\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "print(' Part 1/2 of vectorizing ...')\n",
    "word_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='word',\n",
    "    token_pattern=r'\\w{1,}',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50000)\n",
    "word_vectorizer.fit(all_text)\n",
    "train_word_features = word_vectorizer.transform(train_text)\n",
    "test_word_features = word_vectorizer.transform(test_text)\n",
    "\n",
    "print(' Part 2/2 of vectorizing ...')\n",
    "char_vectorizer = TfidfVectorizer(\n",
    "    sublinear_tf=True,\n",
    "    strip_accents='unicode',\n",
    "    analyzer='char',\n",
    "    stop_words='english',\n",
    "    ngram_range=(4, 6),\n",
    "    max_features=50000)\n",
    "char_vectorizer.fit(all_text)\n",
    "train_char_features = char_vectorizer.transform(train_text)\n",
    "test_char_features = char_vectorizer.transform(test_text)\n",
    "\n",
    "train_features = hstack([train_char_features, train_word_features]).tocsr()\n",
    "test_features = hstack([test_char_features, test_word_features]).tocsr()\n",
    "print(train_features.shape, test_features.shape)\n",
    "\n",
    "del all_text\n",
    "del word_vectorizer\n",
    "del char_vectorizer\n",
    "del train_word_features\n",
    "del train_char_features\n",
    "del test_word_features\n",
    "del test_char_features\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "target = target.values\n",
    "print(target[:5])\n",
    "\n",
    "# In[ ]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 24290)\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.974234\tvalid_1's auc: 0.964093\n",
      "[100]\ttraining's auc: 0.98486\tvalid_1's auc: 0.971615\n",
      "[150]\ttraining's auc: 0.989518\tvalid_1's auc: 0.973233\n",
      "[200]\ttraining's auc: 0.992342\tvalid_1's auc: 0.974292\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.992342\tvalid_1's auc: 0.974292\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "0 0.10393170717380798 0.069876786500053\n",
      "0.9742921882489761 0.9923424838704675\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.973901\tvalid_1's auc: 0.966308\n",
      "[100]\ttraining's auc: 0.984587\tvalid_1's auc: 0.974059\n",
      "[150]\ttraining's auc: 0.989236\tvalid_1's auc: 0.975454\n",
      "[200]\ttraining's auc: 0.992137\tvalid_1's auc: 0.976647\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.992137\tvalid_1's auc: 0.976647\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "1 0.09974077392690561 0.07047085976408762\n",
      "0.9766470178985268 0.9921365612281164\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.974326\tvalid_1's auc: 0.96367\n",
      "[100]\ttraining's auc: 0.984875\tvalid_1's auc: 0.972044\n",
      "[150]\ttraining's auc: 0.98951\tvalid_1's auc: 0.973857\n",
      "[200]\ttraining's auc: 0.992416\tvalid_1's auc: 0.974512\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.992416\tvalid_1's auc: 0.974512\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "2 0.10566915777045532 0.06929016216513328\n",
      "0.9745117693165357 0.9924164589199186\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.973846\tvalid_1's auc: 0.964291\n",
      "[100]\ttraining's auc: 0.984706\tvalid_1's auc: 0.972184\n",
      "[150]\ttraining's auc: 0.989271\tvalid_1's auc: 0.97424\n",
      "[200]\ttraining's auc: 0.99218\tvalid_1's auc: 0.975025\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.99218\tvalid_1's auc: 0.975025\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "3 0.10273462965860299 0.07026620569527962\n",
      "0.9750253108606463 0.992180094526638\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.974197\tvalid_1's auc: 0.965012\n",
      "[100]\ttraining's auc: 0.984767\tvalid_1's auc: 0.972705\n",
      "[150]\ttraining's auc: 0.989512\tvalid_1's auc: 0.974679\n",
      "[200]\ttraining's auc: 0.992377\tvalid_1's auc: 0.975575\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.992377\tvalid_1's auc: 0.975575\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "4 0.10261201882081812 0.06999777242700879\n",
      "0.9755752273466746 0.9923766950243654\n",
      "========= toxic\n",
      "(159571, 6358)\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.99476\tvalid_1's auc: 0.98335\n",
      "Early stopping, best iteration is:\n",
      "[77]\ttraining's auc: 0.99674\tvalid_1's auc: 0.984731\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "0 0.02600947441745662 0.014628606521194193\n",
      "0.9847314111821622 0.9967400928235044\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.994258\tvalid_1's auc: 0.989793\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's auc: 0.994013\tvalid_1's auc: 0.989889\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "1 0.02328897808415346 0.018357222009352355\n",
      "0.9898885830214991 0.994012758331223\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.994222\tvalid_1's auc: 0.984067\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.993936\tvalid_1's auc: 0.984334\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "2 0.02420831460924051 0.01824915839780581\n",
      "0.9843338074305436 0.993935576552753\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.994422\tvalid_1's auc: 0.985272\n",
      "[100]\ttraining's auc: 0.997441\tvalid_1's auc: 0.986388\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's auc: 0.997775\tvalid_1's auc: 0.986724\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "3 0.02416944288249423 0.012722939423353279\n",
      "0.9867242197859766 0.9977747010898205\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.99477\tvalid_1's auc: 0.983591\n",
      "[100]\ttraining's auc: 0.997641\tvalid_1's auc: 0.984528\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's auc: 0.997308\tvalid_1's auc: 0.984868\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "4 0.02558787562813748 0.013845472835014111\n",
      "0.9848679977437801 0.9973077750492185\n",
      "========= severe_toxic\n",
      "(159571, 13712)\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.993802\tvalid_1's auc: 0.989272\n",
      "[100]\ttraining's auc: 0.996733\tvalid_1's auc: 0.990161\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's auc: 0.99624\tvalid_1's auc: 0.990374\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "0 0.05202766633657167 0.03604478916636508\n",
      "0.9903739410045957 0.9962399779897475\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.993659\tvalid_1's auc: 0.989917\n",
      "[100]\ttraining's auc: 0.996747\tvalid_1's auc: 0.990631\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's auc: 0.996055\tvalid_1's auc: 0.990791\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "1 0.04870450098419322 0.03707204876897001\n",
      "0.9907912843026415 0.9960546486987869\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.993901\tvalid_1's auc: 0.990788\n",
      "[100]\ttraining's auc: 0.996628\tvalid_1's auc: 0.991787\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's auc: 0.996799\tvalid_1's auc: 0.991854\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "2 0.04893572360666052 0.0339911078075487\n",
      "0.9918535389408002 0.9967993277392388\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.99408\tvalid_1's auc: 0.988394\n",
      "[100]\ttraining's auc: 0.996832\tvalid_1's auc: 0.989599\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's auc: 0.99706\tvalid_1's auc: 0.98966\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "3 0.05128878939182347 0.032952956246872334\n",
      "0.9896597613558409 0.997059682764422\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.993842\tvalid_1's auc: 0.990365\n",
      "[100]\ttraining's auc: 0.996725\tvalid_1's auc: 0.991359\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's auc: 0.996506\tvalid_1's auc: 0.991443\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "4 0.049196739079565295 0.03527162197109013\n",
      "0.9914431686862427 0.9965062447869156\n",
      "========= obscene\n",
      "(159571, 3143)\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.999101\tvalid_1's auc: 0.985903\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's auc: 0.999207\tvalid_1's auc: 0.986288\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "0 0.009465894420449008 0.003708439137713375\n",
      "0.9862884924625748 0.9992073415092326\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.998767\tvalid_1's auc: 0.986677\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's auc: 0.998533\tvalid_1's auc: 0.987447\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "1 0.009278906935947177 0.00435771961069375\n",
      "0.987447063861215 0.9985327035286117\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.998816\tvalid_1's auc: 0.989373\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's auc: 0.999384\tvalid_1's auc: 0.990029\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "2 0.008887316708128068 0.0033601724375761166\n",
      "0.9900292147249548 0.999383724375172\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.998919\tvalid_1's auc: 0.975137\n",
      "[100]\ttraining's auc: 0.999887\tvalid_1's auc: 0.979418\n",
      "[150]\ttraining's auc: 0.999986\tvalid_1's auc: 0.979615\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's auc: 0.99997\tvalid_1's auc: 0.981065\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "3 0.00962268465864559 0.0015140324800049219\n",
      "0.9810650045819811 0.9999704900830986\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.987244\tvalid_1's auc: 0.986133\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "4 0.012055312175148008 0.009906953555913128\n",
      "0.986133138805906 0.9872444640698557\n",
      "========= threat\n",
      "(159571, 16697)\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.985227\tvalid_1's auc: 0.978921\n",
      "[100]\ttraining's auc: 0.991562\tvalid_1's auc: 0.981289\n",
      "[150]\ttraining's auc: 0.994122\tvalid_1's auc: 0.981834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[169]\ttraining's auc: 0.994854\tvalid_1's auc: 0.981961\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "0 0.06795987235199878 0.04274366959113605\n",
      "0.9819607910308941 0.9948539363399332\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.98532\tvalid_1's auc: 0.976819\n",
      "[100]\ttraining's auc: 0.991402\tvalid_1's auc: 0.979314\n",
      "[150]\ttraining's auc: 0.994125\tvalid_1's auc: 0.979574\n",
      "[200]\ttraining's auc: 0.995749\tvalid_1's auc: 0.979973\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.995749\tvalid_1's auc: 0.979973\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "1 0.069743086625248 0.03944054407329558\n",
      "0.9799727022881707 0.9957485076773324\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.985449\tvalid_1's auc: 0.979583\n",
      "[100]\ttraining's auc: 0.991706\tvalid_1's auc: 0.981472\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's auc: 0.990832\tvalid_1's auc: 0.981592\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "2 0.07053470419734885 0.053300633687717036\n",
      "0.9815918847185534 0.9908324796119916\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.985576\tvalid_1's auc: 0.974784\n",
      "[100]\ttraining's auc: 0.991606\tvalid_1's auc: 0.977083\n",
      "[150]\ttraining's auc: 0.994155\tvalid_1's auc: 0.977563\n",
      "[200]\ttraining's auc: 0.995729\tvalid_1's auc: 0.977849\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\ttraining's auc: 0.995729\tvalid_1's auc: 0.977849\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "3 0.06936101587132482 0.03981229275865842\n",
      "0.9778488058484103 0.9957292850573174\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.984964\tvalid_1's auc: 0.978918\n",
      "[100]\ttraining's auc: 0.991197\tvalid_1's auc: 0.981044\n",
      "[150]\ttraining's auc: 0.993971\tvalid_1's auc: 0.981422\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's auc: 0.993379\tvalid_1's auc: 0.981593\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "4 0.0677433184884166 0.046810111291063335\n",
      "0.9815930882428344 0.9933786703323428\n",
      "========= insult\n",
      "(159571, 6771)\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.994109\tvalid_1's auc: 0.971773\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttraining's auc: 0.995587\tvalid_1's auc: 0.972657\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "0 0.024035018787468797 0.01423414803987064\n",
      "0.9726570717528349 0.9955865116421396\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.993721\tvalid_1's auc: 0.979699\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's auc: 0.99585\tvalid_1's auc: 0.981188\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "1 0.023182303379178298 0.01361054113759359\n",
      "0.9811882788740484 0.995849654288208\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.993819\tvalid_1's auc: 0.978503\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's auc: 0.995931\tvalid_1's auc: 0.97967\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "2 0.022471455866321093 0.013871357098518293\n",
      "0.9796704261608867 0.9959306959800874\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.993062\tvalid_1's auc: 0.983505\n",
      "[100]\ttraining's auc: 0.997653\tvalid_1's auc: 0.984246\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's auc: 0.997137\tvalid_1's auc: 0.984669\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "3 0.02247534027453505 0.011606394549713874\n",
      "0.9846685850950958 0.9971370225870212\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[50]\ttraining's auc: 0.993632\tvalid_1's auc: 0.973106\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.991347\tvalid_1's auc: 0.974161\n",
      "hold out pred done\n",
      "curr train pred done\n",
      "4 0.023583754462358122 0.01802287578288839\n",
      "0.9741605600620011 0.9913468025290858\n",
      "========= identity_hate\n",
      "[[9.99892014e-01 1.95079897e-01 9.95731857e-01 1.27630360e-02\n",
      "  9.77675849e-01 4.32830172e-01]\n",
      " [6.84640034e-03 8.81288498e-04 2.96728032e-03 8.22844509e-04\n",
      "  4.06917532e-03 1.47299106e-03]\n",
      " [1.62957066e-02 2.31310429e-03 8.87912168e-03 1.14614163e-03\n",
      "  6.08842458e-03 1.64998619e-03]\n",
      " [2.34869132e-03 2.21065495e-04 1.81587489e-03 9.48426333e-04\n",
      "  2.66593786e-03 5.81543543e-04]\n",
      " [2.50875852e-02 1.54929026e-03 5.25983244e-03 8.86472315e-04\n",
      "  4.61275061e-03 8.27975241e-04]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model = LogisticRegression(solver='sag')\n",
    "sfm = SelectFromModel(model, threshold=0.2)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "def kf_train(k=5):\n",
    "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=1001)\n",
    "    train_pred, test_pred = np.zeros((159571, 6)), np.zeros((153164, 6))\n",
    "    for j in range(6):\n",
    "        train_x = sfm.fit_transform(train_features, target[:, j])\n",
    "        print(train_x.shape)\n",
    "        test_x = sfm.transform(test_features)\n",
    "        fold_idx = 0\n",
    "        for train_index, test_index in skf.split(train_x, target[:, j]):\n",
    "            # data\n",
    "            curr_x, curr_y = train_x[train_index], target[train_index][:, j]\n",
    "            hold_out_x, hold_out_y = train_x[test_index], target[test_index][:, j]\n",
    "            d_train = lgb.Dataset(curr_x, label=curr_y)\n",
    "            d_valid = lgb.Dataset(hold_out_x, label=hold_out_y)\n",
    "            watchlist = [d_train, d_valid]\n",
    "\n",
    "            params = {'learning_rate': 0.2,\n",
    "                      'application': 'binary',\n",
    "                      'num_leaves': 16,\n",
    "                      'metric': 'auc',\n",
    "                      'data_random_seed': 2,\n",
    "                      'feature_fraction': 0.6,\n",
    "                      'nthread': 4,\n",
    "                      'lambda_l1': 1,\n",
    "                      'lambda_l2': 1}\n",
    "\n",
    "            # train\n",
    "            lgb_m = lgb.train(params,\n",
    "                              train_set=d_train,\n",
    "                              num_boost_round=200,\n",
    "                              valid_sets=watchlist,\n",
    "                              early_stopping_rounds=20,\n",
    "                              verbose_eval=50)\n",
    "\n",
    "            hold_out_pred = lgb_m.predict(hold_out_x)\n",
    "            print('hold out pred done')\n",
    "            curr_train_pred = lgb_m.predict(curr_x)\n",
    "            print('curr train pred done')\n",
    "            # floating point exception (core dumped), seems updated lightgbm fix this\n",
    "            print(fold_idx,log_loss(hold_out_y,hold_out_pred),log_loss(curr_y,curr_train_pred))\n",
    "            print(roc_auc_score(hold_out_y,hold_out_pred),roc_auc_score(curr_y,curr_train_pred))\n",
    "            fold_idx += 1\n",
    "\n",
    "            train_pred[test_index, j] = list(hold_out_pred.flatten())\n",
    "            y_test = lgb_m.predict(test_x)\n",
    "            test_pred[:, j] += y_test\n",
    "        print('=========', class_names[j])\n",
    "    test_pred = test_pred / k\n",
    "    return train_pred, test_pred\n",
    "\n",
    "\n",
    "train_pred, test_pred = kf_train(5)\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('../features/lgb1_feat.pkl', 'wb') as fout:\n",
    "    pickle.dump([train_pred, test_pred], fout)\n",
    "print(test_pred[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
