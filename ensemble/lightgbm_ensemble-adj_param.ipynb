{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/glove_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 36) (153164, 36)\n",
      "file path ../features/pool_gru_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/tfidf_feat1.pkl\n",
      "(159571, 30) (153164, 30)\n",
      "file path ../features/tfidf_feat2.pkl\n",
      "(159571, 30) (153164, 30)\n",
      "(159571, 294)\n",
      "(159571, 294)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss'):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        d_test = test_x\n",
    "        \n",
    "        # share params\n",
    "        params = {\n",
    "                'application': 'binary',\n",
    "                #'num_leaves': 8,\n",
    "                #'lambda_l1': 1,\n",
    "                'lambda_l2': 1.0,\n",
    "                'max_depth': 3,\n",
    "                #'scale_pos_weight':0.9,\n",
    "                'metric': met, # or auc\n",
    "                'data_random_seed': 2,\n",
    "                'learning_rate':lr,\n",
    "#                 'bagging_fraction': bagging_fraction,\n",
    "#                 'bagging_freq':bag_frec,\n",
    "                'feature_fraction': feature_fraction,\n",
    "            \n",
    "                }\n",
    "        if met == 'auc':\n",
    "            s_round = 100\n",
    "        else:\n",
    "            s_round = 50\n",
    "        # train for each class\n",
    "        for i in range(6):\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(i)\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg 6 class\n",
    "        train_loss_l = train_loss_l/6\n",
    "        val_loss_l = val_loss_l/6\n",
    "        train_auc_l = train_auc_l/6\n",
    "        val_auc_l = val_auc_l/6\n",
    "        print('this fold avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this fold auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg k fold\n",
    "        all_train_loss_l += train_loss_l/k\n",
    "        all_val_loss_l += val_loss_l/k\n",
    "        all_train_auc_l += train_auc_l/k\n",
    "        all_val_auc_l += val_auc_l/k\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0678677545129 0.0762115787461 auc 0.991311727195 0.987830339943\n",
      "1\n",
      "ls 0.017774125468 0.0198374317062 auc 0.994353041443 0.992980758607\n",
      "2\n",
      "ls 0.0358970278127 0.0377041286706 auc 0.996088090702 0.995114341355\n",
      "3\n",
      "ls 0.0049035572984 0.00729386741402 auc 0.998525580402 0.996066554183\n",
      "4\n",
      "ls 0.0517114678971 0.0528889928489 auc 0.991122281581 0.989655324126\n",
      "5\n",
      "ls 0.0156699184071 0.0182059982048 auc 0.994847551965 0.987583270862\n",
      "this fold avg train 0.0323039752327 avg val 0.0353569995984\n",
      "this fold auc train 0.994374712215 auc val 0.991538431513\n",
      "========================\n",
      "0\n",
      "ls 0.0680070492823 0.0770493827436 auc 0.991290947281 0.987244263864\n",
      "1\n",
      "ls 0.0179287488607 0.0194019574427 auc 0.994412951743 0.99224859375\n",
      "2\n",
      "ls 0.0364171491368 0.0402022781553 auc 0.995903358841 0.994826560328\n",
      "3\n",
      "ls 0.0049947190696 0.00737471341728 auc 0.998664943337 0.9871431055\n",
      "4\n",
      "ls 0.0471968244464 0.0538351448054 auc 0.992840654594 0.989285169512\n",
      "5\n",
      "ls 0.0126365725245 0.0169152361073 auc 0.997279181044 0.991513094641\n",
      "this fold avg train 0.0311968438867 avg val 0.0357964521119\n",
      "this fold auc train 0.995065339474 auc val 0.990376797933\n",
      "========================\n",
      "0\n",
      "ls 0.0657301235475 0.0775931254192 auc 0.99193415634 0.987756599539\n",
      "1\n",
      "ls 0.0176907270206 0.0206681002381 auc 0.994541938667 0.991065022381\n",
      "2\n",
      "ls 0.0357543616327 0.0398333040762 auc 0.99606876338 0.994601047598\n",
      "3\n",
      "ls 0.0048167579195 0.00682525933782 auc 0.998764620393 0.995882758067\n",
      "4\n",
      "ls 0.0507253249814 0.0555755164245 auc 0.991352517632 0.989520877051\n",
      "5\n",
      "ls 0.0152924989667 0.0182039091299 auc 0.995115469914 0.990313172663\n",
      "this fold avg train 0.0316682990114 avg val 0.0364498691043\n",
      "this fold auc train 0.994629577721 auc val 0.991523246216\n",
      "========================\n",
      "0\n",
      "ls 0.0701378755426 0.0757935297773 auc 0.990535838905 0.988305542683\n",
      "1\n",
      "ls 0.0180187238775 0.0208323215463 auc 0.994128635947 0.992018252611\n",
      "2\n",
      "ls 0.0368819119276 0.0386680752625 auc 0.995832509242 0.995211735939\n",
      "3\n",
      "ls 0.00492662031499 0.00582762916856 auc 0.998789968032 0.992716963194\n",
      "4\n",
      "ls 0.0490440284156 0.0539450708677 auc 0.992055007239 0.989966163608\n",
      "5\n",
      "ls 0.0153772881766 0.0179781929251 auc 0.994873828295 0.993286982142\n",
      "this fold avg train 0.0323977413758 avg val 0.0355074699246\n",
      "this fold auc train 0.994369297943 auc val 0.991917606696\n",
      "========================\n",
      "0\n",
      "ls 0.0670648325755 0.0756641830904 auc 0.991547237491 0.98851845112\n",
      "1\n",
      "ls 0.017531526941 0.0216609795575 auc 0.994619673164 0.990343566073\n",
      "2\n",
      "ls 0.0356894041735 0.0404537448789 auc 0.996098858274 0.99477210828\n",
      "3\n",
      "ls 0.00472455141337 0.00801083329156 auc 0.998756905813 0.993338957709\n",
      "4\n",
      "ls 0.0472974341619 0.0548266571922 auc 0.992657872277 0.989782108007\n",
      "5\n",
      "ls 0.0156476573863 0.0189666798116 auc 0.994797756077 0.986761205711\n",
      "this fold avg train 0.0313259011086 avg val 0.036597179637\n",
      "this fold auc train 0.994746383849 auc val 0.99058606615\n",
      "========================\n",
      "all loss avg 0.031778552123 0.0359415940753\n",
      "all auc avg 0.99463706224 0.991188429702\n",
      "=======================================================\n",
      "../results/lgb_csv_fold5_0.05_0.6.gz\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999129      0.318391  0.973018  0.239955  0.913727   \n",
      "1  0000247867823ef7  0.000294      0.000028  0.000077  0.000046  0.000042   \n",
      "2  00013b17ad220c46  0.000436      0.000029  0.000373  0.000055  0.000322   \n",
      "3  00017563c3f7919a  0.000130      0.000030  0.000076  0.000045  0.000046   \n",
      "4  00017695ad8997eb  0.002240      0.000041  0.000311  0.000057  0.000403   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.505775  \n",
      "1       0.000085  \n",
      "2       0.000127  \n",
      "3       0.000091  \n",
      "4       0.000110  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "# adj lr, feat_frac, bag_frac\n",
    "for lr in [0.05]:\n",
    "    for c1 in [0.6,0.7,0.8]:\n",
    "        lgb_res = simple_ens('lgb',5,233,lr,c1)\n",
    "        sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "        sample_submission[list_classes] = lgb_res\n",
    "        fname = \"../results/lgb_csv_fold5_{}_{}.gz\".format(lr,c1)\n",
    "        sample_submission.to_csv(fname, index=False, compression='gzip')\n",
    "        print(fname)\n",
    "        print(sample_submission.head())\n",
    "        print('save done')\n",
    "        break\n",
    "\n",
    "# lr, feat_frac, bag_frac, bag_freq=40\n",
    "# 0.03   0.7   0.7       all loss avg 0.0322530666235 0.0369762464226 all auc avg 0.994271044586 0.990285134782\n",
    "# 0.03   0.7   0.8       all loss avg 0.0322971080147 0.0369559723174 all auc avg 0.994334369995 0.990306416634\n",
    "# 0.03   0.8   0.7       all loss avg 0.0322229511884 0.0369948009383 all auc avg 0.994234840050 0.990368331216\n",
    "# 0.03   0.8   0.8       all loss avg 0.0324206645596 0.0369651316109 all auc avg 0.994257933028 0.990295813203\n",
    "# 0.05   0.7   0.7       all loss avg 0.0318163169078 0.0370403091733 all auc avg 0.994337086137 0.990254302965\n",
    "\n",
    "# bag_freq = 3\n",
    "# 0.05   0.6   0.6       all loss avg 0.0329345052647 0.0368498383873 all auc avg 0.9939819323 0.990664190969\n",
    "# 0.05   0.6   0.7       all loss avg 0.0326017869132 0.0368044492709 all auc avg 0.994163898916 0.990696436189\n",
    "# 0.05   0.6   0.8       all loss avg 0.0324589992208 0.0368163370811 all auc avg 0.994233438434 0.990618323557\n",
    "# 0.05   0.7   0.6       all loss avg 0.0331541550186 0.0368670775083 all auc avg 0.993940708877 0.990597573572\n",
    "# 0.05   0.7   0.7       all loss avg 0.0325753698442 0.0368285766463 all auc avg 0.994218398119 0.990663705936\n",
    "# 0.05   0.7   0.8       all loss avg 0.0325779317956 0.0368281454058 all auc avg 0.994220915054 0.990630132284\n",
    "# 0.05   0.8   0.6       all loss avg 0.0333336885412 0.0368817399664 all auc avg 0.993874933751 0.990630976344\n",
    "# 0.05   0.8   0.7       all loss avg 0.0329593178033 0.0368484307605 all auc avg 0.994000316129 0.99065277921\n",
    "# 0.05   0.8   0.8       all loss avg 0.0328682234385 0.0368555923112 all auc avg 0.994090826609 0.990708113059\n",
    "\n",
    "# rm bagging\n",
    "# 0.05   0.6             all loss avg 0.0328499864930 0.0368782748851 all auc avg 0.994090121326 0.990573017994   \n",
    "# add 2 feats\n",
    "# all loss avg 0.0319117001045 0.0360410792425 all auc avg 0.994541896459 0.991241823846\n",
    "# rm pos_scale_weights, change l2 lambda to 1\n",
    "# all loss avg 0.0316907179553 0.0359932860253 all auc avg 0.994616385099 0.991125111598\n",
    "\n",
    "# add other feats\n",
    "# all loss avg 0.031778552123 0.0359415940753 all auc avg 0.99463706224 0.991188429702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0690516773143 0.075268809251 auc 0.99089193839 0.988660480225\n",
      "1\n",
      "ls 0.0183673860671 0.0204719222905 auc 0.993897554936 0.99234285165\n",
      "2\n",
      "ls 0.036850289929 0.0405868001567 auc 0.995809378751 0.994215976552\n",
      "3\n",
      "ls 0.00355425488195 0.00702774489089 auc 0.99945717579 0.997556074619\n",
      "4\n",
      "ls 0.0498769422514 0.0565011922078 auc 0.991725310219 0.988094192856\n",
      "5\n",
      "ls 0.0151707349804 0.0196158731389 auc 0.995203140207 0.988543027978\n",
      "this fold avg train 0.0321452142374 avg val 0.036578723656\n",
      "this fold auc train 0.994497416382 auc val 0.991568767313\n",
      "========================\n",
      "0\n",
      "ls 0.067169775596 0.0767170943172 auc 0.991566594449 0.987021484844\n",
      "1\n",
      "ls 0.0179958919375 0.0191807759004 auc 0.994179124113 0.993567899034\n",
      "2\n",
      "ls 0.0358493442744 0.0350216612295 auc 0.996084062435 0.996035696322\n",
      "3\n",
      "ls 0.00492324877664 0.00759232244624 auc 0.998660092707 0.993767245762\n",
      "4\n",
      "ls 0.0517888652451 0.0490554424921 auc 0.991066922959 0.991587240291\n",
      "5\n",
      "ls 0.0160214790479 0.0167066686617 auc 0.9945241601 0.985351813264\n",
      "this fold avg train 0.0322914341463 avg val 0.0340456608412\n",
      "this fold auc train 0.994346826127 auc val 0.991221896586\n",
      "========================\n",
      "0\n",
      "ls 0.0674520221087 0.0731662596718 auc 0.991492821191 0.988368131128\n",
      "1\n",
      "ls 0.0182976574989 0.0184984082117 auc 0.994082597461 0.992376195594\n",
      "2\n",
      "ls 0.0361423118673 0.0388335947953 auc 0.995952613814 0.995574743782\n",
      "3\n",
      "ls 0.00530228936361 0.00807318648997 auc 0.99838136162 0.981950713522\n",
      "4\n",
      "ls 0.0480268397638 0.0535584330285 auc 0.992496874237 0.989600043145\n",
      "5\n",
      "ls 0.0128637033513 0.0185539053332 auc 0.996998911801 0.990443289317\n",
      "this fold avg train 0.0313474706589 avg val 0.0351139645884\n",
      "this fold auc train 0.994900863354 auc val 0.989718852748\n",
      "========================\n",
      "0\n",
      "ls 0.0712765690524 0.0810690214987 auc 0.990096497275 0.986382942555\n",
      "1\n",
      "ls 0.0179619668634 0.0200924667506 auc 0.994228628128 0.99251560156\n",
      "2\n",
      "ls 0.0359809806978 0.0416992262962 auc 0.99602094287 0.994063398385\n",
      "3\n",
      "ls 0.00520529565964 0.00673675455801 auc 0.998398675445 0.993378769788\n",
      "4\n",
      "ls 0.0503537988316 0.0540727707702 auc 0.991607463704 0.988958735015\n",
      "5\n",
      "ls 0.0149051434884 0.0154327598636 auc 0.995565693919 0.992287575509\n",
      "this fold avg train 0.0326139590989 avg val 0.0365171666229\n",
      "this fold auc train 0.994319650224 auc val 0.991264503802\n",
      "========================\n",
      "0\n",
      "ls 0.0708762338069 0.0776004369318 auc 0.99024520939 0.988286612045\n",
      "1\n",
      "ls 0.0175470466682 0.0210440406951 auc 0.994600093411 0.991095014025\n",
      "2\n",
      "ls 0.0362794962233 0.0372644062985 auc 0.995947164594 0.995092338466\n",
      "3\n",
      "ls 0.00479055956824 0.00710025827163 auc 0.998700089105 0.996017377852\n",
      "4\n",
      "ls 0.0512794348438 0.054215463338 auc 0.991178919528 0.990155033884\n",
      "5\n",
      "ls 0.0158827069427 0.0187604297732 auc 0.994503093836 0.987311580984\n",
      "this fold avg train 0.0327759130089 avg val 0.0359975058847\n",
      "this fold auc train 0.994195761644 auc val 0.991326326209\n",
      "========================\n",
      "0\n",
      "ls 0.06831479629 0.0775735674308 auc 0.991164272953 0.987228172902\n",
      "1\n",
      "ls 0.0185408037074 0.0200395075713 auc 0.993894119287 0.99135272631\n",
      "2\n",
      "ls 0.0359298354923 0.0422466870216 auc 0.996024726675 0.994114011\n",
      "3\n",
      "ls 0.0048830900219 0.00642614612207 auc 0.998722453105 0.995470120572\n",
      "4\n",
      "ls 0.0495119167691 0.0566787782097 auc 0.991830886051 0.989004402195\n",
      "5\n",
      "ls 0.0153805555796 0.0170581417296 auc 0.995025532704 0.993043258285\n",
      "this fold avg train 0.0320934996434 avg val 0.0366704713475\n",
      "this fold auc train 0.994443665129 auc val 0.991702115211\n",
      "========================\n",
      "0\n",
      "ls 0.0690765502888 0.0767308355774 auc 0.99086735659 0.987796418735\n",
      "1\n",
      "ls 0.0180593614767 0.0217597964673 auc 0.994044023303 0.992022535998\n",
      "2\n",
      "ls 0.0359196997406 0.0354729472452 auc 0.996046198168 0.996053050087\n",
      "3\n",
      "ls 0.0046486710954 0.00540377049954 auc 0.998913231873 0.990022789671\n",
      "4\n",
      "ls 0.0501561710967 0.0512732763494 auc 0.9916222386 0.991339278364\n",
      "5\n",
      "ls 0.0154328940201 0.0186835611195 auc 0.994871458103 0.993154910461\n",
      "this fold avg train 0.032215557953 avg val 0.034887364543\n",
      "this fold auc train 0.99439408444 auc val 0.991731497219\n",
      "========================\n",
      "0\n",
      "ls 0.0708708361747 0.0746638227667 auc 0.9902419347 0.98880991033\n",
      "1\n",
      "ls 0.0183886214807 0.0197865567364 auc 0.993907329259 0.992123359835\n",
      "2\n",
      "ls 0.0367373915847 0.041260518162 auc 0.995842115119 0.994648297152\n",
      "3\n",
      "ls 0.00466509916987 0.00642882222214 auc 0.998876647523 0.994257428294\n",
      "4\n",
      "ls 0.0503305447222 0.0570907695522 auc 0.991554233616 0.988345347041\n",
      "5\n",
      "ls 0.0147998324945 0.0170722459227 auc 0.995481678157 0.993506573354\n",
      "this fold avg train 0.0326320542711 avg val 0.0360504558937\n",
      "this fold auc train 0.994317323062 auc val 0.991948486001\n",
      "========================\n",
      "0\n",
      "ls 0.0682943447681 0.0770865466687 auc 0.991164520393 0.987611126475\n",
      "1\n",
      "ls 0.0183019630337 0.0211402851789 auc 0.993982021678 0.990638387747\n",
      "2\n",
      "ls 0.0367495053799 0.042476863402 auc 0.995859726438 0.993880396411\n",
      "3\n",
      "ls 0.00514072178194 0.00904302308511 auc 0.998389181334 0.990709478098\n",
      "4\n",
      "ls 0.0499470191888 0.0531599856001 auc 0.991748765011 0.989672666885\n",
      "5\n",
      "ls 0.0157152878779 0.0190924221011 auc 0.994758531615 0.984273710553\n",
      "this fold avg train 0.0323581403384 avg val 0.0369998543393\n",
      "this fold auc train 0.994317124412 auc val 0.989464294361\n",
      "========================\n",
      "0\n",
      "ls 0.0700641222968 0.0740128393793 auc 0.990466464421 0.989458759168\n",
      "1\n",
      "ls 0.0180511380689 0.0223124810468 auc 0.994193605337 0.989865164272\n",
      "2\n",
      "ls 0.0369318170704 0.0387629818259 auc 0.995768075631 0.995425313009\n",
      "3\n",
      "ls 0.00354749542722 0.00664448003826 auc 0.999521302035 0.996807222826\n",
      "4\n",
      "ls 0.0508958306924 0.0570904860905 auc 0.991239079881 0.989411957712\n",
      "5\n",
      "ls 0.0152466098374 0.0185333387307 auc 0.995121964022 0.989170877182\n",
      "this fold avg train 0.0324561688989 avg val 0.0362261011853\n",
      "this fold auc train 0.994385081888 auc val 0.991689882362\n",
      "========================\n",
      "all loss avg 0.0322929412255 0.0359087268902\n",
      "all auc avg 0.994411779666 0.991163662181\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999055      0.317474  0.973468  0.257018  0.924536   \n",
      "1  0000247867823ef7  0.000326      0.000052  0.000088  0.000047  0.000042   \n",
      "2  00013b17ad220c46  0.000425      0.000054  0.000276  0.000054  0.000406   \n",
      "3  00017563c3f7919a  0.000119      0.000053  0.000090  0.000047  0.000049   \n",
      "4  00017695ad8997eb  0.001924      0.000060  0.000316  0.000049  0.000493   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.494741  \n",
      "1       0.000060  \n",
      "2       0.000122  \n",
      "3       0.000062  \n",
      "4       0.000088  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgb_res = simple_ens('lgb',10,233,0.05,0.6)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# all loss avg 0.0335311567862 0.036750116241\n",
    "# all auc avg 0.993683089291 0.990779711364 PUB 9862\n",
    "\n",
    "# change params lr to 0.05, rnd 42\n",
    "# all loss avg 0.0331165975108 0.036782889115 all auc avg 0.993888891968 0.99078987792\n",
    "\n",
    "# rm bagging, rnd 233\n",
    "# all loss avg 0.0330784234373 0.036800843461 all auc avg 0.993977317117 0.990582906649\n",
    "\n",
    "# fix lr, mnb feat, no bagging, rnd 233\n",
    "# all loss avg 0.032247976023 0.0361280397445 all auc avg 0.994391483047 0.991118473891\n",
    "\n",
    "# add 2 feats\n",
    "# all loss avg 0.0322831057545 0.0359632999094 all auc avg 0.994383324993 0.991201300627 PUB 9866\n",
    "\n",
    "# add other feats, 20 dims\n",
    "# all loss avg 0.0322929412255 0.0359087268902 all auc avg 0.994411779666 0.991163662181"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
