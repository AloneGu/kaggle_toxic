{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/fasttext_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 36) (153164, 36)\n",
      "file path ../features/pool_gru_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "(159571, 276)\n",
      "(159571, 276)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat or 'tfidf' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss'):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        d_test = test_x\n",
    "        \n",
    "        # share params\n",
    "        params = {\n",
    "                'application': 'binary',\n",
    "                #'num_leaves': 8,\n",
    "                #'lambda_l1': 1,\n",
    "                'lambda_l2': 1.0,\n",
    "                'max_depth': 3,\n",
    "                #'scale_pos_weight':0.9,\n",
    "                'metric': met, # or auc\n",
    "                'data_random_seed': 2,\n",
    "                'learning_rate':lr,\n",
    "#                 'bagging_fraction': bagging_fraction,\n",
    "#                 'bagging_freq':bag_frec,\n",
    "                'feature_fraction': feature_fraction,\n",
    "            \n",
    "                }\n",
    "        if met == 'auc':\n",
    "            s_round = 100\n",
    "        else:\n",
    "            s_round = 50\n",
    "        # train for each class\n",
    "        for i in range(6):\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(i)\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg 6 class\n",
    "        train_loss_l = train_loss_l/6\n",
    "        val_loss_l = val_loss_l/6\n",
    "        train_auc_l = train_auc_l/6\n",
    "        val_auc_l = val_auc_l/6\n",
    "        print('this fold avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this fold auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg k fold\n",
    "        all_train_loss_l += train_loss_l/k\n",
    "        all_val_loss_l += val_loss_l/k\n",
    "        all_train_auc_l += train_auc_l/k\n",
    "        all_val_auc_l += val_auc_l/k\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0674956971593 0.0749572922159 auc 0.991437975178 0.98854546507\n",
      "1\n",
      "ls 0.0182665004623 0.0206443054284 auc 0.993933653303 0.992121220444\n",
      "2\n",
      "ls 0.0353057648081 0.0400445624363 auc 0.996191283288 0.994634575842\n",
      "3\n",
      "ls 0.00366903482398 0.00678662314936 auc 0.999454645613 0.997943406317\n",
      "4\n",
      "ls 0.0514496577762 0.0564793200085 auc 0.991130416038 0.98809529958\n",
      "5\n",
      "ls 0.0153521241644 0.0196537241074 auc 0.995047253942 0.988926390821\n",
      "this fold avg train 0.0319231298657 avg val 0.036427637891\n",
      "this fold auc train 0.994532537894 auc val 0.991711059679\n",
      "========================\n",
      "0\n",
      "ls 0.0694049451651 0.0773546340312 auc 0.990834481195 0.986829311029\n",
      "1\n",
      "ls 0.018409019844 0.0189733387294 auc 0.993801905864 0.993750308123\n",
      "2\n",
      "ls 0.0351392087998 0.0347716990827 auc 0.996286977757 0.996104300774\n",
      "3\n",
      "ls 0.00489791312486 0.00755040913573 auc 0.998704975143 0.994375667693\n",
      "4\n",
      "ls 0.0495186971221 0.0486650442867 auc 0.991975064413 0.991661089768\n",
      "5\n",
      "ls 0.0154797784855 0.0164968992392 auc 0.995077733119 0.988684725642\n",
      "this fold avg train 0.0321415937569 avg val 0.0339686707508\n",
      "this fold auc train 0.994446856248 auc val 0.991900900505\n",
      "========================\n",
      "0\n",
      "ls 0.0675576519887 0.0727312063674 auc 0.991485935179 0.988338407082\n",
      "1\n",
      "ls 0.0182458646001 0.0184834000668 auc 0.994095493819 0.992412323088\n",
      "2\n",
      "ls 0.0338050221774 0.0383339972355 auc 0.996545294892 0.995648474056\n",
      "3\n",
      "ls 0.00534977522973 0.0081105661666 auc 0.998416738127 0.977704155403\n",
      "4\n",
      "ls 0.0515679996144 0.0538422563812 auc 0.991128721236 0.989511393198\n",
      "5\n",
      "ls 0.0154812506628 0.0188439164037 auc 0.994980414649 0.989577615988\n",
      "this fold avg train 0.0320012607122 avg val 0.0350575571035\n",
      "this fold auc train 0.99444209965 auc val 0.988865394803\n",
      "========================\n",
      "0\n",
      "ls 0.0708961660514 0.0808116665919 auc 0.990203175908 0.986416156759\n",
      "1\n",
      "ls 0.0179815955357 0.0199083027371 auc 0.994174017384 0.992702828052\n",
      "2\n",
      "ls 0.0325924692689 0.041132375764 auc 0.996835270066 0.994239747379\n",
      "3\n",
      "ls 0.00550647831941 0.00656318350983 auc 0.998081674126 0.994846980456\n",
      "4\n",
      "ls 0.0470950038807 0.0536620269548 auc 0.992842519062 0.989179274843\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgb_res = simple_ens('lgb',10,233,0.05,0.6)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# all loss avg 0.0335311567862 0.036750116241\n",
    "# all auc avg 0.993683089291 0.990779711364 PUB 9862\n",
    "\n",
    "# change params lr to 0.05, rnd 42\n",
    "# all loss avg 0.0331165975108 0.036782889115 all auc avg 0.993888891968 0.99078987792\n",
    "\n",
    "# rm bagging, rnd 233\n",
    "# all loss avg 0.0330784234373 0.036800843461 all auc avg 0.993977317117 0.990582906649\n",
    "\n",
    "# fix lr, mnb feat, no bagging, rnd 233\n",
    "# all loss avg 0.032247976023 0.0361280397445 all auc avg 0.994391483047 0.991118473891\n",
    "\n",
    "# add 2 feats\n",
    "# all loss avg 0.0322831057545 0.0359632999094 all auc avg 0.994383324993 0.991201300627 PUB 9866\n",
    "\n",
    "# add other feats, 20 dims\n",
    "# all loss avg 0.0322929412255 0.0359087268902 all auc avg 0.994411779666 0.991163662181\n",
    "\n",
    "# add 7 base fasttext NN models\n",
    "# all loss avg 0.0319116484218 0.0358161833583 all auc avg 0.994546891137 0.991249510282 PUB 9866\n",
    "\n",
    "# rm tfidf test\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# adj lr, feat_frac, bag_frac\n",
    "for lr in [0.05]:\n",
    "    for c1 in [0.6,0.7,0.8]:\n",
    "        lgb_res = simple_ens('lgb',5,233,lr,c1)\n",
    "        sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "        sample_submission[list_classes] = lgb_res\n",
    "        fname = \"../results/lgb_csv_fold5_{}_{}.gz\".format(lr,c1)\n",
    "        sample_submission.to_csv(fname, index=False, compression='gzip')\n",
    "        print(fname)\n",
    "        print(sample_submission.head())\n",
    "        print('save done')\n",
    "        break\n",
    "\n",
    "# lr, feat_frac, bag_frac, bag_freq=40\n",
    "# 0.03   0.7   0.7       all loss avg 0.0322530666235 0.0369762464226 all auc avg 0.994271044586 0.990285134782\n",
    "# 0.03   0.7   0.8       all loss avg 0.0322971080147 0.0369559723174 all auc avg 0.994334369995 0.990306416634\n",
    "# 0.03   0.8   0.7       all loss avg 0.0322229511884 0.0369948009383 all auc avg 0.994234840050 0.990368331216\n",
    "# 0.03   0.8   0.8       all loss avg 0.0324206645596 0.0369651316109 all auc avg 0.994257933028 0.990295813203\n",
    "# 0.05   0.7   0.7       all loss avg 0.0318163169078 0.0370403091733 all auc avg 0.994337086137 0.990254302965\n",
    "\n",
    "# bag_freq = 3\n",
    "# 0.05   0.6   0.6       all loss avg 0.0329345052647 0.0368498383873 all auc avg 0.9939819323 0.990664190969\n",
    "# 0.05   0.6   0.7       all loss avg 0.0326017869132 0.0368044492709 all auc avg 0.994163898916 0.990696436189\n",
    "# 0.05   0.6   0.8       all loss avg 0.0324589992208 0.0368163370811 all auc avg 0.994233438434 0.990618323557\n",
    "# 0.05   0.7   0.6       all loss avg 0.0331541550186 0.0368670775083 all auc avg 0.993940708877 0.990597573572\n",
    "# 0.05   0.7   0.7       all loss avg 0.0325753698442 0.0368285766463 all auc avg 0.994218398119 0.990663705936\n",
    "# 0.05   0.7   0.8       all loss avg 0.0325779317956 0.0368281454058 all auc avg 0.994220915054 0.990630132284\n",
    "# 0.05   0.8   0.6       all loss avg 0.0333336885412 0.0368817399664 all auc avg 0.993874933751 0.990630976344\n",
    "# 0.05   0.8   0.7       all loss avg 0.0329593178033 0.0368484307605 all auc avg 0.994000316129 0.99065277921\n",
    "# 0.05   0.8   0.8       all loss avg 0.0328682234385 0.0368555923112 all auc avg 0.994090826609 0.990708113059\n",
    "\n",
    "# rm bagging\n",
    "# 0.05   0.6             all loss avg 0.0328499864930 0.0368782748851 all auc avg 0.994090121326 0.990573017994   \n",
    "# add 2 feats\n",
    "# all loss avg 0.0319117001045 0.0360410792425 all auc avg 0.994541896459 0.991241823846\n",
    "# rm pos_scale_weights, change l2 lambda to 1\n",
    "# all loss avg 0.0316907179553 0.0359932860253 all auc avg 0.994616385099 0.991125111598\n",
    "\n",
    "# add other feats\n",
    "# all loss avg 0.031778552123 0.0359415940753 all auc avg 0.99463706224 0.991188429702"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
