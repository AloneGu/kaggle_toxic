{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/glove_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 16) (153164, 16)\n",
      "file path ../features/pool_gru_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/tfidf_feat1.pkl\n",
      "(159571, 30) (153164, 30)\n",
      "file path ../features/tfidf_feat2.pkl\n",
      "(159571, 30) (153164, 30)\n",
      "(159571, 262)\n",
      "(159571, 262)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss'):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        d_test = test_x\n",
    "        \n",
    "        # share params\n",
    "        params = {\n",
    "                'application': 'binary',\n",
    "                #'num_leaves': 8,\n",
    "                #'lambda_l1': 1,\n",
    "                'lambda_l2': 1.2,\n",
    "                'max_depth': 3,\n",
    "                'scale_pos_weight':0.9,\n",
    "                'metric': met, # or auc\n",
    "                'data_random_seed': 2,\n",
    "                'learning_rate':lr,\n",
    "#                 'bagging_fraction': bagging_fraction,\n",
    "#                 'bagging_freq':bag_frec,\n",
    "                'feature_fraction': feature_fraction,\n",
    "            \n",
    "                }\n",
    "        if met == 'auc':\n",
    "            s_round = 100\n",
    "        else:\n",
    "            s_round = 50\n",
    "        # train for each class\n",
    "        for i in range(6):\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(i)\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg 6 class\n",
    "        train_loss_l = train_loss_l/6\n",
    "        val_loss_l = val_loss_l/6\n",
    "        train_auc_l = train_auc_l/6\n",
    "        val_auc_l = val_auc_l/6\n",
    "        print('this fold avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this fold auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg k fold\n",
    "        all_train_loss_l += train_loss_l/k\n",
    "        all_val_loss_l += val_loss_l/k\n",
    "        all_train_auc_l += train_auc_l/k\n",
    "        all_val_auc_l += val_auc_l/k\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0715756263364 0.0778918992813 auc 0.990044174728 0.987115901447\n",
      "1\n",
      "ls 0.0183406987171 0.0200192823683 auc 0.993882999672 0.992897558441\n",
      "2\n",
      "ls 0.0360643999099 0.0395503089266 auc 0.996025734909 0.994474435122\n",
      "3\n",
      "ls 0.00492291524905 0.00739562627481 auc 0.998516726113 0.995068637349\n",
      "4\n",
      "ls 0.0521875531828 0.0539351974535 auc 0.990922087735 0.989088400946\n",
      "5\n",
      "ls 0.0159414040964 0.0184446938637 auc 0.994458410342 0.987025937713\n",
      "this fold avg train 0.0331720995819 avg val 0.036206168028\n",
      "this fold auc train 0.99397502225 auc val 0.99094514517\n",
      "========================\n",
      "0\n",
      "ls 0.0717912915926 0.0793601066039 auc 0.989945429095 0.986210083352\n",
      "1\n",
      "ls 0.018485220253 0.0194687940123 auc 0.993962349104 0.99222646\n",
      "2\n",
      "ls 0.0345804837778 0.04162096936 auc 0.996309288835 0.994417816128\n",
      "3\n",
      "ls 0.00527103314331 0.00727455757059 auc 0.998300241738 0.988273299277\n",
      "4\n",
      "ls 0.0491005959018 0.0546654128942 auc 0.992157536817 0.9888137062\n",
      "5\n",
      "ls 0.014993066048 0.0172407853217 auc 0.995351668993 0.990100990954\n",
      "this fold avg train 0.0323702817861 avg val 0.0366051042938\n",
      "this fold auc train 0.99433775243 auc val 0.990007059318\n",
      "========================\n",
      "0\n",
      "ls 0.0689621355207 0.0799566916092 auc 0.990823990779 0.986870505023\n",
      "1\n",
      "ls 0.0182735738681 0.0212663137831 auc 0.994075170159 0.989974702909\n",
      "2\n",
      "ls 0.0385497288746 0.0413803870751 auc 0.995313949771 0.993946899176\n",
      "3\n",
      "ls 0.0049717141954 0.00698019486199 auc 0.998620061551 0.995295010498\n",
      "4\n",
      "ls 0.0506522906576 0.0567240683971 auc 0.991352289221 0.988947512908\n",
      "5\n",
      "ls 0.0159820400695 0.0186059977113 auc 0.994149040876 0.988510896925\n",
      "this fold avg train 0.032898580531 avg val 0.0374856089063\n",
      "this fold auc train 0.994055750393 auc val 0.99059092124\n",
      "========================\n",
      "0\n",
      "ls 0.0715579411696 0.07838252964 auc 0.989998205806 0.987303991544\n",
      "1\n",
      "ls 0.0178100942763 0.0212946269329 auc 0.994322546678 0.991461618849\n",
      "2\n",
      "ls 0.0380357464278 0.0400874376008 auc 0.99549209648 0.994595183842\n",
      "3\n",
      "ls 0.00528959595337 0.00581715686144 auc 0.998410160223 0.993568772919\n",
      "4\n",
      "ls 0.0514954203183 0.0549009278553 auc 0.991071396361 0.989549470528\n",
      "5\n",
      "ls 0.0157599851798 0.0184832923861 auc 0.994210234037 0.992383540327\n",
      "this fold avg train 0.0333247972208 avg val 0.0364943285461\n",
      "this fold auc train 0.993917439931 auc val 0.991477096335\n",
      "========================\n",
      "0\n",
      "ls 0.0711704065539 0.0783308703499 auc 0.990072694073 0.98750008179\n",
      "1\n",
      "ls 0.0181695202171 0.0218612560776 auc 0.994125036933 0.989825243893\n",
      "2\n",
      "ls 0.0357583494151 0.0419545685542 auc 0.996058347953 0.994021264615\n",
      "3\n",
      "ls 0.00493087278764 0.00818261016493 auc 0.998463272719 0.992946532334\n",
      "4\n",
      "ls 0.048886024126 0.0561077053463 auc 0.992044857689 0.989171212986\n",
      "5\n",
      "ls 0.0159898669717 0.0191639774151 auc 0.994223640403 0.985604871834\n",
      "this fold avg train 0.0324841733452 avg val 0.0376001646513\n",
      "this fold auc train 0.994164641628 auc val 0.989844867909\n",
      "========================\n",
      "all loss avg 0.032849986493 0.0368782748851\n",
      "all auc avg 0.994090121326 0.990573017994\n",
      "=======================================================\n",
      "../results/lgb_csv_fold5_0.05_0.6_0.8.gz\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.998146      0.274299  0.968405  0.208784  0.898199   \n",
      "1  0000247867823ef7  0.000160      0.000032  0.000097  0.000047  0.000039   \n",
      "2  00013b17ad220c46  0.000487      0.000033  0.000268  0.000064  0.000434   \n",
      "3  00017563c3f7919a  0.000223      0.000033  0.000107  0.000046  0.000040   \n",
      "4  00017695ad8997eb  0.004663      0.000053  0.000528  0.000062  0.000492   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.475894  \n",
      "1       0.000087  \n",
      "2       0.000179  \n",
      "3       0.000091  \n",
      "4       0.000124  \n",
      "save done\n",
      "0\n",
      "ls 0.0710038844185 0.0779531160866 auc 0.99022788244 0.98709841515\n",
      "1\n",
      "ls 0.0183469135514 0.0199932646174 auc 0.993861878637 0.992921900433\n",
      "2\n",
      "ls 0.0364980637042 0.0394828095802 auc 0.995912973059 0.994477648124\n",
      "3\n",
      "ls 0.00493873101357 0.00737018701346 auc 0.998506725225 0.994767632096\n",
      "4\n",
      "ls 0.0525913437446 0.0540199773464 auc 0.990772486462 0.989041070642\n",
      "5\n",
      "ls 0.0157168311232 0.0184957204363 auc 0.994718535452 0.986485897808\n",
      "this fold avg train 0.0331826279259 avg val 0.0362191791801\n",
      "this fold auc train 0.994000080213 auc val 0.990798760709\n",
      "========================\n",
      "0\n",
      "ls 0.0734069799273 0.0794999213829 auc 0.989382670565 0.986107824253\n",
      "1\n",
      "ls 0.0183254805886 0.0195296494555 auc 0.994095753015 0.992144502483\n",
      "2\n",
      "ls 0.0369054512276 0.0416369207809 auc 0.995735817765 0.994376441078\n",
      "3\n",
      "ls 0.00536172093223 0.00734491037656 auc 0.998185883724 0.988681178705\n",
      "4\n",
      "ls 0.0517720845398 0.0547121613577 auc 0.991131371513 0.988727069687\n",
      "5\n",
      "ls 0.0128729319768 0.0172061195749 auc 0.99703095826 0.990408322624\n",
      "this fold avg train 0.033107441532 avg val 0.0366549471547\n",
      "this fold auc train 0.99426040914 auc val 0.990074223138\n",
      "========================\n",
      "0\n",
      "ls 0.0694881974974 0.0801287289585 auc 0.990640202096 0.986787289249\n",
      "1\n",
      "ls 0.0181459976463 0.0212031192905 auc 0.994183115299 0.9901245092\n",
      "2\n",
      "ls 0.0385042516834 0.0414056936928 auc 0.995323264863 0.993885984878\n",
      "3\n",
      "ls 0.00500992350597 0.00698838701975 auc 0.998601585028 0.99532175669\n",
      "4\n",
      "ls 0.0523577608957 0.056795429532 auc 0.990674412211 0.988918500592\n",
      "5\n",
      "ls 0.0159370665686 0.0184819075003 auc 0.994201415114 0.988443168573\n",
      "this fold avg train 0.0332405329662 avg val 0.0375005443323\n",
      "this fold auc train 0.993937332435 auc val 0.99058020153\n",
      "========================\n",
      "0\n",
      "ls 0.0704461330111 0.0783056457516 auc 0.990356175987 0.987336465026\n",
      "1\n",
      "ls 0.0183863729345 0.021318960761 auc 0.993831844068 0.991474813689\n",
      "2\n",
      "ls 0.0372386102738 0.0400617270764 auc 0.99570668572 0.994544880242\n",
      "3\n",
      "ls 0.00518614867081 0.00585262937964 auc 0.998500881498 0.993222022274\n",
      "4\n",
      "ls 0.0497882110968 0.0549001255711 auc 0.991739869048 0.98954300872\n",
      "5\n",
      "ls 0.0148875066305 0.0184325604522 auc 0.995082071688 0.992415488125\n",
      "this fold avg train 0.0326554971029 avg val 0.0364786081653\n",
      "this fold auc train 0.994202921335 auc val 0.991422779679\n",
      "========================\n",
      "0\n",
      "ls 0.071009927753 0.0782555171544 auc 0.990139663345 0.987547750591\n",
      "1\n",
      "ls 0.0182539644853 0.0218797024796 auc 0.994067459967 0.989817382891\n",
      "2\n",
      "ls 0.0357355900411 0.0418789305134 auc 0.99605614883 0.994059537047\n",
      "3\n",
      "ls 0.00492509993612 0.00817362293825 auc 0.99845908979 0.992587294268\n",
      "4\n",
      "ls 0.0480703514219 0.0560027582382 auc 0.992356404796 0.989173491155\n",
      "5\n",
      "ls 0.0160692582515 0.019106836216 auc 0.994166094417 0.985775102019\n",
      "this fold avg train 0.0323440319815 avg val 0.0375495612567\n",
      "this fold auc train 0.994207476858 auc val 0.989826759662\n",
      "========================\n",
      "all loss avg 0.0329060263017 0.0368805680178\n",
      "all auc avg 0.994121643996 0.990540544944\n",
      "=======================================================\n",
      "../results/lgb_csv_fold5_0.05_0.7_0.8.gz\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.997816      0.273263  0.969912  0.205670  0.900907   \n",
      "1  0000247867823ef7  0.000159      0.000044  0.000096  0.000057  0.000049   \n",
      "2  00013b17ad220c46  0.000545      0.000046  0.000323  0.000072  0.000434   \n",
      "3  00017563c3f7919a  0.000219      0.000044  0.000096  0.000055  0.000056   \n",
      "4  00017695ad8997eb  0.005039      0.000066  0.000530  0.000068  0.000570   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.503922  \n",
      "1       0.000080  \n",
      "2       0.000168  \n",
      "3       0.000087  \n",
      "4       0.000140  \n",
      "save done\n",
      "0\n",
      "ls 0.0705129503685 0.0781068809288 auc 0.990401546061 0.987031118706\n",
      "1\n",
      "ls 0.0183752087495 0.0199936595233 auc 0.993846258851 0.992935022287\n",
      "2\n",
      "ls 0.0371186732327 0.039509276422 auc 0.995764921062 0.994467809553\n",
      "3\n",
      "ls 0.00513539893451 0.00743031281431 auc 0.998303564945 0.994957434248\n",
      "4\n",
      "ls 0.0517348938112 0.0540101153694 auc 0.99111055115 0.989059416709\n",
      "5\n",
      "ls 0.0158940783294 0.0184549960289 auc 0.994533510643 0.986421272534\n",
      "this fold avg train 0.0331285339043 avg val 0.0362508735145\n",
      "this fold auc train 0.993993392119 auc val 0.990812012339\n",
      "========================\n",
      "0\n",
      "ls 0.0713834451895 0.079312526292 auc 0.990112879855 0.986169956946\n",
      "1\n",
      "ls 0.0183438102665 0.019517000169 auc 0.994082409561 0.992157970661\n",
      "2\n",
      "ls 0.0374651812012 0.0417823867881 auc 0.995583581381 0.994322637928\n",
      "3\n",
      "ls 0.00528537995826 0.00732377781427 auc 0.998257968763 0.988344678176\n",
      "4\n",
      "ls 0.0507680824953 0.05469743327 auc 0.991502375619 0.98876552414\n",
      "5\n",
      "ls 0.0149530388434 0.0172800542765 auc 0.995382899372 0.9898234362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this fold avg train 0.0330331563257 avg val 0.036652196435\n",
      "this fold auc train 0.994153685759 auc val 0.989930700675\n",
      "========================\n",
      "0\n",
      "ls 0.0680556047657 0.080029984193 auc 0.99114490849 0.986840765025\n",
      "1\n",
      "ls 0.0181234446655 0.0213300968037 auc 0.99419699418 0.989918896738\n",
      "2\n",
      "ls 0.0385151306695 0.0413620648733 auc 0.99531766085 0.993961496061\n",
      "3\n",
      "ls 0.00492984443482 0.00694799787544 auc 0.998658262734 0.995307046284\n",
      "4\n",
      "ls 0.0521200080303 0.0568299355525 auc 0.990778877086 0.988813454577\n",
      "5\n",
      "ls 0.0160454423024 0.0185734675518 auc 0.994043922869 0.988469288511\n",
      "this fold avg train 0.0329649124781 avg val 0.0375122578083\n",
      "this fold auc train 0.994023437701 auc val 0.990551824533\n",
      "========================\n",
      "0\n",
      "ls 0.0718391246056 0.0783763336007 auc 0.989888200213 0.98727150672\n",
      "1\n",
      "ls 0.0181693759993 0.0213272951438 auc 0.994008037147 0.991458131641\n",
      "2\n",
      "ls 0.0376469422762 0.0400071679387 auc 0.995600998904 0.994559415005\n",
      "3\n",
      "ls 0.00545605317474 0.00580313720539 auc 0.998283064851 0.993717319707\n",
      "4\n",
      "ls 0.0489124967526 0.0547231399595 auc 0.992072765987 0.989637421752\n",
      "5\n",
      "ls 0.0152595621398 0.0184550908749 auc 0.994734866834 0.992360705508\n",
      "this fold avg train 0.0328805924914 avg val 0.0364486941205\n",
      "this fold auc train 0.994097988989 auc val 0.991500750055\n",
      "========================\n",
      "0\n",
      "ls 0.0713036144479 0.0783834984659 auc 0.990019619948 0.987507758122\n",
      "1\n",
      "ls 0.0182378597306 0.021882224045 auc 0.994089320807 0.989807405466\n",
      "2\n",
      "ls 0.0365885804649 0.0419042609557 auc 0.995840476652 0.994034683303\n",
      "3\n",
      "ls 0.00493271314036 0.00819178918627 auc 0.998451934222 0.992260952394\n",
      "4\n",
      "ls 0.0494398609857 0.0561001414421 auc 0.991839993538 0.989157381247\n",
      "5\n",
      "ls 0.0159178820491 0.0190952845916 auc 0.994274454874 0.985146986471\n",
      "this fold avg train 0.0327367518031 avg val 0.0375928664478\n",
      "this fold auc train 0.994085966674 auc val 0.989652527834\n",
      "========================\n",
      "all loss avg 0.0329487894005 0.0368913776652\n",
      "all auc avg 0.994070894248 0.990489563087\n",
      "=======================================================\n",
      "../results/lgb_csv_fold5_0.05_0.8_0.8.gz\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.998134      0.268834  0.966713  0.208243  0.897699   \n",
      "1  0000247867823ef7  0.000156      0.000038  0.000096  0.000062  0.000040   \n",
      "2  00013b17ad220c46  0.000486      0.000040  0.000295  0.000076  0.000431   \n",
      "3  00017563c3f7919a  0.000225      0.000039  0.000106  0.000059  0.000052   \n",
      "4  00017695ad8997eb  0.004642      0.000063  0.000520  0.000078  0.000566   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.491377  \n",
      "1       0.000081  \n",
      "2       0.000161  \n",
      "3       0.000083  \n",
      "4       0.000134  \n",
      "save done\n",
      "CPU times: user 1h 47min 43s, sys: 3.31 s, total: 1h 47min 46s\n",
      "Wall time: 14min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# adj lr, feat_frac, bag_frac\n",
    "for lr in [0.05]:\n",
    "    for c1 in [0.6,0.7,0.8]:\n",
    "        lgb_res = simple_ens('lgb',5,233,lr,c1)\n",
    "        sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "        sample_submission[list_classes] = lgb_res\n",
    "        fname = \"../results/lgb_csv_fold5_{}_{}_{}.gz\".format(lr,c1)\n",
    "        sample_submission.to_csv(fname, index=False, compression='gzip')\n",
    "        print(fname)\n",
    "        print(sample_submission.head())\n",
    "        print('save done')\n",
    "\n",
    "# lr, feat_frac, bag_frac, bag_freq=40\n",
    "# 0.03   0.7   0.7       all loss avg 0.0322530666235 0.0369762464226 all auc avg 0.994271044586 0.990285134782\n",
    "# 0.03   0.7   0.8       all loss avg 0.0322971080147 0.0369559723174 all auc avg 0.994334369995 0.990306416634\n",
    "# 0.03   0.8   0.7       all loss avg 0.0322229511884 0.0369948009383 all auc avg 0.994234840050 0.990368331216\n",
    "# 0.03   0.8   0.8       all loss avg 0.0324206645596 0.0369651316109 all auc avg 0.994257933028 0.990295813203\n",
    "# 0.05   0.7   0.7       all loss avg 0.0318163169078 0.0370403091733 all auc avg 0.994337086137 0.990254302965\n",
    "\n",
    "# bag_freq = 3\n",
    "# 0.05   0.6   0.6       all loss avg 0.0329345052647 0.0368498383873 all auc avg 0.9939819323 0.990664190969\n",
    "# 0.05   0.6   0.7       all loss avg 0.0326017869132 0.0368044492709 all auc avg 0.994163898916 0.990696436189\n",
    "# 0.05   0.6   0.8       all loss avg 0.0324589992208 0.0368163370811 all auc avg 0.994233438434 0.990618323557\n",
    "# 0.05   0.7   0.6       all loss avg 0.0331541550186 0.0368670775083 all auc avg 0.993940708877 0.990597573572\n",
    "# 0.05   0.7   0.7       all loss avg 0.0325753698442 0.0368285766463 all auc avg 0.994218398119 0.990663705936\n",
    "# 0.05   0.7   0.8       all loss avg 0.0325779317956 0.0368281454058 all auc avg 0.994220915054 0.990630132284\n",
    "# 0.05   0.8   0.6       all loss avg 0.0333336885412 0.0368817399664 all auc avg 0.993874933751 0.990630976344\n",
    "# 0.05   0.8   0.7       all loss avg 0.0329593178033 0.0368484307605 all auc avg 0.994000316129 0.99065277921\n",
    "# 0.05   0.8   0.8       all loss avg 0.0328682234385 0.0368555923112 all auc avg 0.994090826609 0.990708113059\n",
    "\n",
    "# rm bagging\n",
    "# 0.05   0.6             all loss avg 0.0328499864930 0.0368782748851 all auc avg 0.994090121326 0.990573017994        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check bag freq, lr 0.03, feat_frac 0.7, bag_frac 0.8\n",
    "# lgb_res1 = simple_ens('lgb',5,233,0.05,0.7,0.8,3)\n",
    "# 10 all loss avg 0.0320961395694 0.036894249837 all auc avg 0.994414864008 0.99045512745\n",
    "# lgb_res2 = simple_ens('lgb',5,233,0.03,0.7,0.8,20)\n",
    "# 20 all loss avg 0.0323257411629 0.0369172677966 all auc avg 0.994317193818 0.990356748918\n",
    "# 40 all loss avg 0.0322971080147 0.0369559723174 all auc avg 0.994334369995 0.990306416634\n",
    "\n",
    "# bag freq=10, rm num_leaves, max_depth=3\n",
    "# all loss avg 0.0331234951497 0.0368040058292 all auc avg 0.993925024791 0.990579738086\n",
    "# bag freq=3, rm num_leaves, max_depth=3\n",
    "# all loss avg 0.0326936843064 0.0367777223524 all auc avg 0.994060646688 0.990669971757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0693102628764 0.0777278542208 auc 0.990750411391 0.987690741101\n",
      "1\n",
      "ls 0.0183214481094 0.0206710347901 auc 0.993922795985 0.992141438093\n",
      "2\n",
      "ls 0.0379091966012 0.0422304253354 auc 0.995484883071 0.993976383034\n",
      "3\n",
      "ls 0.00509222887455 0.00744022050828 auc 0.998356447514 0.996955415566\n",
      "4\n",
      "ls 0.0515478078909 0.0583790529388 auc 0.991102953314 0.987047805961\n",
      "5\n",
      "ls 0.0155465215984 0.0197011010212 auc 0.994714916624 0.988617680536\n",
      "this fold avg train 0.0329545776585 avg val 0.0376916148024\n",
      "this fold auc train 0.994055401316 auc val 0.991071577382\n",
      "========================\n",
      "0\n",
      "ls 0.0727526224745 0.0779744824369 auc 0.98960674163 0.986463238751\n",
      "1\n",
      "ls 0.0184661881181 0.0195785571947 auc 0.993802622465 0.993344153997\n",
      "2\n",
      "ls 0.0370395201329 0.0367886607131 auc 0.995762177344 0.995203606844\n",
      "3\n",
      "ls 0.00509454876836 0.00743725735609 auc 0.998429106671 0.992267614243\n",
      "4\n",
      "ls 0.0512217604669 0.0493441278276 auc 0.991260835117 0.991461572804\n",
      "5\n",
      "ls 0.0162239006901 0.0169449865758 auc 0.994150553194 0.988087495527\n",
      "this fold avg train 0.0334664234418 avg val 0.0346780120174\n",
      "this fold auc train 0.993835339403 auc val 0.991137947028\n",
      "========================\n",
      "0\n",
      "ls 0.0677173113844 0.0752305245922 auc 0.991368369408 0.987385641079\n",
      "1\n",
      "ls 0.0186936260308 0.0185348836088 auc 0.993767143121 0.992316133636\n",
      "2\n",
      "ls 0.0377543725603 0.0405971331832 auc 0.995481491371 0.995144031674\n",
      "3\n",
      "ls 0.00532493815946 0.00782684507705 auc 0.998216496979 0.982737788395\n",
      "4\n",
      "ls 0.052307852761 0.0546135529521 auc 0.990819018167 0.989014471048\n",
      "5\n",
      "ls 0.0158027895988 0.0189137894559 auc 0.994472473801 0.988498495105\n",
      "this fold avg train 0.0329334817491 avg val 0.0359527881449\n",
      "this fold auc train 0.994020832141 auc val 0.989182760156\n",
      "========================\n",
      "0\n",
      "ls 0.074324694653 0.0831790988694 auc 0.988935812715 0.98541810824\n",
      "1\n",
      "ls 0.0178675277284 0.0202497632515 auc 0.9943497796 0.992359450005\n",
      "2\n",
      "ls 0.0380562726922 0.0428500326022 auc 0.995466555214 0.993543092669\n",
      "3\n",
      "ls 0.00518962565946 0.00680075168931 auc 0.998373329501 0.993791525511\n",
      "4\n",
      "ls 0.0495761210301 0.0548972109751 auc 0.991899157685 0.988460998908\n",
      "5\n",
      "ls 0.0159171464001 0.0158012125979 auc 0.994473594951 0.991630885479\n",
      "this fold avg train 0.0334885646939 avg val 0.0372963449976\n",
      "this fold auc train 0.993916371611 auc val 0.990867343469\n",
      "========================\n",
      "0\n",
      "ls 0.0719980384818 0.0796151066254 auc 0.989787574023 0.987454028431\n",
      "1\n",
      "ls 0.0185531137018 0.0213210052018 auc 0.993768306551 0.990839830433\n",
      "2\n",
      "ls 0.038164695654 0.0385251883502 auc 0.995461794997 0.994402190054\n",
      "3\n",
      "ls 0.00470136498075 0.00723875224948 auc 0.998747587002 0.995447923389\n",
      "4\n",
      "ls 0.0520491818598 0.0551376564219 auc 0.990844467126 0.989671111656\n",
      "5\n",
      "ls 0.0162897799247 0.0188387735216 auc 0.993741828008 0.986363181766\n",
      "this fold avg train 0.0336260291005 avg val 0.0367794137284\n",
      "this fold auc train 0.993725259618 auc val 0.990696377622\n",
      "========================\n",
      "0\n",
      "ls 0.0729036268916 0.0804097740931 auc 0.989450568966 0.985986800841\n",
      "1\n",
      "ls 0.0187418969619 0.0210090910758 auc 0.993683143274 0.989326293226\n",
      "2\n",
      "ls 0.0373131819262 0.043880755782 auc 0.995600106023 0.993726271343\n",
      "3\n",
      "ls 0.00470116226461 0.00652301854008 auc 0.998812003174 0.99531994189\n",
      "4\n",
      "ls 0.050610269678 0.0578401040486 auc 0.991381806598 0.988382716852\n",
      "5\n",
      "ls 0.0160320221021 0.0175126805441 auc 0.994171078873 0.991725620873\n",
      "this fold avg train 0.033383693304 avg val 0.0378625706806\n",
      "this fold auc train 0.993849784485 auc val 0.990744607504\n",
      "========================\n",
      "0\n",
      "ls 0.072772872499 0.0796698209267 auc 0.989542080673 0.98676509355\n",
      "1\n",
      "ls 0.018578255033 0.0224970596024 auc 0.993657064737 0.991161983891\n",
      "2\n",
      "ls 0.0361213700044 0.0366869258228 auc 0.995969130457 0.995686772626\n",
      "3\n",
      "ls 0.00501531164589 0.00533290708741 auc 0.998556336514 0.992935201967\n",
      "4\n",
      "ls 0.0497203360588 0.0519716023688 auc 0.991802166601 0.991050829443\n",
      "5\n",
      "ls 0.0159285385621 0.0192717642327 auc 0.994149257297 0.992368528372\n",
      "this fold avg train 0.0330227806339 avg val 0.0359050133401\n",
      "this fold auc train 0.993946006047 auc val 0.991661401642\n",
      "========================\n",
      "0\n",
      "ls 0.0711835282205 0.0768450171639 auc 0.990133154555 0.98788681772\n",
      "1\n",
      "ls 0.0184661954964 0.0199475717679 auc 0.993859844661 0.991631420351\n",
      "2\n",
      "ls 0.0341481366318 0.0424719925337 auc 0.996475014857 0.993890053695\n",
      "3\n",
      "ls 0.00484097514658 0.0062699912458 auc 0.998696324368 0.994347634189\n",
      "4\n",
      "ls 0.0519320256617 0.0578279089938 auc 0.990894729984 0.987953142301\n",
      "5\n",
      "ls 0.0145711302787 0.0171980259625 auc 0.995505526792 0.993227267298\n",
      "this fold avg train 0.0325236652393 avg val 0.0367600846113\n",
      "this fold auc train 0.994260765869 auc val 0.991489389259\n",
      "========================\n",
      "0\n",
      "ls 0.0690110314857 0.079759168722 auc 0.990864526178 0.986766930094\n",
      "1\n",
      "ls 0.0187473867794 0.0214486223955 auc 0.993661315448 0.989707691536\n",
      "2\n",
      "ls 0.0371051053399 0.0440693959142 auc 0.995715625057 0.992985339917\n",
      "3\n",
      "ls 0.00531662287961 0.00926772813277 auc 0.998054218238 0.988931920997\n",
      "4\n",
      "ls 0.0496888950884 0.0543474430444 auc 0.991842867235 0.989230935644\n",
      "5\n",
      "ls 0.0160998570313 0.0193478528462 auc 0.994108512445 0.979296264466\n",
      "this fold avg train 0.0326614831007 avg val 0.0380400351759\n",
      "this fold auc train 0.994041177434 auc val 0.987819847109\n",
      "========================\n",
      "0\n",
      "ls 0.0729702128464 0.0764133285492 auc 0.989405980809 0.988471615452\n",
      "1\n",
      "ls 0.0184657236666 0.0223398541674 auc 0.993854679383 0.989918971957\n",
      "2\n",
      "ls 0.0375929670921 0.0399729631844 auc 0.995545882789 0.994820854123\n",
      "3\n",
      "ls 0.00415803301297 0.0069194538966 auc 0.999120211759 0.996309198896\n",
      "4\n",
      "ls 0.0470211533809 0.0578701718519 auc 0.992733652946 0.988998276263\n",
      "5\n",
      "ls 0.0161331227075 0.0187395710217 auc 0.994072991782 0.988427975212\n",
      "this fold avg train 0.0327235354511 avg val 0.0370425571119\n",
      "this fold auc train 0.994122233245 auc val 0.991157815317\n",
      "========================\n",
      "all loss avg 0.0330784234373 0.036800843461\n",
      "all auc avg 0.993977317117 0.990582906649\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.998340      0.271074  0.966814  0.232140  0.893202   \n",
      "1  0000247867823ef7  0.000145      0.000050  0.000068  0.000039  0.000033   \n",
      "2  00013b17ad220c46  0.000488      0.000052  0.000189  0.000057  0.000474   \n",
      "3  00017563c3f7919a  0.000231      0.000051  0.000076  0.000040  0.000036   \n",
      "4  00017695ad8997eb  0.005150      0.000064  0.000531  0.000053  0.000493   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.483927  \n",
      "1       0.000067  \n",
      "2       0.000179  \n",
      "3       0.000068  \n",
      "4       0.000102  \n",
      "save done\n",
      "CPU times: user 1h 23min 29s, sys: 5.49 s, total: 1h 23min 35s\n",
      "Wall time: 11min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_res = simple_ens('lgb',10,233,0.05,0.6)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# all loss avg 0.0335311567862 0.036750116241\n",
    "# all auc avg 0.993683089291 0.990779711364 PUB 9862\n",
    "\n",
    "# change params lr to 0.05, rnd 42\n",
    "# all loss avg 0.0331165975108 0.036782889115 all auc avg 0.993888891968 0.99078987792\n",
    "\n",
    "# rm bagging, rnd 233\n",
    "# all loss avg 0.0330784234373 0.036800843461 all auc avg 0.993977317117 0.990582906649"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lgb_res = simple_ens('lgb',10,42,0.03,0.8,0.7,3,'auc')\n",
    "# sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "# sample_submission[list_classes] = lgb_res\n",
    "# sample_submission.to_csv(\"../results/lgb_auc_csv_fold10.gz\", index=False, compression='gzip')\n",
    "# print(sample_submission.head())\n",
    "# print('save done')\n",
    "\n",
    "# all loss avg 0.0618597313284 0.0645588610375\n",
    "# all auc avg 0.990260124 0.990006850107 PUB 9862"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
