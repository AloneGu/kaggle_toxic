{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/glove_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 16) (153164, 16)\n",
      "file path ../features/pool_gru_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/tfidf_feat1.pkl\n",
      "(159571, 30) (153164, 30)\n",
      "file path ../features/tfidf_feat2.pkl\n",
      "(159571, 30) (153164, 30)\n",
      "(159571, 262)\n",
      "(159571, 262)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss'):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        d_test = test_x\n",
    "        \n",
    "        # share params\n",
    "        params = {\n",
    "                'application': 'binary',\n",
    "                #'num_leaves': 8,\n",
    "                #'lambda_l1': 1,\n",
    "                'lambda_l2': 1.2,\n",
    "                'max_depth': 3,\n",
    "                'scale_pos_weight':0.9,\n",
    "                'metric': met, # or auc\n",
    "                'data_random_seed': 2,\n",
    "                'learning_rate':lr,\n",
    "#                 'bagging_fraction': bagging_fraction,\n",
    "#                 'bagging_freq':bag_frec,\n",
    "                'feature_fraction': feature_fraction,\n",
    "            \n",
    "                }\n",
    "        if met == 'auc':\n",
    "            s_round = 100\n",
    "        else:\n",
    "            s_round = 50\n",
    "        # train for each class\n",
    "        for i in range(6):\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(i)\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg 6 class\n",
    "        train_loss_l = train_loss_l/6\n",
    "        val_loss_l = val_loss_l/6\n",
    "        train_auc_l = train_auc_l/6\n",
    "        val_auc_l = val_auc_l/6\n",
    "        print('this fold avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this fold auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg k fold\n",
    "        all_train_loss_l += train_loss_l/k\n",
    "        all_val_loss_l += val_loss_l/k\n",
    "        all_train_auc_l += train_auc_l/k\n",
    "        all_val_auc_l += val_auc_l/k\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0715756263364 0.0778918992813 auc 0.990044174728 0.987115901447\n",
      "1\n",
      "ls 0.0183406987171 0.0200192823683 auc 0.993882999672 0.992897558441\n",
      "2\n",
      "ls 0.0360643999099 0.0395503089266 auc 0.996025734909 0.994474435122\n",
      "3\n",
      "ls 0.00492291524905 0.00739562627481 auc 0.998516726113 0.995068637349\n",
      "4\n",
      "ls 0.0521875531828 0.0539351974535 auc 0.990922087735 0.989088400946\n",
      "5\n",
      "ls 0.0159414040964 0.0184446938637 auc 0.994458410342 0.987025937713\n",
      "this fold avg train 0.0331720995819 avg val 0.036206168028\n",
      "this fold auc train 0.99397502225 auc val 0.99094514517\n",
      "========================\n",
      "0\n",
      "ls 0.0717912915926 0.0793601066039 auc 0.989945429095 0.986210083352\n",
      "1\n",
      "ls 0.018485220253 0.0194687940123 auc 0.993962349104 0.99222646\n",
      "2\n",
      "ls 0.0345804837778 0.04162096936 auc 0.996309288835 0.994417816128\n",
      "3\n",
      "ls 0.00527103314331 0.00727455757059 auc 0.998300241738 0.988273299277\n",
      "4\n",
      "ls 0.0491005959018 0.0546654128942 auc 0.992157536817 0.9888137062\n",
      "5\n",
      "ls 0.014993066048 0.0172407853217 auc 0.995351668993 0.990100990954\n",
      "this fold avg train 0.0323702817861 avg val 0.0366051042938\n",
      "this fold auc train 0.99433775243 auc val 0.990007059318\n",
      "========================\n",
      "0\n",
      "ls 0.0689621355207 0.0799566916092 auc 0.990823990779 0.986870505023\n",
      "1\n",
      "ls 0.0182735738681 0.0212663137831 auc 0.994075170159 0.989974702909\n",
      "2\n",
      "ls 0.0385497288746 0.0413803870751 auc 0.995313949771 0.993946899176\n",
      "3\n",
      "ls 0.0049717141954 0.00698019486199 auc 0.998620061551 0.995295010498\n",
      "4\n",
      "ls 0.0506522906576 0.0567240683971 auc 0.991352289221 0.988947512908\n",
      "5\n",
      "ls 0.0159820400695 0.0186059977113 auc 0.994149040876 0.988510896925\n",
      "this fold avg train 0.032898580531 avg val 0.0374856089063\n",
      "this fold auc train 0.994055750393 auc val 0.99059092124\n",
      "========================\n",
      "0\n",
      "ls 0.0715579411696 0.07838252964 auc 0.989998205806 0.987303991544\n",
      "1\n",
      "ls 0.0178100942763 0.0212946269329 auc 0.994322546678 0.991461618849\n",
      "2\n",
      "ls 0.0380357464278 0.0400874376008 auc 0.99549209648 0.994595183842\n",
      "3\n",
      "ls 0.00528959595337 0.00581715686144 auc 0.998410160223 0.993568772919\n",
      "4\n",
      "ls 0.0514954203183 0.0549009278553 auc 0.991071396361 0.989549470528\n",
      "5\n",
      "ls 0.0157599851798 0.0184832923861 auc 0.994210234037 0.992383540327\n",
      "this fold avg train 0.0333247972208 avg val 0.0364943285461\n",
      "this fold auc train 0.993917439931 auc val 0.991477096335\n",
      "========================\n",
      "0\n",
      "ls 0.0711704065539 0.0783308703499 auc 0.990072694073 0.98750008179\n",
      "1\n",
      "ls 0.0181695202171 0.0218612560776 auc 0.994125036933 0.989825243893\n",
      "2\n",
      "ls 0.0357583494151 0.0419545685542 auc 0.996058347953 0.994021264615\n",
      "3\n",
      "ls 0.00493087278764 0.00818261016493 auc 0.998463272719 0.992946532334\n",
      "4\n",
      "ls 0.048886024126 0.0561077053463 auc 0.992044857689 0.989171212986\n",
      "5\n",
      "ls 0.0159898669717 0.0191639774151 auc 0.994223640403 0.985604871834\n",
      "this fold avg train 0.0324841733452 avg val 0.0376001646513\n",
      "this fold auc train 0.994164641628 auc val 0.989844867909\n",
      "========================\n",
      "all loss avg 0.032849986493 0.0368782748851\n",
      "all auc avg 0.994090121326 0.990573017994\n",
      "=======================================================\n",
      "../results/lgb_csv_fold5_0.05_0.6_0.8.gz\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.998146      0.274299  0.968405  0.208784  0.898199   \n",
      "1  0000247867823ef7  0.000160      0.000032  0.000097  0.000047  0.000039   \n",
      "2  00013b17ad220c46  0.000487      0.000033  0.000268  0.000064  0.000434   \n",
      "3  00017563c3f7919a  0.000223      0.000033  0.000107  0.000046  0.000040   \n",
      "4  00017695ad8997eb  0.004663      0.000053  0.000528  0.000062  0.000492   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.475894  \n",
      "1       0.000087  \n",
      "2       0.000179  \n",
      "3       0.000091  \n",
      "4       0.000124  \n",
      "save done\n",
      "0\n",
      "ls 0.0710038844185 0.0779531160866 auc 0.99022788244 0.98709841515\n",
      "1\n",
      "ls 0.0183469135514 0.0199932646174 auc 0.993861878637 0.992921900433\n",
      "2\n",
      "ls 0.0364980637042 0.0394828095802 auc 0.995912973059 0.994477648124\n",
      "3\n",
      "ls 0.00493873101357 0.00737018701346 auc 0.998506725225 0.994767632096\n",
      "4\n",
      "ls 0.0525913437446 0.0540199773464 auc 0.990772486462 0.989041070642\n",
      "5\n",
      "ls 0.0157168311232 0.0184957204363 auc 0.994718535452 0.986485897808\n",
      "this fold avg train 0.0331826279259 avg val 0.0362191791801\n",
      "this fold auc train 0.994000080213 auc val 0.990798760709\n",
      "========================\n",
      "0\n",
      "ls 0.0734069799273 0.0794999213829 auc 0.989382670565 0.986107824253\n",
      "1\n",
      "ls 0.0183254805886 0.0195296494555 auc 0.994095753015 0.992144502483\n",
      "2\n",
      "ls 0.0369054512276 0.0416369207809 auc 0.995735817765 0.994376441078\n",
      "3\n",
      "ls 0.00536172093223 0.00734491037656 auc 0.998185883724 0.988681178705\n",
      "4\n",
      "ls 0.0517720845398 0.0547121613577 auc 0.991131371513 0.988727069687\n",
      "5\n",
      "ls 0.0128729319768 0.0172061195749 auc 0.99703095826 0.990408322624\n",
      "this fold avg train 0.033107441532 avg val 0.0366549471547\n",
      "this fold auc train 0.99426040914 auc val 0.990074223138\n",
      "========================\n",
      "0\n",
      "ls 0.0694881974974 0.0801287289585 auc 0.990640202096 0.986787289249\n",
      "1\n",
      "ls 0.0181459976463 0.0212031192905 auc 0.994183115299 0.9901245092\n",
      "2\n",
      "ls 0.0385042516834 0.0414056936928 auc 0.995323264863 0.993885984878\n",
      "3\n",
      "ls 0.00500992350597 0.00698838701975 auc 0.998601585028 0.99532175669\n",
      "4\n",
      "ls 0.0523577608957 0.056795429532 auc 0.990674412211 0.988918500592\n",
      "5\n",
      "ls 0.0159370665686 0.0184819075003 auc 0.994201415114 0.988443168573\n",
      "this fold avg train 0.0332405329662 avg val 0.0375005443323\n",
      "this fold auc train 0.993937332435 auc val 0.99058020153\n",
      "========================\n",
      "0\n",
      "ls 0.0704461330111 0.0783056457516 auc 0.990356175987 0.987336465026\n",
      "1\n",
      "ls 0.0183863729345 0.021318960761 auc 0.993831844068 0.991474813689\n",
      "2\n",
      "ls 0.0372386102738 0.0400617270764 auc 0.99570668572 0.994544880242\n",
      "3\n",
      "ls 0.00518614867081 0.00585262937964 auc 0.998500881498 0.993222022274\n",
      "4\n",
      "ls 0.0497882110968 0.0549001255711 auc 0.991739869048 0.98954300872\n",
      "5\n",
      "ls 0.0148875066305 0.0184325604522 auc 0.995082071688 0.992415488125\n",
      "this fold avg train 0.0326554971029 avg val 0.0364786081653\n",
      "this fold auc train 0.994202921335 auc val 0.991422779679\n",
      "========================\n",
      "0\n",
      "ls 0.071009927753 0.0782555171544 auc 0.990139663345 0.987547750591\n",
      "1\n",
      "ls 0.0182539644853 0.0218797024796 auc 0.994067459967 0.989817382891\n",
      "2\n",
      "ls 0.0357355900411 0.0418789305134 auc 0.99605614883 0.994059537047\n",
      "3\n",
      "ls 0.00492509993612 0.00817362293825 auc 0.99845908979 0.992587294268\n",
      "4\n",
      "ls 0.0480703514219 0.0560027582382 auc 0.992356404796 0.989173491155\n",
      "5\n",
      "ls 0.0160692582515 0.019106836216 auc 0.994166094417 0.985775102019\n",
      "this fold avg train 0.0323440319815 avg val 0.0375495612567\n",
      "this fold auc train 0.994207476858 auc val 0.989826759662\n",
      "========================\n",
      "all loss avg 0.0329060263017 0.0368805680178\n",
      "all auc avg 0.994121643996 0.990540544944\n",
      "=======================================================\n",
      "../results/lgb_csv_fold5_0.05_0.7_0.8.gz\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.997816      0.273263  0.969912  0.205670  0.900907   \n",
      "1  0000247867823ef7  0.000159      0.000044  0.000096  0.000057  0.000049   \n",
      "2  00013b17ad220c46  0.000545      0.000046  0.000323  0.000072  0.000434   \n",
      "3  00017563c3f7919a  0.000219      0.000044  0.000096  0.000055  0.000056   \n",
      "4  00017695ad8997eb  0.005039      0.000066  0.000530  0.000068  0.000570   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.503922  \n",
      "1       0.000080  \n",
      "2       0.000168  \n",
      "3       0.000087  \n",
      "4       0.000140  \n",
      "save done\n",
      "0\n",
      "ls 0.0705129503685 0.0781068809288 auc 0.990401546061 0.987031118706\n",
      "1\n",
      "ls 0.0183752087495 0.0199936595233 auc 0.993846258851 0.992935022287\n",
      "2\n",
      "ls 0.0371186732327 0.039509276422 auc 0.995764921062 0.994467809553\n",
      "3\n",
      "ls 0.00513539893451 0.00743031281431 auc 0.998303564945 0.994957434248\n",
      "4\n",
      "ls 0.0517348938112 0.0540101153694 auc 0.99111055115 0.989059416709\n",
      "5\n",
      "ls 0.0158940783294 0.0184549960289 auc 0.994533510643 0.986421272534\n",
      "this fold avg train 0.0331285339043 avg val 0.0362508735145\n",
      "this fold auc train 0.993993392119 auc val 0.990812012339\n",
      "========================\n",
      "0\n",
      "ls 0.0713834451895 0.079312526292 auc 0.990112879855 0.986169956946\n",
      "1\n",
      "ls 0.0183438102665 0.019517000169 auc 0.994082409561 0.992157970661\n",
      "2\n",
      "ls 0.0374651812012 0.0417823867881 auc 0.995583581381 0.994322637928\n",
      "3\n",
      "ls 0.00528537995826 0.00732377781427 auc 0.998257968763 0.988344678176\n",
      "4\n",
      "ls 0.0507680824953 0.05469743327 auc 0.991502375619 0.98876552414\n",
      "5\n",
      "ls 0.0149530388434 0.0172800542765 auc 0.995382899372 0.9898234362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this fold avg train 0.0330331563257 avg val 0.036652196435\n",
      "this fold auc train 0.994153685759 auc val 0.989930700675\n",
      "========================\n",
      "0\n",
      "ls 0.0680556047657 0.080029984193 auc 0.99114490849 0.986840765025\n",
      "1\n",
      "ls 0.0181234446655 0.0213300968037 auc 0.99419699418 0.989918896738\n",
      "2\n",
      "ls 0.0385151306695 0.0413620648733 auc 0.99531766085 0.993961496061\n",
      "3\n",
      "ls 0.00492984443482 0.00694799787544 auc 0.998658262734 0.995307046284\n",
      "4\n",
      "ls 0.0521200080303 0.0568299355525 auc 0.990778877086 0.988813454577\n",
      "5\n",
      "ls 0.0160454423024 0.0185734675518 auc 0.994043922869 0.988469288511\n",
      "this fold avg train 0.0329649124781 avg val 0.0375122578083\n",
      "this fold auc train 0.994023437701 auc val 0.990551824533\n",
      "========================\n",
      "0\n",
      "ls 0.0718391246056 0.0783763336007 auc 0.989888200213 0.98727150672\n",
      "1\n",
      "ls 0.0181693759993 0.0213272951438 auc 0.994008037147 0.991458131641\n",
      "2\n",
      "ls 0.0376469422762 0.0400071679387 auc 0.995600998904 0.994559415005\n",
      "3\n",
      "ls 0.00545605317474 0.00580313720539 auc 0.998283064851 0.993717319707\n",
      "4\n",
      "ls 0.0489124967526 0.0547231399595 auc 0.992072765987 0.989637421752\n",
      "5\n",
      "ls 0.0152595621398 0.0184550908749 auc 0.994734866834 0.992360705508\n",
      "this fold avg train 0.0328805924914 avg val 0.0364486941205\n",
      "this fold auc train 0.994097988989 auc val 0.991500750055\n",
      "========================\n",
      "0\n",
      "ls 0.0713036144479 0.0783834984659 auc 0.990019619948 0.987507758122\n",
      "1\n",
      "ls 0.0182378597306 0.021882224045 auc 0.994089320807 0.989807405466\n",
      "2\n",
      "ls 0.0365885804649 0.0419042609557 auc 0.995840476652 0.994034683303\n",
      "3\n",
      "ls 0.00493271314036 0.00819178918627 auc 0.998451934222 0.992260952394\n",
      "4\n",
      "ls 0.0494398609857 0.0561001414421 auc 0.991839993538 0.989157381247\n",
      "5\n",
      "ls 0.0159178820491 0.0190952845916 auc 0.994274454874 0.985146986471\n",
      "this fold avg train 0.0327367518031 avg val 0.0375928664478\n",
      "this fold auc train 0.994085966674 auc val 0.989652527834\n",
      "========================\n",
      "all loss avg 0.0329487894005 0.0368913776652\n",
      "all auc avg 0.994070894248 0.990489563087\n",
      "=======================================================\n",
      "../results/lgb_csv_fold5_0.05_0.8_0.8.gz\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.998134      0.268834  0.966713  0.208243  0.897699   \n",
      "1  0000247867823ef7  0.000156      0.000038  0.000096  0.000062  0.000040   \n",
      "2  00013b17ad220c46  0.000486      0.000040  0.000295  0.000076  0.000431   \n",
      "3  00017563c3f7919a  0.000225      0.000039  0.000106  0.000059  0.000052   \n",
      "4  00017695ad8997eb  0.004642      0.000063  0.000520  0.000078  0.000566   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.491377  \n",
      "1       0.000081  \n",
      "2       0.000161  \n",
      "3       0.000083  \n",
      "4       0.000134  \n",
      "save done\n",
      "CPU times: user 1h 47min 43s, sys: 3.31 s, total: 1h 47min 46s\n",
      "Wall time: 14min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# adj lr, feat_frac, bag_frac\n",
    "for lr in [0.05]:\n",
    "    for c1 in [0.6,0.7,0.8]:\n",
    "        lgb_res = simple_ens('lgb',5,233,lr,c1)\n",
    "        sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "        sample_submission[list_classes] = lgb_res\n",
    "        fname = \"../results/lgb_csv_fold5_{}_{}_{}.gz\".format(lr,c1)\n",
    "        sample_submission.to_csv(fname, index=False, compression='gzip')\n",
    "        print(fname)\n",
    "        print(sample_submission.head())\n",
    "        print('save done')\n",
    "\n",
    "# lr, feat_frac, bag_frac, bag_freq=40\n",
    "# 0.03   0.7   0.7       all loss avg 0.0322530666235 0.0369762464226 all auc avg 0.994271044586 0.990285134782\n",
    "# 0.03   0.7   0.8       all loss avg 0.0322971080147 0.0369559723174 all auc avg 0.994334369995 0.990306416634\n",
    "# 0.03   0.8   0.7       all loss avg 0.0322229511884 0.0369948009383 all auc avg 0.994234840050 0.990368331216\n",
    "# 0.03   0.8   0.8       all loss avg 0.0324206645596 0.0369651316109 all auc avg 0.994257933028 0.990295813203\n",
    "# 0.05   0.7   0.7       all loss avg 0.0318163169078 0.0370403091733 all auc avg 0.994337086137 0.990254302965\n",
    "\n",
    "# bag_freq = 3\n",
    "# 0.05   0.6   0.6       all loss avg 0.0329345052647 0.0368498383873 all auc avg 0.9939819323 0.990664190969\n",
    "# 0.05   0.6   0.7       all loss avg 0.0326017869132 0.0368044492709 all auc avg 0.994163898916 0.990696436189\n",
    "# 0.05   0.6   0.8       all loss avg 0.0324589992208 0.0368163370811 all auc avg 0.994233438434 0.990618323557\n",
    "# 0.05   0.7   0.6       all loss avg 0.0331541550186 0.0368670775083 all auc avg 0.993940708877 0.990597573572\n",
    "# 0.05   0.7   0.7       all loss avg 0.0325753698442 0.0368285766463 all auc avg 0.994218398119 0.990663705936\n",
    "# 0.05   0.7   0.8       all loss avg 0.0325779317956 0.0368281454058 all auc avg 0.994220915054 0.990630132284\n",
    "# 0.05   0.8   0.6       all loss avg 0.0333336885412 0.0368817399664 all auc avg 0.993874933751 0.990630976344\n",
    "# 0.05   0.8   0.7       all loss avg 0.0329593178033 0.0368484307605 all auc avg 0.994000316129 0.99065277921\n",
    "# 0.05   0.8   0.8       all loss avg 0.0328682234385 0.0368555923112 all auc avg 0.994090826609 0.990708113059\n",
    "\n",
    "# rm bagging\n",
    "# 0.05   0.6             all loss avg 0.0328499864930 0.0368782748851 all auc avg 0.994090121326 0.990573017994        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check bag freq, lr 0.03, feat_frac 0.7, bag_frac 0.8\n",
    "# lgb_res1 = simple_ens('lgb',5,233,0.05,0.7,0.8,3)\n",
    "# 10 all loss avg 0.0320961395694 0.036894249837 all auc avg 0.994414864008 0.99045512745\n",
    "# lgb_res2 = simple_ens('lgb',5,233,0.03,0.7,0.8,20)\n",
    "# 20 all loss avg 0.0323257411629 0.0369172677966 all auc avg 0.994317193818 0.990356748918\n",
    "# 40 all loss avg 0.0322971080147 0.0369559723174 all auc avg 0.994334369995 0.990306416634\n",
    "\n",
    "# bag freq=10, rm num_leaves, max_depth=3\n",
    "# all loss avg 0.0331234951497 0.0368040058292 all auc avg 0.993925024791 0.990579738086\n",
    "# bag freq=3, rm num_leaves, max_depth=3\n",
    "# all loss avg 0.0326936843064 0.0367777223524 all auc avg 0.994060646688 0.990669971757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.069645024349 0.0759610723783 auc 0.990690529777 0.988526467231\n",
      "1\n",
      "ls 0.0182990215399 0.0206603745489 auc 0.993931716606 0.992192935877\n",
      "2\n",
      "ls 0.0365139244815 0.0410551587257 auc 0.995903933176 0.99395057005\n",
      "3\n",
      "ls 0.0046896333045 0.00722029264013 auc 0.998700062441 0.997388951806\n",
      "4\n",
      "ls 0.0499780229859 0.0567759176102 auc 0.991719169591 0.988069353054\n",
      "5\n",
      "ls 0.0158267439628 0.0196871885254 auc 0.994543601894 0.988712972331\n",
      "this fold avg train 0.0324920617706 avg val 0.0368933340714\n",
      "this fold auc train 0.994248168914 auc val 0.991473541725\n",
      "========================\n",
      "0\n",
      "ls 0.0691263984349 0.0774643865758 auc 0.990916371247 0.986770292943\n",
      "1\n",
      "ls 0.0180126220209 0.019269718098 auc 0.994210304914 0.993592169682\n",
      "2\n",
      "ls 0.0360659019934 0.0358204530166 auc 0.996055571372 0.995773699004\n",
      "3\n",
      "ls 0.00503408083956 0.00745776253734 auc 0.998564429872 0.992566112327\n",
      "4\n",
      "ls 0.0505256831793 0.0492018707967 auc 0.991572864189 0.991469856635\n",
      "5\n",
      "ls 0.0161379029446 0.0166401417017 auc 0.994414691582 0.986723863947\n",
      "this fold avg train 0.0324837649021 avg val 0.0343090554544\n",
      "this fold auc train 0.994289038863 auc val 0.991149332423\n",
      "========================\n",
      "0\n",
      "ls 0.0683397504554 0.0729849213315 auc 0.991199660157 0.988478715846\n",
      "1\n",
      "ls 0.0182388788847 0.0184206953971 auc 0.994155462487 0.992468772297\n",
      "2\n",
      "ls 0.0367717082371 0.0391481443159 auc 0.995832282413 0.995603690303\n",
      "3\n",
      "ls 0.00525253553209 0.00783895152971 auc 0.998395655817 0.981797321934\n",
      "4\n",
      "ls 0.0518150463784 0.0538118109731 auc 0.991060494494 0.98951983605\n",
      "5\n",
      "ls 0.0152911793675 0.0187728231197 auc 0.995085822073 0.989635686279\n",
      "this fold avg train 0.0326181831425 avg val 0.0351628911112\n",
      "this fold auc train 0.994288229574 auc val 0.989584003785\n",
      "========================\n",
      "0\n",
      "ls 0.0700779960155 0.0813452006704 auc 0.990495448564 0.986432876528\n",
      "1\n",
      "ls 0.0169066069784 0.0200462219064 auc 0.995195099302 0.99258047049\n",
      "2\n",
      "ls 0.0352896531931 0.0419945011431 auc 0.99621024796 0.994137659035\n",
      "3\n",
      "ls 0.00524133201139 0.00677615726536 auc 0.998369700606 0.99358728998\n",
      "4\n",
      "ls 0.0502469605564 0.0543633998392 auc 0.991675913814 0.988812584142\n",
      "5\n",
      "ls 0.0151717376557 0.015663336541 auc 0.995366079681 0.992044473911\n",
      "this fold avg train 0.0321557144017 avg val 0.0366981362276\n",
      "this fold auc train 0.994552081654 auc val 0.991265892348\n",
      "========================\n",
      "0\n",
      "ls 0.0713550038918 0.0785281308103 auc 0.990060714269 0.987999103713\n",
      "1\n",
      "ls 0.0177714914646 0.0210509311554 auc 0.994424863176 0.991125860393\n",
      "2\n",
      "ls 0.0352273645561 0.0374278266918 auc 0.996234199403 0.995206377867\n",
      "3\n",
      "ls 0.00482550797519 0.0070519988949 auc 0.998677075507 0.996033986941\n",
      "4\n",
      "ls 0.049921017477 0.0546799886356 auc 0.991716853872 0.989947709584\n",
      "5\n",
      "ls 0.0158282124119 0.0187413755671 auc 0.994529040682 0.987310512486\n",
      "this fold avg train 0.0324880996294 avg val 0.0362467086258\n",
      "this fold auc train 0.994273791151 auc val 0.991270591831\n",
      "========================\n",
      "0\n",
      "ls 0.0669814766541 0.0778742273962 auc 0.991550909403 0.987097737066\n",
      "1\n",
      "ls 0.0186465443084 0.0201145423317 auc 0.993789076984 0.991218650307\n",
      "2\n",
      "ls 0.0361870904382 0.0428545810145 auc 0.995974802215 0.993943063656\n",
      "3\n",
      "ls 0.00430933122614 0.00639988768394 auc 0.999108558866 0.995588118108\n",
      "4\n",
      "ls 0.0494236571716 0.0570133224635 auc 0.991873219274 0.989037070636\n",
      "5\n",
      "ls 0.0151505930116 0.0173733442021 auc 0.995260390428 0.992602301177\n",
      "this fold avg train 0.0317831154683 avg val 0.0369383175153\n",
      "this fold auc train 0.994592826195 auc val 0.991581156825\n",
      "========================\n",
      "0\n",
      "ls 0.0682911435258 0.0779415425085 auc 0.991137603963 0.987573364153\n",
      "1\n",
      "ls 0.0179762360547 0.0219013997808 auc 0.994148892874 0.991951327714\n",
      "2\n",
      "ls 0.0346990234351 0.0355990027009 auc 0.996363719823 0.995995451286\n",
      "3\n",
      "ls 0.00494236358472 0.00523455131084 auc 0.998692687065 0.991022305166\n",
      "4\n",
      "ls 0.0493595037155 0.0512062352941 auc 0.9919519509 0.991390953023\n",
      "5\n",
      "ls 0.0156196727402 0.0189093998928 auc 0.994660743561 0.993242241738\n",
      "this fold avg train 0.031814657176 avg val 0.0351320219147\n",
      "this fold auc train 0.994492599698 auc val 0.99186260718\n",
      "========================\n",
      "0\n",
      "ls 0.0681278673421 0.0752977940308 auc 0.991193858852 0.988511221583\n",
      "1\n",
      "ls 0.018461183369 0.0198688494913 auc 0.993866364218 0.991994766533\n",
      "2\n",
      "ls 0.0352780101552 0.0418412464883 auc 0.996224377743 0.994319851065\n",
      "3\n",
      "ls 0.00516459359608 0.00638413593462 auc 0.998502764152 0.994275147309\n",
      "4\n",
      "ls 0.0505244009051 0.056967057052 auc 0.991505891053 0.988452597148\n",
      "5\n",
      "ls 0.0140116822405 0.0169086978622 auc 0.996137685515 0.993549171919\n",
      "this fold avg train 0.031927956268 avg val 0.0362112968099\n",
      "this fold auc train 0.994571823589 auc val 0.99185045926\n",
      "========================\n",
      "0\n",
      "ls 0.0658560808896 0.0780296131828 auc 0.991910737654 0.987470915018\n",
      "1\n",
      "ls 0.0182788848955 0.0211428258081 auc 0.993996638172 0.990692216092\n",
      "2\n",
      "ls 0.0370658921984 0.0424850657563 auc 0.995795918085 0.993780656903\n",
      "3\n",
      "ls 0.00532122495552 0.00922041080952 auc 0.998120943789 0.99085291846\n",
      "4\n",
      "ls 0.0506414980246 0.0534856869755 auc 0.991496380763 0.989536464263\n",
      "5\n",
      "ls 0.01603904381 0.0192748724989 auc 0.994350128586 0.984809171183\n",
      "this fold avg train 0.0322004374623 avg val 0.0372730791719\n",
      "this fold auc train 0.994278457842 auc val 0.989523723653\n",
      "========================\n",
      "0\n",
      "ls 0.0687380421498 0.0743315293935 auc 0.990948590954 0.989482920335\n",
      "1\n",
      "ls 0.0181675213135 0.0222120502572 auc 0.994106702566 0.989978714313\n",
      "2\n",
      "ls 0.0370171657384 0.0389689220596 auc 0.995766210417 0.995349615676\n",
      "3\n",
      "ls 0.00396211288735 0.00682584454334 auc 0.999288740658 0.996529858014\n",
      "4\n",
      "ls 0.0517731529804 0.0576838856294 auc 0.990934097983 0.989218865291\n",
      "5\n",
      "ls 0.0154366249861 0.0184711073734 auc 0.994922535388 0.98918060566\n",
      "this fold avg train 0.0325157700093 avg val 0.0364155565428\n",
      "this fold auc train 0.994327812994 auc val 0.991623429881\n",
      "========================\n",
      "all loss avg 0.032247976023 0.0361280397445\n",
      "all auc avg 0.994391483047 0.991118473891\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999008      0.280049  0.969774  0.240840  0.912096   \n",
      "1  0000247867823ef7  0.000214      0.000036  0.000070  0.000042  0.000042   \n",
      "2  00013b17ad220c46  0.000449      0.000039  0.000224  0.000053  0.000330   \n",
      "3  00017563c3f7919a  0.000124      0.000037  0.000073  0.000041  0.000047   \n",
      "4  00017695ad8997eb  0.002259      0.000047  0.000322  0.000046  0.000393   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.479965  \n",
      "1       0.000062  \n",
      "2       0.000134  \n",
      "3       0.000066  \n",
      "4       0.000086  \n",
      "save done\n",
      "CPU times: user 1h 29min 59s, sys: 7.05 s, total: 1h 30min 6s\n",
      "Wall time: 12min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_res = simple_ens('lgb',10,233,0.05,0.6)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# all loss avg 0.0335311567862 0.036750116241\n",
    "# all auc avg 0.993683089291 0.990779711364 PUB 9862\n",
    "\n",
    "# change params lr to 0.05, rnd 42\n",
    "# all loss avg 0.0331165975108 0.036782889115 all auc avg 0.993888891968 0.99078987792\n",
    "\n",
    "# rm bagging, rnd 233\n",
    "# all loss avg 0.0330784234373 0.036800843461 all auc avg 0.993977317117 0.990582906649\n",
    "\n",
    "# fix lr, mnb feat, no bagging, rnd 233\n",
    "# all loss avg 0.032247976023 0.0361280397445 all auc avg 0.994391483047 0.991118473891"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lgb_res = simple_ens('lgb',10,42,0.03,0.8,0.7,3,'auc')\n",
    "# sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "# sample_submission[list_classes] = lgb_res\n",
    "# sample_submission.to_csv(\"../results/lgb_auc_csv_fold10.gz\", index=False, compression='gzip')\n",
    "# print(sample_submission.head())\n",
    "# print('save done')\n",
    "\n",
    "# all loss avg 0.0618597313284 0.0645588610375\n",
    "# all auc avg 0.990260124 0.990006850107 PUB 9862"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
