{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/fasttext_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 36) (153164, 36)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "(159571, 144)\n",
      "(159571, 144)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "\n",
    "feats_files = [\n",
    "#'../features/fasttext_cnn2d_4_feat.pkl',\n",
    "# '../features/fasttext_cnn_gru_4_feat.pkl',\n",
    "'../features/fasttext_cnn_v1_4_feat.pkl',\n",
    "'../features/fasttext_cnn_v2_4_feat.pkl',\n",
    "# '../features/fasttext_cudnn_gru_4_feat.pkl',\n",
    "# '../features/fasttext_gru_v1_4_feat.pkl',\n",
    "# '../features/fasttext_lstm_v1_4_feat.pkl',\n",
    "# '../features/glove_cnn2d_4_feat.pkl',\n",
    "# '../features/glove_cnn_gru_4_feat.pkl',\n",
    "# '../features/glove_cnn_v1_4_feat.pkl',\n",
    "'../features/glove_cnn_v2_4_feat.pkl',\n",
    "# '../features/glove_cudnn_gru_4_feat.pkl',\n",
    "# '../features/glove_gru_v1_4_feat.pkl',\n",
    "# '../features/glove_lstm_v1_4_feat.pkl',\n",
    "'../features/lr_feat1.pkl',\n",
    "'../features/lr_feat2.pkl',\n",
    "'../features/lstm_attention_fasttext_10_feat.pkl',\n",
    "# '../features/lstm_attention_fasttext_4_feat.pkl',\n",
    "# '../features/lstm_attention_fasttext_adj2_4_feat.pkl',\n",
    "# '../features/lstm_attention_glove_4_feat.pkl',\n",
    "'../features/mnb_feat1.pkl',\n",
    "'../features/mnb_feat2.pkl',\n",
    "'../features/muse_cnn2d_4_feat.pkl',\n",
    "# '../features/muse_cnn_gru_4_feat.pkl',\n",
    "# '../features/muse_cnn_v1_4_feat.pkl',\n",
    "# '../features/muse_cnn_v2_4_feat.pkl',\n",
    "# '../features/muse_cudnn_gru_4_feat.pkl',\n",
    "# '../features/muse_gru_v1_4_feat.pkl',\n",
    "# '../features/muse_lstm_v1_4_feat.pkl',\n",
    "'../features/no_pretrained_cnn2d_4_feat.pkl',\n",
    "'../features/no_pretrained_cnn_gru_4_feat.pkl',\n",
    "'../features/no_pretrained_cnn_v1_4_feat.pkl',\n",
    "'../features/no_pretrained_cnn_v2_4_feat.pkl',\n",
    "'../features/no_pretrained_cudnn_gru_4_feat.pkl',\n",
    "'../features/no_pretrained_gru_v1_4_feat.pkl',\n",
    "'../features/no_pretrained_lstm_v1_4_feat.pkl',\n",
    "'../features/other_feat.pkl',\n",
    "# '../features/pool_gru_fasttext_4_feat.pkl',\n",
    "'../features/pool_gru_fasttext_adj1_10_feat.pkl',\n",
    "'../features/pool_gru_fasttext_adj2_4_feat.pkl',\n",
    "# '../features/pool_gru_glove_4_feat.pkl',\n",
    "# '../features/tfidf_feat1.pkl',\n",
    "# '../features/tfidf_feat2.pkl',\n",
    "]\n",
    "\n",
    "for feat in feats_files:\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss'):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        d_test = test_x\n",
    "        \n",
    "        # share params\n",
    "        params = {\n",
    "                'application': 'binary',\n",
    "                #'num_leaves': 8,\n",
    "                #'lambda_l1': 1,\n",
    "                'lambda_l2': 1.0,\n",
    "                'max_depth': 3,\n",
    "                #'scale_pos_weight':0.9,\n",
    "                'metric': met, # or auc\n",
    "                'data_random_seed': 2,\n",
    "                'learning_rate':lr,\n",
    "#                 'bagging_fraction': bagging_fraction,\n",
    "#                 'bagging_freq':bag_frec,\n",
    "                'feature_fraction': feature_fraction,\n",
    "            \n",
    "                }\n",
    "        if met == 'auc':\n",
    "            s_round = 100\n",
    "        else:\n",
    "            s_round = 50\n",
    "        # train for each class\n",
    "        for i in range(6):\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(i)\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg 6 class\n",
    "        train_loss_l = train_loss_l/6\n",
    "        val_loss_l = val_loss_l/6\n",
    "        train_auc_l = train_auc_l/6\n",
    "        val_auc_l = val_auc_l/6\n",
    "        print('this fold avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this fold auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg k fold\n",
    "        all_train_loss_l += train_loss_l/k\n",
    "        all_val_loss_l += val_loss_l/k\n",
    "        all_train_auc_l += train_auc_l/k\n",
    "        all_val_auc_l += val_auc_l/k\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0722950327943 0.0758841402698 auc 0.98977905169 0.988408814729\n",
      "1\n",
      "ls 0.0184703904194 0.0208987212404 auc 0.993821881006 0.991894630193\n",
      "2\n",
      "ls 0.0369573838598 0.0406375909944 auc 0.995796865228 0.993841764873\n",
      "3\n",
      "ls 0.00523920755345 0.00702568399438 auc 0.998174628982 0.997425325595\n",
      "4\n",
      "ls 0.0511083035143 0.0568211730727 auc 0.99126463786 0.987573376815\n",
      "5\n",
      "ls 0.0156078672677 0.0195740668938 auc 0.994739996584 0.988401188117\n",
      "this fold avg train 0.0332796975682 avg val 0.0368068960776\n",
      "this fold auc train 0.993929510225 auc val 0.99125751672\n",
      "========================\n",
      "0\n",
      "ls 0.0711483592486 0.0779591240108 auc 0.990225803366 0.986554238704\n",
      "1\n",
      "ls 0.0168186131537 0.0191583501973 auc 0.995273894797 0.993633126401\n",
      "2\n",
      "ls 0.0365372123245 0.0350621341141 auc 0.995914639852 0.996058119891\n",
      "3\n",
      "ls 0.00528121608976 0.00732677667353 auc 0.998112242139 0.994324251755\n",
      "4\n",
      "ls 0.0512508454583 0.0492695964348 auc 0.991246449448 0.99146271844\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3276fd65437c>\u001b[0m in \u001b[0;36msimple_ens\u001b[0;34m(model_name, k, rnd, lr, feature_fraction, bagging_fraction, bag_frec, met)\u001b[0m\n\u001b[1;32m     46\u001b[0m                       \u001b[0mvalid_sets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwatchlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                       \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                       verbose_eval=None)\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    197\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1505\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1506\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "lgb_res = simple_ens('lgb',10,233,0.05,0.6)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_some_fold10.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# select feats\n",
    "# all loss avg 0.0323893274343 0.0361490549659\n",
    "# all auc avg 0.994298774643 0.991023792329\n",
    "\n",
    "# 1 fold\n",
    "# rf tfidf select feats, feat_fraction 0.6 this fold avg train 0.0324570163191 avg val 0.0365732819959\n",
    "# rf tfidf select feats, feat_fraction 0.75 this fold avg train 0.0325535548896 avg val 0.0366403197325\n",
    "# rf tfidf select feats, feat_fraction 0.5 this fold avg train 0.0328270646453 avg val 0.0366173320613\n",
    "\n",
    "# add tfidf, feat_fraction this fold avg train 0.0332796975682 avg val 0.0368068960776\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
