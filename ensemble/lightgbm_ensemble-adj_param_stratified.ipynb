{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/fasttext_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lgb1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 37) (153164, 37)\n",
      "file path ../features/pool_gru_fasttext_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/ridge_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/ridge_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/tilli_lr_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/wordbatch_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "(159571, 313)\n",
      "(159571, 313)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(14400)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat or 'tfidf' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.hstack(train_x)\n",
    "test_x = np.hstack(test_x)\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss',max_d=3):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    cls_auc_res = [0,0,0,0,0,0]\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for i in range(6):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = test_x\n",
    "\n",
    "            # share params\n",
    "            params = {\n",
    "                    'application': 'binary',\n",
    "                    #'num_leaves': 8,\n",
    "                    #'lambda_l1': 1,\n",
    "                    'lambda_l2': 1.0,\n",
    "                    'max_depth': max_d,\n",
    "                    'metric': met, # or auc\n",
    "                    'data_random_seed': 2,\n",
    "                    'learning_rate':lr,\n",
    "                    # 'bagging_fraction': bagging_fraction,\n",
    "                    # 'bagging_freq':bag_frec,\n",
    "                    'feature_fraction': feature_fraction,\n",
    "\n",
    "                    }\n",
    "            if met == 'auc':\n",
    "                s_round = 60\n",
    "            else:\n",
    "                s_round = 30\n",
    "            # train for each class\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_auc_l = train_auc_l/k\n",
    "        val_auc_l = val_auc_l/k\n",
    "        print(list_classes[i], lr, feature_fraction, max_d)\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        cls_auc_res[i] = val_auc_l\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/6\n",
    "        all_val_loss_l += val_loss_l/6\n",
    "        all_train_auc_l += train_auc_l/6\n",
    "        all_val_auc_l += val_auc_l/6\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred, cls_auc_res\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.0701461797096452 0.07801615635891698 auc 0.9906122184812396 0.9869962364393128\n",
      "1 fold: ls 0.07037840323424928 0.071295365077439 auc 0.990521975787274 0.989788057353983\n",
      "2 fold: ls 0.07094377319551964 0.07530325152593936 auc 0.9902848024854317 0.988670586060873\n",
      "3 fold: ls 0.06614382554676579 0.07264003164035851 auc 0.991893373728453 0.9894589949462828\n",
      "4 fold: ls 0.06920242084187422 0.07761195746407645 auc 0.9908886114964512 0.98796414137687\n",
      "5 fold: ls 0.0687686656784246 0.07544745851319139 auc 0.9910595491009526 0.9879742046522069\n",
      "6 fold: ls 0.0684518988156945 0.07722394770028321 auc 0.9911430051710824 0.9880209852835022\n",
      "7 fold: ls 0.07104156493308908 0.06986341907854433 auc 0.990267760685616 0.9905210975551211\n",
      "8 fold: ls 0.06759409867709222 0.07391844104036682 auc 0.9914021848395582 0.9894022739048028\n",
      "9 fold: ls 0.06997786109459782 0.07696660222007166 auc 0.9905878368975015 0.9880193389665287\n",
      "toxic 0.05 0.45 3\n",
      "this class avg train 0.06926486917269523 avg val 0.07482866306191878\n",
      "this class auc train 0.9908661318673563 auc val 0.9886815916539483\n",
      "========================\n",
      "0 fold: ls 0.017909351838608787 0.02095344394596112 auc 0.9942490747354388 0.991396854032156\n",
      "1 fold: ls 0.017878928232305424 0.02041288189758806 auc 0.9942888540903946 0.9918826750221548\n",
      "2 fold: ls 0.017785209063210048 0.02084800008518297 auc 0.9943658052822142 0.9913675781744524\n",
      "3 fold: ls 0.0157290083773371 0.01961187583788009 auc 0.9961248997245098 0.9928155462716799\n",
      "4 fold: ls 0.018032631487283315 0.02071534841982437 auc 0.9941781767106188 0.9916021806557793\n",
      "5 fold: ls 0.016864060445896945 0.019804925712353327 auc 0.9951597855816581 0.9923818077441535\n",
      "6 fold: ls 0.017692030591310855 0.019297611972170118 auc 0.9944737557766102 0.9927941894866592\n",
      "7 fold: ls 0.01773244006534024 0.020228700061482394 auc 0.9944215612823264 0.9921173632602003\n",
      "8 fold: ls 0.018064619306405932 0.021008351520409318 auc 0.9941804057230146 0.9910822172667926\n",
      "9 fold: ls 0.018196394181320356 0.01844991952656461 auc 0.9940507239677332 0.9937242283484286\n",
      "severe_toxic 0.05 0.45 3\n",
      "this class avg train 0.0175884673589019 avg val 0.02013310589794164\n",
      "this class auc train 0.9945493042874519 auc val 0.9921164640262455\n",
      "========================\n",
      "0 fold: ls 0.034876930583908464 0.036940995628472126 auc 0.9963150095015876 0.9957219322523773\n",
      "1 fold: ls 0.0347283080408978 0.03678833999965036 auc 0.9963568229612741 0.9956511440246788\n",
      "2 fold: ls 0.03305204690836922 0.038792155576793726 auc 0.9967185237485825 0.9953759072299612\n",
      "3 fold: ls 0.03502257693635343 0.03411132774694956 auc 0.9962827770190954 0.996399193712587\n",
      "4 fold: ls 0.03461233630656724 0.04200383783362092 auc 0.9963799386443913 0.9945417411923907\n",
      "5 fold: ls 0.032897557735415 0.03725868627890748 auc 0.9967596450751428 0.9955888341409781\n",
      "6 fold: ls 0.03575608340284409 0.03769953650144814 auc 0.9961320847157439 0.9954650248558299\n",
      "7 fold: ls 0.035422821471432026 0.03817278478265853 auc 0.9961918157184422 0.9955438837743273\n",
      "8 fold: ls 0.03507907571076834 0.03867148251519699 auc 0.9962854940424477 0.9952694829298243\n",
      "9 fold: ls 0.034955660175470374 0.03840380215228567 auc 0.9963017077146694 0.9954263301629038\n",
      "obscene 0.05 0.45 3\n",
      "this class avg train 0.0346403397272026 avg val 0.037884294901598344\n",
      "this class auc train 0.9963723819141379 auc val 0.9954983474275858\n",
      "========================\n",
      "0 fold: ls 0.00487539720926422 0.006474611943773676 auc 0.9986647433947351 0.9971886130316363\n",
      "1 fold: ls 0.004980604078297139 0.006032449747349182 auc 0.9985725455584649 0.9973418185627488\n",
      "2 fold: ls 0.004571357104668293 0.007372565841797228 auc 0.9989105501513837 0.9939778441231929\n",
      "3 fold: ls 0.0041272723526042795 0.006355729182401206 auc 0.9992104970803546 0.9933082950950196\n",
      "4 fold: ls 0.004560192390314568 0.006620216338441747 auc 0.9988932844906667 0.9969055775556813\n",
      "5 fold: ls 0.004985772157651173 0.006874739761834508 auc 0.9985298717928728 0.9966096234835629\n",
      "6 fold: ls 0.004955923588702853 0.006327526061789143 auc 0.9985384800042619 0.9950617574957572\n",
      "7 fold: ls 0.00513588994938985 0.007485950197927088 auc 0.9983031753580366 0.9956680704842122\n",
      "8 fold: ls 0.00512027271670675 0.007148843390130022 auc 0.998389129986137 0.9939670171975451\n",
      "9 fold: ls 0.005263161028415438 0.007350134809331148 auc 0.998290235606825 0.9922618402804249\n",
      "threat 0.05 0.45 3\n",
      "this class avg train 0.004857584257601457 avg val 0.0068042767274774955\n",
      "this class auc train 0.9986302513423739 auc val 0.9952290457309783\n",
      "========================\n",
      "0 fold: ls 0.049266689623402346 0.049780417927141773 auc 0.9919741502063822 0.9914752935428929\n",
      "1 fold: ls 0.05116231082671782 0.053456769819670416 auc 0.9912316893017548 0.9896383708829543\n",
      "2 fold: ls 0.05115012275048396 0.05504874525567289 auc 0.9912733386340786 0.9887212689351478\n",
      "3 fold: ls 0.049759296105560284 0.0512629360502936 auc 0.9917721831303938 0.990685095148386\n",
      "4 fold: ls 0.048871236346931364 0.05484332251490512 auc 0.9921003933843564 0.9891663903104548\n",
      "5 fold: ls 0.0467743371881638 0.051871460146310014 auc 0.9929089774917896 0.9907583526782681\n",
      "6 fold: ls 0.048338898012605165 0.0562154844220925 auc 0.9922730065890736 0.989168816444706\n",
      "7 fold: ls 0.049955791083196754 0.05549355067819272 auc 0.991680957599328 0.9895347655717628\n",
      "8 fold: ls 0.0505766575851277 0.0523296210048957 auc 0.9914564788037964 0.9905807529115213\n",
      "9 fold: ls 0.05100192080018955 0.05474234536837688 auc 0.9913044801075662 0.9893765314014412\n",
      "insult 0.05 0.45 3\n",
      "this class avg train 0.04968572603223788 avg val 0.053504465318755155\n",
      "this class auc train 0.9917975655248519 auc val 0.9899105637827535\n",
      "========================\n",
      "0 fold: ls 0.014491122408433973 0.016991621890990297 auc 0.995772833033556 0.9929970312039699\n",
      "1 fold: ls 0.01537280537454321 0.017430916455624394 auc 0.9949747827389112 0.9922172794600657\n",
      "2 fold: ls 0.014276692504901526 0.017516973660588752 auc 0.9959196213780518 0.9924535814549118\n",
      "3 fold: ls 0.01411463804027012 0.018279636654398745 auc 0.9960511287065815 0.9886552622929723\n",
      "4 fold: ls 0.014767173796695707 0.01899216938510189 auc 0.9955337222316235 0.9897697378303352\n",
      "5 fold: ls 0.014558215781242318 0.01629395499053257 auc 0.9956946959147919 0.9937327829911757\n",
      "6 fold: ls 0.01440161988555189 0.016498516926611986 auc 0.9957923283783916 0.991842347712985\n",
      "7 fold: ls 0.015372745199112787 0.01878366639139489 auc 0.9950164919456164 0.9882555639858371\n",
      "8 fold: ls 0.013806599446997898 0.016548310769752588 auc 0.9963371359631038 0.993167407327119\n",
      "9 fold: ls 0.015320121344541825 0.0165911306897225 auc 0.9951028653696908 0.9922980345400679\n",
      "identity_hate 0.05 0.45 3\n",
      "this class avg train 0.014648173378229126 avg val 0.01739268978147186\n",
      "this class auc train 0.995619560566032 auc val 0.9915389028799438\n",
      "========================\n",
      "all loss avg 0.03178085998781136 0.035091249281527216\n",
      "all auc avg 0.9946391992503673 0.9921624859169091\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999054      0.392506  0.981619  0.150013  0.925587   \n",
      "1  0000247867823ef7  0.000292      0.000028  0.000059  0.000036  0.000081   \n",
      "2  00013b17ad220c46  0.000532      0.000028  0.000139  0.000038  0.000208   \n",
      "3  00017563c3f7919a  0.000078      0.000026  0.000044  0.000067  0.000075   \n",
      "4  00017695ad8997eb  0.001412      0.000030  0.000140  0.000101  0.000221   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.393408  \n",
      "1       0.000040  \n",
      "2       0.000058  \n",
      "3       0.000041  \n",
      "4       0.000051  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "lgb_res,tmp_auc_res = simple_ens('lgb',10,666,0.05,0.45)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# add 7 base fasttext NN models\n",
    "# all loss avg 0.0319116484218 0.0358161833583 all auc avg 0.994546891137 0.991249510282 PUB 9866\n",
    "\n",
    "# rm tfidf test\n",
    "# all loss avg 0.0319555637279 0.0357756335619 all auc avg 0.994512718368 0.991251471241\n",
    "\n",
    "# change to stratified\n",
    "# all loss avg 0.0316412744167 0.0357232681944 all auc avg 0.994584962017 0.991293307537 pub 9866\n",
    "\n",
    "# change to base model 5 fold, add word batch, tilli, lgb feat\n",
    "# feat dim 217\n",
    "# all loss avg 0.031983129767200906 0.035387924581 all auc avg 0.9945427088311004 0.99188514127 PUB 9870\n",
    "\n",
    "# add more base models\n",
    "# feat dim 247, all loss avg 0.031885221777487156 0.0353958  all auc avg 0.9945986685511962 0.9919487331094685\n",
    "\n",
    "# change early stopping to 30, and test later part\n",
    "# all loss avg 0.03208696729295824 0.035406264613808025 all auc avg 0.9945261773637045 0.991946174432887\n",
    "\n",
    "# add fasttext lstm v1\n",
    "# all loss avg 0.031977558955160815 0.03537909655655411 all auc avg 0.9945299073418443 0.9919307178575658\n",
    "\n",
    "# add muse base model, feat dim 295, lower loss, but lower auc\n",
    "# all loss avg 0.03196610276261484 0.03530962013098028 all auc avg 0.9945635742334386 0.9918682952070021\n",
    "\n",
    "# fix pool gru fold to 5, and adj params\n",
    "# all loss avg 0.03172365669814678 0.03528054768190897 all auc avg 0.9946437910139179 0.991903618166854\n",
    "\n",
    "# updated pool gru v2\n",
    "# all loss avg 0.03204678384090053 0.035272185628381025 all auc avg 0.9944980867573662 0.9919033708443966\n",
    "\n",
    "# updated other feat, change some cnt to ratio, a bit worse\n",
    "# all loss avg 0.03197308230179816 0.03527747086566205 all auc avg 0.9945654974291834 0.991902658184264\n",
    "\n",
    "# updated pool gru v2 10 fold PUB 9870\n",
    "# all loss avg 0.03188938973578164 0.035151701851945265 all auc avg 0.9945816630869728 0.9919824289801534\n",
    "\n",
    "# rm lr, mnb feat1\n",
    "# worse all loss avg 0.032097370918022436 0.03520186226431002\n",
    "# all auc avg 0.9944811076726177 0.9919214297276806\n",
    "\n",
    "# add ridge , change lr,mnb,ridge to fold 6\n",
    "# all loss avg 0.03187703661408994 0.0351472518210873 all auc avg 0.9946115814252721 0.9920990121249438\n",
    "\n",
    "# ridge, lr, mnb fold 10, feat frac 0.6\n",
    "# all loss avg 0.031754244562510095 0.03510006533423048 all auc avg 0.9946626820706096 0.9921195758845225\n",
    "\n",
    "# lgb v1 feat fold 10, 5 fold is better, change feat file back\n",
    "# all loss avg 0.031846113030824186 0.03510235514884163 all auc avg 0.9946147807624219 0.9920710159886731\n",
    "\n",
    "# feat frac 0.45 PUB 9871\n",
    "# all loss avg 0.03178085998781136 0.035091249281527216 all auc avg 0.9946391992503673 0.9921624859169091"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "{'feature_fraction': 0.4, 'max_depth': 4, 'learning_rate': 0.05, 'lambda_l2': 1.0, 'application': 'binary', 'metric': 'binary_logloss', 'data_random_seed': 2}\n",
      "0 fold: ls 0.06696321505466694 0.07808999299738749 auc 0.9916958534307556 0.9869048654486285\n",
      "1 fold: ls 0.06303855556133289 0.07096451163531511 auc 0.992889441615493 0.9899266767052445\n",
      "2 fold: ls 0.06722168931452523 0.07542947440710139 auc 0.9915968136610711 0.9886690458458588\n",
      "3 fold: ls 0.06143346454733205 0.0726748192207435 auc 0.9933412730767426 0.9893768199452407\n",
      "4 fold: ls 0.06543866677533601 0.07752241946965202 auc 0.9921329577438122 0.9879959630853676\n",
      "5 fold: ls 0.06370754273564935 0.0750665015567107 auc 0.9927020839766838 0.988260192058063\n",
      "6 fold: ls 0.0631175325855247 0.07702720660208447 auc 0.9928248474882658 0.9880800956935891\n",
      "7 fold: ls 0.06778323722881177 0.06974333061674629 auc 0.9914154024712916 0.990567609429725\n",
      "8 fold: ls 0.06771805583936838 0.0738967994947421 auc 0.9914450150016623 0.9892846795551705\n",
      "9 fold: ls 0.06385282788159989 0.0767090120259878 auc 0.9926195155744961 0.9881561545976738\n",
      "toxic\n",
      "this class avg train 0.06502747875241473 avg val 0.0747124068026471\n",
      "this class auc train 0.9922663204040274 auc val 0.9887222102364561\n",
      "========================\n",
      "{'feature_fraction': 0.6, 'max_depth': 3, 'learning_rate': 0.075, 'lambda_l2': 1.0, 'application': 'binary', 'metric': 'binary_logloss', 'data_random_seed': 2}\n",
      "0 fold: ls 0.017755068824567666 0.02097801286097703 auc 0.9943691382000763 0.991370743132042\n",
      "1 fold: ls 0.01773868991096958 0.02035139194119036 auc 0.994395691262604 0.9919701069755665\n",
      "2 fold: ls 0.018027847150497878 0.020847560287291917 auc 0.9941797377905293 0.9913695562729459\n",
      "3 fold: ls 0.01694694280132932 0.019663067004408227 auc 0.9950751580329962 0.9927522471198885\n",
      "4 fold: ls 0.01817314951743071 0.02081557315798101 auc 0.9940802967551645 0.9915357165463984\n",
      "5 fold: ls 0.017982593152001587 0.01994177314619959 auc 0.9942005369431571 0.9923093521112856\n",
      "6 fold: ls 0.017919727347333107 0.01928281360798321 auc 0.9942699663128168 0.992787819357469\n",
      "7 fold: ls 0.017418388097165692 0.02019016983527168 auc 0.9946844512824383 0.9921599634991598\n",
      "8 fold: ls 0.017918640875236185 0.020974039233373157 auc 0.9942906623983605 0.9911347708326118\n",
      "9 fold: ls 0.017663567583540152 0.018616162917476968 auc 0.9945203544176854 0.9935156066174495\n",
      "severe_toxic\n",
      "this class avg train 0.017754461526007185 avg val 0.020166056399215315\n",
      "this class auc train 0.994406599339583 auc val 0.9920905882464817\n",
      "========================\n",
      "{'feature_fraction': 0.6, 'max_depth': 4, 'learning_rate': 0.095, 'lambda_l2': 1.0, 'application': 'binary', 'metric': 'binary_logloss', 'data_random_seed': 2}\n",
      "0 fold: ls 0.03242544758695619 0.03715203358452487 auc 0.9968703427000756 0.9956543545527049\n",
      "1 fold: ls 0.03410293459700619 0.03675335609686418 auc 0.9965382576389752 0.9956608539143189\n",
      "2 fold: ls 0.033116551027445665 0.03901094755309984 auc 0.996715710517464 0.9953493598879843\n",
      "3 fold: ls 0.03290605276097257 0.033991617419267976 auc 0.9967670975511168 0.996407964515836\n",
      "4 fold: ls 0.03276326858101805 0.04225855559302014 auc 0.9967983215641422 0.9944903693447896\n",
      "5 fold: ls 0.02885489406121841 0.03753331363915971 auc 0.9976177719395188 0.9954845242309103\n",
      "6 fold: ls 0.034117908317036164 0.03736463499382309 auc 0.9965331425022474 0.9955858583327328\n",
      "7 fold: ls 0.03304168284832555 0.03824353918752396 auc 0.9967328935146141 0.9955420043164882\n",
      "8 fold: ls 0.03223501070893179 0.038804245037704854 auc 0.9969102474556576 0.9952004128542387\n",
      "9 fold: ls 0.032557175185240116 0.03844667678534156 auc 0.9968366453698414 0.9953759950975842\n",
      "obscene\n",
      "this class avg train 0.03261209256741507 avg val 0.03795589198903303\n",
      "this class auc train 0.9968320430753653 auc val 0.9954751697047588\n",
      "========================\n",
      "{'feature_fraction': 0.6, 'max_depth': 4, 'learning_rate': 0.05, 'lambda_l2': 1.0, 'application': 'binary', 'metric': 'binary_logloss', 'data_random_seed': 2}\n",
      "0 fold: ls 0.0037990598651044807 0.006515077344500278 auc 0.9994040314971782 0.9971008799497172\n",
      "1 fold: ls 0.003830902662651921 0.00600422335766307 auc 0.9994110886556138 0.997231824848104\n",
      "2 fold: ls 0.0035368355476712507 0.007300596099345017 auc 0.9995523373974662 0.9947556568196103\n",
      "3 fold: ls 0.0039523091770447775 0.006509804327987927 auc 0.9993609702396266 0.9930300196953507\n",
      "4 fold: ls 0.003889395421329087 0.006663442535799409 auc 0.9993712676094769 0.996734028956356\n",
      "5 fold: ls 0.0037903984554097307 0.00694778821406304 auc 0.999419018819824 0.996593909108052\n",
      "6 fold: ls 0.0035041347685261025 0.006325582855132667 auc 0.9995576759908213 0.9947697320175163\n",
      "7 fold: ls 0.003996702111896648 0.007675000031438503 auc 0.9992993809234239 0.9953419971923649\n",
      "8 fold: ls 0.004365433725115618 0.007330211082799454 auc 0.999040329137606 0.9936821523478613\n",
      "9 fold: ls 0.004187031372044207 0.007364025583237311 auc 0.9992002000119782 0.9926269487497374\n",
      "threat\n",
      "this class avg train 0.0038852203106793824 avg val 0.006863575143196668\n",
      "this class auc train 0.9993616300283016 auc val 0.9951867149684672\n",
      "========================\n",
      "{'feature_fraction': 0.4, 'max_depth': 3, 'learning_rate': 0.075, 'lambda_l2': 1.0, 'application': 'binary', 'metric': 'binary_logloss', 'data_random_seed': 2}\n",
      "0 fold: ls 0.04867081293051843 0.049925367943780774 auc 0.9922040543348248 0.9913897988616324\n",
      "1 fold: ls 0.05122002953878089 0.05340420529903249 auc 0.9912072901022335 0.9901001425469049\n",
      "2 fold: ls 0.05133854798286238 0.05493074895358782 auc 0.9911998940884207 0.9888772841803051\n",
      "3 fold: ls 0.049889924779384164 0.05116218709983992 auc 0.9917074917743164 0.9907495089493357\n",
      "4 fold: ls 0.049454384111955796 0.054839707693944 auc 0.9918859565341684 0.9893406536775343\n",
      "5 fold: ls 0.04912922192475185 0.0523296100383871 auc 0.9920034751091165 0.9905707037429061\n",
      "6 fold: ls 0.04972813525371967 0.056231651047228964 auc 0.9917616882936233 0.9891182022646374\n",
      "7 fold: ls 0.04874610393905405 0.055498887137428926 auc 0.9921389026276592 0.9895316662259173\n",
      "8 fold: ls 0.05082024946982178 0.05229094170514437 auc 0.9913481879071212 0.9906101548140002\n",
      "9 fold: ls 0.04985794523594628 0.0547962674241009 auc 0.9917465350534073 0.9892783575276367\n",
      "insult\n",
      "this class avg train 0.04988553551667953 avg val 0.05354095743424753\n",
      "this class auc train 0.991720347582489 auc val 0.989956647279081\n",
      "========================\n",
      "{'feature_fraction': 0.4, 'max_depth': 3, 'learning_rate': 0.095, 'lambda_l2': 1.0, 'application': 'binary', 'metric': 'binary_logloss', 'data_random_seed': 2}\n",
      "0 fold: ls 0.014070991085157993 0.017027509970396114 auc 0.996057383946978 0.9929795439595696\n",
      "1 fold: ls 0.013783106458430006 0.017051403334485498 auc 0.9962674861063079 0.9928342653137816\n",
      "2 fold: ls 0.015101992038599934 0.017490934524154362 auc 0.9952499521811743 0.9925298079048622\n",
      "3 fold: ls 0.015006388063522497 0.0181692255987013 auc 0.9953262210962875 0.987940975617849\n",
      "4 fold: ls 0.014925548580646267 0.018924228552742183 auc 0.995364647335382 0.9896614514323174\n",
      "5 fold: ls 0.015031091165645884 0.016412939453885483 auc 0.9953337836915156 0.9936519477235163\n",
      "6 fold: ls 0.013056065197418568 0.016377418223503575 auc 0.9967712327378796 0.9912272382397572\n",
      "7 fold: ls 0.015108294297695621 0.018748318322833957 auc 0.995193675889328 0.986830470048414\n",
      "8 fold: ls 0.0141214377206566 0.016713564374599095 auc 0.9960598813535086 0.9926823650552786\n",
      "9 fold: ls 0.014890805958811672 0.016440773743497783 auc 0.9954205175408273 0.9926132668545415\n",
      "identity_hate\n",
      "this class avg train 0.014509572056658504 avg val 0.017335631609879935\n",
      "this class auc train 0.9957044781879189 auc val 0.9912951332149887\n",
      "========================\n",
      "all loss avg 0.030612393454975732 0.035095753229703264\n",
      "all auc avg 0.9950485697696142 0.9921210772750391\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999334      0.400925  0.981617  0.133019  0.929769   \n",
      "1  0000247867823ef7  0.000284      0.000032  0.000085  0.000046  0.000083   \n",
      "2  00013b17ad220c46  0.000455      0.000033  0.000120  0.000046  0.000194   \n",
      "3  00017563c3f7919a  0.000064      0.000031  0.000073  0.000064  0.000078   \n",
      "4  00017695ad8997eb  0.001290      0.000036  0.000116  0.000074  0.000211   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.378622  \n",
      "1       0.000029  \n",
      "2       0.000047  \n",
      "3       0.000028  \n",
      "4       0.000043  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "def special_ens(model_name,k=3,rnd=233):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    params_list = [\n",
    "        [0.05, 3,0.4], # depth should be 3\n",
    "        [0.075,3,0.6],\n",
    "        [0.095,3,0.6],\n",
    "        [0.05, 3,0.6],\n",
    "        [0.075,3,0.4],\n",
    "        [0.095,3,0.4],\n",
    "    ]\n",
    "    \n",
    "    for i in range(6):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        \n",
    "        # special params\n",
    "        params = {\n",
    "                'application': 'binary',\n",
    "                #'num_leaves': 8,\n",
    "                #'lambda_l1': 1,\n",
    "                'lambda_l2': 1.0,\n",
    "                'max_depth': params_list[i][1],\n",
    "                'metric': 'binary_logloss', # or auc\n",
    "                'data_random_seed': 2,\n",
    "                'learning_rate':params_list[i][0],\n",
    "                'feature_fraction': params_list[i][2],\n",
    "\n",
    "                }\n",
    "        print(params)\n",
    "            \n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = test_x\n",
    "            s_round = 30\n",
    "            # train for each class\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_auc_l = train_auc_l/k\n",
    "        val_auc_l = val_auc_l/k\n",
    "        print(list_classes[i])\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/6\n",
    "        all_val_loss_l += val_loss_l/6\n",
    "        all_train_auc_l += train_auc_l/6\n",
    "        all_val_auc_l += val_auc_l/6\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')\n",
    "\n",
    "lgb_res = special_ens('lgb',10,666)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10_stratified_special.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# best params changed when base models changed\n",
    "# all loss avg 0.03111512578966158 0.03534320053008906 all auc avg 0.9948524214184179 0.9918450388634261\n",
    "\n",
    "# change lr, ridge, mnb fold to 10, train loss too low ?\n",
    "# all loss avg 0.030612393454975732 0.035095753229703264 all auc avg 0.9950485697696142 0.9921210772750391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.095 max depth 3 feature fraction 0.4\n",
      "0 fold: ls 0.07061737961759704 0.07775928680520683 auc 0.9904295713822548 0.9870631451915393\n",
      "1 fold: ls 0.06978029561549126 0.07145282016458328 auc 0.9907204797236494 0.9897310693984644\n",
      "2 fold: ls 0.06961053786924241 0.07523377254243167 auc 0.9907552553794691 0.9886870301211695\n",
      "3 fold: ls 0.07043228685873615 0.0734208127397867 auc 0.9905142818080588 0.9890545073033372\n",
      "4 fold: ls 0.06932434768590719 0.07776492803204109 auc 0.9907917891506477 0.9878860829979059\n",
      "5 fold: ls 0.07055630326132173 0.07581794629202872 auc 0.9904214584692226 0.9879176327259891\n",
      "6 fold: ls 0.06981054734403931 0.07766761434216077 auc 0.9906565612464159 0.9878052594847275\n",
      "7 fold: ls 0.07061174620035217 0.06981370568054665 auc 0.9903866606261856 0.9904415831028254\n",
      "8 fold: ls 0.06576400798133654 0.0735997702164948 auc 0.9919821907448325 0.989493801658044\n",
      "9 fold: ls 0.06968508568127503 0.07721907256609754 auc 0.9906951976357643 0.988006736333839\n",
      "toxic 0.095 0.4 3\n",
      "this class avg train 0.06961925381152988 avg val 0.07497497293813779\n",
      "this class auc train 0.9907353446166501 auc val 0.9886086848317841\n",
      "========================\n",
      "0 fold: ls 0.01707854691717704 0.020889016547750428 auc 0.9949404150257152 0.9914478889732877\n",
      "1 fold: ls 0.017073702786925563 0.020197658780203465 auc 0.9949512298540433 0.9921544657551588\n",
      "2 fold: ls 0.017814484068248804 0.020913277026911252 auc 0.994329807318627 0.9913663913153564\n",
      "3 fold: ls 0.017778084889125394 0.01975792623844634 auc 0.9943718510971891 0.9926232750981138\n",
      "4 fold: ls 0.01802510281535681 0.0208598652062765 auc 0.9941827227125561 0.9914830991264719\n",
      "5 fold: ls 0.017564555864942287 0.01999161843850741 auc 0.9945559606105587 0.992226147565849\n",
      "6 fold: ls 0.017739746744872817 0.01937245036663405 auc 0.9944248967536922 0.9927062020772195\n",
      "7 fold: ls 0.017387148780292256 0.020162636227691846 auc 0.9947096167036958 0.992172504691003\n",
      "8 fold: ls 0.018070427310417966 0.02083853800685192 auc 0.9941662360920885 0.9913895760002198\n",
      "9 fold: ls 0.018087909664974096 0.018622782964866844 auc 0.9941197672454204 0.9935251618112348\n",
      "severe_toxic 0.095 0.4 3\n",
      "this class avg train 0.0176619709842333 avg val 0.020160576980414006\n",
      "this class auc train 0.9944752503413585 auc val 0.9921094712413915\n",
      "========================\n",
      "0 fold: ls 0.034992825575530205 0.03707046358572619 auc 0.9962894354521182 0.9956936639446349\n",
      "1 fold: ls 0.03470504501748423 0.03677163354963249 auc 0.9963596874598015 0.9956209963834576\n",
      "2 fold: ls 0.03241802224038494 0.03881766940708574 auc 0.9968492585001544 0.995379352902666\n",
      "3 fold: ls 0.03312587216693006 0.03408085837893751 auc 0.996701515279089 0.9963930854746101\n",
      "4 fold: ls 0.03256594342460689 0.04187135179329282 auc 0.9968200853079582 0.9945578732055093\n",
      "5 fold: ls 0.03308178147145843 0.037336188239651805 auc 0.9967124708780541 0.9956528140182496\n",
      "6 fold: ls 0.03396623958770446 0.03780904509258415 auc 0.9965208370938161 0.9952715190091499\n",
      "7 fold: ls 0.03532393328347062 0.038169885291548133 auc 0.9962128915042103 0.9955417693842582\n",
      "8 fold: ls 0.03556806927516386 0.03870061598333945 auc 0.9961799589572834 0.9952865546718623\n",
      "9 fold: ls 0.03509646171383769 0.03848472398116364 auc 0.9962667168621482 0.9954004569984871\n",
      "obscene 0.095 0.4 3\n",
      "this class avg train 0.034084419375657135 avg val 0.03791124353029619\n",
      "this class auc train 0.9964912857294633 auc val 0.9954798085992886\n",
      "========================\n",
      "0 fold: ls 0.004887966598640541 0.006484466809744399 auc 0.9986500443650823 0.9971846846846847\n",
      "1 fold: ls 0.0050070527210668275 0.0061280771933433145 auc 0.998545323930069 0.9970301697045882\n",
      "2 fold: ls 0.004942233546011442 0.007500685222707777 auc 0.9986143606433724 0.9946076890844333\n",
      "3 fold: ls 0.005211866849977173 0.006526329482609477 auc 0.9983950883170005 0.9900495264734845\n",
      "4 fold: ls 0.004904351275863946 0.006734748458047243 auc 0.9985993059507753 0.9966855762985313\n",
      "5 fold: ls 0.00497506702278824 0.006929826786636306 auc 0.9985614947882964 0.9965664089509083\n",
      "6 fold: ls 0.004338558574384252 0.006244285642328133 auc 0.9990473714745314 0.9950250906195655\n",
      "7 fold: ls 0.004946296666767556 0.00741190972848605 auc 0.9985479896415606 0.9959627150250383\n",
      "8 fold: ls 0.004584611034585076 0.00716147223045933 auc 0.9988613048704194 0.9939951024644154\n",
      "9 fold: ls 0.005337832432535575 0.0073261227879798186 auc 0.9981064310935465 0.991276181152646\n",
      "threat 0.095 0.4 3\n",
      "this class avg train 0.004913583672262063 avg val 0.006844792434234184\n",
      "this class auc train 0.9985928715074653 auc val 0.9948383144458296\n",
      "========================\n",
      "0 fold: ls 0.04780939789929706 0.04982921093426899 auc 0.9925215425382654 0.9914839099344487\n",
      "1 fold: ls 0.05089073256730365 0.05334511156419595 auc 0.9913387687649362 0.9899498576204036\n",
      "2 fold: ls 0.05091871058429322 0.05511120171559121 auc 0.9913412997143403 0.9891251936596743\n",
      "3 fold: ls 0.04995128922275608 0.05125012831820489 auc 0.9916941581810995 0.990788993772775\n",
      "4 fold: ls 0.050243426275043204 0.05526285929895839 auc 0.9915954440041362 0.9890649109709121\n",
      "5 fold: ls 0.04694319205617725 0.05206830043021229 auc 0.9928546154319261 0.9906723504020523\n",
      "6 fold: ls 0.04934209892192174 0.05622740103338828 auc 0.9919222027292155 0.9891404557719072\n",
      "7 fold: ls 0.05057586340562442 0.05548813121769831 auc 0.991439207469093 0.9895524821027436\n",
      "8 fold: ls 0.04871197946139575 0.05242265161173446 auc 0.9921628457101503 0.9905014264111007\n",
      "9 fold: ls 0.049873372970172074 0.05478483150442306 auc 0.9917394263051064 0.9891135896012089\n",
      "insult 0.095 0.4 3\n",
      "this class avg train 0.04952600633639845 avg val 0.053578982762867586\n",
      "this class auc train 0.9918609510848269 auc val 0.9899393170247226\n",
      "========================\n",
      "0 fold: ls 0.014223376467461118 0.016954819433945233 auc 0.9959324125248953 0.9928840367016905\n",
      "1 fold: ls 0.015022272587646839 0.01740890255650589 auc 0.9952108145509019 0.9921616789906901\n",
      "2 fold: ls 0.014710936602554688 0.017619586704191132 auc 0.9954950014321193 0.9924558234093221\n",
      "3 fold: ls 0.01495421524427126 0.018107276937959667 auc 0.9953948897970587 0.9895888121094235\n",
      "4 fold: ls 0.014814480314564053 0.01892803294813044 auc 0.9954225006671515 0.9897060663250825\n",
      "5 fold: ls 0.014934206665258397 0.01625210521078504 auc 0.9953163128520877 0.993793748137176\n",
      "6 fold: ls 0.01315327282484388 0.016699294690991275 auc 0.9967219304420019 0.9902946383409207\n",
      "7 fold: ls 0.015280820646877259 0.01867433326607136 auc 0.9950328464467832 0.9884425355878316\n",
      "8 fold: ls 0.014106294550016793 0.01664427556196002 auc 0.9960392313662116 0.9929443059469615\n",
      "9 fold: ls 0.015308194387310568 0.01641452504455721 auc 0.9950413568960323 0.9926399125659369\n",
      "identity_hate 0.095 0.4 3\n",
      "this class avg train 0.014650807029080486 avg val 0.017370315235509727\n",
      "this class auc train 0.9955607296975242 auc val 0.9914911558115035\n",
      "========================\n",
      "all loss avg 0.03174267353486022 0.03514014731357658\n",
      "all auc avg 0.9946194054962147 0.99207779199242\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.095 3 0.4 toxic\n",
      "FIND BETTER PARAMS 0.095 3 0.4 severe_toxic\n",
      "FIND BETTER PARAMS 0.095 3 0.4 obscene\n",
      "FIND BETTER PARAMS 0.095 3 0.4 threat\n",
      "FIND BETTER PARAMS 0.095 3 0.4 insult\n",
      "FIND BETTER PARAMS 0.095 3 0.4 identity_hate\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 3 feature fraction 0.5\n",
      "0 fold: ls 0.07046298632504915 0.07802339480581515 auc 0.9904820315522237 0.9870792721487449\n",
      "1 fold: ls 0.06612261078813307 0.07118138969342129 auc 0.9918936383820907 0.9898213984789924\n",
      "2 fold: ls 0.07076165722011332 0.07538071643162418 auc 0.990334647731987 0.988605262824102\n",
      "3 fold: ls 0.0682960182802839 0.0734252935311857 auc 0.9911985046212295 0.9891355497933393\n",
      "4 fold: ls 0.07012780360668489 0.07783691164619894 auc 0.9905093512219705 0.9878910693055053\n",
      "5 fold: ls 0.06533558095219245 0.07550343226954585 auc 0.9921321280338096 0.9879018125318785\n",
      "6 fold: ls 0.06858044252188869 0.07741167874895867 auc 0.9911217728753235 0.9879136890099787\n",
      "7 fold: ls 0.07196973742748988 0.06996851813853343 auc 0.9898997594391024 0.9904565883957043\n",
      "8 fold: ls 0.06729749947157924 0.073896169971603 auc 0.9915125024109939 0.9894353218157057\n",
      "9 fold: ls 0.06892595942691808 0.07719669995711359 auc 0.9909236019487125 0.9879106752594862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic 0.095 0.5 3\n",
      "this class avg train 0.06878802960203327 avg val 0.07498242051939999\n",
      "this class auc train 0.9910007938217443 auc val 0.9886150639563438\n",
      "========================\n",
      "0 fold: ls 0.018159802255339617 0.021012651452617513 auc 0.9940554787704652 0.9913687650335486\n",
      "1 fold: ls 0.017954455127797458 0.020284301859314537 auc 0.9942023060556717 0.9919792062286366\n",
      "2 fold: ls 0.018213842828436043 0.0209621094696875 auc 0.9940441983139063 0.9912619477149007\n",
      "3 fold: ls 0.01584533353091705 0.019540398130610783 auc 0.9959977194999663 0.9928143594125839\n",
      "4 fold: ls 0.018007367231727817 0.020736782924777014 auc 0.9941803725153282 0.9915463982782631\n",
      "5 fold: ls 0.018080494744634818 0.02003000282874693 auc 0.994113466324198 0.9922173891926452\n",
      "6 fold: ls 0.018073144929191612 0.01929794509591248 auc 0.9941192211293304 0.9927408396546913\n",
      "7 fold: ls 0.017824278721464287 0.020262629120251886 auc 0.994327291359605 0.992093475275737\n",
      "8 fold: ls 0.01755797206719156 0.021016414892181767 auc 0.9945646412489446 0.9911419372279507\n",
      "9 fold: ls 0.017755070326699943 0.01859174791172005 auc 0.9944022023240704 0.9935355132711688\n",
      "severe_toxic 0.095 0.5 3\n",
      "this class avg train 0.01774717617634002 avg val 0.020173498368582045\n",
      "this class auc train 0.9944006897541489 auc val 0.9920699831290125\n",
      "========================\n",
      "0 fold: ls 0.034608000820939504 0.036922681843709594 auc 0.9963747791367691 0.9957085420013414\n",
      "1 fold: ls 0.03486201356088614 0.0368125474199234 auc 0.9963192818346656 0.9956149668552133\n",
      "2 fold: ls 0.03361572665807162 0.03898397563727169 auc 0.9965861254245276 0.9953371434120304\n",
      "3 fold: ls 0.03532804700331057 0.03424134933134417 auc 0.9962105486758891 0.9963648936070242\n",
      "4 fold: ls 0.034895035244423174 0.042084021370366556 auc 0.9963173388131215 0.9945025858207437\n",
      "5 fold: ls 0.033080660693759915 0.03722262953559539 auc 0.9967074690411143 0.9955711359129937\n",
      "6 fold: ls 0.03471169100084816 0.03759685020687149 auc 0.9963507794724225 0.9952975964866667\n",
      "7 fold: ls 0.0348995772954726 0.038220493669661466 auc 0.9963123413272866 0.9955391851297296\n",
      "8 fold: ls 0.03347774830075355 0.038641495388577175 auc 0.9966351778486133 0.9952987711478163\n",
      "9 fold: ls 0.03422012928957404 0.03845070834459203 auc 0.99645852847286 0.995415980897137\n",
      "obscene 0.095 0.5 3\n",
      "this class avg train 0.03436986298680393 avg val 0.0379176752747913\n",
      "this class auc train 0.996427237004727 auc val 0.9954650801270697\n",
      "========================\n",
      "0 fold: ls 0.005038764232134223 0.006418331367514505 auc 0.9984955502545207 0.9971637335009428\n",
      "1 fold: ls 0.005022732994503337 0.006177603408420693 auc 0.9985025911709344 0.9970288602556044\n",
      "2 fold: ls 0.005050219890573873 0.0073461713131594145 auc 0.9985007639434913 0.9949560025141421\n",
      "3 fold: ls 0.005217373421873209 0.006546722879820278 auc 0.9983945198502105 0.9872032602091059\n",
      "4 fold: ls 0.004805692470149945 0.006788521681069746 auc 0.9987165400447497 0.9966633142665577\n",
      "5 fold: ls 0.005033618896145048 0.006865656611006477 auc 0.9984386409940568 0.9967104573930898\n",
      "6 fold: ls 0.004242647046102489 0.0063909806716722466 auc 0.9990733422858732 0.9946885410773776\n",
      "7 fold: ls 0.005148420619617134 0.007492033462987507 auc 0.9982386300145267 0.9957492614243508\n",
      "8 fold: ls 0.004561437393131561 0.007252946753981932 auc 0.9988906021074824 0.9943187517302531\n",
      "9 fold: ls 0.005346903444833295 0.007439233695797403 auc 0.9981399252246358 0.9917088280018134\n",
      "threat 0.095 0.5 3\n",
      "this class avg train 0.004946781040906412 avg val 0.0068718201845430205\n",
      "this class auc train 0.9985391105890484 auc val 0.9946191010373239\n",
      "========================\n",
      "0 fold: ls 0.050918917796649636 0.050267618878882536 auc 0.9913416427538186 0.9912817175228962\n",
      "1 fold: ls 0.05123711410855148 0.053401942783495665 auc 0.9911970588464676 0.9897253295142363\n",
      "2 fold: ls 0.05109457198159122 0.05496959265565741 auc 0.9912822783255437 0.9891287071397261\n",
      "3 fold: ls 0.04966398531863871 0.05142459704850971 auc 0.9918110411339506 0.990550997326409\n",
      "4 fold: ls 0.05075696764939497 0.055077451433657464 auc 0.9913817469565608 0.9891420453081408\n",
      "5 fold: ls 0.04706077119317695 0.05216621174778943 auc 0.9928015738577314 0.990635205450068\n",
      "6 fold: ls 0.04855755817302241 0.056309258529306475 auc 0.9922020464996423 0.9891295799976776\n",
      "7 fold: ls 0.048794127956205295 0.055389522858220026 auc 0.992144238579552 0.9895983440446446\n",
      "8 fold: ls 0.04889606184141191 0.05240164376020627 auc 0.9921054101025117 0.9905600626838509\n",
      "9 fold: ls 0.0494227464259042 0.05478444039038439 auc 0.9919097707581055 0.9890000027642815\n",
      "insult 0.095 0.5 3\n",
      "this class avg train 0.049640282244454687 avg val 0.05361922800861093\n",
      "this class auc train 0.9918176807813885 auc val 0.9898751991751931\n",
      "========================\n",
      "0 fold: ls 0.014518753355461449 0.01707923919055502 auc 0.995694718947575 0.9927593840364776\n",
      "1 fold: ls 0.014571437769971217 0.017440432356616617 auc 0.9956414451965133 0.9921217722021867\n",
      "2 fold: ls 0.015202975319227013 0.017725336481863786 auc 0.9950611334008741 0.992271983147677\n",
      "3 fold: ls 0.014555577015058312 0.01812474083575162 auc 0.995692154048914 0.9891202436376697\n",
      "4 fold: ls 0.01532969258770811 0.01903403244676152 auc 0.9949809824018717 0.9900650032261725\n",
      "5 fold: ls 0.014745738157434697 0.016278163202011878 auc 0.9954979268372225 0.9937820067016501\n",
      "6 fold: ls 0.012563913082290924 0.01657347405654133 auc 0.9971130612488563 0.9904423188091626\n",
      "7 fold: ls 0.015154068028670066 0.018652045331829844 auc 0.99516742816445 0.9865337542452489\n",
      "8 fold: ls 0.012717196166062886 0.016640346038177354 auc 0.9970428396300939 0.9928869499241274\n",
      "9 fold: ls 0.01476917411234489 0.01654912383492025 auc 0.9955269384179449 0.9923883589854758\n",
      "identity_hate 0.095 0.5 3\n",
      "this class avg train 0.014412852559422953 avg val 0.01740969337750292\n",
      "this class auc train 0.9957418628294314 auc val 0.9912371774915849\n",
      "========================\n",
      "all loss avg 0.03165083076832688 0.03516238928890504\n",
      "all auc avg 0.9946545624634148 0.991980267486088\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.095 3 0.5 toxic\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 3 feature fraction 0.6\n",
      "0 fold: ls 0.07128447700190847 0.07804612845995772 auc 0.9901978584500702 0.986998954465808\n",
      "1 fold: ls 0.06951670256727828 0.07133982088678047 auc 0.9907784654475228 0.9897501408843733\n",
      "2 fold: ls 0.07126703582467181 0.07521235524812851 auc 0.9901716552221146 0.9886156366252259\n",
      "3 fold: ls 0.07136433310237346 0.07355120332687051 auc 0.9901550240070616 0.9890024570959517\n",
      "4 fold: ls 0.06871317116937509 0.07760339246931566 auc 0.99100593601559 0.9880323178007737\n",
      "5 fold: ls 0.06836586319563481 0.0756898987777515 auc 0.9912072953877297 0.9878452406056605\n",
      "6 fold: ls 0.06740321409141553 0.07752119078059237 auc 0.9915145160772216 0.9878504988936745\n",
      "7 fold: ls 0.07220298652233466 0.07006814200075938 auc 0.9898326745730949 0.9904266231431573\n",
      "8 fold: ls 0.0703514837684919 0.07408082602909323 auc 0.9904766966159086 0.989325842110863\n",
      "9 fold: ls 0.07083156119772885 0.07720999809299255 auc 0.9902845452596188 0.9879102672605862\n",
      "toxic 0.095 0.6 3\n",
      "this class avg train 0.07013008284412128 avg val 0.0750322956072242\n",
      "this class auc train 0.9905624667055933 auc val 0.9885757978886076\n",
      "========================\n",
      "0 fold: ls 0.01686076408434611 0.020809046802432174 auc 0.9951344423094709 0.991563409925307\n",
      "1 fold: ls 0.017471815917831788 0.020282469226750317 auc 0.9946281965929444 0.992068220660843\n",
      "2 fold: ls 0.018092718351938337 0.0210078106603565 auc 0.9941424385185709 0.991235441195088\n",
      "3 fold: ls 0.016882924408037406 0.019732739545606632 auc 0.9951243234728141 0.9927039815166476\n",
      "4 fold: ls 0.01807736726991867 0.020855755771236474 auc 0.9941539664932946 0.9914862640840613\n",
      "5 fold: ls 0.017170895574183553 0.019952511855052837 auc 0.9948697101843893 0.992246451067367\n",
      "6 fold: ls 0.017353127367674435 0.019325625132438573 auc 0.9947463460719344 0.9927424321869887\n",
      "7 fold: ls 0.01638932715731541 0.020059666111429442 auc 0.9955616998431946 0.9923076708697576\n",
      "8 fold: ls 0.018001266126632647 0.021018459522191665 auc 0.9942156020478794 0.9911407428287277\n",
      "9 fold: ls 0.01828365441634399 0.01859983074227217 auc 0.9939758693291428 0.9935924463008061\n",
      "severe_toxic 0.095 0.6 3\n",
      "this class avg train 0.017458386067422234 avg val 0.020164391536976682\n",
      "this class auc train 0.9946552594863635 auc val 0.9921087060635593\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.03514853960801476 0.0370275268264882 auc 0.9962598907484033 0.9956900618888007\n",
      "1 fold: ls 0.036013710087676995 0.037084881271528085 auc 0.9960683918908128 0.995500797346381\n",
      "2 fold: ls 0.03489600059230024 0.03907963189169119 auc 0.9963038537717759 0.9953300171343906\n",
      "3 fold: ls 0.03431183859790538 0.034164607880901796 auc 0.9964340804109733 0.9963843929821045\n",
      "4 fold: ls 0.03505906207862771 0.04210810790879396 auc 0.9962781029653999 0.994504621900069\n",
      "5 fold: ls 0.033719796603668015 0.037203789702455976 auc 0.996569700970018 0.9956073937871389\n",
      "6 fold: ls 0.03541456005948037 0.03768331118364482 auc 0.9961931283017877 0.9953916476893632\n",
      "7 fold: ls 0.0354221965850771 0.03827718830814151 auc 0.9961934159581747 0.9955228181843812\n",
      "8 fold: ls 0.03416260004031948 0.03874712044178929 auc 0.9964765500966313 0.9952300926259472\n",
      "9 fold: ls 0.03498723626067744 0.0384949102345425 auc 0.9962872624953467 0.9954128447559957\n",
      "obscene 0.095 0.6 3\n",
      "this class avg train 0.03491355405137475 avg val 0.03798710756499773\n",
      "this class auc train 0.9963064377609323 auc val 0.9954574688294571\n",
      "========================\n",
      "0 fold: ls 0.005121005958269671 0.0065845213012779066 auc 0.9983629666312537 0.9969306515818144\n",
      "1 fold: ls 0.004849439917397349 0.006139007955246616 auc 0.9986576212682128 0.9970013618269432\n",
      "2 fold: ls 0.004088486955000617 0.007293700424454028 auc 0.9992134963404289 0.9951825371883511\n",
      "3 fold: ls 0.004094481922577712 0.006499871281699698 auc 0.9992465297538766 0.9917984055146981\n",
      "4 fold: ls 0.004807839916900416 0.006711430842024422 auc 0.998710433087236 0.9966502189536321\n",
      "5 fold: ls 0.0050041415459339275 0.006929470200297762 auc 0.9985431414319386 0.9965978377019298\n",
      "6 fold: ls 0.004755953534239112 0.006324900107769023 auc 0.998752296605831 0.994705564984181\n",
      "7 fold: ls 0.005086204023981436 0.007587975706078776 auc 0.9983460702378075 0.9956314036080207\n",
      "8 fold: ls 0.004537971091197889 0.007110252078297747 auc 0.9989121699296788 0.9941208174685011\n",
      "9 fold: ls 0.00534480649859934 0.007553936616139957 auc 0.998125616894809 0.9815105326437731\n",
      "threat 0.095 0.6 3\n",
      "this class avg train 0.004769033136409748 avg val 0.006873506651328594\n",
      "this class auc train 0.9986870342181072 auc val 0.9940129331471844\n",
      "========================\n",
      "0 fold: ls 0.04687048909775925 0.05006441452482709 auc 0.9928624803831532 0.991301041663181\n",
      "1 fold: ls 0.050891729567821335 0.053607385554602226 auc 0.9913296172569259 0.9897852678108343\n",
      "2 fold: ls 0.05121504120169333 0.05500433809544902 auc 0.9912368777738642 0.9891021887307638\n",
      "3 fold: ls 0.05083692051792947 0.05143112213283222 auc 0.9913440853602244 0.990641929536321\n",
      "4 fold: ls 0.04887061668100814 0.05531470627785981 auc 0.9921091609752365 0.9889508826611044\n",
      "5 fold: ls 0.048487547144998096 0.052017835979373594 auc 0.9922646378303285 0.9907246377781562\n",
      "6 fold: ls 0.04863741801543932 0.05611345443456336 auc 0.9921808267702329 0.9892272109863391\n",
      "7 fold: ls 0.048701492623833414 0.055404703602526466 auc 0.9921729762705105 0.9895683557794381\n",
      "8 fold: ls 0.04958583137012204 0.05238762862156483 auc 0.9918331944246792 0.990616353505691\n",
      "9 fold: ls 0.05022027881731832 0.054865100209417664 auc 0.9915996574246567 0.9889412827254273\n",
      "insult 0.095 0.6 3\n",
      "this class avg train 0.049431736503792276 avg val 0.05362106894330163\n",
      "this class auc train 0.9918933514469812 auc val 0.9898859151177257\n",
      "========================\n",
      "0 fold: ls 0.01470918927461935 0.017016154086588537 auc 0.9955330219559327 0.9928118457696786\n",
      "1 fold: ls 0.01547425248833973 0.017615195869790237 auc 0.9948224310930943 0.9917706821415327\n",
      "2 fold: ls 0.0152249901406074 0.017746011521990263 auc 0.9950543196072481 0.9921417255964383\n",
      "3 fold: ls 0.014251432562255398 0.01822061604539124 auc 0.9959077417011551 0.9886090780321201\n",
      "4 fold: ls 0.014476421905320995 0.018976872696277597 auc 0.9956969614971085 0.9883994552947565\n",
      "5 fold: ls 0.014760524454506459 0.016356809615401105 auc 0.9954955222366273 0.9936573668476052\n",
      "6 fold: ls 0.014652779577461106 0.016680409786769882 auc 0.9954960286884051 0.9909856203482911\n",
      "7 fold: ls 0.014941444591009954 0.018672301443100392 auc 0.9953379148149845 0.9860791964737335\n",
      "8 fold: ls 0.014506715253906389 0.016854194052226004 auc 0.995747546477743 0.992698623455452\n",
      "9 fold: ls 0.015449004284303978 0.016620453638841376 auc 0.994923113019599 0.9923657778741238\n",
      "identity_hate 0.095 0.6 3\n",
      "this class avg train 0.014844675453233078 avg val 0.017475901875637665\n",
      "this class auc train 0.9954014601091898 auc val 0.9909519371833732\n",
      "========================\n",
      "all loss avg 0.031924578009392225 0.03519237869657775\n",
      "all auc avg 0.9945843349545279 0.9918321263716512\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 4 feature fraction 0.4\n",
      "0 fold: ls 0.06772045224565083 0.07786723404844735 auc 0.9914639340351626 0.9870617408778501\n",
      "1 fold: ls 0.0669347957015176 0.0713145588475855 auc 0.9916985066813875 0.989862621880838\n",
      "2 fold: ls 0.06728354906211505 0.07529447626787836 auc 0.9915657812036336 0.9886975851240597\n",
      "3 fold: ls 0.05794880895283702 0.07267305634827857 auc 0.9942467046464891 0.9893161173535119\n",
      "4 fold: ls 0.0677021532551986 0.0780146792468093 auc 0.9914032753521298 0.9878071180175602\n",
      "5 fold: ls 0.06246066121784061 0.07590825655181141 auc 0.9930534748348634 0.9878735718988385\n",
      "6 fold: ls 0.06298415334401633 0.07726000980452412 auc 0.9928819285152688 0.9879805055318096\n",
      "7 fold: ls 0.06819258451531701 0.06985392771963905 auc 0.99129535196735 0.990467468366372\n",
      "8 fold: ls 0.06529444907901304 0.07388765919045891 auc 0.9921756672211544 0.9893266581086632\n",
      "9 fold: ls 0.06644483460146824 0.07685352369092019 auc 0.9918382150686317 0.9880579628623988\n",
      "toxic 0.095 0.4 4\n",
      "this class avg train 0.06529664419749742 avg val 0.07489273817163526\n",
      "this class auc train 0.992162283952607 auc val 0.9886451350021902\n",
      "========================\n",
      "0 fold: ls 0.016039201849658728 0.021152807298376944 auc 0.9958934089735774 0.991216055829852\n",
      "1 fold: ls 0.016060474391680502 0.02045510323068183 auc 0.995878344674975 0.9918727845296873\n",
      "2 fold: ls 0.01647009933318166 0.020943987481851264 auc 0.9955785560652906 0.9912378149132801\n",
      "3 fold: ls 0.016171737172895388 0.019630221912810074 auc 0.9957782615627866 0.9927012121787568\n",
      "4 fold: ls 0.01656462386739762 0.02102985601907009 auc 0.9955093318514265 0.9913909197366755\n",
      "5 fold: ls 0.012895416788483672 0.01963224767308409 auc 0.9981887969221837 0.9925892219459354\n",
      "6 fold: ls 0.016663104844420736 0.019236944928831795 auc 0.995467748284113 0.9928977040859999\n",
      "7 fold: ls 0.01589565369443366 0.020179022327698776 auc 0.9960096252397597 0.9921667317614243\n",
      "8 fold: ls 0.016680000400693142 0.02100884498953176 auc 0.9954300809676124 0.9912558032872255\n",
      "9 fold: ls 0.01584962045079885 0.018842709477807543 auc 0.9960968764686972 0.9932739398412962\n",
      "severe_toxic 0.095 0.4 4\n",
      "this class avg train 0.0159289932793644 avg val 0.02021117453397442\n",
      "this class auc train 0.9959831031010422 auc val 0.9920602188110133\n",
      "========================\n",
      "0 fold: ls 0.03172171662858885 0.036885798464174786 auc 0.99701190984325 0.9957135535572846\n",
      "1 fold: ls 0.03386107038533973 0.036820840987642045 auc 0.9965713030741394 0.9956137922717891\n",
      "2 fold: ls 0.03302163866787408 0.03903901714802458 auc 0.9967395637585982 0.9953385530054097\n",
      "3 fold: ls 0.032364161498046724 0.034305670263620996 auc 0.996877931315274 0.9963185336469939\n",
      "4 fold: ls 0.0333700570183427 0.041930571672187014 auc 0.996685330618811 0.9945696198170035\n",
      "5 fold: ls 0.032393141487347656 0.037533931508446 auc 0.9968675200878915 0.995541691073515\n",
      "6 fold: ls 0.03252924671743763 0.03709226223574573 auc 0.9968427811551592 0.9955096619795076\n",
      "7 fold: ls 0.03320917473651646 0.037924481323790456 auc 0.9966965661388654 0.9956077853408554\n",
      "8 fold: ls 0.030807062228579218 0.03833910235239001 auc 0.9972136756313482 0.9953558596796777\n",
      "9 fold: ls 0.03257709068860616 0.038021919258266694 auc 0.9968410321571571 0.9955386824192946\n",
      "obscene 0.095 0.4 4\n",
      "this class avg train 0.03258543600566792 avg val 0.037789359521428825\n",
      "this class auc train 0.9968347613780495 auc val 0.995510773279133\n",
      "========================\n",
      "0 fold: ls 0.003714903305931373 0.006563777039649966 auc 0.999444522857316 0.9972423004399749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold: ls 0.0038013991340242375 0.006108898674322724 auc 0.9994160099881937 0.9971899224806201\n",
      "2 fold: ls 0.0037589476260691188 0.007289763192891955 auc 0.9994233432609985 0.995045045045045\n",
      "3 fold: ls 0.004109614120580821 0.006358073273365257 auc 0.9992867284768729 0.9900927410061392\n",
      "4 fold: ls 0.003965049590243477 0.006916370464727435 auc 0.999318725036187 0.9964629559787961\n",
      "5 fold: ls 0.004086233014601164 0.0070535206985022 auc 0.9992260811913504 0.9965520041066902\n",
      "6 fold: ls 0.003308370786333995 0.006387726600850115 auc 0.9996330140823841 0.9946741362331595\n",
      "7 fold: ls 0.0039049277734833298 0.007742913868505792 auc 0.9993512738203827 0.9954925932910093\n",
      "8 fold: ls 0.004337287688237121 0.007204515948587411 auc 0.9989705051362205 0.9945113364173632\n",
      "9 fold: ls 0.004198239938376271 0.007446822627362225 auc 0.9991587820153337 0.9907719837426429\n",
      "threat 0.095 0.4 4\n",
      "this class avg train 0.003918497297788091 avg val 0.0069072382388765076\n",
      "this class auc train 0.999322898586524 auc val 0.9948035018741441\n",
      "========================\n",
      "0 fold: ls 0.03919234735407831 0.0496320066523811 auc 0.9954497673053692 0.9915020629147162\n",
      "1 fold: ls 0.0491069689347986 0.0535803783912494 auc 0.9921004662282613 0.9896752624234982\n",
      "2 fold: ls 0.04942993802310059 0.05491348371555512 auc 0.9920453489800337 0.9890363528069359\n",
      "3 fold: ls 0.04687898545439951 0.05167638089930807 auc 0.992895653437283 0.9906040341443338\n",
      "4 fold: ls 0.048333811058850575 0.05526174403865167 auc 0.992378900653834 0.989082897828292\n",
      "5 fold: ls 0.04669005142745434 0.05202741332268514 auc 0.9929672984255508 0.990720873087077\n",
      "6 fold: ls 0.04817592994423749 0.05650828645957512 auc 0.9924220013887315 0.9890384744735539\n",
      "7 fold: ls 0.04545305436320061 0.05540020455245942 auc 0.9933887106651111 0.9895717064235954\n",
      "8 fold: ls 0.04779641948869646 0.05220930211136235 auc 0.9925736881784387 0.990588124328667\n",
      "9 fold: ls 0.04844620265458223 0.05492320637764701 auc 0.9923328476911161 0.989065172793138\n",
      "insult 0.095 0.4 4\n",
      "this class avg train 0.04695037087033987 avg val 0.053613240652087446\n",
      "this class auc train 0.992855468295373 auc val 0.9898884961223807\n",
      "========================\n",
      "0 fold: ls 0.012971097623573812 0.017105513944975583 auc 0.9969638547033317 0.9928055682973297\n",
      "1 fold: ls 0.01292234985601753 0.0176208125316382 auc 0.9970209104988977 0.9917783047865278\n",
      "2 fold: ls 0.013008947452585042 0.017826301616169733 auc 0.9969051760466409 0.9919966711460916\n",
      "3 fold: ls 0.01330818018859881 0.018242424063858325 auc 0.9967455854398145 0.9880033019504554\n",
      "4 fold: ls 0.013961320919308837 0.019280386213292405 auc 0.9962928794367133 0.9867096942557092\n",
      "5 fold: ls 0.01300719608000137 0.016318800846113483 auc 0.9969509775520538 0.9937237511176944\n",
      "6 fold: ls 0.012524967734001425 0.016678850373739014 auc 0.9972081117215126 0.98898583712696\n",
      "7 fold: ls 0.01379520725525391 0.018905035360693438 auc 0.9963486424236871 0.9869695696943421\n",
      "8 fold: ls 0.012855370302967201 0.016782851758542643 auc 0.9970319440337307 0.9926457836548884\n",
      "9 fold: ls 0.013684490451299514 0.016650232954430112 auc 0.9965173603446386 0.9922908085844353\n",
      "identity_hate 0.095 0.4 4\n",
      "this class avg train 0.013203912786360744 avg val 0.017541120966345292\n",
      "this class auc train 0.996798544220102 auc val 0.9905909290614433\n",
      "========================\n",
      "all loss avg 0.02964730907283641 0.03515914534739129\n",
      "all auc avg 0.9956595099222829 0.9919165090250507\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.095 4 0.4 toxic\n",
      "FIND BETTER PARAMS 0.095 4 0.4 obscene\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 4 feature fraction 0.5\n",
      "0 fold: ls 0.0674469080105125 0.07769252178583758 auc 0.9915279550369651 0.987128604329635\n",
      "1 fold: ls 0.059977299262206775 0.07082537503550371 auc 0.9936991670442488 0.9898989075345507\n",
      "2 fold: ls 0.06479416726880648 0.07532035944537575 auc 0.992316788494961 0.988734006679097\n",
      "3 fold: ls 0.0685419655662157 0.07360173138888326 auc 0.9912020195348673 0.9890512456715429\n",
      "4 fold: ls 0.06738822563882534 0.07829837449593431 auc 0.991469520394637 0.9877209455562298\n",
      "5 fold: ls 0.06630418733118952 0.07546507314952884 auc 0.9919114648961741 0.9880248383393745\n",
      "6 fold: ls 0.06704428118340482 0.07762596550899692 auc 0.9916853213645176 0.9878568451033464\n",
      "7 fold: ls 0.06895629001249752 0.06990459975410074 auc 0.9910353551367843 0.9905335641881776\n",
      "8 fold: ls 0.06412250624228219 0.0738196784487848 auc 0.9925134052661563 0.9893842766199901\n",
      "9 fold: ls 0.06678753956045545 0.07717514196860042 auc 0.9916853269321767 0.987960269792446\n",
      "toxic 0.095 0.5 4\n",
      "this class avg train 0.06613633700763963 avg val 0.07497288209815463\n",
      "this class auc train 0.9919046324101487 auc val 0.988629350381439\n",
      "========================\n",
      "0 fold: ls 0.01646805989308668 0.02103264899615812 auc 0.9955626560865477 0.99137746866692\n",
      "1 fold: ls 0.01640437521114998 0.020536077001570147 auc 0.995632135170601 0.9918506298265604\n",
      "2 fold: ls 0.01645651913433911 0.020991087923255068 auc 0.995587157934185 0.9912540353209267\n",
      "3 fold: ls 0.016328020273555538 0.01979924190955796 auc 0.9956848295822733 0.9926561115331055\n",
      "4 fold: ls 0.016400395470084372 0.020907145147438386 auc 0.9956255600098478 0.9914277123686542\n",
      "5 fold: ls 0.01658378747102607 0.019937553938097655 auc 0.9954776812588215 0.9923284612891847\n",
      "6 fold: ls 0.016330994090694387 0.019498134903694484 auc 0.9956879677606759 0.9925999005463579\n",
      "7 fold: ls 0.01565760816544065 0.020381770918403336 auc 0.9961676805422081 0.9919851830795036\n",
      "8 fold: ls 0.016467331550931323 0.02116027190735131 auc 0.9955625300376094 0.9911280025703472\n",
      "9 fold: ls 0.01544445235370789 0.01869275241687977 auc 0.9964223322708999 0.9934300080064562\n",
      "severe_toxic 0.095 0.5 4\n",
      "this class avg train 0.016254154361401603 avg val 0.020293668506240623\n",
      "this class auc train 0.995741053065367 auc val 0.9920037513208015\n",
      "========================\n",
      "0 fold: ls 0.030925761293916634 0.036908322000939034 auc 0.9971834287631792 0.9956975792227154\n",
      "1 fold: ls 0.03389730137084022 0.03684181030032303 auc 0.9965733563273457 0.9955792595191177\n",
      "2 fold: ls 0.03299419111635543 0.038923295354854885 auc 0.9967401090970931 0.9953669014944823\n",
      "3 fold: ls 0.0335870210124638 0.03432390413571086 auc 0.9966253728751959 0.9962921429265038\n",
      "4 fold: ls 0.03208793105947657 0.041934739421319624 auc 0.9969363183099798 0.9945661741442986\n",
      "5 fold: ls 0.03330255836186052 0.03754695195015249 auc 0.9966810080377093 0.9954958792886879\n",
      "6 fold: ls 0.03397531977566475 0.037436171745247125 auc 0.9965458960744951 0.9954545312162285\n",
      "7 fold: ls 0.03349368238078483 0.03799176972502163 auc 0.9966385194972629 0.9956087250697749\n",
      "8 fold: ls 0.03203603577285076 0.03845435251310649 auc 0.9969544445300055 0.9953236739641839\n",
      "9 fold: ls 0.031094267537687268 0.03850296598979139 auc 0.9971523533893383 0.9953994377526162\n",
      "obscene 0.095 0.5 4\n",
      "this class avg train 0.03273940696819008 avg val 0.03788642831364665\n",
      "this class auc train 0.9968030806901605 auc val 0.9954784304598607\n",
      "========================\n",
      "0 fold: ls 0.00388535664218284 0.006572259249243618 auc 0.9993583751741347 0.9970550492352818\n",
      "1 fold: ls 0.004236168618252231 0.006131291180438725 auc 0.9991540261779162 0.9971034988476848\n",
      "2 fold: ls 0.00387426264385751 0.00729261229043296 auc 0.9993676006424694 0.9951589671066414\n",
      "3 fold: ls 0.002858005988909784 0.0064918585655265775 auc 0.9998089545538413 0.9922763844364826\n",
      "4 fold: ls 0.0037532989456212566 0.006904665915654487 auc 0.9994456230655887 0.9964092651958011\n",
      "5 fold: ls 0.003997116582207103 0.007040011622503619 auc 0.999284081045823 0.99665938567268\n",
      "6 fold: ls 0.0038990413517964026 0.006623570829636245 auc 0.9993610189653515 0.994018061055587\n",
      "7 fold: ls 0.004104597166894794 0.007785314885294156 auc 0.999220461491085 0.9955659270433926\n",
      "8 fold: ls 0.00403252325976942 0.007322213117999529 auc 0.9992574171270611 0.9925386807681454\n",
      "9 fold: ls 0.00433372723916657 0.0074760044175690744 auc 0.9990674226001999 0.9828405706391268\n",
      "threat 0.095 0.5 4\n",
      "this class avg train 0.0038974098438657916 avg val 0.006963980207429899\n",
      "this class auc train 0.9993324980843472 auc val 0.9939625790000821\n",
      "========================\n",
      "0 fold: ls 0.04483766563027866 0.05006870181430726 auc 0.9936167322365965 0.9912880752487042\n",
      "1 fold: ls 0.046248578114374 0.05361190024681278 auc 0.9931284883834373 0.9899648317377672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 fold: ls 0.047591547477326364 0.054944464992350624 auc 0.9926349646154158 0.9892255788040114\n",
      "3 fold: ls 0.04842828017215234 0.05158870685802453 auc 0.9923479645622364 0.9904725296052522\n",
      "4 fold: ls 0.04846112703415528 0.05527230396648496 auc 0.9923293834744886 0.9890156353476716\n",
      "5 fold: ls 0.04721714684236866 0.05201066460414472 auc 0.9927966726654223 0.9907300756652712\n",
      "6 fold: ls 0.045944912027801536 0.05625684630763563 auc 0.9932027809035558 0.9891576896910711\n",
      "7 fold: ls 0.046565843161742844 0.05549654089621556 auc 0.9930177096265893 0.9895397077718945\n",
      "8 fold: ls 0.04909823296561537 0.05220401374234562 auc 0.9921287875637712 0.9907386520174271\n",
      "9 fold: ls 0.04911932742586718 0.05482416373755757 auc 0.992108977390389 0.9890637906524233\n",
      "insult 0.095 0.5 4\n",
      "this class avg train 0.04735126608516822 avg val 0.05362783071658792\n",
      "this class auc train 0.9927312461421902 auc val 0.9899196566541493\n",
      "========================\n",
      "0 fold: ls 0.013418849725249052 0.017224813665512078 auc 0.9966459934537784 0.9925674727389554\n",
      "1 fold: ls 0.013849338114803175 0.017606348276636048 auc 0.9963503048222274 0.9921253593292431\n",
      "2 fold: ls 0.013595147939661972 0.017964309944179725 auc 0.9965310593165968 0.9919401738949518\n",
      "3 fold: ls 0.01330898413286573 0.018366419997566982 auc 0.9967654460364885 0.9883830890275612\n",
      "4 fold: ls 0.01153877043182183 0.01933015312816173 auc 0.9978365371576063 0.9889292291219117\n",
      "5 fold: ls 0.012634761479982194 0.016323756921899864 auc 0.9971651258387746 0.9936167234169385\n",
      "6 fold: ls 0.011874500394145062 0.016682856450165113 auc 0.9976134395681745 0.9908429077245466\n",
      "7 fold: ls 0.013493939541519383 0.019069499864634114 auc 0.996573259974094 0.9871183792181515\n",
      "8 fold: ls 0.01234780539674681 0.016864443724362563 auc 0.9973516092801382 0.9924868126309705\n",
      "9 fold: ls 0.01360254559812066 0.01670687928402839 auc 0.996540281636172 0.9923147445624685\n",
      "identity_hate 0.095 0.5 4\n",
      "this class avg train 0.012966464275491585 avg val 0.017613948125714658\n",
      "this class auc train 0.996937305708405 auc val 0.9910324891665698\n",
      "========================\n",
      "all loss avg 0.029890839756959487 0.0352264563279624\n",
      "all auc avg 0.9955749693501031 0.9918377094971504\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 4 feature fraction 0.6\n",
      "0 fold: ls 0.06851602480099014 0.07759473073576473 auc 0.9911860124659719 0.987112658574196\n",
      "1 fold: ls 0.06535397021732076 0.07123969079910587 auc 0.9921462399279065 0.9897791331669901\n",
      "2 fold: ls 0.06360676508912905 0.07544675210872538 auc 0.9926725688702567 0.9887032929796999\n",
      "3 fold: ls 0.06604455136122502 0.07351754704386648 auc 0.9919252054622569 0.9890016416880031\n",
      "4 fold: ls 0.06256855855911718 0.07787909790848949 auc 0.9929657672702549 0.987882365932241\n",
      "5 fold: ls 0.06456825475575333 0.0753364156573609 auc 0.9924353654998586 0.9881028060582007\n",
      "6 fold: ls 0.06759897020294545 0.0776856883243794 auc 0.9914933260222623 0.9878118323447451\n",
      "7 fold: ls 0.06809416238187237 0.06979353534170096 auc 0.9913276306828648 0.9905603561159464\n",
      "8 fold: ls 0.06701740090905857 0.07396459776535584 auc 0.9915812156332833 0.9893229634519572\n",
      "9 fold: ls 0.06963575295200912 0.07703290951835096 auc 0.9908119603761977 0.9879734617568805\n",
      "toxic 0.095 0.6 4\n",
      "this class avg train 0.0663004411229421 avg val 0.07494909652031\n",
      "this class auc train 0.9918545292211114 auc val 0.9886250512068859\n",
      "========================\n",
      "0 fold: ls 0.01598467885428473 0.021032885525465516 auc 0.9959049173429018 0.9913343461197619\n",
      "1 fold: ls 0.01636568879472357 0.020520298125049085 auc 0.9956504221066952 0.9918870268388402\n",
      "2 fold: ls 0.016561616227308305 0.02087463608534395 auc 0.9955356373957893 0.9912769812634511\n",
      "3 fold: ls 0.016099911963211387 0.019707771148764406 auc 0.9958525390682915 0.9927716324851248\n",
      "4 fold: ls 0.01635018277975685 0.02093463423055002 auc 0.9956598179942568 0.9914356247626281\n",
      "5 fold: ls 0.0166033891851318 0.0200319268584916 auc 0.9954576486981226 0.9922325172918155\n",
      "6 fold: ls 0.01645766631861339 0.019485657802696624 auc 0.9956142714759443 0.9926428989183919\n",
      "7 fold: ls 0.015497484259976248 0.020456689411897107 auc 0.9962872603743005 0.9919995158701815\n",
      "8 fold: ls 0.016115790003523908 0.02113511607261791 auc 0.9958175393131585 0.991119641775785\n",
      "9 fold: ls 0.016238716397976177 0.0189656178022126 auc 0.9957765683616562 0.9932193956101051\n",
      "severe_toxic 0.095 0.6 4\n",
      "this class avg train 0.016227512478450633 avg val 0.020314523306308882\n",
      "this class auc train 0.9957556622131116 auc val 0.9919919580936085\n",
      "========================\n",
      "0 fold: ls 0.030733910545257054 0.036892864917669 auc 0.9972253742073549 0.9956946036113742\n",
      "1 fold: ls 0.03384439983842259 0.03693585653756133 auc 0.9965820967946667 0.9955241324037418\n",
      "2 fold: ls 0.032399807962112344 0.03912506481424526 auc 0.9968673421760421 0.9953184271443831\n",
      "3 fold: ls 0.03236346742572276 0.034257234423440815 auc 0.9968899263448812 0.9963269912072696\n",
      "4 fold: ls 0.03333793747168391 0.042000410048031414 auc 0.9966945776838749 0.994578547241739\n",
      "5 fold: ls 0.03066187139884458 0.03737486450266802 auc 0.9972406350780052 0.9955170231893773\n",
      "6 fold: ls 0.031547607502871146 0.037397170572305155 auc 0.997055305078018 0.9954560191203511\n",
      "7 fold: ls 0.03277149439887412 0.037952253367270275 auc 0.9967999856200813 0.9956138935788323\n",
      "8 fold: ls 0.03296178779443329 0.038750603981026456 auc 0.9967675258932327 0.995243092209334\n",
      "9 fold: ls 0.032985383582455556 0.03844784494928103 auc 0.9967511080928081 0.9954006922090728\n",
      "obscene 0.095 0.6 4\n",
      "this class avg train 0.03236076679206774 avg val 0.03791341681134988\n",
      "this class auc train 0.9968873876968963 auc val 0.9954673421915474\n",
      "========================\n",
      "0 fold: ls 0.0038467513303189083 0.0064837065129585095 auc 0.9993838751482287 0.9971755185417976\n",
      "1 fold: ls 0.0038649660783938054 0.0061559445808810065 auc 0.9993867905911268 0.9968062539283469\n",
      "2 fold: ls 0.003592978202392871 0.007297340550459427 auc 0.99950466706373 0.9954915671485439\n",
      "3 fold: ls 0.004202111517487882 0.006505214815694901 auc 0.9992405364897208 0.9919725731766087\n",
      "4 fold: ls 0.0038818619272739862 0.0067138314292947985 auc 0.999366589939892 0.996591290045467\n",
      "5 fold: ls 0.0037481545341796797 0.007039778205799981 auc 0.9994349683737562 0.9965637898883232\n",
      "6 fold: ls 0.0041341345198751345 0.006386628393480004 auc 0.9992247493548714 0.9939172271460598\n",
      "7 fold: ls 0.003909947524485873 0.007707640885350247 auc 0.9993587938239169 0.995571165168563\n",
      "8 fold: ls 0.003419179417279277 0.0072354011963406675 auc 0.9995909486704628 0.993777107297756\n",
      "9 fold: ls 0.003931152590653274 0.007416819697784097 auc 0.9993321023956584 0.9882162244574528\n",
      "threat 0.095 0.6 4\n",
      "this class avg train 0.0038531237642340692 avg val 0.006894230626804364\n",
      "this class auc train 0.9993824021851365 auc val 0.994608271679892\n",
      "========================\n",
      "0 fold: ls 0.047501946595184974 0.049889294851735745 auc 0.9926849450541062 0.9914012594989442\n",
      "1 fold: ls 0.04875857631046038 0.05383122547799101 auc 0.9922292816853757 0.9898269694728775\n",
      "2 fold: ls 0.049172029446566345 0.05497721013748399 auc 0.9921131995023912 0.9893080619309416\n",
      "3 fold: ls 0.047493952629189075 0.05159428345781979 auc 0.9926830335389409 0.9905997677756995\n",
      "4 fold: ls 0.0477444897144507 0.05526492374996285 auc 0.9925862881977021 0.98899045374734\n",
      "5 fold: ls 0.043197936041202194 0.0518724651778146 auc 0.9941538896375173 0.9907905617019481\n",
      "6 fold: ls 0.04722123986840264 0.05624078135538559 auc 0.9927563038273238 0.9891924921686058\n",
      "7 fold: ls 0.043604484700518066 0.05518909652927054 auc 0.9940307687619017 0.9896718906838942\n",
      "8 fold: ls 0.04773579170157138 0.052142745648195765 auc 0.9926113384070504 0.9907293539798909\n",
      "9 fold: ls 0.04894413450184289 0.054825464058660615 auc 0.9921832881395942 0.9891517031784964\n",
      "insult 0.095 0.6 4\n",
      "this class avg train 0.047137458150938866 avg val 0.05358274904443204\n",
      "this class auc train 0.9928032336751904 auc val 0.9899662514138636\n",
      "========================\n",
      "0 fold: ls 0.012428485536600996 0.017318377403482094 auc 0.9972861426956444 0.992601998836874\n",
      "1 fold: ls 0.01338960403561915 0.01764400895548454 auc 0.9966675686143461 0.9918146244479747\n",
      "2 fold: ls 0.013108235528753606 0.017843716751455338 auc 0.9968724103693801 0.9921791662350904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold: ls 0.01226835192999421 0.018270728543195988 auc 0.9974198759004768 0.9879786404519422\n",
      "4 fold: ls 0.01371887925732385 0.01933713789741426 auc 0.9964786359003025 0.9884729913994146\n",
      "5 fold: ls 0.013100468117880714 0.016538906619523057 auc 0.9968743357672649 0.9934491821638564\n",
      "6 fold: ls 0.011530028919066215 0.016600742501250734 auc 0.9978391011410666 0.9912994977960835\n",
      "7 fold: ls 0.013393990045198716 0.018968779996197015 auc 0.9966569844687774 0.9870842817400103\n",
      "8 fold: ls 0.011351942246452822 0.016675626633541076 auc 0.9979583807100186 0.9926502998771587\n",
      "9 fold: ls 0.013430351556976201 0.016683807105489452 auc 0.9966868585057984 0.9922858407399379\n",
      "identity_hate 0.095 0.6 4\n",
      "this class avg train 0.012772033717386647 avg val 0.017588183240703353\n",
      "this class auc train 0.9970740294073075 auc val 0.9909816523688342\n",
      "========================\n",
      "all loss avg 0.02977522267100334 0.035207033258318095\n",
      "all auc avg 0.9956262073997922 0.991940087825772\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.095 4 0.6 insult\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 3 feature fraction 0.4\n",
      "0 fold: ls 0.07044301749422209 0.07766660321149162 auc 0.9905066717570583 0.9871148782958336\n",
      "1 fold: ls 0.066221632445787 0.07123165288018084 auc 0.9918899953380451 0.989825837922268\n",
      "2 fold: ls 0.07066360601208098 0.07550350559636623 auc 0.9903815910206336 0.9885576520599924\n",
      "3 fold: ls 0.0694608817691679 0.07335266767426615 auc 0.9908146186451084 0.9891058780040988\n",
      "4 fold: ls 0.06915396035526483 0.07768941084019391 auc 0.9908670174963655 0.9879121931176987\n",
      "5 fold: ls 0.070593201616679 0.07574030495407415 auc 0.9904337653680315 0.987880779379823\n",
      "6 fold: ls 0.0685026149068907 0.07756199830059139 auc 0.9911362013252661 0.987840662268683\n",
      "7 fold: ls 0.07027590079296703 0.0697069720897154 auc 0.9905125934657902 0.9905485241478456\n",
      "8 fold: ls 0.06367237655996108 0.07370480204707007 auc 0.9926334001021883 0.989497382981722\n",
      "9 fold: ls 0.07074180564377743 0.07739229078679762 auc 0.9903543228859027 0.9878364647928909\n",
      "toxic 0.075 0.4 3\n",
      "this class avg train 0.06897289975967981 avg val 0.07495502083807475\n",
      "this class auc train 0.990953017740439 auc val 0.9886120252970854\n",
      "========================\n",
      "0 fold: ls 0.017421272573114422 0.020910642958044182 auc 0.9946633368203169 0.9914443283959995\n",
      "1 fold: ls 0.017569745045676745 0.020240595639092168 auc 0.9945234792545223 0.9920963096594506\n",
      "2 fold: ls 0.017960653956410992 0.020869909925358913 auc 0.9942172037083808 0.9912607608558044\n",
      "3 fold: ls 0.01690508561160975 0.019723058620886753 auc 0.9951187530887693 0.992699629699962\n",
      "4 fold: ls 0.01795035914923206 0.020685698104705 auc 0.9942347064285075 0.991598620078491\n",
      "5 fold: ls 0.017852283695235636 0.019999366411374175 auc 0.9943028940222487 0.9921986781226189\n",
      "6 fold: ls 0.017882541534752425 0.019206931190995924 auc 0.9943080866852667 0.9928395766571394\n",
      "7 fold: ls 0.01709991654576766 0.020246393209880306 auc 0.9949586505386194 0.9920460974398848\n",
      "8 fold: ls 0.018039565129941988 0.02082860157574268 auc 0.9941723217355125 0.9913545402896737\n",
      "9 fold: ls 0.01825347551612531 0.01867876831502771 auc 0.993995360530757 0.9934984868952507\n",
      "severe_toxic 0.075 0.4 3\n",
      "this class avg train 0.017693489875786696 avg val 0.02013899659511078\n",
      "this class auc train 0.99444947928129 auc val 0.9921037028094274\n",
      "========================\n",
      "0 fold: ls 0.034751920076230104 0.036995735461512275 auc 0.9963415978494383 0.9957039219732061\n",
      "1 fold: ls 0.03604378734463118 0.03696556970371407 auc 0.9960646238061673 0.9955290656541236\n",
      "2 fold: ls 0.034507832244756086 0.03903471109028727 auc 0.9963909010117421 0.9953264931509423\n",
      "3 fold: ls 0.03363198252128564 0.03423925248882885 auc 0.9965917944309027 0.9963728813028402\n",
      "4 fold: ls 0.03521973358015921 0.04207457853098261 auc 0.9962455310767329 0.9945126879066286\n",
      "5 fold: ls 0.034188395699962 0.037559709209643515 auc 0.9964666552003768 0.9955663589576528\n",
      "6 fold: ls 0.03598271158198999 0.03770689080351786 auc 0.9960852943828085 0.9954054303801831\n",
      "7 fold: ls 0.03508953935608732 0.038179515521842754 auc 0.9962653513269768 0.9955476426900054\n",
      "8 fold: ls 0.03425139372844704 0.038543642967148184 auc 0.9964613130103338 0.995305114318023\n",
      "9 fold: ls 0.03316709293257161 0.038274292115568036 auc 0.9966962353050479 0.9954715689988686\n",
      "obscene 0.075 0.4 3\n",
      "this class avg train 0.03468343890661202 avg val 0.03795738978930454\n",
      "this class auc train 0.9963609297400527 auc val 0.9954741165332474\n",
      "========================\n",
      "0 fold: ls 0.004880925810806609 0.006483550117786451 auc 0.998635426545538 0.9971349256232978\n",
      "1 fold: ls 0.005081269385001987 0.006143246292197659 auc 0.9984800472447928 0.9970576681332495\n",
      "2 fold: ls 0.004311661602598887 0.007268138528000371 auc 0.9990787200442303 0.9945160276555626\n",
      "3 fold: ls 0.0051485253978831216 0.0064875027365699075 auc 0.9984787016608326 0.9901143482724664\n",
      "4 fold: ls 0.004936788344641935 0.006719669781604804 auc 0.998605055586307 0.9966528380162173\n",
      "5 fold: ls 0.004930127532173645 0.006915743134554088 auc 0.9985798643865627 0.9965480755128124\n",
      "6 fold: ls 0.004586972782850238 0.006426725195324778 auc 0.9988451272326128 0.9944646112263498\n",
      "7 fold: ls 0.005075438864691731 0.0074730040334969085 auc 0.9983643099008075 0.9956942611100634\n",
      "8 fold: ls 0.005327509167309764 0.007170800550228951 auc 0.9980199086392886 0.9945996043989551\n",
      "9 fold: ls 0.005315015154382781 0.007449259332548819 auc 0.998072791124441 0.9907077888469393\n",
      "threat 0.075 0.4 3\n",
      "this class avg train 0.004959423404234069 avg val 0.0068537639702312735\n",
      "this class auc train 0.9985159952365414 auc val 0.9947490148795914\n",
      "========================\n",
      "0 fold: ls 0.04666200104057926 0.049646731413602936 auc 0.9929540078622746 0.991508420640524\n",
      "1 fold: ls 0.050510898426819516 0.05349341120842725 auc 0.991477115966591 0.9900230969486262\n",
      "2 fold: ls 0.0513168919996083 0.05516605972455145 auc 0.9912088973248496 0.9891028161379158\n",
      "3 fold: ls 0.04956848515208325 0.05152967118805756 auc 0.9918497565488086 0.9906743873996567\n",
      "4 fold: ls 0.049461780607069177 0.055080370680424054 auc 0.9918835077461906 0.9890476770517483\n",
      "5 fold: ls 0.04818674256694396 0.051750216098870004 auc 0.9923971146768185 0.9907985930429178\n",
      "6 fold: ls 0.050024867232087857 0.05620038988775311 auc 0.9916491587367137 0.9891568112631526\n",
      "7 fold: ls 0.049465386872570814 0.05528036615766521 auc 0.9918766981873518 0.9896372115168676\n",
      "8 fold: ls 0.050635678779782145 0.052326294297519296 auc 0.9914225002059739 0.9906121652004947\n",
      "9 fold: ls 0.050725590011148104 0.05488040420198961 auc 0.9914234491066155 0.9891163538826385\n",
      "insult 0.075 0.4 3\n",
      "this class avg train 0.04965583226886924 avg val 0.053535391485886055\n",
      "this class auc train 0.9918142206362189 auc val 0.9899677533084541\n",
      "========================\n",
      "0 fold: ls 0.01459103025511971 0.01718728154704875 auc 0.9956481200465499 0.9924715170901942\n",
      "1 fold: ls 0.013508643220061834 0.017586070991963073 auc 0.9965049851626032 0.9915653191175489\n",
      "2 fold: ls 0.014755096368603317 0.017611545076003654 auc 0.9954877346823918 0.9923903583405412\n",
      "3 fold: ls 0.013184379764836699 0.018125527550123022 auc 0.9967149511572155 0.9891188984650234\n",
      "4 fold: ls 0.015086653136379646 0.019113959392648018 auc 0.9952096946655711 0.9888639882485717\n",
      "5 fold: ls 0.015223397027805584 0.01637157206390954 auc 0.9951174057347281 0.9937354925532202\n",
      "6 fold: ls 0.012371914948409866 0.016485962107764533 auc 0.9972741572503336 0.9907914227906641\n",
      "7 fold: ls 0.014507863948548473 0.018655310106718614 auc 0.9956965781885377 0.986826179637257\n",
      "8 fold: ls 0.013961402969009377 0.016590734507657356 auc 0.9961734909918353 0.9929804357251246\n",
      "9 fold: ls 0.014959301331158387 0.01659033965992326 auc 0.9953658090966013 0.992253323939591\n",
      "identity_hate 0.075 0.4 3\n",
      "this class avg train 0.014214968296993289 avg val 0.017431830300375983\n",
      "this class auc train 0.9959192926976366 auc val 0.9910996935907738\n",
      "========================\n",
      "all loss avg 0.03169667541869585 0.03514539882983057\n",
      "all auc avg 0.9946688225553632 0.9920010510697632\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.075 3 0.4 insult\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 3 feature fraction 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.07017223690567272 0.0779871055061875 auc 0.9905985669975742 0.986996100537988\n",
      "1 fold: ls 0.06751916590217605 0.07120668684587665 auc 0.9914642996824186 0.9897792237678734\n",
      "2 fold: ls 0.07020885095519837 0.07543687810029209 auc 0.9905420293151674 0.9885404831926302\n",
      "3 fold: ls 0.06780227212948095 0.07327107562217158 auc 0.9913973786810326 0.9891796724234468\n",
      "4 fold: ls 0.07017308776839887 0.07762165774545164 auc 0.9905351211866289 0.9879474145813778\n",
      "5 fold: ls 0.06473959201866393 0.07519312425769172 auc 0.9923374720280937 0.9880934680639691\n",
      "6 fold: ls 0.06997705357848476 0.07763808860747945 auc 0.990612864678212 0.9878533546880267\n",
      "7 fold: ls 0.07029018148784805 0.06996862951066402 auc 0.9905415477720877 0.9904302044668355\n",
      "8 fold: ls 0.06643234428425501 0.07395982626091538 auc 0.9917510044351097 0.9894413964659952\n",
      "9 fold: ls 0.06890098245551901 0.07710840948537641 auc 0.9909571442418473 0.9879314378701769\n",
      "toxic 0.075 0.5 3\n",
      "this class avg train 0.06862157674856977 avg val 0.07493914819421063\n",
      "this class auc train 0.9910737429018172 auc val 0.988619275605832\n",
      "========================\n",
      "0 fold: ls 0.016246075093366324 0.020977154003719002 auc 0.9956602370596647 0.9913972496518546\n",
      "1 fold: ls 0.01702378550586568 0.020186444216230844 auc 0.9950087104337925 0.9921588175718445\n",
      "2 fold: ls 0.017932727977166482 0.020888680967023225 auc 0.9942475357116024 0.9912975534877833\n",
      "3 fold: ls 0.01658008132685799 0.01970973341809615 auc 0.9953943241291049 0.9927186194454994\n",
      "4 fold: ls 0.018179788851867704 0.020701586780563917 auc 0.9940966084472901 0.9916520287378149\n",
      "5 fold: ls 0.016116673999951404 0.019847632777584525 auc 0.9957795998667918 0.9923993244905613\n",
      "6 fold: ls 0.017973231315935534 0.019276426799974693 auc 0.9942273937473107 0.9927965782851056\n",
      "7 fold: ls 0.017393652633392907 0.020134940419734022 auc 0.994692461801408 0.9922129151980533\n",
      "8 fold: ls 0.017962286773260307 0.020939875284570687 auc 0.9942378924005738 0.9912569976864487\n",
      "9 fold: ls 0.017769438522199 0.018663143337628165 auc 0.9944061794206178 0.9934702194469692\n",
      "severe_toxic 0.075 0.5 3\n",
      "this class avg train 0.017317774199986334 avg val 0.020132561800512525\n",
      "this class auc train 0.9947750943018157 auc val 0.9921360304001935\n",
      "========================\n",
      "0 fold: ls 0.03517408328292222 0.0368427326401949 auc 0.9962455919452897 0.995762494533293\n",
      "1 fold: ls 0.03454153423613728 0.036880181703826925 auc 0.9963972643624254 0.9956238153836757\n",
      "2 fold: ls 0.03202862959789839 0.03890300719004147 auc 0.9969339372886257 0.995366588251509\n",
      "3 fold: ls 0.03573826426887853 0.03421691028968616 auc 0.996117331569015 0.9963968443902882\n",
      "4 fold: ls 0.03496121342986282 0.04206704309215523 auc 0.9963011314304062 0.9945207539131878\n",
      "5 fold: ls 0.033792543238608655 0.03742133393850023 auc 0.9965526359361593 0.9955896172484111\n",
      "6 fold: ls 0.03590508002123417 0.03782063855794338 auc 0.9960997318326958 0.9953423510764594\n",
      "7 fold: ls 0.03549862283069862 0.038171180603319574 auc 0.9961736595241375 0.9955617386237983\n",
      "8 fold: ls 0.0351330344407754 0.038601530839939696 auc 0.9962729638269241 0.995301903577548\n",
      "9 fold: ls 0.03439158971386491 0.038447474564472554 auc 0.9964239736404112 0.9954304071463875\n",
      "obscene 0.075 0.5 3\n",
      "this class avg train 0.0347164595060881 avg val 0.037937203342008015\n",
      "this class auc train 0.9963518221356089 auc val 0.9954896514144558\n",
      "========================\n",
      "0 fold: ls 0.004956169990411379 0.006535641791562402 auc 0.9985784008072934 0.9970471925413786\n",
      "1 fold: ls 0.0049047311297188536 0.006139472928945872 auc 0.9986458458024688 0.9969974334799916\n",
      "2 fold: ls 0.00477177573831712 0.007239123965451514 auc 0.9987369554232841 0.9946522103498848\n",
      "3 fold: ls 0.004538097384833237 0.006607306478579054 auc 0.9989515117318553 0.9898589896704171\n",
      "4 fold: ls 0.005175413425909862 0.006742407226809013 auc 0.9982515342106564 0.9967235527060154\n",
      "5 fold: ls 0.005110483235678989 0.006863837672851541 auc 0.9983432685086289 0.9967327194250634\n",
      "6 fold: ls 0.004436571777844847 0.0064240762679080845 auc 0.9989621664236876 0.9949177090535755\n",
      "7 fold: ls 0.004854233962733705 0.007566714248908038 auc 0.9986543985036654 0.9955187839168604\n",
      "8 fold: ls 0.005103568500518451 0.007167058272004011 auc 0.9983643294212445 0.9943816092322959\n",
      "9 fold: ls 0.004971867158568538 0.007362597216512168 auc 0.9985780226257636 0.9894907606158966\n",
      "threat 0.075 0.5 3\n",
      "this class avg train 0.004882291230453498 avg val 0.00686482360695317\n",
      "this class auc train 0.9986066433458548 auc val 0.994632096099138\n",
      "========================\n",
      "0 fold: ls 0.048092812294409794 0.049996723531463165 auc 0.9924063577341571 0.9913340014522385\n",
      "1 fold: ls 0.049743252535626246 0.05352774757265201 auc 0.9917806025797585 0.9899961184410856\n",
      "2 fold: ls 0.0513041662930958 0.05507084449033986 auc 0.9912014930450255 0.9892213542625206\n",
      "3 fold: ls 0.05009857626901469 0.051501431752036884 auc 0.9916360873836283 0.990643518967773\n",
      "4 fold: ls 0.05066093681438181 0.05507526063308025 auc 0.9914360490882798 0.9891720791769749\n",
      "5 fold: ls 0.04880531147795178 0.05215543594988496 auc 0.9921598111064882 0.9906065937978639\n",
      "6 fold: ls 0.04939546161529624 0.0562862162099094 auc 0.9918992590324048 0.989116947367611\n",
      "7 fold: ls 0.04834771827126371 0.05536582987689365 auc 0.9923125013397992 0.9895902187325637\n",
      "8 fold: ls 0.04955788462462611 0.05218077834050667 auc 0.9918606991130077 0.9906686235545425\n",
      "9 fold: ls 0.051061499618718836 0.05489477228573494 auc 0.991301207769208 0.989185167737016\n",
      "insult 0.075 0.5 3\n",
      "this class avg train 0.04970676198143851 avg val 0.05360550406425019\n",
      "this class auc train 0.9917994068191757 auc val 0.989953462349019\n",
      "========================\n",
      "0 fold: ls 0.013931201356859942 0.017076309196870226 auc 0.9961595686203929 0.9927221675932665\n",
      "1 fold: ls 0.015138727316956854 0.017580741019660777 auc 0.9951362296320925 0.9917437786886091\n",
      "2 fold: ls 0.015121480313202753 0.017700487344552585 auc 0.9951581632671209 0.9922997833823649\n",
      "3 fold: ls 0.014867321018418811 0.01818473384381606 auc 0.9954237261496104 0.9879750533248856\n",
      "4 fold: ls 0.014703441602319171 0.019090378285467505 auc 0.9955254717612828 0.9885043787611587\n",
      "5 fold: ls 0.014638607174686263 0.016359802048636216 auc 0.9955660997631024 0.993697558684598\n",
      "6 fold: ls 0.012986468974347257 0.016510683728794072 auc 0.9968494344646817 0.990766583568177\n",
      "7 fold: ls 0.015302676968434244 0.018669998950560873 auc 0.9950025087082859 0.9872154779969652\n",
      "8 fold: ls 0.013976506442043044 0.01676412686306206 auc 0.9961430782836381 0.9928002384565359\n",
      "9 fold: ls 0.015126442801339162 0.016540928321079014 auc 0.9952020669423886 0.9924863610087434\n",
      "identity_hate 0.075 0.5 3\n",
      "this class avg train 0.014579287396860749 avg val 0.01744781896024994\n",
      "this class auc train 0.9956166347592597 auc val 0.9910211381465306\n",
      "========================\n",
      "all loss avg 0.03163735851056616 0.035154509994697415\n",
      "all auc avg 0.9947038907105886 0.9919752756691949\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.075 3 0.5 severe_toxic\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 3 feature fraction 0.6\n",
      "0 fold: ls 0.07095144911896974 0.07804513727741397 auc 0.9903087097171902 0.9870093735673735\n",
      "1 fold: ls 0.06843007328300708 0.07131174630193649 auc 0.9911765814524702 0.9897215110052893\n",
      "2 fold: ls 0.07022603135403743 0.07526448924602366 auc 0.9905186816048414 0.9886705407604314\n",
      "3 fold: ls 0.069492834992159 0.07325069411304114 auc 0.990796545263564 0.9891654027843463\n",
      "4 fold: ls 0.068855331069945 0.07753129224834589 auc 0.9909636753548188 0.9879641413768699\n",
      "5 fold: ls 0.06685031088878497 0.07547104183024785 auc 0.9917078401863393 0.9879274693509804\n",
      "6 fold: ls 0.06892688530795084 0.07752539835299896 auc 0.9910318592779833 0.9878743878400821\n",
      "7 fold: ls 0.07227050915543391 0.0701046630613566 auc 0.9898236306358688 0.9904389537765808\n",
      "8 fold: ls 0.06780258481902315 0.07382550481355601 auc 0.9913189352994829 0.9894628390748524\n",
      "9 fold: ls 0.0703963853259532 0.07724662257440436 auc 0.9904497060720401 0.9878415421125358\n",
      "toxic 0.075 0.6 3\n",
      "this class avg train 0.06942023953152641 avg val 0.07495765898193249\n",
      "this class auc train 0.9908096164864597 auc val 0.9886076161649342\n",
      "========================\n",
      "0 fold: ls 0.01768858119549752 0.020999439016735354 auc 0.9944339217910241 0.9913351373591593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold: ls 0.017607923716997136 0.020228107781619094 auc 0.9945124634708526 0.9921006614761363\n",
      "2 fold: ls 0.01771003381092809 0.020775616289138193 auc 0.9944360710329101 0.9915325515888087\n",
      "3 fold: ls 0.01712534241296225 0.019479102857536033 auc 0.9949191211115203 0.9929112862387643\n",
      "4 fold: ls 0.017479390866000234 0.020712740920962976 auc 0.9946207759493509 0.99155945372832\n",
      "5 fold: ls 0.016339443199913276 0.01981926355447558 auc 0.9955827811824097 0.9923790209890432\n",
      "6 fold: ls 0.017689023372017977 0.01925156751779895 auc 0.9944675868688498 0.9928228550680149\n",
      "7 fold: ls 0.016039679969274846 0.02016329246165187 auc 0.9958476516155897 0.9922260535895081\n",
      "8 fold: ls 0.018065752391835065 0.02102293299256963 auc 0.9941621267521831 0.9912036478544808\n",
      "9 fold: ls 0.01831271321388847 0.01857825870235844 auc 0.9939512010449536 0.9936262876121292\n",
      "severe_toxic 0.075 0.6 3\n",
      "this class avg train 0.017405788414931487 avg val 0.02010303220948461\n",
      "this class auc train 0.9946933700819643 auc val 0.9921696955504364\n",
      "========================\n",
      "0 fold: ls 0.03550067158099559 0.03703709023500324 auc 0.9961747162746359 0.9956916280000327\n",
      "1 fold: ls 0.03528515225196762 0.03698042023451323 auc 0.9962279925630289 0.995527969376261\n",
      "2 fold: ls 0.03407366720098502 0.03892082760289649 auc 0.9964879180836604 0.9953625944036011\n",
      "3 fold: ls 0.03488135326934499 0.034297738029687865 auc 0.996311302863557 0.9963594118549935\n",
      "4 fold: ls 0.03506803293610191 0.04202937661631441 auc 0.9962797607364097 0.9945302295131264\n",
      "5 fold: ls 0.03329676821835306 0.037267093963615015 auc 0.9966657467786062 0.9956189054664031\n",
      "6 fold: ls 0.03300132827146428 0.03761662037711955 auc 0.9967333697188849 0.9953232824104673\n",
      "7 fold: ls 0.035268938656656666 0.038110815772177384 auc 0.9962219886978791 0.9955665938898826\n",
      "8 fold: ls 0.033982297757840445 0.038624684589946966 auc 0.9965225451442615 0.9952831873099007\n",
      "9 fold: ls 0.0347577162334491 0.038325605655809857 auc 0.9963386128016557 0.9954644342777718\n",
      "obscene 0.075 0.6 3\n",
      "this class avg train 0.03451159263771587 avg val 0.037921027307708396\n",
      "this class auc train 0.996396395366258 auc val 0.995472823650244\n",
      "========================\n",
      "0 fold: ls 0.004921363136176784 0.006542795854263108 auc 0.9986193631860609 0.9970760004190237\n",
      "1 fold: ls 0.005043006224629593 0.006126174670955789 auc 0.9985350264883013 0.9969791011942174\n",
      "2 fold: ls 0.004006487789306526 0.007282939512527452 auc 0.9992695150733271 0.9949717159019486\n",
      "3 fold: ls 0.004712659094083324 0.006643923870808817 auc 0.9988253283464178 0.9905739937561548\n",
      "4 fold: ls 0.005275974842486829 0.00677147851854934 auc 0.9981639497202495 0.9967418861441113\n",
      "5 fold: ls 0.00478529011235691 0.006916642509568676 auc 0.9987393518049308 0.9966921239549941\n",
      "6 fold: ls 0.003992088140239402 0.006396646606559518 auc 0.9992758301564161 0.9941398474657951\n",
      "7 fold: ls 0.005273370522508502 0.007548622426978726 auc 0.998007629473996 0.9955868795440738\n",
      "8 fold: ls 0.004175896196025129 0.007248347500887324 auc 0.9991491891147023 0.9945113364173631\n",
      "9 fold: ls 0.005031164223778389 0.007298802563630893 auc 0.9984869386824384 0.9900685146772268\n",
      "threat 0.075 0.6 3\n",
      "this class avg train 0.0047217300281591395 avg val 0.006877637403472965\n",
      "this class auc train 0.998707212204684 auc val 0.9947341399474908\n",
      "========================\n",
      "0 fold: ls 0.04945933036256539 0.05011852696917712 auc 0.9918998294635029 0.9913242139006656\n",
      "1 fold: ls 0.05114986189660222 0.05361919320025785 auc 0.9912320612722733 0.9896215563712778\n",
      "2 fold: ls 0.05140250857023657 0.055184552954606406 auc 0.9911929237742019 0.9891553092029755\n",
      "3 fold: ls 0.050692476134881204 0.051434293790603026 auc 0.9914088862409548 0.9906763114482564\n",
      "4 fold: ls 0.04998849547404876 0.05499236600760206 auc 0.9916932172886808 0.9892464527407453\n",
      "5 fold: ls 0.04953532079725317 0.052334945938299536 auc 0.9918789408082742 0.9905850095690081\n",
      "6 fold: ls 0.04921439592729157 0.056422179977820244 auc 0.9919692463227302 0.9890644090121016\n",
      "7 fold: ls 0.04878649690231138 0.055382550592886985 auc 0.992122326568004 0.9895808369289235\n",
      "8 fold: ls 0.049498272154215164 0.05234040178075426 auc 0.9918660340318024 0.9906137567564691\n",
      "9 fold: ls 0.05024809133639137 0.05484111603693494 auc 0.9915898595218977 0.9890040235372699\n",
      "insult 0.075 0.6 3\n",
      "this class avg train 0.04999752495557967 avg val 0.05366701272489425\n",
      "this class auc train 0.9916853325292323 auc val 0.9898871879467691\n",
      "========================\n",
      "0 fold: ls 0.014849133788203486 0.017120048349800177 auc 0.9954217198041788 0.9927015416126916\n",
      "1 fold: ls 0.01503893903313558 0.01743984887188198 auc 0.9952568965817743 0.9921181850751302\n",
      "2 fold: ls 0.014491643689554608 0.017761233682892785 auc 0.9956988316778224 0.9922060696880142\n",
      "3 fold: ls 0.014560201225022702 0.01821159288635848 auc 0.9956574014783242 0.9885781390612578\n",
      "4 fold: ls 0.014828104203179803 0.0191920685291788 auc 0.9954351028507135 0.9892904079774119\n",
      "5 fold: ls 0.014382819337355355 0.016368238652471417 auc 0.9958153535525073 0.9936442706310571\n",
      "6 fold: ls 0.013504429501916862 0.016532248677709686 auc 0.9964545107463512 0.991144139749982\n",
      "7 fold: ls 0.015159292828388644 0.01869926059835422 auc 0.9951453954026914 0.9860069369174074\n",
      "8 fold: ls 0.014443911900430944 0.016807483983919676 auc 0.9957691877310698 0.9926222992990824\n",
      "9 fold: ls 0.015026004499367569 0.01661437411188567 auc 0.9952859025032939 0.9923802297853892\n",
      "identity_hate 0.075 0.6 3\n",
      "this class avg train 0.014628448000655556 avg val 0.017474639834445287\n",
      "this class auc train 0.9955940302328725 auc val 0.9910692219797423\n",
      "========================\n",
      "all loss avg 0.03178088726142802 0.03516683474365633\n",
      "all auc avg 0.9946476594835784 0.9919901142066029\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.075 3 0.6 severe_toxic\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 4 feature fraction 0.4\n",
      "0 fold: ls 0.06814307918314975 0.0775392712615592 auc 0.9913599245961167 0.9871791143220063\n",
      "1 fold: ls 0.06393704270936666 0.07140451489733027 auc 0.9926231650861115 0.9897151236430254\n",
      "2 fold: ls 0.06577674422739938 0.07559319879649402 auc 0.9920376021275727 0.9885977429507982\n",
      "3 fold: ls 0.06726616502919186 0.07322035977294637 auc 0.9915823217762145 0.9890936015844283\n",
      "4 fold: ls 0.066018542737368 0.07794627115993986 auc 0.9919260273417644 0.9877938816373875\n",
      "5 fold: ls 0.06367595354151236 0.07555087411340344 auc 0.9927144865467068 0.9880018106642796\n",
      "6 fold: ls 0.06542562304083935 0.07714497649478815 auc 0.9921879155412398 0.9880309125686321\n",
      "7 fold: ls 0.06878359215181366 0.06963592651355296 auc 0.9911309481266 0.9905831587211376\n",
      "8 fold: ls 0.06391022426619888 0.07377687580807725 auc 0.9926055516011447 0.9893659166694888\n",
      "9 fold: ls 0.06443305315094068 0.07710158360838255 auc 0.9924039526453515 0.987977677745514\n",
      "toxic 0.075 0.4 4\n",
      "this class avg train 0.06573700200377805 avg val 0.0748913852426474\n",
      "this class auc train 0.9920571895388823 auc val 0.9886338940506698\n",
      "========================\n",
      "0 fold: ls 0.015846582694462586 0.021003148876702755 auc 0.9960288038603814 0.9913521490062034\n",
      "1 fold: ls 0.016074505971180056 0.020259903426414042 auc 0.9958682650491165 0.9920761330548169\n",
      "2 fold: ls 0.016435857100432407 0.02100300763723782 auc 0.995597443416735 0.9910534561336877\n",
      "3 fold: ls 0.016345405634762517 0.019731226192157853 auc 0.9956595165612443 0.9926889479680974\n",
      "4 fold: ls 0.016268264550049042 0.020914523131556107 auc 0.995718947878213 0.9914285036080516\n",
      "5 fold: ls 0.015851779470654075 0.019931023201870467 auc 0.9960344786916444 0.9923021861695733\n",
      "6 fold: ls 0.01625581884439567 0.019289221801394266 auc 0.9957607652803624 0.9928264382656845\n",
      "7 fold: ls 0.016317962123609517 0.02018977465556966 auc 0.9956657998555354 0.9921408531115893\n",
      "8 fold: ls 0.016699668776095227 0.021028654942695825 auc 0.9954171505059308 0.991188518797654\n",
      "9 fold: ls 0.015158412518918689 0.01875196321542919 auc 0.9966712730456826 0.9933575477869175\n",
      "severe_toxic 0.075 0.4 4\n",
      "this class avg train 0.016125425768455978 avg val 0.020210244708102797\n",
      "this class auc train 0.9958422444144845 auc val 0.9920414733902275\n",
      "========================\n",
      "0 fold: ls 0.03390108195504118 0.037022456223706826 auc 0.996563033496534 0.9957177820576117\n",
      "1 fold: ls 0.03271103910905315 0.03689249143835674 auc 0.9968156160326812 0.995525933431659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 fold: ls 0.033485541663280216 0.038944139647412286 auc 0.9966482408327728 0.9953675279804286\n",
      "3 fold: ls 0.03093559675308006 0.03411949498690669 auc 0.9971897619581999 0.9963598817194533\n",
      "4 fold: ls 0.03164536149727755 0.04198469012623005 auc 0.9970319319088035 0.9945554455724671\n",
      "5 fold: ls 0.03365742167536832 0.03760403211983238 auc 0.9966076145652719 0.9955168665678907\n",
      "6 fold: ls 0.03417030642727555 0.03726690145380898 auc 0.9965172193917263 0.9955117763695767\n",
      "7 fold: ls 0.03339891020704332 0.03808322897207624 auc 0.9966692963133841 0.9955976049442271\n",
      "8 fold: ls 0.03185572744006834 0.03873936314233366 auc 0.9969959037923883 0.9952612603017783\n",
      "9 fold: ls 0.0335914776673333 0.038124754365646746 auc 0.9966372812340585 0.9955092810960939\n",
      "obscene 0.075 0.4 4\n",
      "this class avg train 0.032935246439482105 avg val 0.037878155247631065\n",
      "this class auc train 0.9967675899525819 auc val 0.9954923360041187\n",
      "========================\n",
      "0 fold: ls 0.0038952675832494665 0.006458229200394733 auc 0.9993562961953552 0.9971964697255395\n",
      "1 fold: ls 0.003975607744950867 0.006208018566640624 auc 0.999328238102841 0.9968141106222501\n",
      "2 fold: ls 0.003285865812295314 0.00733399694405044 auc 0.9996527455757139 0.9946037607374817\n",
      "3 fold: ls 0.004141679271882086 0.006583699963571429 auc 0.9992763742603434 0.9914009627674062\n",
      "4 fold: ls 0.003773689269506503 0.006688198678807302 auc 0.9994316956292375 0.996624028327781\n",
      "5 fold: ls 0.004033779144685316 0.0069375344809687765 auc 0.9992832527085006 0.9967117669243825\n",
      "6 fold: ls 0.003792533519514439 0.006530313980332183 auc 0.9994097040854246 0.9936527018249629\n",
      "7 fold: ls 0.004208267708860966 0.007640249526056133 auc 0.9990633859960969 0.9957008087665263\n",
      "8 fold: ls 0.0039853863301064245 0.007175466493808066 auc 0.9992988513279297 0.9939589928355821\n",
      "9 fold: ls 0.004416025971097469 0.007516132043318444 auc 0.9990018116970644 0.9911531409358814\n",
      "threat 0.075 0.4 4\n",
      "this class avg train 0.003950810235614885 avg val 0.006907183987794813\n",
      "this class auc train 0.9993102355578507 auc val 0.9947816743467793\n",
      "========================\n",
      "0 fold: ls 0.04279002642408303 0.049881091944376746 auc 0.9943149973607245 0.9914073662618915\n",
      "1 fold: ls 0.04680962698388345 0.05355280448756169 auc 0.9929250592566602 0.9899291950115275\n",
      "2 fold: ls 0.04922681276540058 0.054993635336418684 auc 0.9920739018503463 0.9888883265461822\n",
      "3 fold: ls 0.044507517056899995 0.051427600744444725 auc 0.993723115288307 0.990704251980097\n",
      "4 fold: ls 0.048885993828601156 0.05514304464242719 auc 0.9921892533906349 0.988970417224817\n",
      "5 fold: ls 0.04779839677710249 0.05217409893504535 auc 0.9925633579330618 0.99064524462628\n",
      "6 fold: ls 0.04846716357212051 0.056527917098320155 auc 0.992316317589099 0.9890308196016924\n",
      "7 fold: ls 0.04597647888599789 0.05506882046266954 auc 0.9932171900298797 0.9897097529628699\n",
      "8 fold: ls 0.04901301803290587 0.05222454945437019 auc 0.9921410711006551 0.9906804345751966\n",
      "9 fold: ls 0.048919533808848156 0.05453630531011098 auc 0.9921889469346559 0.9891707180840883\n",
      "insult 0.075 0.4 4\n",
      "this class avg train 0.04723945681358431 avg val 0.05355298684157452\n",
      "this class auc train 0.9927653210734023 auc val 0.9899136526874642\n",
      "========================\n",
      "0 fold: ls 0.01105642338082545 0.0172126728626597 auc 0.9981094723869512 0.992623521599213\n",
      "1 fold: ls 0.013825201299431381 0.017618893385442407 auc 0.9963554012730879 0.9920424070160618\n",
      "2 fold: ls 0.013335984935995774 0.017716468490025866 auc 0.9967366013473216 0.9920751395504523\n",
      "3 fold: ls 0.013299535799661068 0.018319449261683704 auc 0.9967776730723589 0.9882351200364811\n",
      "4 fold: ls 0.013944552396401683 0.019306316242116334 auc 0.9963423489122963 0.9890218218390572\n",
      "5 fold: ls 0.013089408318716926 0.016442823930860245 auc 0.9969006086666081 0.9935711124558567\n",
      "6 fold: ls 0.011317716790112469 0.016599468671507033 auc 0.9979856085943042 0.9912299479731195\n",
      "7 fold: ls 0.013795761785921675 0.018849421574027452 auc 0.9964066606413241 0.9859579359057735\n",
      "8 fold: ls 0.012885344251919171 0.016915605094778362 auc 0.9970298421054824 0.9925667497651565\n",
      "9 fold: ls 0.013899628208657627 0.016759138783654388 auc 0.9963658299215177 0.9921652576053183\n",
      "identity_hate 0.075 0.4 4\n",
      "this class avg train 0.013044955716764322 avg val 0.01757402582967555\n",
      "this class auc train 0.9969010046921252 auc val 0.9909489013746489\n",
      "========================\n",
      "all loss avg 0.02983881616294661 0.035168996976237696\n",
      "all auc avg 0.9956072642048878 0.9919686553089847\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 4 feature fraction 0.5\n",
      "0 fold: ls 0.06915443100000401 0.07796334627088458 auc 0.9910421891603692 0.9869154657519602\n",
      "1 fold: ls 0.06844538034041756 0.07145655295506873 auc 0.9912597492776853 0.9896941948390112\n",
      "2 fold: ls 0.06899593847529142 0.07560917895333195 auc 0.9910250927032455 0.9885511287964035\n",
      "3 fold: ls 0.06684384218547595 0.07362072577575494 auc 0.9917489008184679 0.9889834309104845\n",
      "4 fold: ls 0.06270218092427404 0.077599870375847 auc 0.9929568194940741 0.9880279661141413\n",
      "5 fold: ls 0.06432677644624508 0.07551984774270805 auc 0.9925345094111759 0.9880129165312054\n",
      "6 fold: ls 0.06553655367667281 0.07744754839764707 auc 0.9921725119162902 0.9879116944869389\n",
      "7 fold: ls 0.07012882059732992 0.06998829242664134 auc 0.9907243242608161 0.9904811589961288\n",
      "8 fold: ls 0.05866856080634353 0.07380244227371976 auc 0.9940635786269355 0.9893122874807396\n",
      "9 fold: ls 0.06499961454037924 0.07719547600749116 auc 0.9922553831078107 0.9879435871707556\n",
      "toxic 0.075 0.5 4\n",
      "this class avg train 0.06598020989924336 avg val 0.07502032811790946\n",
      "this class auc train 0.991978305877687 auc val 0.988583383107777\n",
      "========================\n",
      "0 fold: ls 0.015932874686872933 0.021089918823921076 auc 0.9959441134372319 0.9912552221800228\n",
      "1 fold: ls 0.016283254852417436 0.020457514018737424 auc 0.9957250451573613 0.9919744587922521\n",
      "2 fold: ls 0.016382778838694507 0.020867125253665016 auc 0.9956435014007812 0.9913398847955437\n",
      "3 fold: ls 0.01592552114354238 0.01970527052169312 auc 0.9959754918786349 0.992728114318268\n",
      "4 fold: ls 0.016405479996489714 0.02098029057179598 auc 0.9956313215465347 0.9913948759336624\n",
      "5 fold: ls 0.01587298953635143 0.019976008953797107 auc 0.9960234436404819 0.9922516264697148\n",
      "6 fold: ls 0.016308038955290132 0.019296953357317553 auc 0.9957226693974236 0.9928065316119652\n",
      "7 fold: ls 0.016089024559967247 0.020294820473836395 auc 0.9958600604506921 0.9921030304695222\n",
      "8 fold: ls 0.016213229481822144 0.021002272579459504 auc 0.9957716459699932 0.9911893150638028\n",
      "9 fold: ls 0.016682327791373068 0.018768402832224623 auc 0.9954496284951013 0.993391787231315\n",
      "severe_toxic 0.075 0.5 4\n",
      "this class avg train 0.0162095519842821 avg val 0.020243857738644778\n",
      "this class auc train 0.9957746921374235 auc val 0.9920434846866069\n",
      "========================\n",
      "0 fold: ls 0.033603126715441856 0.03687477065446211 auc 0.9966206130594237 0.9957583443385274\n",
      "1 fold: ls 0.033741110093074685 0.03678648873154757 auc 0.9965978657986279 0.9956158282163912\n",
      "2 fold: ls 0.030446783096589186 0.03873955980001539 auc 0.9972821562227705 0.9954018280859914\n",
      "3 fold: ls 0.03183791574088627 0.03423724780798807 auc 0.9970003167797832 0.9963522855773538\n",
      "4 fold: ls 0.03299661342804957 0.04192111751169313 auc 0.996756301976125 0.9945658609013253\n",
      "5 fold: ls 0.029972963454164014 0.037228012049965085 auc 0.9973887955216957 0.995581316309622\n",
      "6 fold: ls 0.03405298907494742 0.037490347200436834 auc 0.9965391136686926 0.9954936474325039\n",
      "7 fold: ls 0.0337166175696515 0.0382041151077457 auc 0.9966132647168586 0.9955824126600279\n",
      "8 fold: ls 0.03236668764723595 0.03872038521754004 auc 0.9968914734044412 0.9952542123348818\n",
      "9 fold: ls 0.03227939692640887 0.03828493218603552 auc 0.9968964700307984 0.9954523601343774\n",
      "obscene 0.075 0.5 4\n",
      "this class avg train 0.03250142037464492 avg val 0.037848697626742936\n",
      "this class auc train 0.9968586371179216 auc val 0.9955058095991001\n",
      "========================\n",
      "0 fold: ls 0.003689145629833377 0.006421292195058769 auc 0.9994621129668343 0.9972671799706684\n",
      "1 fold: ls 0.0039060849240161546 0.0061244534183335945 auc 0.9993634832899643 0.9969476744186048\n",
      "2 fold: ls 0.003961944851266783 0.007173202302012099 auc 0.9993305525909355 0.9950227844123194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold: ls 0.00421852602558666 0.0066327144802502055 auc 0.9992351929018961 0.9893705344982924\n",
      "4 fold: ls 0.0038164182083094368 0.00679884980173229 auc 0.999402338380019 0.996421050977434\n",
      "5 fold: ls 0.003977969210143013 0.006946157179774602 auc 0.9992979353935868 0.9967052192679196\n",
      "6 fold: ls 0.0036274284075420537 0.006516555224761667 auc 0.9994952745792047 0.9948771135835063\n",
      "7 fold: ls 0.0041844057492337675 0.0077192820367653495 auc 0.9991692263914119 0.9954153309447482\n",
      "8 fold: ls 0.0037003723481583636 0.007207271776806132 auc 0.9994532937872487 0.9944030075308636\n",
      "9 fold: ls 0.004095070166029749 0.007499475325289306 auc 0.999226904573195 0.9910448120493818\n",
      "threat 0.075 0.5 4\n",
      "this class avg train 0.003917736552011936 avg val 0.006903925374078401\n",
      "this class auc train 0.9993436314854296 auc val 0.9947474707653738\n",
      "========================\n",
      "0 fold: ls 0.04783528818795779 0.050023638952505306 auc 0.9925691568311565 0.9913705583756346\n",
      "1 fold: ls 0.048461071243341994 0.05359011569786941 auc 0.9923309076474531 0.9900204618385873\n",
      "2 fold: ls 0.04934500403782641 0.05494532132663686 auc 0.9920638545133369 0.9889394393155071\n",
      "3 fold: ls 0.048060252607430826 0.05160974269683044 auc 0.9924903533269016 0.9906233582846188\n",
      "4 fold: ls 0.046997083386443525 0.05525802305686456 auc 0.9928591761703793 0.9890243359670555\n",
      "5 fold: ls 0.04199313564004496 0.051694673509125655 auc 0.994561414453 0.9908517170170394\n",
      "6 fold: ls 0.04539736327136814 0.05641151621107099 auc 0.993406277767622 0.9890788821578071\n",
      "7 fold: ls 0.048201260262540305 0.055410427413647906 auc 0.9924317792351923 0.9895805018645079\n",
      "8 fold: ls 0.04773721587666699 0.05229615277324562 auc 0.9926099509562486 0.9905260536456558\n",
      "9 fold: ls 0.04884041065208217 0.054646205060223725 auc 0.9922148828634587 0.9891037470839972\n",
      "insult 0.075 0.5 4\n",
      "this class avg train 0.04728680851657031 avg val 0.05358858166980205\n",
      "this class auc train 0.9927537753764749 auc val 0.9899119055550409\n",
      "========================\n",
      "0 fold: ls 0.01363469969378275 0.017139168724954898 auc 0.9964963234192377 0.992755348518539\n",
      "1 fold: ls 0.013728410782147982 0.017627019618586152 auc 0.9964680539565309 0.9920172971266663\n",
      "2 fold: ls 0.013525791681394186 0.01790754545338094 auc 0.9965741123772195 0.9919877033284503\n",
      "3 fold: ls 0.013281003598663348 0.018379957011966087 auc 0.9967849981783939 0.9883342144214166\n",
      "4 fold: ls 0.01371452258739235 0.01920452785946124 auc 0.9964765962084096 0.9894592271445077\n",
      "5 fold: ls 0.012923476678333158 0.016224824415735962 auc 0.997023690341644 0.9938407138792801\n",
      "6 fold: ls 0.012967429746620025 0.016713292235056725 auc 0.9969291633520341 0.9907991003685238\n",
      "7 fold: ls 0.013636686827595836 0.018993018026951834 auc 0.9964883720607366 0.9856508327913867\n",
      "8 fold: ls 0.012433229461387032 0.016674662114694004 auc 0.9973076048430426 0.9928720463906351\n",
      "9 fold: ls 0.013421898754686037 0.016837810981611225 auc 0.9967357720698996 0.9921327408049715\n",
      "identity_hate 0.075 0.5 4\n",
      "this class avg train 0.013326714981200272 avg val 0.017570182644239908\n",
      "this class auc train 0.9967284686807147 auc val 0.9909849224774376\n",
      "========================\n",
      "all loss avg 0.029870407051325484 0.035195928861902925\n",
      "all auc avg 0.995572918445942 0.9919628293652226\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 4 feature fraction 0.6\n",
      "0 fold: ls 0.06745888037722123 0.07770598771632324 auc 0.991561224461089 0.9871950600774456\n",
      "1 fold: ls 0.067383760013547 0.07127788556326731 auc 0.9915644042213887 0.9897630968106678\n",
      "2 fold: ls 0.06685931804478555 0.07532471731858757 auc 0.9916991702738063 0.9887202806452956\n",
      "3 fold: ls 0.06335744817806198 0.07306243421572775 auc 0.9927917413401174 0.9891364558021711\n",
      "4 fold: ls 0.06448375055658348 0.07763879664464966 auc 0.9923839875402287 0.9879431082248147\n",
      "5 fold: ls 0.06489900192797428 0.07529803848657064 auc 0.9923333234780795 0.9880689898266632\n",
      "6 fold: ls 0.06886096323503535 0.0777099943518106 auc 0.9910977221951148 0.9878761557127764\n",
      "7 fold: ls 0.07012555402894438 0.06993527051794092 auc 0.9907003800663566 0.9905256308762325\n",
      "8 fold: ls 0.06336458095904167 0.07375830402607135 auc 0.992759256573254 0.9894451591225175\n",
      "9 fold: ls 0.0675450554334521 0.07725182252039688 auc 0.9914637689328588 0.9878465740989695\n",
      "toxic 0.075 0.6 4\n",
      "this class avg train 0.06643383127546469 avg val 0.07489632513613459\n",
      "this class auc train 0.9918354979082293 auc val 0.9886520511197556\n",
      "========================\n",
      "0 fold: ls 0.015723390720337717 0.020992666193043782 auc 0.9961039758622247 0.991344632231928\n",
      "1 fold: ls 0.016206089647806832 0.020454176690549882 auc 0.9957821409811511 0.9918803013039625\n",
      "2 fold: ls 0.01653776665376351 0.021089905342876365 auc 0.9955433790777946 0.9910281364729712\n",
      "3 fold: ls 0.015836116747156872 0.019563482440669546 auc 0.9960481176292584 0.9928555038612482\n",
      "4 fold: ls 0.016283102412409805 0.020919928067839145 auc 0.9957163550641701 0.9914364160020257\n",
      "5 fold: ls 0.015514427473089544 0.019990952813478617 auc 0.9962939615769021 0.992233711615434\n",
      "6 fold: ls 0.016218283834849842 0.019232658155548053 auc 0.9957829650218667 0.9928451505201809\n",
      "7 fold: ls 0.01473681248807579 0.020157425743714794 auc 0.996894313713885 0.9921727037575401\n",
      "8 fold: ls 0.016230157592136286 0.021119313964300872 auc 0.9957451532172528 0.9910447927578001\n",
      "9 fold: ls 0.01584591399147 0.019054213206923916 auc 0.9960968617749908 0.9931019463531607\n",
      "severe_toxic 0.075 0.6 4\n",
      "this class avg train 0.015913206156109617 avg val 0.020257472261894498\n",
      "this class auc train 0.9960007223919497 auc val 0.9919943294876251\n",
      "========================\n",
      "0 fold: ls 0.03248747145671534 0.036902438940203224 auc 0.996852201359528 0.995697500917154\n",
      "1 fold: ls 0.03390244653605637 0.036718413591066264 auc 0.9965679966934763 0.9956247550504151\n",
      "2 fold: ls 0.03281340567438004 0.038979966118106224 auc 0.996783411777633 0.9953408240169652\n",
      "3 fold: ls 0.029826321254819606 0.03416193879846138 auc 0.997426749727263 0.9963634840136449\n",
      "4 fold: ls 0.03298688084607053 0.04213429309730639 auc 0.9967571369048311 0.9945241212751496\n",
      "5 fold: ls 0.033473403451683224 0.037513275762129226 auc 0.996643582733129 0.9955224266306646\n",
      "6 fold: ls 0.031331671032727666 0.03742516079314575 auc 0.9971006924213149 0.995420857596612\n",
      "7 fold: ls 0.03337352934917758 0.03823864915408712 auc 0.9966658555562316 0.9955495221478445\n",
      "8 fold: ls 0.03327271641652592 0.038553396369077564 auc 0.9967053505364294 0.995296030271801\n",
      "9 fold: ls 0.03129710179997429 0.03839833711300493 auc 0.9971045816380153 0.9954119039136533\n",
      "obscene 0.075 0.6 4\n",
      "this class avg train 0.03247649478181305 avg val 0.037902586973658815\n",
      "this class auc train 0.9968607559347852 auc val 0.9954751425833905\n",
      "========================\n",
      "0 fold: ls 0.0037529487934283676 0.006534160258018527 auc 0.9994323738250723 0.9971768279907814\n",
      "1 fold: ls 0.004184057741231664 0.006209283629742296 auc 0.9991956869636175 0.9967538759689922\n",
      "2 fold: ls 0.003383632028987391 0.0073256540388564086 auc 0.9996037109121535 0.9951864655353028\n",
      "3 fold: ls 0.00428080150585201 0.006619586357045237 auc 0.9991950591465334 0.9919620969262681\n",
      "4 fold: ls 0.003925507429063406 0.00683497437820931 auc 0.9993593785326149 0.9965009323862803\n",
      "5 fold: ls 0.0040696100799851405 0.00715369414588646 auc 0.999252782888565 0.9963778364447796\n",
      "6 fold: ls 0.0032971195492564193 0.006514734567179664 auc 0.9996418090757185 0.9938399647997989\n",
      "7 fold: ls 0.004169496001391442 0.0076074892885515 auc 0.9991923792316668 0.9954506882896474\n",
      "8 fold: ls 0.00399160959655075 0.007222294018115756 auc 0.9992814155828633 0.9940499356044952\n",
      "9 fold: ls 0.004119679028917254 0.007491132582757383 auc 0.9992347798260781 0.9878557968659517\n",
      "threat 0.075 0.6 4\n",
      "this class avg train 0.003917446175466384 avg val 0.0069513003264362536\n",
      "this class auc train 0.9993389375984885 auc val 0.9945154420812299\n",
      "========================\n",
      "0 fold: ls 0.048471928138675166 0.05027206396571717 auc 0.9923392170555394 0.9912475865738216\n",
      "1 fold: ls 0.048689239476164915 0.05357653818292842 auc 0.9922636016486047 0.9898301483357816\n",
      "2 fold: ls 0.04900954197209696 0.05498714776452156 auc 0.9921678094241616 0.9887919568076184\n",
      "3 fold: ls 0.04687034767243124 0.0517836984470463 auc 0.9929019469718084 0.9904716094080958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 fold: ls 0.04633283465907878 0.055113400470487364 auc 0.993103306899597 0.9891403721121054\n",
      "5 fold: ls 0.04398454301220421 0.05186571045102348 auc 0.9939055706542622 0.9907970871664861\n",
      "6 fold: ls 0.04624647878508133 0.056385145231218285 auc 0.9930996786637387 0.9890632377748768\n",
      "7 fold: ls 0.0446214447865876 0.05538215708419164 auc 0.9936888463367244 0.9895953284649031\n",
      "8 fold: ls 0.04880994540306867 0.0524556585796334 auc 0.9922319589426137 0.9906076418308823\n",
      "9 fold: ls 0.04604007934302002 0.05455849301220027 auc 0.9931857957270545 0.9890503461927427\n",
      "insult 0.075 0.6 4\n",
      "this class avg train 0.04690763832484089 avg val 0.05363800131889679\n",
      "this class auc train 0.9928887732324105 auc val 0.9898595314667313\n",
      "========================\n",
      "0 fold: ls 0.012738676074275528 0.01715082517527864 auc 0.9970941254339153 0.9927383096650206\n",
      "1 fold: ls 0.01390493756480458 0.017604294120009332 auc 0.9963401313726088 0.9921612305998079\n",
      "2 fold: ls 0.011832122948178108 0.017777670062116 auc 0.9976972823345298 0.9920428554069438\n",
      "3 fold: ls 0.01337983812049064 0.0183091803361909 auc 0.996709604607894 0.9877826936364814\n",
      "4 fold: ls 0.013128587883733136 0.019282664850219813 auc 0.9968521107109634 0.989005455571862\n",
      "5 fold: ls 0.013640030436811069 0.016414594453714168 auc 0.9965086726529745 0.993614465448568\n",
      "6 fold: ls 0.011768958002855223 0.016845500776624042 auc 0.9976844330971788 0.9903307681190838\n",
      "7 fold: ls 0.013831318495167829 0.019032103114708477 auc 0.9963720246400413 0.9859005798829394\n",
      "8 fold: ls 0.013183631158091385 0.016790727557845334 auc 0.9968369284081018 0.9925089421200953\n",
      "9 fold: ls 0.013683696818816116 0.016761213864276703 auc 0.9965132536710857 0.9921584832719127\n",
      "identity_hate 0.075 0.6 4\n",
      "this class avg train 0.013109179750322364 avg val 0.01759687743109834\n",
      "this class auc train 0.9968608566929295 auc val 0.9908243783722714\n",
      "========================\n",
      "all loss avg 0.029792966077336162 0.035207093908019876\n",
      "all auc avg 0.9956309239597987 0.9918868125185006\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.075 4 0.6 toxic\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 3 feature fraction 0.4\n",
      "0 fold: ls 0.07100438623096626 0.07802995281106002 auc 0.9903110585881628 0.9870165763375861\n",
      "1 fold: ls 0.06952166140613628 0.071401472349376 auc 0.9908086230932011 0.989767355052177\n",
      "2 fold: ls 0.06964106322698498 0.07537384357310238 auc 0.9907738594670923 0.9885752286313286\n",
      "3 fold: ls 0.06820543970693642 0.07320188990232158 auc 0.9912509703864129 0.9892217112332411\n",
      "4 fold: ls 0.06982089279781171 0.0778442937477958 auc 0.9906539179794512 0.9878512695048488\n",
      "5 fold: ls 0.06880618040327731 0.07550641944884906 auc 0.9910696102438941 0.9880197160415681\n",
      "6 fold: ls 0.06776686269677182 0.07733161133996136 auc 0.991395577735761 0.9878979594760062\n",
      "7 fold: ls 0.07215519890672602 0.07002022145919273 auc 0.9898716071423327 0.9904471590877924\n",
      "8 fold: ls 0.06756390270021545 0.07371508498055089 auc 0.9914062583877762 0.9895389082031034\n",
      "9 fold: ls 0.06980601823870443 0.07724324949257415 auc 0.9906706626341468 0.9879242752228207\n",
      "toxic 0.05 0.4 3\n",
      "this class avg train 0.06942916063145307 avg val 0.0749668039104784\n",
      "this class auc train 0.9908212145658231 auc val 0.9886260158790471\n",
      "========================\n",
      "0 fold: ls 0.01771925249968176 0.020928466113333793 auc 0.9944002127577919 0.9914063489049246\n",
      "1 fold: ls 0.017604282974624387 0.020188610338455933 auc 0.9945037194628141 0.9921327066717306\n",
      "2 fold: ls 0.018032642030368314 0.020861745190074592 auc 0.9941661218407922 0.9914209868337764\n",
      "3 fold: ls 0.017438779568840553 0.01953939847621333 auc 0.9946543281393893 0.9928555038612482\n",
      "4 fold: ls 0.017727073320737103 0.020721977248171826 auc 0.9944232540031896 0.991567366122294\n",
      "5 fold: ls 0.017820280428916258 0.019974052694335803 auc 0.9943245502489308 0.9922297305367052\n",
      "6 fold: ls 0.017903505522484427 0.01917208582998275 auc 0.99428852201512 0.9929128331428265\n",
      "7 fold: ls 0.017509960555912234 0.020140440367424763 auc 0.9946081860480279 0.9922093320003837\n",
      "8 fold: ls 0.018021009893168613 0.020912678981685816 auc 0.9941821322335233 0.9912374891658038\n",
      "9 fold: ls 0.01769018011247621 0.01860203098446438 auc 0.9944867009319983 0.9935279487427555\n",
      "severe_toxic 0.05 0.4 3\n",
      "this class avg train 0.017746696690720987 avg val 0.0201041486224143\n",
      "this class auc train 0.9944037727681578 auc val 0.9921500245982449\n",
      "========================\n",
      "0 fold: ls 0.03510392798616973 0.0369574301386465 auc 0.9962637468227079 0.9957253776970882\n",
      "1 fold: ls 0.03450641793747158 0.03678335056909528 auc 0.9964012785280412 0.9956513789413636\n",
      "2 fold: ls 0.034370496518535694 0.0389612744475779 auc 0.9964250610537386 0.9953485767805513\n",
      "3 fold: ls 0.03507916422259754 0.034276323323458625 auc 0.9962685508395294 0.9963320030948406\n",
      "4 fold: ls 0.03506214121825609 0.04207262717125941 auc 0.9962840315877073 0.9945119831099388\n",
      "5 fold: ls 0.03235724434090064 0.03742875110759068 auc 0.9968731673387414 0.9955913400847636\n",
      "6 fold: ls 0.03588294644432431 0.037711819170607154 auc 0.9961058654403951 0.9954041774082902\n",
      "7 fold: ls 0.035511391075641094 0.03819621186121321 auc 0.9961690860293134 0.9955391851297296\n",
      "8 fold: ls 0.03485726294204088 0.03861062139442381 auc 0.996327853983568 0.9953059757361994\n",
      "9 fold: ls 0.03473175189192605 0.03828296145007951 auc 0.9963508199135105 0.9954633366283723\n",
      "obscene 0.05 0.4 3\n",
      "this class avg train 0.03474627445778637 avg val 0.03792813706339521\n",
      "this class auc train 0.9963469461537253 auc val 0.9954873334611136\n",
      "========================\n",
      "0 fold: ls 0.004865690778778786 0.006517937734685212 auc 0.9986654255596473 0.9971545673580557\n",
      "1 fold: ls 0.004736405301988752 0.006152672328242315 auc 0.9987715428085282 0.9970563586842657\n",
      "2 fold: ls 0.004727887159503408 0.00719077903886947 auc 0.9987863474113222 0.9951406348208673\n",
      "3 fold: ls 0.005129127262087129 0.006529696978718437 auc 0.9984995643920199 0.9907933402476585\n",
      "4 fold: ls 0.004701637678046291 0.006701303839519288 auc 0.9988155019919076 0.9967156955182601\n",
      "5 fold: ls 0.0051650642609038875 0.006900787038724259 auc 0.9983221215440468 0.9966200997339032\n",
      "6 fold: ls 0.0047306245690739305 0.0063147172453809075 auc 0.9987486665393301 0.9949740188991556\n",
      "7 fold: ls 0.005073187426685439 0.0075329137257333315 auc 0.9983403287232301 0.9955135457916902\n",
      "8 fold: ls 0.004420544541030979 0.007114268470728397 auc 0.998976435882219 0.9945862304623503\n",
      "9 fold: ls 0.005286346985991454 0.00737135997128456 auc 0.9981885703052019 0.989574347719677\n",
      "threat 0.05 0.4 3\n",
      "this class avg train 0.004883651596409006 avg val 0.006832643637188618\n",
      "this class auc train 0.9986114505157453 auc val 0.9948128839235881\n",
      "========================\n",
      "0 fold: ls 0.05063930563659784 0.05004626392652548 auc 0.991448033554915 0.9913773343728772\n",
      "1 fold: ls 0.05133175868413144 0.05341303856119758 auc 0.9911773072119268 0.9897084731754164\n",
      "2 fold: ls 0.051256256273742154 0.05507866084539945 auc 0.9912239833125098 0.9889909285291234\n",
      "3 fold: ls 0.05107580221618266 0.05148195034660321 auc 0.991268774762465 0.9907004875371844\n",
      "4 fold: ls 0.049557662441489875 0.0550083411864457 auc 0.991845806227149 0.9891449734012027\n",
      "5 fold: ls 0.04932403036164207 0.05230168225309509 auc 0.9919623086067484 0.9905993153951101\n",
      "6 fold: ls 0.048912459922310234 0.056040278909131186 auc 0.9920823462302576 0.989231812275436\n",
      "7 fold: ls 0.04605878474542181 0.055177120391716857 auc 0.9931613908496948 0.9896869685826012\n",
      "8 fold: ls 0.05047748128033054 0.05235524061890512 auc 0.9915050411315111 0.990606804169843\n",
      "9 fold: ls 0.05093642217204769 0.054810162822578244 auc 0.9913356254337398 0.989131180483034\n",
      "insult 0.05 0.4 3\n",
      "this class avg train 0.04995699637338963 avg val 0.053571273986159795\n",
      "this class auc train 0.9917010617320917 auc val 0.9899178277921828\n",
      "========================\n",
      "0 fold: ls 0.014416094296612364 0.01714283630499373 auc 0.9957992656620104 0.9927315838017896\n",
      "1 fold: ls 0.015225781291697483 0.017459145550112427 auc 0.9951057593029292 0.9919966711460916\n",
      "2 fold: ls 0.014643691721959808 0.01752302691052201 auc 0.9955933290314916 0.9926212796448027\n",
      "3 fold: ls 0.014626869093821914 0.01820682896553267 auc 0.9956446520145575 0.9877042252321209\n",
      "4 fold: ls 0.01449234217432105 0.019028972701019324 auc 0.995746619935973 0.9889287807310296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold: ls 0.014355441234641544 0.01634289607596243 auc 0.9958385082457669 0.9936171750106124\n",
      "6 fold: ls 0.012722564631529154 0.016538210464715004 auc 0.9970271015464583 0.9905985800997181\n",
      "7 fold: ls 0.015354052466559083 0.01882433270090625 auc 0.9950093503875517 0.9867807916034396\n",
      "8 fold: ls 0.013107808655497771 0.01652880738657252 auc 0.996788159230089 0.993053598525905\n",
      "9 fold: ls 0.014790044190966934 0.016499679584218798 auc 0.9954886733278634 0.9924664896307536\n",
      "identity_hate 0.05 0.4 3\n",
      "this class avg train 0.014373468975760712 avg val 0.01740947366445552\n",
      "this class auc train 0.995804141868469 auc val 0.9910499175426264\n",
      "========================\n",
      "all loss avg 0.031856041454253296 0.03513541348068197\n",
      "all auc avg 0.9946147646006687 0.9920073338661338\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 3 feature fraction 0.5\n",
      "0 fold: ls 0.07048505638781383 0.0780099928470403 auc 0.9904824998716626 0.9870710274683758\n",
      "1 fold: ls 0.06833916094072293 0.0711782474174137 auc 0.9912008199209164 0.9898545584022352\n",
      "2 fold: ls 0.06959633809188372 0.07530928676896079 auc 0.9907447156742493 0.9886474828356627\n",
      "3 fold: ls 0.0688788073510097 0.07336010733630476 auc 0.9910102172664468 0.9891249494900075\n",
      "4 fold: ls 0.06930445464734171 0.07775154196988801 auc 0.9908206779409374 0.9879187206476469\n",
      "5 fold: ls 0.06943807459329811 0.07554479116694485 auc 0.9908381066065849 0.9879650479782517\n",
      "6 fold: ls 0.0685394529044238 0.07745039518786646 auc 0.9911257435104488 0.9878619674011528\n",
      "7 fold: ls 0.07234994446425769 0.07007061943784179 auc 0.9897769993905903 0.9904483830844926\n",
      "8 fold: ls 0.0708452167288337 0.07410415980769322 auc 0.9902788013943831 0.9893721726526226\n",
      "9 fold: ls 0.06767390090935013 0.0769906209081279 auc 0.9913618572157291 0.9880626775163548\n",
      "toxic 0.05 0.5 3\n",
      "this class avg train 0.06954504070189352 avg val 0.07497697628480818\n",
      "this class auc train 0.9907640438791949 auc val 0.9886326987476803\n",
      "========================\n",
      "0 fold: ls 0.01753352761922917 0.020887418867834143 auc 0.9945665106550688 0.9914340422838334\n",
      "1 fold: ls 0.01759205080435304 0.02026550111122319 auc 0.994519761580701 0.9920686162805418\n",
      "2 fold: ls 0.017255290777539 0.020815056826714813 auc 0.9948097450401159 0.9915835865299405\n",
      "3 fold: ls 0.017755397795396057 0.01953016464969089 auc 0.9943998255511581 0.99284284403089\n",
      "4 fold: ls 0.01804889265604538 0.020700663847952397 auc 0.9941660605739195 0.9916148404861376\n",
      "5 fold: ls 0.017978788912442967 0.01998898874997137 auc 0.9941929475903933 0.9922074364958224\n",
      "6 fold: ls 0.017909971565326015 0.01921866596187773 auc 0.994274871561822 0.9928391785240649\n",
      "7 fold: ls 0.01767816706756666 0.020088536044803984 auc 0.9944623559093513 0.9922706444938395\n",
      "8 fold: ls 0.017981096230228564 0.020900514245115107 auc 0.9942325365445704 0.9912526182226303\n",
      "9 fold: ls 0.01831549400455161 0.018647886449138232 auc 0.993963957631109 0.9935371058034663\n",
      "severe_toxic 0.05 0.5 3\n",
      "this class avg train 0.01780486774326785 avg val 0.020104339675432188\n",
      "this class auc train 0.9943588572638211 auc val 0.9921650913151165\n",
      "========================\n",
      "0 fold: ls 0.03486969378077381 0.03701050699624877 auc 0.9963124094554979 0.9957095599736423\n",
      "1 fold: ls 0.03547963099776841 0.03702779358292195 auc 0.9961850497415601 0.9955320412654649\n",
      "2 fold: ls 0.033059110855669635 0.03895221690460146 auc 0.9967129591687277 0.9953522573854862\n",
      "3 fold: ls 0.03584368252457735 0.0342104400762986 auc 0.9960977114696018 0.9963707669127712\n",
      "4 fold: ls 0.03478725116898444 0.041957369374809164 auc 0.9963400994434415 0.9945506686171263\n",
      "5 fold: ls 0.033267950474338615 0.0373736177984226 auc 0.9966716695994404 0.9956044179788938\n",
      "6 fold: ls 0.03569212673750452 0.03754320467463789 auc 0.9961382947095088 0.9953663533192791\n",
      "7 fold: ls 0.03540982031944207 0.03813113017705066 auc 0.9961922160201034 0.9955622867990014\n",
      "8 fold: ls 0.03483118468141673 0.03879889908613168 auc 0.996338988461295 0.9952432488308206\n",
      "9 fold: ls 0.0354402149019375 0.03846684672169515 auc 0.9962001116540091 0.9954276630228889\n",
      "obscene 0.05 0.5 3\n",
      "this class avg train 0.03486806664424131 avg val 0.03794720253928179\n",
      "this class auc train 0.9963189509723185 auc val 0.9954719264105375\n",
      "========================\n",
      "0 fold: ls 0.004975866936139725 0.0065367655328238735 auc 0.9985493925565088 0.9970943327047979\n",
      "1 fold: ls 0.004931600593639872 0.006145183441486417 auc 0.9986174060224442 0.9969660067043788\n",
      "2 fold: ls 0.0045782595283689565 0.007312002954281249 auc 0.9989067820023457 0.994649591451917\n",
      "3 fold: ls 0.005231802891402111 0.006498778644364601 auc 0.9984098116068574 0.9885946372074507\n",
      "4 fold: ls 0.0052671414728800575 0.006715438629737224 auc 0.9981741333967418 0.9968296247407129\n",
      "5 fold: ls 0.005184793925653714 0.006949638089663439 auc 0.9982756209606376 0.9965716470760786\n",
      "6 fold: ls 0.004514399103537207 0.0063593394075594015 auc 0.9989146913257815 0.9948862803025541\n",
      "7 fold: ls 0.005153377028736915 0.007548641618132455 auc 0.9982784308107702 0.9953825926624345\n",
      "8 fold: ls 0.004689911366130608 0.00712322606559031 auc 0.9987873325876798 0.9946477505707327\n",
      "9 fold: ls 0.005207649148411873 0.007368234778870341 auc 0.9982868813324488 0.9862148148445347\n",
      "threat 0.05 0.5 3\n",
      "this class avg train 0.004973480199490105 avg val 0.006855724916250932\n",
      "this class auc train 0.9985200482602214 auc val 0.9941837278265593\n",
      "========================\n",
      "0 fold: ls 0.046331696167313655 0.04984246420520673 auc 0.9930807278854671 0.9914419991366877\n",
      "1 fold: ls 0.051096944155594584 0.05339287633310079 auc 0.9912632525501399 0.989923590174302\n",
      "2 fold: ls 0.05147774906781399 0.055159500985175136 auc 0.9911719596190954 0.9891523813029324\n",
      "3 fold: ls 0.051006854299717165 0.05133939266752534 auc 0.9912931228160397 0.9907656542267166\n",
      "4 fold: ls 0.050681344427197364 0.05510600209672066 auc 0.9914263830918527 0.9891169473676109\n",
      "5 fold: ls 0.0490822944510131 0.052345878574718084 auc 0.992051047723494 0.9905723769389413\n",
      "6 fold: ls 0.049379782268139424 0.056161469245499356 auc 0.9919024584720559 0.9891791902601251\n",
      "7 fold: ls 0.047627348912085865 0.05525937990087537 auc 0.9925792886034555 0.9896439128051819\n",
      "8 fold: ls 0.05076486196139893 0.05236083259215389 auc 0.9913888692456757 0.9906463417708976\n",
      "9 fold: ls 0.04927296414182577 0.05473218554431748 auc 0.9919732685856293 0.9890042748355817\n",
      "insult 0.05 0.5 3\n",
      "this class avg train 0.04967218398520998 avg val 0.05356999821452929\n",
      "this class auc train 0.9918130378592904 auc val 0.9899446668818976\n",
      "========================\n",
      "0 fold: ls 0.014532664027723184 0.01711972847146416 auc 0.995693507359475 0.9926988512673992\n",
      "1 fold: ls 0.014782058355217972 0.01740446503544048 auc 0.995493625890584 0.9920307488531283\n",
      "2 fold: ls 0.014652025476576241 0.017599665478905187 auc 0.995558179082236 0.9924724138719584\n",
      "3 fold: ls 0.015153299562626527 0.018128367713247412 auc 0.9951922433507377 0.9885808294065501\n",
      "4 fold: ls 0.01541965490110292 0.019093000113383652 auc 0.994925738430712 0.989203420146292\n",
      "5 fold: ls 0.01434536082502774 0.01639228724991376 auc 0.9958497621097532 0.9935954985142568\n",
      "6 fold: ls 0.013721515196282607 0.016584614455058305 auc 0.99630081730856 0.9908894248139317\n",
      "7 fold: ls 0.015358969789178261 0.01867458579215897 auc 0.9950178552834896 0.9873735457764289\n",
      "8 fold: ls 0.014748835587783494 0.01680284008470917 auc 0.9955557212293366 0.9926918491220463\n",
      "9 fold: ls 0.01516581305114204 0.016515235553864242 auc 0.9951842935702375 0.9924691993641158\n",
      "identity_hate 0.05 0.5 3\n",
      "this class avg train 0.014788019677266099 avg val 0.017431478994814533\n",
      "this class auc train 0.9954771743615123 auc val 0.9912005781136107\n",
      "========================\n",
      "all loss avg 0.03194194315856148 0.03514762010418615\n",
      "all auc avg 0.9945420187660596 0.991933114882567\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 3 feature fraction 0.6\n",
      "0 fold: ls 0.06953481353228956 0.07802044132013086 auc 0.990811422099166 0.9870366444332098\n",
      "1 fold: ls 0.0709043495930651 0.07137352135219097 auc 0.990313719392334 0.9897383627695602\n",
      "2 fold: ls 0.06765738479991514 0.07517466688619043 auc 0.9913995317195038 0.9886875284260271\n",
      "3 fold: ls 0.06665269794884694 0.07326828200419479 auc 0.9917352373050915 0.9891698875280637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 fold: ls 0.06779634010274735 0.0775894900790881 auc 0.9913295559260866 0.9879393004990116\n",
      "5 fold: ls 0.06771584933002278 0.0754902409286598 auc 0.9914162533481393 0.9879212138014467\n",
      "6 fold: ls 0.0696782834291993 0.07732314130220892 auc 0.9907517283683197 0.9879465533100652\n",
      "7 fold: ls 0.07243148939004662 0.07013710158949128 auc 0.9897586566746034 0.9904187351644234\n",
      "8 fold: ls 0.06931333111402917 0.0739117954710366 auc 0.9908082300667973 0.9893665513344442\n",
      "9 fold: ls 0.06915516424801603 0.07706986383730047 auc 0.990849452293511 0.9879574138001457\n",
      "toxic 0.05 0.6 3\n",
      "this class avg train 0.06908397034881779 avg val 0.07493585447704923\n",
      "this class auc train 0.9909173787193553 auc val 0.9886182191066398\n",
      "========================\n",
      "0 fold: ls 0.017461971862011476 0.021008241444619255 auc 0.994624405398876 0.9913280162045828\n",
      "1 fold: ls 0.017533005558762325 0.020172782314556877 auc 0.994568103593753 0.992147740220281\n",
      "2 fold: ls 0.01775793228721981 0.020899814505396998 auc 0.9943894518443118 0.9914103051019116\n",
      "3 fold: ls 0.017967989455575265 0.01954859983964798 auc 0.9941988579560893 0.9928135681731864\n",
      "4 fold: ls 0.01804748531871731 0.020743757425339238 auc 0.9941723906671831 0.9915756741359667\n",
      "5 fold: ls 0.017882360557836444 0.019939490992562366 auc 0.9942720002871366 0.9922480434988588\n",
      "6 fold: ls 0.01785430177212025 0.019350540210796803 auc 0.9943301860197771 0.9927376545900962\n",
      "7 fold: ls 0.016881720283475465 0.020139347769220783 auc 0.9951482483309272 0.992215702129574\n",
      "8 fold: ls 0.018026653495753366 0.02095277723875611 auc 0.9942004063064526 0.9912333087685227\n",
      "9 fold: ls 0.018210659105975562 0.01859576881947335 auc 0.9940407126557345 0.9935812985747232\n",
      "severe_toxic 0.05 0.6 3\n",
      "this class avg train 0.017762407969744726 avg val 0.020135112056036974\n",
      "this class auc train 0.9943944763060241 auc val 0.9921291311397702\n",
      "========================\n",
      "0 fold: ls 0.03454105562965625 0.037033948384673186 auc 0.9963900463095959 0.9956780811378738\n",
      "1 fold: ls 0.034023539203670156 0.03674152495802948 auc 0.9965111176636441 0.9956244418281686\n",
      "2 fold: ls 0.03434197329082813 0.03886116819415566 auc 0.9964262764624054 0.995380136010099\n",
      "3 fold: ls 0.0355202155073781 0.034285492728828054 auc 0.9961639584937844 0.9963605082053997\n",
      "4 fold: ls 0.035061253620276824 0.04205857888320194 auc 0.9962823080666663 0.9945234164784599\n",
      "5 fold: ls 0.035346872160867626 0.037533260512341675 auc 0.9962056063040512 0.99553848033304\n",
      "6 fold: ls 0.035822076329670764 0.037488554760978045 auc 0.9961107241743257 0.9954342878890869\n",
      "7 fold: ls 0.03547146239254039 0.03810701136559543 auc 0.9961805705292657 0.9955656150055913\n",
      "8 fold: ls 0.035377383324590804 0.0386355184522572 auc 0.9962206712799725 0.9952954820965979\n",
      "9 fold: ls 0.035351686423863736 0.03846271393553005 auc 0.996212290245704 0.9954320536204868\n",
      "obscene 0.05 0.6 3\n",
      "this class avg train 0.03508575178833427 avg val 0.03792077721755908\n",
      "this class auc train 0.9962703569529415 auc val 0.9954832502604803\n",
      "========================\n",
      "0 fold: ls 0.0051321656028421175 0.006478904147754894 auc 0.9984137229491159 0.9971375445212655\n",
      "1 fold: ls 0.005111197493596396 0.006097758735868738 auc 0.9984314511158188 0.99703409805154\n",
      "2 fold: ls 0.004791441974104344 0.007380207416426803 auc 0.9987456611469239 0.9945801906557721\n",
      "3 fold: ls 0.0042691326694236816 0.006533632437938726 auc 0.9991360685356555 0.9909393529867789\n",
      "4 fold: ls 0.005204137345739569 0.006716395965593056 auc 0.998261393048983 0.9967837911454733\n",
      "5 fold: ls 0.0051386025842674364 0.006972386033055824 auc 0.9983490343860688 0.9965703375447859\n",
      "6 fold: ls 0.005008853181042979 0.0064596726651276635 auc 0.998519606906839 0.9945222306032225\n",
      "7 fold: ls 0.0051886468701436445 0.00753236081390377 auc 0.998192446148329 0.9954965218848868\n",
      "8 fold: ls 0.004392990943952876 0.007114025867441603 auc 0.9990244003853754 0.9944886007251348\n",
      "9 fold: ls 0.00521817241805419 0.007428500017779886 auc 0.9982686677846284 0.9889023074052825\n",
      "threat 0.05 0.6 3\n",
      "this class avg train 0.004945534108316723 avg val 0.006871384410089096\n",
      "this class auc train 0.9985342452407739 auc val 0.9946454975524143\n",
      "========================\n",
      "0 fold: ls 0.04943387515580665 0.05015233648702389 auc 0.9919088063520198 0.9913206167663268\n",
      "1 fold: ls 0.05100279689591516 0.05359591098075596 auc 0.9912983211040379 0.9897165039869633\n",
      "2 fold: ls 0.051511624127978425 0.05511513305527879 auc 0.99116433938972 0.9888808394875004\n",
      "3 fold: ls 0.04987738940587097 0.051343615960518466 auc 0.991719683624691 0.9907023279314972\n",
      "4 fold: ls 0.0508264185652186 0.05517312521734263 auc 0.9913758027045624 0.9891746726308297\n",
      "5 fold: ls 0.048404063389595436 0.0521170266414962 auc 0.9923018537247499 0.9906606380298051\n",
      "6 fold: ls 0.048566465186051046 0.056161396428011864 auc 0.9922182270986856 0.9891780190229004\n",
      "7 fold: ls 0.0495815772236544 0.055491211414866445 auc 0.9918413806943401 0.9895374460870885\n",
      "8 fold: ls 0.05137704446316322 0.05243421246541508 auc 0.9911466805652803 0.9907178780236526\n",
      "9 fold: ls 0.048274924428049565 0.05472009606738119 auc 0.9923379682420466 0.989082847441067\n",
      "insult 0.05 0.6 3\n",
      "this class avg train 0.04988561788413035 avg val 0.053630406471809056\n",
      "this class auc train 0.9917313063500135 auc val 0.989897178940763\n",
      "========================\n",
      "0 fold: ls 0.014569948416519044 0.0171113439013772 auc 0.9956428818732281 0.9927253063294409\n",
      "1 fold: ls 0.014516336519844169 0.01733579550781125 auc 0.9956992790761803 0.9921518143912847\n",
      "2 fold: ls 0.015043162468709141 0.01761004204784662 auc 0.995244338860161 0.9924091907575878\n",
      "3 fold: ls 0.013883826666971449 0.018103300147264228 auc 0.996220123015541 0.9888978417601674\n",
      "4 fold: ls 0.014551532311996433 0.019113709325672884 auc 0.9956701398266038 0.9891762924979273\n",
      "5 fold: ls 0.014886694695613928 0.016414158030807327 auc 0.9953869542420889 0.9936379483196199\n",
      "6 fold: ls 0.013232435559959753 0.01651779624844741 auc 0.996664792424173 0.9909914914372425\n",
      "7 fold: ls 0.015346355208430477 0.01867414705431657 auc 0.9950061405737403 0.985888160271696\n",
      "8 fold: ls 0.014545871188831265 0.016718697149269567 auc 0.9956954591963526 0.9928955307464413\n",
      "9 fold: ls 0.015154400116583918 0.016567775378468416 auc 0.9951920404392114 0.9924393922971312\n",
      "identity_hate 0.05 0.6 3\n",
      "this class avg train 0.014573056315345959 avg val 0.017416676479128153\n",
      "this class auc train 0.9956422149527281 auc val 0.9911212968808538\n",
      "========================\n",
      "all loss avg 0.03188938973578164 0.035151701851945265\n",
      "all auc avg 0.9945816630869728 0.9919824289801534\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 4 feature fraction 0.4\n",
      "0 fold: ls 0.067550834772944 0.07751692057233613 auc 0.991540726113657 0.9871842785723475\n",
      "1 fold: ls 0.0682509759493892 0.07143174190068127 auc 0.9913165068520148 0.9897784989608079\n",
      "2 fold: ls 0.06845276109915167 0.07542126065499066 auc 0.9912269943335184 0.9886436775985691\n",
      "3 fold: ls 0.06495699792972154 0.07315116875401143 auc 0.9922838128195889 0.989152446858052\n",
      "4 fold: ls 0.06581055659223847 0.0778667859824881 auc 0.9920265926140139 0.9879053936073362\n",
      "5 fold: ls 0.06498321477794262 0.0755337963487143 auc 0.9923060448734864 0.9880247476792364\n",
      "6 fold: ls 0.06233946039257636 0.07710428179178688 auc 0.9930618883068953 0.9879811854828459\n",
      "7 fold: ls 0.06777942406312107 0.06986130823409789 auc 0.9914192897138433 0.9904681483645387\n",
      "8 fold: ls 0.06504077762285593 0.07366057130695605 auc 0.9922556757140073 0.9894723590491867\n",
      "9 fold: ls 0.06730622126017437 0.07712010043983054 auc 0.9915575240424526 0.9879222805615315\n",
      "toxic 0.05 0.4 4\n",
      "this class avg train 0.06624712244601152 avg val 0.0748667935985893\n",
      "this class auc train 0.9918995055383478 auc val 0.988653301673445\n",
      "========================\n",
      "0 fold: ls 0.01592479662494398 0.021131759337264303 auc 0.9959850152012915 0.9912140777313584\n",
      "1 fold: ls 0.016011477013989004 0.020445550015665354 auc 0.9959316100938986 0.9919222369920243\n",
      "2 fold: ls 0.016360945108285858 0.0210003100131245 auc 0.9956684125111267 0.9912623433345994\n",
      "3 fold: ls 0.016287991618600804 0.019622881026092106 auc 0.9957024915962682 0.992816733130776\n",
      "4 fold: ls 0.01628946667311713 0.02094471647075044 auc 0.995718538615505 0.9914261298898593\n",
      "5 fold: ls 0.015938678875326493 0.01988234766399956 auc 0.9959813262836483 0.9923368215545156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fold: ls 0.016015497627088916 0.019125700051658517 auc 0.9959741693260806 0.9929506557848935\n",
      "7 fold: ls 0.016044869451937768 0.019966564893646573 auc 0.9958974877699873 0.992364603899395\n",
      "8 fold: ls 0.016595493340221607 0.02098357257697114 auc 0.9954991364900547 0.9912239526412745\n",
      "9 fold: ls 0.016278025664388514 0.018811218663785788 auc 0.9957811038190492 0.9933782507067858\n",
      "severe_toxic 0.05 0.4 4\n",
      "this class avg train 0.016174724199790012 avg val 0.02019146207129583\n",
      "this class auc train 0.995813929170691 auc val 0.9920895805665481\n",
      "========================\n",
      "0 fold: ls 0.03314032902166893 0.037003570480217844 auc 0.9967201022904737 0.9957092467513959\n",
      "1 fold: ls 0.03387676066319782 0.03687247409825699 auc 0.9965711759242469 0.9956036908543411\n",
      "2 fold: ls 0.03188051334978406 0.038884671126702054 auc 0.9969776968351919 0.9953860093158461\n",
      "3 fold: ls 0.033643161367225234 0.034106174620050826 auc 0.9966145623130644 0.9963972359440046\n",
      "4 fold: ls 0.03219392790444366 0.042083611130430534 auc 0.9969198445429466 0.994540488220498\n",
      "5 fold: ls 0.03153726472973119 0.03742373515793992 auc 0.9970616731619317 0.9955310408124269\n",
      "6 fold: ls 0.03028484424982121 0.037401300219469746 auc 0.9973252055723074 0.9954055086909263\n",
      "7 fold: ls 0.03354538136028377 0.03821989173448119 auc 0.9966315466097525 0.9955530461312927\n",
      "8 fold: ls 0.03351379354213953 0.038629044969384074 auc 0.9966606806420034 0.9952833439313873\n",
      "9 fold: ls 0.03325356991031397 0.038370052119968336 auc 0.996701461261816 0.995447342308551\n",
      "obscene 0.05 0.4 4\n",
      "this class avg train 0.03268695460986094 avg val 0.03789945256569015\n",
      "this class auc train 0.9968183949153735 auc val 0.9954856952960671\n",
      "========================\n",
      "0 fold: ls 0.003779421321776507 0.006455401012552402 auc 0.9994248862530615 0.9973038445422168\n",
      "1 fold: ls 0.003914834824662008 0.006092002946417063 auc 0.9993808135271353 0.9969673161533626\n",
      "2 fold: ls 0.0035098131540472507 0.0072471028718519995 auc 0.9995607994907801 0.9955937041692856\n",
      "3 fold: ls 0.004257161519600348 0.00647105748343704 auc 0.9992095306868118 0.9906375060238439\n",
      "4 fold: ls 0.003906373249739385 0.006773181521259783 auc 0.9993803143523896 0.9966646237978503\n",
      "5 fold: ls 0.003921061865136487 0.007031149270368651 auc 0.9993554317489028 0.9965624803570307\n",
      "6 fold: ls 0.0034528909684062295 0.006425905826997542 auc 0.9995884462860604 0.9946937792025478\n",
      "7 fold: ls 0.004047560142666803 0.007698063013833388 auc 0.9992749855771856 0.9953812831311417\n",
      "8 fold: ls 0.004007496790983984 0.007253113865957534 auc 0.9992838786249173 0.9937891438407003\n",
      "9 fold: ls 0.004243084098125715 0.0074247408671174785 auc 0.9991192761171256 0.9896933757554602\n",
      "threat 0.05 0.4 4\n",
      "this class avg train 0.0039039697935144718 avg val 0.006887171867979288\n",
      "this class auc train 0.999357836266437 auc val 0.9947287056973438\n",
      "========================\n",
      "0 fold: ls 0.044373469632583366 0.04989554893552356 auc 0.9937836369581955 0.9913900498244932\n",
      "1 fold: ls 0.04893620745721961 0.053502579411182125 auc 0.9921785655716594 0.9896505007545616\n",
      "2 fold: ls 0.04917416879811262 0.05491249796843116 auc 0.9921076090954711 0.9888769495631572\n",
      "3 fold: ls 0.04880259708916954 0.05147762157713259 auc 0.9922197282425547 0.9906547286422239\n",
      "4 fold: ls 0.04851050466269188 0.05508837555159109 auc 0.9923101496398021 0.9890982912318168\n",
      "5 fold: ls 0.04738603125311927 0.052087451339212124 auc 0.9927266523112929 0.9907008783944546\n",
      "6 fold: ls 0.04610430919025688 0.05632901169737297 auc 0.9931557326604435 0.9891601158253224\n",
      "7 fold: ls 0.043781961123667675 0.05512767693774744 auc 0.9939607216087196 0.9897139412680662\n",
      "8 fold: ls 0.047808543450539275 0.052146562539879086 auc 0.9925880585735652 0.9906818585989634\n",
      "9 fold: ls 0.048806206899454835 0.05474588318062192 auc 0.9922193561784047 0.9891876388370819\n",
      "insult 0.05 0.4 4\n",
      "this class avg train 0.0473683999556815 avg val 0.053531320913869404\n",
      "this class auc train 0.9927250210840108 auc val 0.9899114952940142\n",
      "========================\n",
      "0 fold: ls 0.01251094252622285 0.017095896545498944 auc 0.9972543829699709 0.9928934529102138\n",
      "1 fold: ls 0.013896369178221828 0.017554340453820122 auc 0.9963306331888351 0.9920235745990152\n",
      "2 fold: ls 0.013480243029267291 0.01765488753502421 auc 0.9966134250764145 0.9924177101843469\n",
      "3 fold: ls 0.013861132470502417 0.018221552903158397 auc 0.9963903039027544 0.9885503388265698\n",
      "4 fold: ls 0.013829959128082076 0.01918205475882724 auc 0.9964032006467258 0.9875721741173538\n",
      "5 fold: ls 0.013032778403192141 0.016488984257492775 auc 0.9969393710503359 0.9935539518962418\n",
      "6 fold: ls 0.013850806068239959 0.016805152010031747 auc 0.9963403207870152 0.9907918744128911\n",
      "7 fold: ls 0.013792766830718716 0.018800827672467785 auc 0.9964070854696226 0.9861114874629671\n",
      "8 fold: ls 0.011950984131331199 0.016627515973093563 auc 0.9975893465280006 0.9929429510802804\n",
      "9 fold: ls 0.013458243492281575 0.016591336411800644 auc 0.996655823826759 0.9923233253847822\n",
      "identity_hate 0.05 0.4 4\n",
      "this class avg train 0.013366422525806004 avg val 0.017502254852121542\n",
      "this class auc train 0.9966923893446433 auc val 0.9909180840874663\n",
      "========================\n",
      "all loss avg 0.02995793225511074 0.03514640931159092\n",
      "all auc avg 0.995551179386584 0.9919644771024807\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.05 4 0.4 toxic\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 4 feature fraction 0.5\n",
      "0 fold: ls 0.06723685716988488 0.07776027693471638 auc 0.9916266095761435 0.987109985848142\n",
      "1 fold: ls 0.06739314825571155 0.0713272427833054 auc 0.9915753333535253 0.989808669054906\n",
      "2 fold: ls 0.06775865590593927 0.07549529398051846 auc 0.9914372627675286 0.9885831109081651\n",
      "3 fold: ls 0.0658169703394503 0.07350737527876239 auc 0.9920434177933398 0.989000101472989\n",
      "4 fold: ls 0.06696264863499204 0.07804046425989926 auc 0.9916521894719607 0.9878622393815674\n",
      "5 fold: ls 0.06699295790708758 0.07558980439356365 auc 0.9917154580766963 0.9879640507167318\n",
      "6 fold: ls 0.06180650078462033 0.0769812056998585 auc 0.9931926954737111 0.9880802316837962\n",
      "7 fold: ls 0.06879457411617859 0.06974808116667092 auc 0.9911011182396186 0.9905314335272553\n",
      "8 fold: ls 0.06682594710298341 0.07378298136456182 auc 0.991690947432849 0.9893128314792731\n",
      "9 fold: ls 0.06555870628948957 0.0770451719729008 auc 0.9920740679716363 0.9879324352008214\n",
      "toxic 0.05 0.5 4\n",
      "this class avg train 0.06651469665063375 avg val 0.07492778978347577\n",
      "this class auc train 0.9918109100157009 auc val 0.9886185089273649\n",
      "========================\n",
      "0 fold: ls 0.015957228216184175 0.021135024203720387 auc 0.9959423930634529 0.9912362324344852\n",
      "1 fold: ls 0.016603586383930467 0.020368330833075023 auc 0.9955025385806073 0.9920207462969995\n",
      "2 fold: ls 0.01661000145162161 0.02104566622117982 auc 0.9955203084242977 0.99103763134574\n",
      "3 fold: ls 0.01608013506322164 0.019610569986618923 auc 0.9958699070012988 0.9928305798202303\n",
      "4 fold: ls 0.016605006735424987 0.020943175506327242 auc 0.9955178234399507 0.9914451196353968\n",
      "5 fold: ls 0.015110038581813251 0.019704598794707727 auc 0.996614110304902 0.9925271171177626\n",
      "6 fold: ls 0.016248253806464386 0.019189124154133045 auc 0.9957742785924001 0.9928574926454868\n",
      "7 fold: ls 0.015373846408867025 0.02009563175744436 auc 0.9964154384736209 0.9922348125171446\n",
      "8 fold: ls 0.016464925974826326 0.021107423173026486 auc 0.9955573088739152 0.9911654270793395\n",
      "9 fold: ls 0.016352831357885317 0.018733320931421472 auc 0.9957191257652165 0.9933810376383063\n",
      "severe_toxic 0.05 0.5 4\n",
      "this class avg train 0.016140585398023922 avg val 0.020193286556165445\n",
      "this class auc train 0.9958433232519661 auc val 0.992073619653089\n",
      "========================\n",
      "0 fold: ls 0.03293096180394244 0.03692337253962458 auc 0.9967656901197811 0.9957144932240239\n",
      "1 fold: ls 0.03385446135428321 0.0369068259117571 auc 0.9965815354979932 0.99553180634878\n",
      "2 fold: ls 0.03226278132412529 0.038821849260140914 auc 0.996901830484739 0.995392665729026\n",
      "3 fold: ls 0.03244447488713409 0.03406186208134056 auc 0.9968676428857443 0.9964057718150237\n",
      "4 fold: ls 0.032779680266818385 0.04190444494292325 auc 0.996796339394081 0.99458332419708\n",
      "5 fold: ls 0.033204094671937065 0.03759487891137564 auc 0.9967016946413066 0.9954890662540212\n",
      "6 fold: ls 0.033934071342564744 0.03753190696563899 auc 0.9965579616886944 0.9954662778277226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 fold: ls 0.033344387061391395 0.03804373328126119 auc 0.9966774294955646 0.9955923581244264\n",
      "8 fold: ls 0.03268275806628089 0.03867928101200202 auc 0.9968258195809084 0.9952607121265752\n",
      "9 fold: ls 0.030584679229279953 0.038364938710532204 auc 0.9972590874293238 0.9954230372147053\n",
      "obscene 0.05 0.5 4\n",
      "this class avg train 0.03280223500077574 avg val 0.037883309361659644\n",
      "this class auc train 0.9967935031218136 auc val 0.9954859512861383\n",
      "========================\n",
      "0 fold: ls 0.0038554395256276673 0.006524287101203074 auc 0.9993692086026192 0.9972056358684265\n",
      "1 fold: ls 0.004116937358939139 0.0060513252618656 auc 0.9992509179584622 0.9970877854598785\n",
      "2 fold: ls 0.004092378178821716 0.0072964900206976616 auc 0.9992538740064145 0.9951615860046092\n",
      "3 fold: ls 0.004012140265436217 0.006502575053762169 auc 0.999337955455592 0.9905956010224821\n",
      "4 fold: ls 0.003998196872581158 0.006730499869369558 auc 0.9993288437450463 0.9967026002053345\n",
      "5 fold: ls 0.0041270424861729075 0.006957061605568035 auc 0.9992173430446951 0.9965925995767594\n",
      "6 fold: ls 0.003825730840956466 0.006484704712696651 auc 0.9994092899167635 0.9943886584113814\n",
      "7 fold: ls 0.004134379777291257 0.007683573272215267 auc 0.9991687147713011 0.9953681878182162\n",
      "8 fold: ls 0.004303856618038588 0.007223252093035017 auc 0.9990267337936369 0.9945675069511036\n",
      "9 fold: ls 0.004233829584872772 0.007502154979278126 auc 0.9991238132998566 0.9797137442609094\n",
      "threat 0.05 0.5 4\n",
      "this class avg train 0.004069993150873788 avg val 0.0068955923969691146\n",
      "this class auc train 0.9992486694594387 auc val 0.99373839055791\n",
      "========================\n",
      "0 fold: ls 0.047491074323798614 0.05001685270847864 auc 0.9926888750259609 0.9913744064728341\n",
      "1 fold: ls 0.047859132705786955 0.0536226105572668 auc 0.9925663954666812 0.9898674581477603\n",
      "2 fold: ls 0.04931757281265154 0.054936150922576844 auc 0.9920664784553704 0.9892986089965166\n",
      "3 fold: ls 0.04674072600672882 0.05141246685226671 auc 0.9929457588993977 0.9906649344652316\n",
      "4 fold: ls 0.04838575706664847 0.05507593072073408 auc 0.9923605616083413 0.9891508295873263\n",
      "5 fold: ls 0.04541336355242034 0.05187245794368115 auc 0.9934281443076954 0.9907851238148334\n",
      "6 fold: ls 0.04697199720495185 0.056476878686847795 auc 0.9928566845027808 0.9890726913324764\n",
      "7 fold: ls 0.04732736663316232 0.055334765283347444 auc 0.9927396316333618 0.9896043752041275\n",
      "8 fold: ls 0.04792437531320795 0.05228167473415491 auc 0.9925476623700976 0.9906041236545174\n",
      "9 fold: ls 0.0488223042907884 0.05491662320116971 auc 0.9922143167256781 0.9890756435561291\n",
      "insult 0.05 0.5 4\n",
      "this class avg train 0.04762536699101453 avg val 0.05359464116105241\n",
      "this class auc train 0.9926414508995365 auc val 0.9899498195231754\n",
      "========================\n",
      "0 fold: ls 0.013232612230882769 0.01728081818384082 auc 0.9968004403689239 0.99265984126066\n",
      "1 fold: ls 0.01375146241024604 0.01758918924445222 auc 0.9964414907211026 0.9919105800967358\n",
      "2 fold: ls 0.013103479909158972 0.01772824149866172 auc 0.9968799494485429 0.9921782694533263\n",
      "3 fold: ls 0.013290581135726386 0.018227267096739476 auc 0.9967762280590287 0.9887104143714659\n",
      "4 fold: ls 0.013856221861385944 0.01915685848033079 auc 0.9963946417216165 0.9891980394557073\n",
      "5 fold: ls 0.013776471255142763 0.0165136316168668 auc 0.9964393918337487 0.9935688544874863\n",
      "6 fold: ls 0.010231710602205598 0.01646813162048403 auc 0.9985574219308586 0.9909368451477708\n",
      "7 fold: ls 0.013857122716217373 0.0187323096516701 auc 0.9963726077377059 0.9860740028181226\n",
      "8 fold: ls 0.012779949105001158 0.016752716852367955 auc 0.9970998776883231 0.9927126237444902\n",
      "9 fold: ls 0.013491612627067707 0.016767067166329457 auc 0.9966753381619373 0.9921223534937496\n",
      "identity_hate 0.05 0.5 4\n",
      "this class avg train 0.01313712238530347 avg val 0.017521623141174336\n",
      "this class auc train 0.9968437387671788 auc val 0.9910071824329517\n",
      "========================\n",
      "all loss avg 0.030048333262770868 0.03516937373341612\n",
      "all auc avg 0.9955302659192724 0.9918122453967716\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 4 feature fraction 0.6\n",
      "0 fold: ls 0.06817876600242592 0.07777803629540941 auc 0.9913398249077049 0.9871415602559294\n",
      "1 fold: ls 0.06557326533747558 0.07127171044434359 auc 0.9921008711325702 0.9897626891066934\n",
      "2 fold: ls 0.06837252337450082 0.07539041469027369 auc 0.9912322135494386 0.9886229752967632\n",
      "3 fold: ls 0.06495488767863988 0.07337908184150735 auc 0.9922975613802231 0.989035028113454\n",
      "4 fold: ls 0.06580029936100416 0.07791712105054166 auc 0.991999301141363 0.9878837711643825\n",
      "5 fold: ls 0.06683662283179237 0.0754285196052458 auc 0.9917325412629597 0.988000450762207\n",
      "6 fold: ls 0.06593666988090452 0.07726613961031524 auc 0.9919924335147373 0.9879923820099099\n",
      "7 fold: ls 0.06697282384519965 0.0698696103665438 auc 0.9916725574410998 0.9905093562534423\n",
      "8 fold: ls 0.06485126768427282 0.07379146590421763 auc 0.9922795972496695 0.9894223565173268\n",
      "9 fold: ls 0.06645506376725385 0.07696684165689562 auc 0.991812371731276 0.9880342535929856\n",
      "toxic 0.05 0.6 4\n",
      "this class avg train 0.06639321897634697 avg val 0.07490589414652939\n",
      "this class auc train 0.9918459273311043 auc val 0.9886404823073093\n",
      "========================\n",
      "0 fold: ls 0.01616680123082871 0.021123529350973943 auc 0.9957862997764543 0.9912065609570831\n",
      "1 fold: ls 0.016249144527042958 0.020316993257136057 auc 0.9957631408986615 0.992034592986454\n",
      "2 fold: ls 0.01620175516415675 0.020918228054887678 auc 0.9958074441994804 0.9914150525382961\n",
      "3 fold: ls 0.014713186327443931 0.019532818392336254 auc 0.9969346076123943 0.9929013957462971\n",
      "4 fold: ls 0.01649200615838628 0.020945268728143708 auc 0.9955970978715742 0.9914538232687682\n",
      "5 fold: ls 0.016179062159381637 0.019914203583226413 auc 0.9957815541434958 0.9923045748168107\n",
      "6 fold: ls 0.016472990671733936 0.019240587649409953 auc 0.9956292272201656 0.992867047839272\n",
      "7 fold: ls 0.015937960697393415 0.020125433557121 auc 0.995985647559774 0.992232025585624\n",
      "8 fold: ls 0.016188901838609 0.021125935154024406 auc 0.9957901600401283 0.9910957537913216\n",
      "9 fold: ls 0.01653934727810687 0.018856644194673738 auc 0.9955844383539358 0.9933185307456276\n",
      "severe_toxic 0.05 0.6 4\n",
      "this class avg train 0.01611411560530835 avg val 0.020209964192193314\n",
      "this class auc train 0.9958659617676064 auc val 0.9920829358275555\n",
      "========================\n",
      "0 fold: ls 0.033551623157661116 0.0368653921384874 auc 0.9966351323201456 0.9957488693655722\n",
      "1 fold: ls 0.033795031624359886 0.036900398770528434 auc 0.9965918235197087 0.9955558461561953\n",
      "2 fold: ls 0.030741898713843904 0.03889138079034955 auc 0.9972260550085648 0.9953647871044133\n",
      "3 fold: ls 0.03334051952208324 0.03421737555926193 auc 0.9966801199288307 0.9963581588831009\n",
      "4 fold: ls 0.032854414317843444 0.04214831498223604 auc 0.9967836191803051 0.9945134710140615\n",
      "5 fold: ls 0.03249750998941722 0.03767061959434022 auc 0.9968521345805677 0.995445368859263\n",
      "6 fold: ls 0.03397088726088808 0.037483612250796786 auc 0.9965525199066922 0.9954931384126726\n",
      "7 fold: ls 0.033345447803944 0.03808919979835755 auc 0.9966725949344396 0.9955844487393536\n",
      "8 fold: ls 0.032425937163153055 0.03864832851528363 auc 0.9968818971057648 0.9952847535247666\n",
      "9 fold: ls 0.03281381773307444 0.03836326121417383 auc 0.9967902889918806 0.9954380906921839\n",
      "obscene 0.05 0.6 4\n",
      "this class avg train 0.032933708728626845 avg val 0.03792778836138154\n",
      "this class auc train 0.9967666185476899 auc val 0.9954786932751583\n",
      "========================\n",
      "0 fold: ls 0.0037727463967288637 0.006577932559343426 auc 0.9994124448644272 0.9971048082966687\n",
      "1 fold: ls 0.004003524139862599 0.00609369891788439 auc 0.9993245024378463 0.997073381521056\n",
      "2 fold: ls 0.003949844815937414 0.007389470337805869 auc 0.9993344669181689 0.9950214749633354\n",
      "3 fold: ls 0.004167033760706942 0.006567099104333323 auc 0.9992566159789191 0.9922724558426048\n",
      "4 fold: ls 0.00402572996160994 0.006749578320744627 auc 0.9993153954449894 0.9967314098937708\n",
      "5 fold: ls 0.004060759400033594 0.007052962954970875 auc 0.9992565185274696 0.9966043853583926\n",
      "6 fold: ls 0.0038897114136100127 0.006382274089263687 auc 0.9993719984953495 0.9943336580970938\n",
      "7 fold: ls 0.004161471582224273 0.007701854579465621 auc 0.9991676022005838 0.9954912837597168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 fold: ls 0.003873224812447109 0.0071750183396012196 auc 0.9993701337094788 0.9941020939572541\n",
      "9 fold: ls 0.004312310905854931 0.007497354260061673 auc 0.9990854903100037 0.9898431638454348\n",
      "threat 0.05 0.6 4\n",
      "this class avg train 0.004021635718901568 avg val 0.006918724346347471\n",
      "this class auc train 0.9992895168887236 auc val 0.9948578115535328\n",
      "========================\n",
      "0 fold: ls 0.04669101221216726 0.049885251945004136 auc 0.9929883934369703 0.9914292836850717\n",
      "1 fold: ls 0.04846292297732719 0.053628728602552134 auc 0.992340509136466 0.9897956409424158\n",
      "2 fold: ls 0.04931522080326125 0.05492467615533997 auc 0.9920770129704343 0.9889534514085709\n",
      "3 fold: ls 0.045901180019375105 0.051494417280043565 auc 0.9932617437219922 0.9905819494125796\n",
      "4 fold: ls 0.048241973312669544 0.055015570647356224 auc 0.9924225397087889 0.9891893967559405\n",
      "5 fold: ls 0.047063627595908396 0.05195763204868201 auc 0.9928504638580463 0.9907650454624095\n",
      "6 fold: ls 0.047102060797921355 0.05646861011914467 auc 0.9928073000952728 0.9890591384445903\n",
      "7 fold: ls 0.04394013312518128 0.05500100094050711 auc 0.9939173826252006 0.9897404113569079\n",
      "8 fold: ls 0.048080962538400274 0.05232188041233695 auc 0.9924892205248707 0.9905464925750144\n",
      "9 fold: ls 0.04799694784049213 0.054822954724430197 auc 0.9925075952083875 0.9890714552509327\n",
      "insult 0.05 0.6 4\n",
      "this class avg train 0.04727960412227038 avg val 0.0535520722875397\n",
      "this class auc train 0.9927662161286429 auc val 0.9899132265294434\n",
      "========================\n",
      "0 fold: ls 0.013127605986229994 0.017162655984625422 auc 0.9968736275152236 0.9927934617435141\n",
      "1 fold: ls 0.013950090424357426 0.01747836761902902 auc 0.9962882609518003 0.9922473216491637\n",
      "2 fold: ls 0.013460161915169133 0.017763390795532245 auc 0.9966284504361762 0.9922302827956453\n",
      "3 fold: ls 0.013512007123144064 0.018226226206855746 auc 0.9966147394827705 0.9889588229201277\n",
      "4 fold: ls 0.013834437550193878 0.019169432863422303 auc 0.9963690038504937 0.9889523212523377\n",
      "5 fold: ls 0.012154785944047817 0.016521469237038018 auc 0.9975014311677387 0.9935385977113232\n",
      "6 fold: ls 0.012261305312033297 0.01674041632405292 auc 0.9973844237953827 0.9908858118361153\n",
      "7 fold: ls 0.013659696399600964 0.01867705432894171 auc 0.9965078947258816 0.9875185165113086\n",
      "8 fold: ls 0.011857350692541329 0.01655300171824462 auc 0.9976976971807229 0.9930179203699689\n",
      "9 fold: ls 0.013831654964984818 0.01669877893671151 auc 0.9964015377118413 0.992414101452417\n",
      "identity_hate 0.05 0.6 4\n",
      "this class avg train 0.013164909631230274 avg val 0.017499079401445353\n",
      "this class auc train 0.9968267066818031 auc val 0.9912557158241923\n",
      "========================\n",
      "all loss avg 0.029984532130447397 0.035168920455906125\n",
      "all auc avg 0.9955601578909283 0.9920381442195318\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.05 4 0.6 threat\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "[0.988653301673445, 0.9921696955504364, 0.995510773279133, 0.9948578115535328, 0.9899677533084541, 0.9914911558115035]\n",
      "0.9921084151960842\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999105      0.373315  0.983606  0.154619  0.925160   \n",
      "1  0000247867823ef7  0.000229      0.000020  0.000054  0.000055  0.000060   \n",
      "2  00013b17ad220c46  0.000326      0.000022  0.000095  0.000057  0.000197   \n",
      "3  00017563c3f7919a  0.000087      0.000021  0.000054  0.000057  0.000059   \n",
      "4  00017695ad8997eb  0.001789      0.000025  0.000093  0.000060  0.000221   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.392953  \n",
      "1       0.000030  \n",
      "2       0.000050  \n",
      "3       0.000031  \n",
      "4       0.000047  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "# find best params for each column, early stopping = 30\n",
    "\n",
    "best_pred = np.zeros((153164,6))\n",
    "val_auc_res = [0,0,0,0,0,0]\n",
    "for lr in [0.095,0.075,0.05]:\n",
    "    for max_d in [3]:\n",
    "        for s_rate in [0.4,0.48,0.56,0.62]:\n",
    "            print('learning rate',lr,'max depth',max_d,'feature fraction',s_rate)\n",
    "            lgb_res,tmp_auc_res = simple_ens('lgb',k=10,rnd=666,lr=lr,\n",
    "                                 feature_fraction=s_rate,bagging_fraction=0.9,\n",
    "                                 bag_frec=3,met='binary_logloss',max_d=max_d)\n",
    "            # check for each cls\n",
    "            for i in range(6):\n",
    "                # find better params for this class\n",
    "                if tmp_auc_res[i] > val_auc_res[i]:\n",
    "                    val_auc_res[i] = tmp_auc_res[i]\n",
    "                    best_pred[:,i] = lgb_res[:,i]\n",
    "                    print('FIND BETTER PARAMS',lr,max_d,s_rate,list_classes[i])\n",
    "            print('TEST PARAM DONE ------------------------------------------')\n",
    "\n",
    "print(val_auc_res)\n",
    "print(np.mean(val_auc_res))\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = best_pred\n",
    "sample_submission.to_csv(\"../results/lgb_grid_search_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "                \n",
    "            \n",
    "# best auc params\n",
    "# toxic 0.05,4,0.5\n",
    "# severe toxic 0.075 3 0.5\n",
    "# obs 0.075 3 0.6\n",
    "# threat 0.095 3 0.5\n",
    "# insult 0.075 0.5 4\n",
    "# hate 0.05 0.5 3\n",
    "\n",
    "# TEST PARAM DONE ------------------------------------------\n",
    "# [0.9884873039634368, 0.9920148292218363, 0.9954573112511824, \n",
    "#  0.994769628570376, 0.9898761527824232, 0.9912880359235366]\n",
    "# 0.9919822102854652 PUB 9870\n",
    "\n",
    "# updated pool gru v2 10 fold\n",
    "# TEST PARAM DONE ------------------------------------------\n",
    "# [0.988653301673445, 0.9921696955504364, 0.995510773279133, \n",
    "#  0.9948578115535328, 0.9899677533084541, 0.9914911558115035]\n",
    "# 0.9921084151960842"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
