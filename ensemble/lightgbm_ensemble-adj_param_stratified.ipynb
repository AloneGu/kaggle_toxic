{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/fasttext_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lgb1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 37) (153164, 37)\n",
      "file path ../features/pool_gru_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/tilli_lr_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/wordbatch_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "(159571, 295)\n",
      "(159571, 295)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat or 'tfidf' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss',max_d=3):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    cls_auc_res = [0,0,0,0,0,0]\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for i in range(6):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = test_x\n",
    "\n",
    "            # share params\n",
    "            params = {\n",
    "                    'application': 'binary',\n",
    "                    #'num_leaves': 8,\n",
    "                    #'lambda_l1': 1,\n",
    "                    'lambda_l2': 1.0,\n",
    "                    'max_depth': max_d,\n",
    "                    'metric': met, # or auc\n",
    "                    'data_random_seed': 2,\n",
    "                    'learning_rate':lr,\n",
    "                    # 'bagging_fraction': bagging_fraction,\n",
    "                    # 'bagging_freq':bag_frec,\n",
    "                    'feature_fraction': feature_fraction,\n",
    "\n",
    "                    }\n",
    "            if met == 'auc':\n",
    "                s_round = 60\n",
    "            else:\n",
    "                s_round = 30\n",
    "            # train for each class\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_auc_l = train_auc_l/k\n",
    "        val_auc_l = val_auc_l/k\n",
    "        print(list_classes[i], lr, feature_fraction, max_d)\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        cls_auc_res[i] = val_auc_l\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/6\n",
    "        all_val_loss_l += val_loss_l/6\n",
    "        all_train_auc_l += train_auc_l/6\n",
    "        all_val_auc_l += val_auc_l/6\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred, cls_auc_res\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.0701452724888359 0.07799274013322345 auc 0.9905986050450313 0.9871054558039831\n",
      "1 fold: ls 0.07007731504136679 0.07154207938668194 auc 0.9905919721982126 0.9897577513585603\n",
      "2 fold: ls 0.07061349029250148 0.07602982624979221 auc 0.9904227446612598 0.9883437433748105\n",
      "3 fold: ls 0.06931647037392062 0.07322326840017794 auc 0.9908508658422951 0.9890206678734704\n",
      "4 fold: ls 0.06812558906497987 0.07835384154450283 auc 0.9911960596148819 0.987742930639736\n",
      "5 fold: ls 0.06965230897618752 0.07646615787767941 auc 0.9907760243808521 0.9876632403782849\n",
      "6 fold: ls 0.0694829914573264 0.07788357054890263 auc 0.990786925584191 0.9875776118777836\n",
      "7 fold: ls 0.07196767900922992 0.07091523519955178 auc 0.9898936997493964 0.9900605574634038\n",
      "8 fold: ls 0.06851295097164081 0.07424784193449253 auc 0.9910957013883829 0.9893987832475472\n",
      "9 fold: ls 0.06692787708051355 0.07751200288404718 auc 0.9915481516925352 0.9877562703424284\n",
      "toxic 0.05 0.6 3\n",
      "this class avg train 0.06948219447565027 avg val 0.07541665641590518\n",
      "this class auc train 0.990776075015704 auc val 0.9884427012360009\n",
      "========================\n",
      "0 fold: ls 0.017942673164580345 0.021266907107269778 auc 0.9942128390563861 0.9910459393594127\n",
      "1 fold: ls 0.017724219425885635 0.020429064659787145 auc 0.994421023889032 0.9918462780098747\n",
      "2 fold: ls 0.018191207155726367 0.021168679555119932 auc 0.9940711826952159 0.991166603367515\n",
      "3 fold: ls 0.01769292838032247 0.01983286023513993 auc 0.9944474299110655 0.9925587890872262\n",
      "4 fold: ls 0.01799484376868337 0.021126213694687323 auc 0.9941988726601386 0.9910795670338017\n",
      "5 fold: ls 0.017679808424768868 0.020060244149719585 auc 0.9944613569651067 0.9921142792535637\n",
      "6 fold: ls 0.017941103425057447 0.019215225318986964 auc 0.9942668341043904 0.9928833712953218\n",
      "7 fold: ls 0.016438178370128727 0.020083940173004345 auc 0.9955414249772361 0.9922228685249129\n",
      "8 fold: ls 0.01798098800194385 0.02104489392161252 auc 0.9942199930171587 0.9911905094630261\n",
      "9 fold: ls 0.017743819619635393 0.01909590565059538 auc 0.99444405489796 0.9930553647834575\n",
      "severe_toxic 0.05 0.6 3\n",
      "this class avg train 0.017732976973673247 avg val 0.02033239344659229\n",
      "this class auc train 0.994428501217369 auc val 0.9919163570178112\n",
      "========================\n",
      "0 fold: ls 0.034849204895909106 0.03723403364317541 auc 0.996331806340801 0.9956313327175906\n",
      "1 fold: ls 0.03528186953634736 0.036930494205746504 auc 0.9962401375533256 0.9955738564353664\n",
      "2 fold: ls 0.03436452930531354 0.03912398086678819 auc 0.9964333450742262 0.9953416854351415\n",
      "3 fold: ls 0.034770494182917326 0.0338158974148686 auc 0.9963449233685319 0.9964705347997281\n",
      "4 fold: ls 0.035116440263709255 0.0420277910590662 auc 0.9962834161480763 0.9945161335793334\n",
      "5 fold: ls 0.03522984565054149 0.03754119561929374 auc 0.9962426429099169 0.9956095864879512\n",
      "6 fold: ls 0.03609724165440518 0.037593351682317054 auc 0.9960778984711995 0.99545147709724\n",
      "7 fold: ls 0.035050160589207985 0.03828471489598772 auc 0.9962834760966341 0.9955472511362888\n",
      "8 fold: ls 0.034286028528862436 0.038746854397227665 auc 0.9964629364559596 0.995212237776476\n",
      "9 fold: ls 0.035008613437900016 0.03888690865737709 auc 0.9962991307490298 0.9952521175224986\n",
      "obscene 0.05 0.6 3\n",
      "this class avg train 0.035005442804511365 avg val 0.03801852224418482\n",
      "this class auc train 0.9962999713167701 auc val 0.9954606212987616\n",
      "========================\n",
      "0 fold: ls 0.005137896706342496 0.006591695585128054 auc 0.9984096137176216 0.9968311334590404\n",
      "1 fold: ls 0.005104445219731662 0.006248406561087626 auc 0.9984934956387737 0.9968717263775404\n",
      "2 fold: ls 0.004523068519509141 0.007279679295012826 auc 0.9989445122187918 0.9949677875549968\n",
      "3 fold: ls 0.005198365061404603 0.006536789846317117 auc 0.9984700122399021 0.9907389946990174\n",
      "4 fold: ls 0.005030736554101377 0.00679633085439509 auc 0.9985204514860695 0.9962285498774279\n",
      "5 fold: ls 0.004888414165377894 0.006930824525641322 auc 0.9986332515390831 0.9960124772141556\n",
      "6 fold: ls 0.004737469017067556 0.006307585094629261 auc 0.9987515738409124 0.9953433067236576\n",
      "7 fold: ls 0.005124894090894414 0.0074570522463556395 auc 0.9983701569877885 0.9957191422046221\n",
      "8 fold: ls 0.004703445356957974 0.007073083470612487 auc 0.9987846750949374 0.994711945466436\n",
      "9 fold: ls 0.005127758323151431 0.007450897321620491 auc 0.9984039568511329 0.98862078603975\n",
      "threat 0.05 0.6 3\n",
      "this class avg train 0.004957649301453855 avg val 0.006867234480079992\n",
      "this class auc train 0.9985781699615013 auc val 0.9946045849616644\n",
      "========================\n",
      "0 fold: ls 0.05007471918925734 0.05006630614646603 auc 0.9916707839670077 0.9913859507644328\n",
      "1 fold: ls 0.05139776462567269 0.05389223621471819 auc 0.9911519538047002 0.9898222848328087\n",
      "2 fold: ls 0.050886196308375674 0.05528749793951326 auc 0.991347086439034 0.9890116747922865\n",
      "3 fold: ls 0.04813637719329108 0.051765948947509494 auc 0.9924094626547366 0.9905402895776796\n",
      "4 fold: ls 0.04936142697763991 0.0553973669514039 auc 0.9919405133605019 0.9889446918357737\n",
      "5 fold: ls 0.049259085748548814 0.05264538914214821 auc 0.9919954411213858 0.9903760273841956\n",
      "6 fold: ls 0.04967047316063072 0.05605945008300126 auc 0.9917952465047362 0.9891912372715794\n",
      "7 fold: ls 0.04885877209574953 0.055487978520864366 auc 0.9921073574925056 0.9894601299731621\n",
      "8 fold: ls 0.05129720489550034 0.05228937896216763 auc 0.9911758723028713 0.990404760327167\n",
      "9 fold: ls 0.05102363161416035 0.05485092074351717 auc 0.9912847427676027 0.9891831154674697\n",
      "insult 0.05 0.6 3\n",
      "this class avg train 0.04999656518088265 avg val 0.05377424736513096\n",
      "this class auc train 0.9916878460415083 auc val 0.9898320162226554\n",
      "========================\n",
      "0 fold: ls 0.014463724618661043 0.017011270814323385 auc 0.9957241082956125 0.9929566760245844\n",
      "1 fold: ls 0.01418514382706446 0.017632590625885344 auc 0.995992866880659 0.9913509882759236\n",
      "2 fold: ls 0.0145962709885852 0.01773050924521312 auc 0.9956098772129934 0.9922392506132865\n",
      "3 fold: ls 0.014553626273302126 0.018163847449506464 auc 0.9956652128869223 0.9879988180416349\n",
      "4 fold: ls 0.01526340066145835 0.018993334460913912 auc 0.9950846815604117 0.9890363945427242\n",
      "5 fold: ls 0.014829678723306875 0.016393452229500893 auc 0.9954376479985158 0.9937273638670869\n",
      "6 fold: ls 0.014693251227799903 0.016555244440534977 auc 0.9955408577921978 0.9907977455018426\n",
      "7 fold: ls 0.015076123567723717 0.018507339990770765 auc 0.9952198181012952 0.9868162439482622\n",
      "8 fold: ls 0.013734381758598776 0.016735977099495616 auc 0.9963570445833697 0.992755076233832\n",
      "9 fold: ls 0.014822276748676505 0.016763101983740092 auc 0.9954767031658037 0.9918563480020233\n",
      "identity_hate 0.05 0.6 3\n",
      "this class avg train 0.014621787839517694 avg val 0.017448666833988456\n",
      "this class auc train 0.9956108818477782 auc val 0.99095349050512\n",
      "========================\n",
      "all loss avg 0.03196610276261484 0.03530962013098028\n",
      "all auc avg 0.9945635742334386 0.9918682952070021\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999133      0.343865  0.977909  0.160542  0.928827   \n",
      "1  0000247867823ef7  0.000214      0.000023  0.000078  0.000045  0.000072   \n",
      "2  00013b17ad220c46  0.000363      0.000025  0.000148  0.000047  0.000235   \n",
      "3  00017563c3f7919a  0.000073      0.000023  0.000072  0.000047  0.000071   \n",
      "4  00017695ad8997eb  0.001910      0.000036  0.000199  0.000066  0.000251   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.402594  \n",
      "1       0.000029  \n",
      "2       0.000044  \n",
      "3       0.000030  \n",
      "4       0.000047  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "lgb_res,tmp_auc_res = simple_ens('lgb',10,666,0.05,0.6)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# add 7 base fasttext NN models\n",
    "# all loss avg 0.0319116484218 0.0358161833583 all auc avg 0.994546891137 0.991249510282 PUB 9866\n",
    "\n",
    "# rm tfidf test\n",
    "# all loss avg 0.0319555637279 0.0357756335619 all auc avg 0.994512718368 0.991251471241\n",
    "\n",
    "# change to stratified\n",
    "# all loss avg 0.0316412744167 0.0357232681944 all auc avg 0.994584962017 0.991293307537 pub 9866\n",
    "\n",
    "# change to base model 5 fold, add word batch, tilli, lgb feat\n",
    "# feat dim 217\n",
    "# all loss avg 0.031983129767200906 0.035387924581 all auc avg 0.9945427088311004 0.99188514127 PUB 9870\n",
    "\n",
    "# add more base models\n",
    "# feat dim 247, all loss avg 0.031885221777487156 0.0353958  all auc avg 0.9945986685511962 0.9919487331094685\n",
    "\n",
    "# change early stopping to 30, and test later part\n",
    "# all loss avg 0.03208696729295824 0.035406264613808025 all auc avg 0.9945261773637045 0.991946174432887\n",
    "\n",
    "# add fasttext lstm v1\n",
    "# all loss avg 0.031977558955160815 0.03537909655655411 all auc avg 0.9945299073418443 0.9919307178575658\n",
    "\n",
    "# add muse base model, feat dim 295, lower loss, but lower auc\n",
    "# all loss avg 0.03196610276261484 0.03530962013098028 all auc avg 0.9945635742334386 0.9918682952070021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.095 max depth 3 feature fraction 0.4\n",
      "0 fold: ls 0.07055900792121056 0.07845851850483938 auc 0.9904317585515335 0.9869234386296798\n",
      "1 fold: ls 0.07112099324841784 0.07132731780698526 auc 0.99019070161143 0.9898649322033591\n",
      "2 fold: ls 0.06935924063822202 0.07556019794440967 auc 0.9908043936706946 0.9885162021559386\n",
      "3 fold: ls 0.06497260357247332 0.07280091655739042 auc 0.992192585088142 0.9892247916632692\n",
      "4 fold: ls 0.06894506079113848 0.07792721171645994 auc 0.9909000263031499 0.9878534906782339\n",
      "5 fold: ls 0.06577492446228168 0.07645398182283704 auc 0.9919903108446425 0.9876221260056249\n",
      "6 fold: ls 0.06797329110174438 0.07772442055333846 auc 0.9912493848473811 0.9876035860073693\n",
      "7 fold: ls 0.07310551182282535 0.07122791366621857 auc 0.9894850349134301 0.9899879336591975\n",
      "8 fold: ls 0.0704343227293608 0.07448200464055142 auc 0.9904142517680505 0.9892556209668459\n",
      "9 fold: ls 0.06958413131063694 0.0776744481375048 auc 0.9906593620485566 0.9876591212710091\n",
      "toxic 0.095 0.4 3\n",
      "this class avg train 0.06918290875983113 avg val 0.0753636931350535\n",
      "this class auc train 0.9908317809647013 auc val 0.9884511243240528\n",
      "========================\n",
      "0 fold: ls 0.0173626262569297 0.02123369200332841 auc 0.9947173251883356 0.9911215027218636\n",
      "1 fold: ls 0.017957597326474017 0.020465733507910026 auc 0.9941950054951483 0.9917521205215851\n",
      "2 fold: ls 0.01809987325505951 0.020987466155493108 auc 0.9941158535972697 0.9913418628940371\n",
      "3 fold: ls 0.01813292551800216 0.019753649343837335 auc 0.9940495040250621 0.9926248575769084\n",
      "4 fold: ls 0.016990016919460005 0.020981375232007583 auc 0.9950395791348167 0.9912164514495505\n",
      "5 fold: ls 0.01724012973424655 0.019908817037307912 auc 0.9948294442475909 0.9923169161608706\n",
      "6 fold: ls 0.016811855881870636 0.018962973333904225 auc 0.9952142083792096 0.9930533741180855\n",
      "7 fold: ls 0.01697999780678863 0.019816391357856428 auc 0.9950624958600481 0.9924509987765371\n",
      "8 fold: ls 0.01811298513440045 0.021171274060080483 auc 0.9940965291486598 0.9910794303352718\n",
      "9 fold: ls 0.018224596911183798 0.01905961631974591 auc 0.993996070726569 0.993072484505656\n",
      "severe_toxic 0.095 0.4 3\n",
      "this class avg train 0.017591260474441546 avg val 0.02023409883514714\n",
      "this class auc train 0.9945316015802709 auc val 0.9920029999060367\n",
      "========================\n",
      "0 fold: ls 0.03539338693966496 0.03725131251832009 auc 0.9962086077642176 0.9956512223302404\n",
      "1 fold: ls 0.03420304709400305 0.03690920361374102 auc 0.9964650555604032 0.9955566292118114\n",
      "2 fold: ls 0.03492724574341849 0.039237561229174725 auc 0.9963021258996296 0.9953174874154636\n",
      "3 fold: ls 0.03582668954614773 0.03388668210861935 auc 0.9961037106765017 0.9964871366773065\n",
      "4 fold: ls 0.03458082386780181 0.041948888480961406 auc 0.9963891136744943 0.99453672930482\n",
      "5 fold: ls 0.03552231381693149 0.03774828154788253 auc 0.9961716643007614 0.9955292396653312\n",
      "6 fold: ls 0.036000173698471534 0.03730905838521062 auc 0.9960806710920049 0.9955060596853161\n",
      "7 fold: ls 0.0355504700677173 0.0385655493092969 auc 0.996162569040917 0.9954580551996768\n",
      "8 fold: ls 0.03333348066309105 0.038686749572848275 auc 0.996664331702565 0.9952571881431269\n",
      "9 fold: ls 0.034517271114544175 0.0389283295976646 auc 0.9963979419852574 0.9952733648787317\n",
      "obscene 0.095 0.4 3\n",
      "this class avg train 0.03498549025517916 avg val 0.03804716163637196\n",
      "this class auc train 0.9962945791696752 auc val 0.9954573112511824\n",
      "========================\n",
      "0 fold: ls 0.005041276160286182 0.006636722844114922 auc 0.998526174586466 0.9967041169076053\n",
      "1 fold: ls 0.005122367268918162 0.006186816321047197 auc 0.9984779439029805 0.9969293421328305\n",
      "2 fold: ls 0.004371900357069308 0.007073806339137408 auc 0.9990235621384831 0.9953082442908024\n",
      "3 fold: ls 0.005215352706267624 0.006629164795256937 auc 0.998461233488476 0.9883805288411172\n",
      "4 fold: ls 0.0038583659528688146 0.006872901223354544 auc 0.9993433721320039 0.9961093825298049\n",
      "5 fold: ls 0.004881359813429125 0.0068849645804210415 auc 0.9986538137949673 0.9959443815869424\n",
      "6 fold: ls 0.0050223007160047775 0.0064039370589696505 auc 0.9985280526991455 0.9948116370188782\n",
      "7 fold: ls 0.005035967051101942 0.007565942768361033 auc 0.9984531612600602 0.9954231881325035\n",
      "8 fold: ls 0.0048519202369824025 0.0070100178355797455 auc 0.9986433337507542 0.9945795434940479\n",
      "9 fold: ls 0.0052181238125438584 0.007611001749782194 auc 0.9983084977673173 0.9907465732630933\n",
      "threat 0.095 0.4 3\n",
      "this class avg train 0.004861893407547219 avg val 0.006887527551602467\n",
      "this class auc train 0.9986419145520653 auc val 0.9944936938197625\n",
      "========================\n",
      "0 fold: ls 0.05061749578548859 0.0501484820351916 auc 0.9914450128443281 0.9913594323554705\n",
      "1 fold: ls 0.0509141123840465 0.05395330902283659 auc 0.9913171867254682 0.9898476320817536\n",
      "2 fold: ls 0.051629986925511226 0.055248032565830246 auc 0.9910685998611004 0.9890951199435164\n",
      "3 fold: ls 0.05086054257267935 0.051947248520800515 auc 0.9913377856261903 0.9905387419733711\n",
      "4 fold: ls 0.049748895432873905 0.05533610485546489 auc 0.9917857840573518 0.989095781437764\n",
      "5 fold: ls 0.04851206445541918 0.05273276563948131 auc 0.9922797144082939 0.9903355360401408\n",
      "6 fold: ls 0.05004023483398414 0.056110456808808884 auc 0.9916573564935981 0.9892575376644793\n",
      "7 fold: ls 0.04752931200953754 0.055501782302452264 auc 0.9926120202518228 0.9894813227974562\n",
      "8 fold: ls 0.04972964530070382 0.0522948464177982 auc 0.9917736859056229 0.9903643012989694\n",
      "9 fold: ls 0.050550955845766195 0.054928881705518726 auc 0.9914698605240029 0.9891704667857764\n",
      "insult 0.095 0.4 3\n",
      "this class avg train 0.050013324554601044 avg val 0.053820190987418325\n",
      "this class auc train 0.9916747006697779 auc val 0.9898545872378698\n",
      "========================\n",
      "0 fold: ls 0.01454592970860193 0.017053729695258486 auc 0.9956521244007974 0.9929140788907885\n",
      "1 fold: ls 0.015760753915519708 0.018035453127468844 auc 0.9945163883852586 0.990869864859472\n",
      "2 fold: ls 0.014556949722228589 0.017858196303342354 auc 0.9956584018721681 0.9920092260907893\n",
      "3 fold: ls 0.014936781205722373 0.018311036256926684 auc 0.9953415521319461 0.9886359814850437\n",
      "4 fold: ls 0.015052183508962981 0.018933349730195604 auc 0.9951790909505618 0.9887234177070456\n",
      "5 fold: ls 0.014817776378815234 0.0164196628127401 auc 0.9954435900831272 0.9935169212149676\n",
      "6 fold: ls 0.014327081039620762 0.01664445600192914 auc 0.995878524096511 0.9891055170171255\n",
      "7 fold: ls 0.015473192716769639 0.01862576915995356 auc 0.9948271879004458 0.9898922429366284\n",
      "8 fold: ls 0.013868174652616723 0.016864570636182314 auc 0.9962419494343259 0.992767721656189\n",
      "9 fold: ls 0.014630580928984898 0.016701024410102728 auc 0.9955733696519878 0.9920491906929692\n",
      "identity_hate 0.095 0.4 3\n",
      "this class avg train 0.014796940377784285 avg val 0.017544724813409983\n",
      "this class auc train 0.9954312178907131 auc val 0.991048416255102\n",
      "========================\n",
      "all loss avg 0.03190530297156406 0.035316232826500565\n",
      "all auc avg 0.9945676324712005 0.991884688799001\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.095 3 0.4 toxic\n",
      "FIND BETTER PARAMS 0.095 3 0.4 severe_toxic\n",
      "FIND BETTER PARAMS 0.095 3 0.4 obscene\n",
      "FIND BETTER PARAMS 0.095 3 0.4 threat\n",
      "FIND BETTER PARAMS 0.095 3 0.4 insult\n",
      "FIND BETTER PARAMS 0.095 3 0.4 identity_hate\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 3 feature fraction 0.5\n",
      "0 fold: ls 0.07166514434560606 0.0786129199543451 auc 0.9900679661090885 0.9867957366848412\n",
      "1 fold: ls 0.07155954080160669 0.0714281690260189 auc 0.9900622712999508 0.9898481257395297\n",
      "2 fold: ls 0.0675653999833657 0.07589417215850251 auc 0.9914218943923483 0.9883349097887006\n",
      "3 fold: ls 0.06984400030577968 0.07350743309432826 auc 0.9906051623564571 0.9889201461935851\n",
      "4 fold: ls 0.06835590220860033 0.07811459463506958 auc 0.9910906967949084 0.9878249780647795\n",
      "5 fold: ls 0.06753230029693248 0.07675559335129595 auc 0.9914363622064835 0.9875669139814796\n",
      "6 fold: ls 0.0683898600534778 0.07798751843016409 auc 0.9911236107696997 0.9875697697758321\n",
      "7 fold: ls 0.07204103866576128 0.07148509594940962 auc 0.9899055645670122 0.989879723284266\n",
      "8 fold: ls 0.06745342180763421 0.07401682061117183 auc 0.991411154366413 0.9894644710704525\n",
      "9 fold: ls 0.06940525152211004 0.07814732448848856 auc 0.9907367261758482 0.9874680417861592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic 0.095 0.5 3\n",
      "this class avg train 0.06938118599908744 avg val 0.07559496416987946\n",
      "this class auc train 0.990786140903821 auc val 0.9883672816369625\n",
      "========================\n",
      "0 fold: ls 0.017906577710877336 0.021184588850506145 auc 0.9942284572075157 0.9911464267628813\n",
      "1 fold: ls 0.017322633815901163 0.02052464275821394 auc 0.9947602536605363 0.9917010855804532\n",
      "2 fold: ls 0.017502525843847296 0.021137535246129414 auc 0.9946054788366333 0.9912144733510572\n",
      "3 fold: ls 0.018127065755140153 0.019999904463978653 auc 0.9940710283026972 0.9924674009368275\n",
      "4 fold: ls 0.017554294298551983 0.021112351147607965 auc 0.9945542352245011 0.9910142897835168\n",
      "5 fold: ls 0.01778366661478703 0.019919998316783 auc 0.9943610227338315 0.9922755129420888\n",
      "6 fold: ls 0.018160210122930027 0.01903681796179376 auc 0.9940604463035052 0.9930784565017718\n",
      "7 fold: ls 0.017106348494256657 0.020023243398108247 auc 0.9949557166952303 0.9922459602432275\n",
      "8 fold: ls 0.016380160382229014 0.020935282161855716 auc 0.9955436682164217 0.9913441888297396\n",
      "9 fold: ls 0.01777228975889517 0.018978177952899047 auc 0.9943967117757577 0.9931959057587163\n",
      "severe_toxic 0.095 0.5 3\n",
      "this class avg train 0.01756157727974158 avg val 0.02028525422578759\n",
      "this class auc train 0.9945537018956632 auc val 0.991968370069028\n",
      "========================\n",
      "0 fold: ls 0.03444289191226836 0.03724306929770726 auc 0.9964137111768399 0.9956519270802949\n",
      "1 fold: ls 0.03565414732384934 0.03689979186576389 auc 0.9961579436084058 0.9955335290711356\n",
      "2 fold: ls 0.032637017416421894 0.039002854653338984 auc 0.9968118003205585 0.9953754373655013\n",
      "3 fold: ls 0.035781221052411986 0.03390007235391635 auc 0.9961189917573053 0.9965086721317123\n",
      "4 fold: ls 0.03546938881780541 0.04204300567957046 auc 0.996215258988793 0.9945463615262452\n",
      "5 fold: ls 0.03249041522994417 0.03752585021475676 auc 0.9968412104062496 0.9955912617740202\n",
      "6 fold: ls 0.03590966240161808 0.037395809141703866 auc 0.9961054709402072 0.9954127132793096\n",
      "7 fold: ls 0.034684434877469236 0.03835874544945013 auc 0.9963646488613778 0.9955231314273543\n",
      "8 fold: ls 0.0348597992974048 0.038731148004671694 auc 0.9963321673790038 0.9951520951256262\n",
      "9 fold: ls 0.034351162703902094 0.038956086393694744 auc 0.9964330884901771 0.9952445907837593\n",
      "obscene 0.095 0.5 3\n",
      "this class avg train 0.03462801410330954 avg val 0.038005643305457415\n",
      "this class auc train 0.9963794291928918 auc val 0.9954539719564959\n",
      "========================\n",
      "0 fold: ls 0.004851944562589231 0.006594322373262835 auc 0.9987226380811416 0.9967132830504923\n",
      "1 fold: ls 0.0050863334601379245 0.006192657583661325 auc 0.9984897031267028 0.9968900586633145\n",
      "2 fold: ls 0.004918838669380468 0.007289185288920631 auc 0.9986261198670947 0.9946430442069977\n",
      "3 fold: ls 0.002908207166423278 0.006489851237764749 auc 0.9997915675910262 0.9916124520711547\n",
      "4 fold: ls 0.004728653651246093 0.006756570846003882 auc 0.9987977820699727 0.9962023592515766\n",
      "5 fold: ls 0.00509849359751758 0.007053476928396808 auc 0.9984261509665884 0.9957047373604039\n",
      "6 fold: ls 0.004875271952815849 0.006348317799978455 auc 0.9986657109927835 0.9946138977937018\n",
      "7 fold: ls 0.005144420775564977 0.007490138301768531 auc 0.9983994005436492 0.9955384268862488\n",
      "8 fold: ls 0.005138281240101638 0.00708816271438838 auc 0.9983442523876601 0.9937771072977559\n",
      "9 fold: ls 0.005078173092815428 0.00757773469526872 auc 0.9984292516448584 0.9891697861373798\n",
      "threat 0.095 0.5 3\n",
      "this class avg train 0.004782861816859246 avg val 0.006888041776941431\n",
      "this class auc train 0.9986692577271477 auc val 0.9944865152719025\n",
      "========================\n",
      "0 fold: ls 0.04888019406457901 0.05002293124969837 auc 0.9921297067274079 0.9913699727956258\n",
      "1 fold: ls 0.050212955896248274 0.05396293818914342 auc 0.9915942169354961 0.989898075616783\n",
      "2 fold: ls 0.051102951717107534 0.055354520327295695 auc 0.9912391473106538 0.9888712192445015\n",
      "3 fold: ls 0.050692375562319744 0.05206196659247091 auc 0.9913903491934826 0.990380258926749\n",
      "4 fold: ls 0.04985149318053802 0.05527193308108878 auc 0.9917558814630599 0.9891346832455854\n",
      "5 fold: ls 0.0476540368052096 0.052509172141952234 auc 0.9925910969146847 0.9904364297610709\n",
      "6 fold: ls 0.05019031672783196 0.05619372949581306 auc 0.9915816352164022 0.9891820346933851\n",
      "7 fold: ls 0.05066044623465101 0.055640878540252715 auc 0.9914107006755686 0.9894092839480774\n",
      "8 fold: ls 0.05064824154454599 0.05260811663092332 auc 0.9914262152268851 0.9903001364633599\n",
      "9 fold: ls 0.051043141781868466 0.0550420350651628 auc 0.9912892444927476 0.989083852634314\n",
      "insult 0.095 0.5 3\n",
      "this class avg train 0.05009361535148995 avg val 0.05386682213138013\n",
      "this class auc train 0.9916408194156388 auc val 0.9898065947329451\n",
      "========================\n",
      "0 fold: ls 0.015249917061498528 0.017040471576322765 auc 0.9950401946019459 0.9928925561284496\n",
      "1 fold: ls 0.015269542272471582 0.01807111179351352 auc 0.9950333502407304 0.9907972255365781\n",
      "2 fold: ls 0.014522659020021294 0.017745991913290803 auc 0.9956737634754163 0.9920016034457942\n",
      "3 fold: ls 0.01328341965805463 0.01809084678865891 auc 0.9966059582479182 0.9900085059750326\n",
      "4 fold: ls 0.01546623253198159 0.018833742118703607 auc 0.9948411551312069 0.989160598817055\n",
      "5 fold: ls 0.015075494297391174 0.016443087430514664 auc 0.9952087194704926 0.9934609235993822\n",
      "6 fold: ls 0.014547812535514291 0.01653586843097709 auc 0.995693229541949 0.990047149360503\n",
      "7 fold: ls 0.01541518434455625 0.0186714766994646 auc 0.9948833596421445 0.9896348182672159\n",
      "8 fold: ls 0.014244329782624222 0.01666924704828571 auc 0.9959600022768575 0.993007533058747\n",
      "9 fold: ls 0.015149971567205791 0.01678943832408719 auc 0.9951817529304129 0.9918694450466073\n",
      "identity_hate 0.095 0.5 3\n",
      "this class avg train 0.014822456307131934 avg val 0.017489128212381886\n",
      "this class auc train 0.9954121485559074 auc val 0.9912880359235366\n",
      "========================\n",
      "all loss avg 0.03187828514293661 0.03535497563697131\n",
      "all auc avg 0.9945735829485117 0.991895128265145\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.095 3 0.5 identity_hate\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 3 feature fraction 0.6\n",
      "0 fold: ls 0.06923091587570898 0.0782447844217389 auc 0.9908937198685539 0.9870231449016166\n",
      "1 fold: ls 0.06945546315426775 0.0715048269143079 auc 0.9907759459225132 0.9898373895348731\n",
      "2 fold: ls 0.0707512313230649 0.07621127071405769 auc 0.9903119490665222 0.9883028823764973\n",
      "3 fold: ls 0.06593913093565762 0.07330018529659456 auc 0.9919239194022447 0.9890426838880825\n",
      "4 fold: ls 0.06687001050793175 0.07811678981840563 auc 0.9915916805061931 0.9877991399254014\n",
      "5 fold: ls 0.06952837219383573 0.0769355993126716 auc 0.9907504113505539 0.9874704969245361\n",
      "6 fold: ls 0.06734084971777328 0.07766894967116397 auc 0.9914823764238354 0.9878244794340196\n",
      "7 fold: ls 0.06875172566250799 0.07109524446858144 auc 0.9910289922108286 0.9899518484231499\n",
      "8 fold: ls 0.06646958382742835 0.07391333611744373 auc 0.991753008479845 0.9894834203526988\n",
      "9 fold: ls 0.07023476277301847 0.07787031341060353 auc 0.9904800708185322 0.9875214443088528\n",
      "toxic 0.095 0.6 3\n",
      "this class avg train 0.06845720459711949 avg val 0.07548613001455691\n",
      "this class auc train 0.9910992074049624 auc val 0.9884256930069727\n",
      "========================\n",
      "0 fold: ls 0.01768661598567404 0.021177976920961388 auc 0.9944267780736941 0.9911361406507153\n",
      "1 fold: ls 0.017247788331427004 0.020562913056573213 auc 0.9948159109381609 0.9916852607925053\n",
      "2 fold: ls 0.018000562346861766 0.02110099321769108 auc 0.9941831638340377 0.9912390017723763\n",
      "3 fold: ls 0.01716185132514262 0.019815271445467058 auc 0.994901054736167 0.9926212969996202\n",
      "4 fold: ls 0.017994588684745183 0.021234564504510927 auc 0.9941923685689573 0.9909517818711229\n",
      "5 fold: ls 0.01794196510382469 0.019862401585894293 auc 0.9942266502921462 0.9923404045253719\n",
      "6 fold: ls 0.018146204887528418 0.01901786377146422 auc 0.9940656576713951 0.9930493927873415\n",
      "7 fold: ls 0.016659065813219954 0.019922877851902457 auc 0.9953271686965435 0.9923419103141548\n",
      "8 fold: ls 0.017855751780714454 0.02111166382900223 auc 0.994285749802502 0.9911029201866607\n",
      "9 fold: ls 0.0180616097219855 0.019045592218582118 auc 0.9941330258665463 0.9930625311787964\n",
      "severe_toxic 0.095 0.6 3\n",
      "this class avg train 0.017675600398112362 avg val 0.020285211840204896\n",
      "this class auc train 0.994455752848015 auc val 0.9919530641078665\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.03494977666811921 0.03725287503188428 auc 0.9963043753227504 0.9956300015230432\n",
      "1 fold: ls 0.03582070852237579 0.03698556199148193 auc 0.996124820336235 0.9955101157082131\n",
      "2 fold: ls 0.03195444835935681 0.03878083435607207 auc 0.9969636253615817 0.9954401220394625\n",
      "3 fold: ls 0.035835934813539486 0.033893640961965156 auc 0.9961095720984094 0.9964988441334289\n",
      "4 fold: ls 0.034164538032889824 0.04198606043703194 auc 0.9964842602547134 0.9945381388981992\n",
      "5 fold: ls 0.03389509653876179 0.03753737316766365 auc 0.9965324424577965 0.9956091166234913\n",
      "6 fold: ls 0.03172194789132538 0.03732420149605098 auc 0.9970218421797358 0.995228448100338\n",
      "7 fold: ls 0.033759061065030196 0.03842424606720479 auc 0.9965684942635612 0.9954971322605805\n",
      "8 fold: ls 0.034652884829612055 0.03864862489473035 auc 0.9963780492979039 0.9951816965865913\n",
      "9 fold: ls 0.03507308709139142 0.03881393310410665 auc 0.9962790583571295 0.9953099793265576\n",
      "obscene 0.095 0.6 3\n",
      "this class avg train 0.0341827483812402 avg val 0.037964735150819176\n",
      "this class auc train 0.9964766539929819 auc val 0.9954443595199907\n",
      "========================\n",
      "0 fold: ls 0.004954896414165491 0.006587640909346623 auc 0.998625648848465 0.9967839932956213\n",
      "1 fold: ls 0.005051029426620754 0.006263072060293686 auc 0.9985417100802372 0.9968533940917661\n",
      "2 fold: ls 0.004899596316838478 0.007353365252663085 auc 0.9986588800248958 0.9943471087366436\n",
      "3 fold: ls 0.005186705235620322 0.00669271947379724 auc 0.9984786610560619 0.9910205439269177\n",
      "4 fold: ls 0.004786846929392295 0.006782787824544855 auc 0.9987247259665234 0.9962390261277683\n",
      "5 fold: ls 0.004522458977150951 0.0069517506719592205 auc 0.9989385994147716 0.9959352148678945\n",
      "6 fold: ls 0.004961107601427296 0.006342385205345188 auc 0.9986121451792718 0.9950643765583422\n",
      "7 fold: ls 0.004996191426390854 0.0075467179104455094 auc 0.998522774078954 0.9954598550086953\n",
      "8 fold: ls 0.005195930140054819 0.007089724216091871 auc 0.9982893929871748 0.9941582644909945\n",
      "9 fold: ls 0.005099592473340334 0.0076173815821022305 auc 0.9984504872804619 0.9886963487815675\n",
      "threat 0.095 0.6 3\n",
      "this class avg train 0.004965435494100159 avg val 0.0069227545106589515\n",
      "this class auc train 0.9985843024916816 auc val 0.994455812588621\n",
      "========================\n",
      "0 fold: ls 0.05049012619563656 0.05012047377372923 auc 0.9915011462953478 0.9913748247442689\n",
      "1 fold: ls 0.05058903897631995 0.054077264556394916 auc 0.991434691179061 0.9898341637415551\n",
      "2 fold: ls 0.05133924341322526 0.05517727567624552 auc 0.9911737554100994 0.9890854578733741\n",
      "3 fold: ls 0.05035326668300529 0.051873499837929646 auc 0.9915442163484026 0.9904943633741454\n",
      "4 fold: ls 0.05048610703291994 0.055427706699580755 auc 0.9915110842915443 0.9889986524079133\n",
      "5 fold: ls 0.04811049878465126 0.052475736682207924 auc 0.9924338981586793 0.9904078181088668\n",
      "6 fold: ls 0.04998027481680659 0.05613045631748129 auc 0.9916696603616317 0.989220769181603\n",
      "7 fold: ls 0.050371371352215304 0.05547395934227225 auc 0.9915194120431867 0.9894701819056336\n",
      "8 fold: ls 0.0513823173419361 0.05254992479781551 auc 0.9911375562425084 0.9901964759097481\n",
      "9 fold: ls 0.0502282291397864 0.054899946948205075 auc 0.9916089950821946 0.9891372116425168\n",
      "insult 0.095 0.6 3\n",
      "this class avg train 0.050333047373650276 avg val 0.053820624463186216\n",
      "this class auc train 0.9915534415412655 auc val 0.9898219918889625\n",
      "========================\n",
      "0 fold: ls 0.015008378971644767 0.017036787378186456 auc 0.995270329648001 0.9927566936911851\n",
      "1 fold: ls 0.015566766358997964 0.0179580735490137 auc 0.9947149332168195 0.9908922844035751\n",
      "2 fold: ls 0.014181746483836594 0.017785275214474365 auc 0.9958805282097279 0.9920083293090252\n",
      "3 fold: ls 0.015166512127163006 0.018183615358839927 auc 0.9951637988191084 0.9883178481542213\n",
      "4 fold: ls 0.01546170720859739 0.01898237074729832 auc 0.9948753547063106 0.9892195622180462\n",
      "5 fold: ls 0.014139151396040358 0.016455522458756998 auc 0.9959618065014568 0.9933055753755002\n",
      "6 fold: ls 0.014288856512595644 0.016549702415640567 auc 0.9958855795782539 0.990139731917046\n",
      "7 fold: ls 0.015410204972483358 0.018759878619829636 auc 0.9949351637046693 0.9882587253414264\n",
      "8 fold: ls 0.01376329844271381 0.016699778772344857 auc 0.9963066205186516 0.9928444974347856\n",
      "9 fold: ls 0.015360982282570159 0.016949025453371475 auc 0.994994872905534 0.991509953753884\n",
      "identity_hate 0.095 0.6 3\n",
      "this class avg train 0.014834760475664305 avg val 0.01753600299677563\n",
      "this class auc train 0.9953988987808534 auc val 0.9909253201598694\n",
      "========================\n",
      "all loss avg 0.03174146611998113 0.03533590982936697\n",
      "all auc avg 0.9945947095099599 0.9918377068787139\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 4 feature fraction 0.4\n",
      "0 fold: ls 0.06638297083943048 0.07812456741922232 auc 0.9918553424971798 0.9870443002078385\n",
      "1 fold: ls 0.06845333520224553 0.07123498691274446 auc 0.9912004724581069 0.9898834147835273\n",
      "2 fold: ls 0.06598893633179961 0.07569716846540742 auc 0.9919326672400777 0.9884178548972495\n",
      "3 fold: ls 0.0666824749437328 0.07323814865295203 auc 0.9916802693600631 0.988964993630758\n",
      "4 fold: ls 0.06701357467440357 0.07838837366743047 auc 0.9915970148757298 0.9876865853638636\n",
      "5 fold: ls 0.06501240513744498 0.07660206395239604 auc 0.9922929144189632 0.9875701324163847\n",
      "6 fold: ls 0.06684266153549685 0.07800584573840734 auc 0.991655109961654 0.9875576666473863\n",
      "7 fold: ls 0.066341057035878 0.07095120672725293 auc 0.9918496809795202 0.9900072456071324\n",
      "8 fold: ls 0.06400120696984538 0.07491270223174534 auc 0.9925277172338756 0.9890867547554426\n",
      "9 fold: ls 0.06709153114633387 0.07763127911425995 auc 0.9915526700245512 0.9876429826478519\n",
      "toxic 0.095 0.4 4\n",
      "this class avg train 0.06638101538166111 avg val 0.07547863428818183\n",
      "this class auc train 0.9918143859049721 auc val 0.9883861930957435\n",
      "========================\n",
      "0 fold: ls 0.015592041013092948 0.021142623577317592 auc 0.9962490460135288 0.9912635301936954\n",
      "1 fold: ls 0.016391057585213167 0.020706032204847975 auc 0.9956012052027046 0.9914755823521965\n",
      "2 fold: ls 0.016548154914857147 0.021186744832744478 auc 0.9955065184766427 0.9912267375617166\n",
      "3 fold: ls 0.0164491231989672 0.02001420719483709 auc 0.995588586677651 0.9925045891885049\n",
      "4 fold: ls 0.016791990409483887 0.021240280270316932 auc 0.9953298027603715 0.9910550386124827\n",
      "5 fold: ls 0.01661015501339651 0.020045494154122993 auc 0.9954669474307598 0.9922432662043839\n",
      "6 fold: ls 0.016140075987213377 0.018873885993513525 auc 0.9958356468574149 0.993172017774253\n",
      "7 fold: ls 0.014778899504485285 0.019951898812876363 auc 0.9968805359151311 0.9922495434408969\n",
      "8 fold: ls 0.016610627357050115 0.021309583825146586 auc 0.9954593263413625 0.9909619810783277\n",
      "9 fold: ls 0.01635778509517572 0.01906438020408264 auc 0.9956920697537281 0.993111501546946\n",
      "severe_toxic 0.095 0.4 4\n",
      "this class avg train 0.016226991007893533 avg val 0.020353513106980615\n",
      "this class auc train 0.9957609685429295 auc val 0.9919263787953405\n",
      "========================\n",
      "0 fold: ls 0.03253470163522308 0.0371195399244681 auc 0.9968442619848753 0.9956902184999238\n",
      "1 fold: ls 0.032038324474800664 0.037143876942258555 auc 0.9969684424680424 0.9955284392096306\n",
      "2 fold: ls 0.03243066080824967 0.03911103782648991 auc 0.99685901271068 0.9953368301690573\n",
      "3 fold: ls 0.03374135588423866 0.03404881845588566 auc 0.9965969132642218 0.9963511109162044\n",
      "4 fold: ls 0.03330131970891865 0.04211726276811383 auc 0.9966955774711154 0.9945367293048198\n",
      "5 fold: ls 0.03276250233820243 0.037920708899575786 auc 0.9967977273965799 0.9954737173483356\n",
      "6 fold: ls 0.03441235635057974 0.03743837079865585 auc 0.9964802122766834 0.9955709009807638\n",
      "7 fold: ls 0.033474178186407376 0.03851183845515412 auc 0.9966512310088287 0.9954593864823127\n",
      "8 fold: ls 0.03332948775606638 0.03887080397311316 auc 0.9966862293637242 0.9951726908511125\n",
      "9 fold: ls 0.033231279198732845 0.038968335479846836 auc 0.9966979556991038 0.9952525879436698\n",
      "obscene 0.095 0.4 4\n",
      "this class avg train 0.033125616634141944 avg val 0.03812505935235618\n",
      "this class auc train 0.9967277563643855 auc val 0.9954372611705831\n",
      "========================\n",
      "0 fold: ls 0.0038714694785450094 0.0065661905901447685 auc 0.999358245237961 0.9968664885816049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold: ls 0.003988048583730065 0.006114999226034538 auc 0.999314627288643 0.9971048082966687\n",
      "2 fold: ls 0.004238654843538619 0.007390458196229382 auc 0.9991249448380337 0.9949481458202388\n",
      "3 fold: ls 0.004195360454438888 0.00669774687316152 auc 0.9992271937620676 0.9912588786221636\n",
      "4 fold: ls 0.004039453325756143 0.0066911300332559605 auc 0.9992843652792178 0.9963765269134872\n",
      "5 fold: ls 0.004025442758317083 0.007049136747562741 auc 0.9992613748580457 0.9959155718985062\n",
      "6 fold: ls 0.004287852739327959 0.006308494747856267 auc 0.9991120548742616 0.9945863976365578\n",
      "7 fold: ls 0.004140903865941209 0.007490696191338755 auc 0.9991697623743852 0.9960203344019108\n",
      "8 fold: ls 0.00417165748513597 0.0071405796059674795 auc 0.9991831936788489 0.9938988101208603\n",
      "9 fold: ls 0.004288430522231775 0.007670597807387139 auc 0.9989170230947786 0.9812417165180153\n",
      "threat 0.095 0.4 4\n",
      "this class avg train 0.004124727405696272 avg val 0.006912003001893856\n",
      "this class auc train 0.9991952785286242 auc val 0.9938217678810014\n",
      "========================\n",
      "0 fold: ls 0.04752170838425084 0.050110467714590025 auc 0.9926765385203845 0.9913483063353064\n",
      "1 fold: ls 0.04863746581667246 0.05396101817370231 auc 0.9922674556764787 0.9898467118845973\n",
      "2 fold: ls 0.049404326504470804 0.055252814160628674 auc 0.9920034315189608 0.9889510254342494\n",
      "3 fold: ls 0.04885627949430267 0.05210916067838608 auc 0.9921891217850035 0.9904118802472152\n",
      "4 fold: ls 0.0488300673859176 0.05535657979694627 auc 0.9922090348445739 0.9890573815887531\n",
      "5 fold: ls 0.04595054706661138 0.05256525458316152 auc 0.9932408032448198 0.9904240481104095\n",
      "6 fold: ls 0.04763237036653992 0.056289202049078 auc 0.9926254429742504 0.9891284924202547\n",
      "7 fold: ls 0.04753340860920054 0.05556198739919889 auc 0.992654088008081 0.989455522837446\n",
      "8 fold: ls 0.047864300322197156 0.05235804675388169 auc 0.9925363287669534 0.9904156499206777\n",
      "9 fold: ls 0.04903455016858206 0.05473072049658946 auc 0.9921301099293904 0.9892967860705011\n",
      "insult 0.095 0.4 4\n",
      "this class avg train 0.048126502411874536 avg val 0.05382952518061629\n",
      "this class auc train 0.9924532355268898 auc val 0.989833580484941\n",
      "========================\n",
      "0 fold: ls 0.012383741099196035 0.016971167677181716 auc 0.9973011958441239 0.993042318683058\n",
      "1 fold: ls 0.013381352583155206 0.01814580099851011 auc 0.9966515095142789 0.9905788591770144\n",
      "2 fold: ls 0.011228993702568876 0.017794521542572116 auc 0.9980212098611978 0.9921132527754275\n",
      "3 fold: ls 0.013517892402745695 0.01835749412631812 auc 0.9965894989903137 0.9879257303278588\n",
      "4 fold: ls 0.013890073336001308 0.01901887144372849 auc 0.996300618594645 0.9891760683024864\n",
      "5 fold: ls 0.013574112335551706 0.01667273859161655 auc 0.9965688570847294 0.9932351267623443\n",
      "6 fold: ls 0.012061742405636941 0.016600492426193023 auc 0.9975172701033332 0.9896777223787846\n",
      "7 fold: ls 0.01420957199927317 0.018942886176069488 auc 0.9960878839246915 0.9900595689717465\n",
      "8 fold: ls 0.013480769183186058 0.01683411691797353 auc 0.9966203270622568 0.9927126237444902\n",
      "9 fold: ls 0.014067097992779266 0.016804095231079848 auc 0.9962164625130676 0.9916630536888503\n",
      "identity_hate 0.095 0.4 4\n",
      "this class avg train 0.013179534704009427 avg val 0.0176142185131243\n",
      "this class auc train 0.9967874833492638 auc val 0.9910184324812061\n",
      "========================\n",
      "all loss avg 0.03019406459087947 0.03538549224052551\n",
      "all auc avg 0.9954565180361775 0.9917372689848026\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 4 feature fraction 0.5\n",
      "0 fold: ls 0.06594610513610949 0.0780221061491829 auc 0.9919903041023379 0.9870611066716679\n",
      "1 fold: ls 0.06751392357684516 0.0713876671958512 auc 0.9914561759907433 0.9897730629078173\n",
      "2 fold: ls 0.0647944651648093 0.07598588750897084 auc 0.992344743584521 0.9884040835630066\n",
      "3 fold: ls 0.0637143884965081 0.07343236188324126 auc 0.992624050528778 0.9888878469787323\n",
      "4 fold: ls 0.0611992009064267 0.07818392901086682 auc 0.9933293078131433 0.9878063474063857\n",
      "5 fold: ls 0.0650871537674527 0.07635003590504853 auc 0.9922806545165399 0.9876944274658153\n",
      "6 fold: ls 0.06423476289161241 0.07799782966215361 auc 0.9924864287515475 0.9875246210270235\n",
      "7 fold: ls 0.07008270240710718 0.07122984085149592 auc 0.990625114815063 0.9899795016819302\n",
      "8 fold: ls 0.06395363401069867 0.07458065999394689 auc 0.9925783699960599 0.9891651812106714\n",
      "9 fold: ls 0.06617126861346433 0.0777588231077334 auc 0.9918505392164335 0.987569225513368\n",
      "toxic 0.095 0.5 4\n",
      "this class avg train 0.0652697604971034 avg val 0.07549291412684914\n",
      "this class auc train 0.9921565689315166 auc val 0.9883865404426417\n",
      "========================\n",
      "0 fold: ls 0.01574665733261205 0.02126874631931154 auc 0.9961195376478316 0.9911262501582478\n",
      "1 fold: ls 0.015436645612284434 0.02071384202773139 auc 0.9963613285853632 0.991590707684517\n",
      "2 fold: ls 0.016140515860679973 0.021062831613831604 auc 0.9958357249878115 0.9913533358652995\n",
      "3 fold: ls 0.01616799834332195 0.01981313051179363 auc 0.9958036334000128 0.9926153627041396\n",
      "4 fold: ls 0.016612959123864186 0.021279776992648096 auc 0.9954960173347016 0.9910301145714647\n",
      "5 fold: ls 0.016120118841893488 0.01997686507162222 auc 0.9958397710179372 0.9922647640295204\n",
      "6 fold: ls 0.016791989640171475 0.019225466756756925 auc 0.9953256870811423 0.9928825750291732\n",
      "7 fold: ls 0.014048573931226872 0.019958913557451833 auc 0.9974304674708669 0.9923685852301388\n",
      "8 fold: ls 0.01640574354540773 0.02107910287237444 auc 0.995576782932872 0.9911582606840005\n",
      "9 fold: ls 0.016561018802401323 0.019083484681651372 auc 0.9955229745798291 0.9931047332846814\n",
      "severe_toxic 0.095 0.5 4\n",
      "this class avg train 0.016003222103386346 avg val 0.020346216040517305\n",
      "this class auc train 0.9959311925038368 auc val 0.9919494689241184\n",
      "========================\n",
      "0 fold: ls 0.033471024823608385 0.03729983662235056 auc 0.9966599221980348 0.9956277306617562\n",
      "1 fold: ls 0.03401277837405515 0.03734515414141869 auc 0.9965548755981116 0.9953490411679744\n",
      "2 fold: ls 0.030328079789662676 0.03890114470858568 auc 0.997312641998312 0.9953941536331486\n",
      "3 fold: ls 0.030354464084417866 0.03408545291226226 auc 0.9973187557843106 0.9963614479343192\n",
      "4 fold: ls 0.03328626748342523 0.04211640303165463 auc 0.9967052088837884 0.9945126879066286\n",
      "5 fold: ls 0.03369489394026969 0.037858383961939884 auc 0.9966033823904631 0.9954763016028643\n",
      "6 fold: ls 0.03437675405734404 0.03751138446334465 auc 0.9964924364644878 0.9954769280888105\n",
      "7 fold: ls 0.03351705119732628 0.03826436248727455 auc 0.9966501200266821 0.9955503835660207\n",
      "8 fold: ls 0.03277745901534938 0.03893664935045852 auc 0.9967998197946348 0.9951354932480477\n",
      "9 fold: ls 0.03339884437895422 0.0389767881574911 auc 0.9966804936269286 0.9952370640450199\n",
      "obscene 0.095 0.5 4\n",
      "this class avg train 0.03292176171444129 avg val 0.03812955598367805\n",
      "this class auc train 0.9967777656765753 auc val 0.9954121231854589\n",
      "========================\n",
      "0 fold: ls 0.003796913039493645 0.006714511811841518 auc 0.9994120875399493 0.9967028074586214\n",
      "1 fold: ls 0.0039412605354278455 0.006173074957565521 auc 0.9993397780592699 0.9971139744395559\n",
      "2 fold: ls 0.00418236899679913 0.007609924631565702 auc 0.9991630323789576 0.994648282002933\n",
      "3 fold: ls 0.004274378127428313 0.006659067200524263 auc 0.9992147687022326 0.9908149475139858\n",
      "4 fold: ls 0.003882567241694252 0.006863521893464838 auc 0.9993806148276927 0.996079263310076\n",
      "5 fold: ls 0.003992417906534214 0.007025900816160509 auc 0.9993075343613811 0.9962337880025981\n",
      "6 fold: ls 0.004161661364049522 0.006372558247222714 auc 0.99919730865083 0.9947867559243195\n",
      "7 fold: ls 0.00425005091440615 0.007537707452716751 auc 0.9991458380434868 0.9957558090808138\n",
      "8 fold: ls 0.0038521288607148447 0.007095784684840953 auc 0.9993816468106587 0.9938667126730085\n",
      "9 fold: ls 0.0043214640135766065 0.00756087296440443 auc 0.9990728996279251 0.9915877938755395\n",
      "threat 0.095 0.5 4\n",
      "this class avg train 0.004065521100012452 avg val 0.00696129246603072\n",
      "this class auc train 0.9992615509002384 auc val 0.9947590134281452\n",
      "========================\n",
      "0 fold: ls 0.047440654626050446 0.05015853715622073 auc 0.9927080046431345 0.9913447928552547\n",
      "1 fold: ls 0.047461190111908705 0.05374387670308304 auc 0.9926741491264278 0.989867792764908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 fold: ls 0.04967580845953204 0.055093581536661836 auc 0.9919432575381819 0.9891918661263714\n",
      "3 fold: ls 0.04579873204731029 0.05208357617904119 auc 0.9932878818836879 0.9903970734384254\n",
      "4 fold: ls 0.04699117132954316 0.05523596326562538 auc 0.9928615097516653 0.9891971771175049\n",
      "5 fold: ls 0.04347723998202296 0.05249802343633111 auc 0.994073364809558 0.9904509029067765\n",
      "6 fold: ls 0.04655846467277939 0.056300705171345854 auc 0.9929967830726962 0.9891309185545059\n",
      "7 fold: ls 0.04601123886833809 0.05564600522357967 auc 0.9932005494015907 0.9894426228574409\n",
      "8 fold: ls 0.04838821809640416 0.05257368713625432 auc 0.9923729556602027 0.9903932006048247\n",
      "9 fold: ls 0.047665586149476934 0.05468082850132548 auc 0.9926200148817788 0.9892286004619031\n",
      "insult 0.095 0.5 4\n",
      "this class avg train 0.04694683043433662 avg val 0.05380147843094686\n",
      "this class auc train 0.9928738470768923 auc val 0.9898644947687915\n",
      "========================\n",
      "0 fold: ls 0.012569690637461956 0.01715887328501066 auc 0.9972245879066522 0.9927688002450007\n",
      "1 fold: ls 0.014150451111632201 0.018129615372390218 auc 0.9960922949132596 0.9906470145910877\n",
      "2 fold: ls 0.013243738104016455 0.017942496439567863 auc 0.9967281674714428 0.9919769419472809\n",
      "3 fold: ls 0.01307271672101593 0.01841884368572476 auc 0.9968783404817773 0.9887117595441121\n",
      "4 fold: ls 0.014001981103784394 0.019117720346574815 auc 0.9962531415701346 0.9891397486410394\n",
      "5 fold: ls 0.012643628929788807 0.016436843051275313 auc 0.9971548327043562 0.9934067323584931\n",
      "6 fold: ls 0.012440120636778313 0.01651043651070733 auc 0.9973024180504824 0.9901898619842475\n",
      "7 fold: ls 0.013857702249323773 0.018873485663371777 auc 0.9963751483775307 0.9894970734879687\n",
      "8 fold: ls 0.013517959280715556 0.016797793126035115 auc 0.9965717689100655 0.9927257207890743\n",
      "9 fold: ls 0.013912390396561542 0.01701683168104999 auc 0.9963633503681151 0.9913640797745502\n",
      "identity_hate 0.095 0.5 4\n",
      "this class avg train 0.013341037917107893 avg val 0.01764029391617078\n",
      "this class auc train 0.9966944050753817 auc val 0.9910427733362855\n",
      "========================\n",
      "all loss avg 0.029758022294398 0.03539529182736548\n",
      "all auc avg 0.9956158883607401 0.9919024023475737\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.095 4 0.5 threat\n",
      "FIND BETTER PARAMS 0.095 4 0.5 insult\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 4 feature fraction 0.6\n",
      "0 fold: ls 0.0683852061632398 0.07781144213694093 auc 0.9912432778060012 0.9871831913617494\n",
      "1 fold: ls 0.06504947637187176 0.0715865519286271 auc 0.9922005605066376 0.9897230512203031\n",
      "2 fold: ls 0.06964839468608022 0.07624914333359127 auc 0.9908025973271362 0.9882092010632919\n",
      "3 fold: ls 0.06609654831374458 0.07364615180316138 auc 0.9919208881948854 0.9887419795568165\n",
      "4 fold: ls 0.06398042139657234 0.07820197958265479 auc 0.9925079620479679 0.9877677715175945\n",
      "5 fold: ls 0.06447711522171415 0.07664752842841269 auc 0.99241620943729 0.9875612477228438\n",
      "6 fold: ls 0.06593608479353803 0.07796758017816899 auc 0.9919433597767171 0.987610929478561\n",
      "7 fold: ls 0.0688306193961706 0.07100546844854314 auc 0.9910381539178528 0.9899936909770092\n",
      "8 fold: ls 0.0658503233070818 0.07421944564953352 auc 0.9919766547251075 0.9893268847747188\n",
      "9 fold: ls 0.06528299150065303 0.07794879859339071 auc 0.9921202905193495 0.9874399351952681\n",
      "toxic 0.095 0.6 4\n",
      "this class avg train 0.06635371811506663 avg val 0.07552840900830245\n",
      "this class auc train 0.9918169954258944 auc val 0.9883557882868157\n",
      "========================\n",
      "0 fold: ls 0.016807903395576022 0.021447694625780177 auc 0.9953349932898071 0.9909790796303328\n",
      "1 fold: ls 0.01668267042714714 0.020675785686179293 auc 0.9954354096937816 0.9916682491454614\n",
      "2 fold: ls 0.016459008593311633 0.021260449894691346 auc 0.9956124488991397 0.9910902487656665\n",
      "3 fold: ls 0.01664538115688042 0.01985613039695006 auc 0.9954304936399349 0.9926525509558173\n",
      "4 fold: ls 0.015068503313897788 0.0213242934213575 auc 0.9966658739550261 0.9907053107988353\n",
      "5 fold: ls 0.015118009597236162 0.019997507518547668 auc 0.9966214302711525 0.9922711337554869\n",
      "6 fold: ls 0.016619501263608838 0.019265754166600705 auc 0.9954811366996458 0.9928443542540321\n",
      "7 fold: ls 0.013730963649332857 0.020034549659634346 auc 0.9976188995624625 0.9923339476526671\n",
      "8 fold: ls 0.01669000125902938 0.02119374284527301 auc 0.9954181913101381 0.9911411409618018\n",
      "9 fold: ls 0.015171356008549223 0.01920091334295371 auc 0.9966527638734499 0.9930175421413906\n",
      "severe_toxic 0.095 0.6 4\n",
      "this class avg train 0.015899329866456948 avg val 0.02042568215579678\n",
      "this class auc train 0.9960271641194538 auc val 0.9918703558061492\n",
      "========================\n",
      "0 fold: ls 0.029365255590007393 0.03731592592831872 auc 0.9975168370533884 0.9955780849356934\n",
      "1 fold: ls 0.033771071926300925 0.03729901552793767 auc 0.9965986016242412 0.9954342376190097\n",
      "2 fold: ls 0.03146368798148525 0.038792997457498535 auc 0.9970652734596015 0.9954026895041677\n",
      "3 fold: ls 0.03184076806710143 0.03414018648050809 auc 0.9970039538201175 0.996325190060174\n",
      "4 fold: ls 0.03267309165540117 0.04193212769197192 auc 0.9968219741709898 0.9945537227361148\n",
      "5 fold: ls 0.031763567043394086 0.03772000282101935 auc 0.9970100269958025 0.9955305709479672\n",
      "6 fold: ls 0.03239523898751757 0.03733954786874652 auc 0.9968817211277399 0.9953398842880458\n",
      "7 fold: ls 0.03149591034981167 0.038301968808808005 auc 0.9970678966924679 0.9955287698008715\n",
      "8 fold: ls 0.03322962832466305 0.03899464738553025 auc 0.9967067124322982 0.9951098073242471\n",
      "9 fold: ls 0.03315250179834588 0.03876087169237925 auc 0.9967206190750274 0.9952608987176946\n",
      "obscene 0.095 0.6 4\n",
      "this class avg train 0.03211507217240284 avg val 0.03805972916627183\n",
      "this class auc train 0.9969393616451674 auc val 0.9954063855933984\n",
      "========================\n",
      "0 fold: ls 0.0037882473400843632 0.006685845224605188 auc 0.9994027646194845 0.9968258956631051\n",
      "1 fold: ls 0.003826159379488234 0.006366848206250687 auc 0.9994078564932923 0.9968075633773309\n",
      "2 fold: ls 0.004109404529355032 0.007550097444000006 auc 0.9992251256279775 0.9947137544521265\n",
      "3 fold: ls 0.004272283390407895 0.006699171403162563 auc 0.999202327400489 0.9912287594024346\n",
      "4 fold: ls 0.004145925016020112 0.006738113282821228 auc 0.9992349330313637 0.9963149789427368\n",
      "5 fold: ls 0.0038017747708809202 0.007082793147138101 auc 0.9993938925877128 0.9961250969053157\n",
      "6 fold: ls 0.003870444769550359 0.006396932503926976 auc 0.9993758803114288 0.9946505646698933\n",
      "7 fold: ls 0.004231427583688608 0.007879324359708773 auc 0.9991329825730823 0.995421878601211\n",
      "8 fold: ls 0.004231460400251301 0.007262972030326318 auc 0.9991406008759615 0.9931819671188395\n",
      "9 fold: ls 0.004283658261949548 0.007621905508327536 auc 0.9990590693227075 0.9812637835134133\n",
      "threat 0.095 0.6 4\n",
      "this class avg train 0.0040560785441676375 avg val 0.007028400311026736\n",
      "this class auc train 0.9992575432843498 auc val 0.9936534242646407\n",
      "========================\n",
      "0 fold: ls 0.04714990799442906 0.04988268014724805 auc 0.9928112843241427 0.9914524559225563\n",
      "1 fold: ls 0.04851721609990408 0.054149107857298186 auc 0.9923271636608576 0.9897500911831727\n",
      "2 fold: ls 0.04957357489368404 0.05503198988216424 auc 0.9919793128472056 0.9888527734742295\n",
      "3 fold: ls 0.04898383929215324 0.05212364128548177 auc 0.992146840102798 0.9904101235071893\n",
      "4 fold: ls 0.048741861033391724 0.05552179588191564 auc 0.9922360081924873 0.9889486238464569\n",
      "5 fold: ls 0.04872293836080885 0.052828228949761566 auc 0.9922560117938588 0.9902985584077598\n",
      "6 fold: ls 0.048228959117302225 0.05658650058370703 auc 0.9924042481925143 0.9889957243148513\n",
      "7 fold: ls 0.046267135671857924 0.0557252190316997 auc 0.9931008058423766 0.9893880911237833\n",
      "8 fold: ls 0.04864547512897227 0.05249300858098673 auc 0.9922742741258763 0.9903704999906602\n",
      "9 fold: ls 0.04843301293573963 0.05473680160262793 auc 0.9923365296528868 0.9891681213348665\n",
      "insult 0.095 0.6 4\n",
      "this class avg train 0.04832639205282431 avg val 0.05390789738028908\n",
      "this class auc train 0.9923872478735003 auc val 0.9897635063105525\n",
      "========================\n",
      "0 fold: ls 0.013623221151074593 0.01727662937205121 auc 0.9965075750711102 0.9926185892995103\n",
      "1 fold: ls 0.014048073402082101 0.018064072836386023 auc 0.996169680934832 0.9908972167032777\n",
      "2 fold: ls 0.013405882961430098 0.018098307829086776 auc 0.9966359672843645 0.9917953436400462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold: ls 0.013358619407518348 0.018239952871842602 auc 0.9966628223013309 0.9888243056555093\n",
      "4 fold: ls 0.013265776701744413 0.019085658817559248 auc 0.996737871291729 0.9881956616388597\n",
      "5 fold: ls 0.013063698372163318 0.016506085996131466 auc 0.9968859950258088 0.993465439536123\n",
      "6 fold: ls 0.01176492284051216 0.016479749112794363 auc 0.997686376756061 0.990220120673459\n",
      "7 fold: ls 0.0135504483849068 0.018771519491234127 auc 0.9965535790395827 0.9884443420767397\n",
      "8 fold: ls 0.01003195460562757 0.01686397643126295 auc 0.9986216570802634 0.9927193980778959\n",
      "9 fold: ls 0.013883694063030312 0.01702484857974374 auc 0.9963745708331772 0.9913807897969507\n",
      "identity_hate 0.095 0.6 4\n",
      "this class avg train 0.01299962918900897 avg val 0.017641080133809252\n",
      "this class auc train 0.996883609561826 auc val 0.9908561207098371\n",
      "========================\n",
      "all loss avg 0.029958369989987892 0.03543186635924936\n",
      "all auc avg 0.995551986985032 0.991650930161899\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 3 feature fraction 0.4\n",
      "0 fold: ls 0.06980263505431768 0.0779922411716394 auc 0.9906879393559518 0.9871405183457729\n",
      "1 fold: ls 0.07139088858947125 0.07148052211349076 auc 0.9900892368758581 0.98981990356442\n",
      "2 fold: ls 0.06974828885227126 0.07607027585020555 auc 0.990625304288737 0.9883481375176446\n",
      "3 fold: ls 0.06811259730761168 0.07309867747470263 auc 0.9912246882659351 0.989084269693461\n",
      "4 fold: ls 0.06659817452114002 0.0777195276431251 auc 0.9916756208069415 0.9879799162409115\n",
      "5 fold: ls 0.06712741570668866 0.07645635859419973 auc 0.9915831682858027 0.9876219900154176\n",
      "6 fold: ls 0.06861020921014016 0.07809410620601785 auc 0.9910502281510886 0.9875306499262118\n",
      "7 fold: ls 0.07032105164545706 0.07095547848011236 auc 0.9904500719696552 0.9900622801254262\n",
      "8 fold: ls 0.06840227574788624 0.07427474849452688 auc 0.9910784365038259 0.9893865432805461\n",
      "9 fold: ls 0.06917666995019166 0.0778054789485975 auc 0.9907930195798584 0.9876394013241742\n",
      "toxic 0.075 0.4 3\n",
      "this class avg train 0.06892902065851758 avg val 0.07539474149766176\n",
      "this class auc train 0.9909257714083655 auc val 0.9884613610033985\n",
      "========================\n",
      "0 fold: ls 0.017884588966358767 0.02123071262111407 auc 0.994260774257405 0.9910783801747056\n",
      "1 fold: ls 0.01795591783983821 0.020476098165960237 auc 0.9941977208429362 0.9917390650715281\n",
      "2 fold: ls 0.018136562699245466 0.020975214139824488 auc 0.9940803335152876 0.99134107165464\n",
      "3 fold: ls 0.01634527283986075 0.01975345994374926 auc 0.9955941864697944 0.9927380048107356\n",
      "4 fold: ls 0.018057964806082703 0.02106036346898441 auc 0.9941391006993587 0.9910898531459678\n",
      "5 fold: ls 0.018039654927072192 0.019861288138217706 auc 0.9941444580180415 0.9923423950647364\n",
      "6 fold: ls 0.018163237285844742 0.019103118303708234 auc 0.9940528692488761 0.9930266992021014\n",
      "7 fold: ls 0.0165609278037328 0.019952588592974448 auc 0.995441823688022 0.9923287719227001\n",
      "8 fold: ls 0.018127130454620454 0.02101496756714668 auc 0.9940861725345593 0.991225545173572\n",
      "9 fold: ls 0.01828512824446136 0.01891785166383946 auc 0.9939450860141168 0.9932385059976757\n",
      "severe_toxic 0.075 0.4 3\n",
      "this class avg train 0.017755638586711742 avg val 0.020234566260551902\n",
      "this class auc train 0.9943942525288397 auc val 0.9920148292218363\n",
      "========================\n",
      "0 fold: ls 0.03549659348095671 0.037204468815033 auc 0.9961833861568455 0.9956809001380919\n",
      "1 fold: ls 0.0352360478037116 0.037030074470150304 auc 0.9962410933530874 0.9954992312351488\n",
      "2 fold: ls 0.03411643225975216 0.03909857239641119 auc 0.9964790896915902 0.9953289990947278\n",
      "3 fold: ls 0.035289651943321315 0.033935490823217986 auc 0.9962249165080963 0.9964596496064101\n",
      "4 fold: ls 0.03443067562632583 0.04196849332653941 auc 0.9964229149920553 0.9945310126205594\n",
      "5 fold: ls 0.0335497653865295 0.03763044304383997 auc 0.996607301285711 0.9955835090104341\n",
      "6 fold: ls 0.03275729767176822 0.03731603003801033 auc 0.996789033405309 0.9952950122321381\n",
      "7 fold: ls 0.03554334677566889 0.038496957688233295 auc 0.9961698817980745 0.9954842892986804\n",
      "8 fold: ls 0.03412876994953226 0.03873731870994656 auc 0.996495621956813 0.9952089487252577\n",
      "9 fold: ls 0.034407426032423194 0.038974651767669156 auc 0.9964251830885505 0.9952424738884889\n",
      "obscene 0.075 0.4 3\n",
      "this class avg train 0.034495600692998965 avg val 0.03803925010790512\n",
      "this class auc train 0.9964038422236132 auc val 0.9954314025849937\n",
      "========================\n",
      "0 fold: ls 0.004975087161968411 0.006710675811690616 auc 0.9985662355330283 0.9965011523151058\n",
      "1 fold: ls 0.005023503318218107 0.006237837518602486 auc 0.9985785551064998 0.9968494657448146\n",
      "2 fold: ls 0.005286661956006004 0.00730655993520197 auc 0.9981876989749173 0.9942947307772888\n",
      "3 fold: ls 0.005101083831731899 0.006566143667283209 auc 0.9985426622956444 0.9907560186058206\n",
      "4 fold: ls 0.0047068423117043005 0.006683595320058693 auc 0.9987893606405288 0.9963477172250508\n",
      "5 fold: ls 0.005088196467436892 0.006820130709184018 auc 0.9984213189988748 0.9963162884740293\n",
      "6 fold: ls 0.0050522273950307835 0.006388419408963197 auc 0.9984698498208192 0.9951927106250131\n",
      "7 fold: ls 0.00499755755132532 0.007505283249463302 auc 0.9985450011304369 0.9957623567372766\n",
      "8 fold: ls 0.004560792193613085 0.007031418640882991 auc 0.998913069264113 0.9942679307711545\n",
      "9 fold: ls 0.0052945782016739044 0.007611768491097506 auc 0.9982376610019292 0.9914079144282041\n",
      "threat 0.075 0.4 3\n",
      "this class avg train 0.005008653038870871 avg val 0.0068861832752428\n",
      "this class auc train 0.9985251412766794 auc val 0.994769628570376\n",
      "========================\n",
      "0 fold: ls 0.05153126097325995 0.05024894607403359 auc 0.9910946822272185 0.9913241302463787\n",
      "1 fold: ls 0.05034077444715766 0.05382339060386365 auc 0.9915441915503682 0.9899391498716743\n",
      "2 fold: ls 0.05126275708074497 0.055070308061496286 auc 0.9911798908571543 0.9891045310507982\n",
      "3 fold: ls 0.05120660081186745 0.052049109197860544 auc 0.9912155700626538 0.9903873695411395\n",
      "4 fold: ls 0.05019050661433896 0.05532948122617244 auc 0.9916212859500092 0.988927039617601\n",
      "5 fold: ls 0.05011141170199817 0.05271426811904678 auc 0.9916525178125432 0.9902998969645881\n",
      "6 fold: ls 0.049963845952929284 0.056218117586724015 auc 0.9916721313643528 0.9891574387116657\n",
      "7 fold: ls 0.05051961749083561 0.05557787599403136 auc 0.9914652002182937 0.9894302254740597\n",
      "8 fold: ls 0.05140999402118221 0.052294481600534085 auc 0.991121805628267 0.9903857873046271\n",
      "9 fold: ls 0.05000670176194517 0.055034427056988106 auc 0.9916903928846399 0.9890173423477947\n",
      "insult 0.075 0.4 3\n",
      "this class avg train 0.05065434708562595 avg val 0.05383604055207508\n",
      "this class auc train 0.9914257668555502 auc val 0.9897972911130328\n",
      "========================\n",
      "0 fold: ls 0.01501718844265759 0.017208171334347266 auc 0.995230450058961 0.9926504250521366\n",
      "1 fold: ls 0.015570265466625668 0.01785433396300412 auc 0.9946750063869589 0.991199880548669\n",
      "2 fold: ls 0.014683086524444744 0.017823379828034166 auc 0.9955397690566358 0.9921047333486683\n",
      "3 fold: ls 0.013897386395457054 0.0181002220114692 auc 0.9961811159922427 0.9892942192999093\n",
      "4 fold: ls 0.014792183481512518 0.01886732244222978 auc 0.9954651313392623 0.9880019567778093\n",
      "5 fold: ls 0.013991689951677657 0.016406866386191817 auc 0.9961393776477159 0.9935205339643602\n",
      "6 fold: ls 0.01449497917136804 0.016667714699096246 auc 0.9956751063111993 0.9894817183322494\n",
      "7 fold: ls 0.015306179479796685 0.01861978793236646 auc 0.9950017034781775 0.9892857142857142\n",
      "8 fold: ls 0.013544461308361181 0.016772467538573855 auc 0.996467708190162 0.9929447575691885\n",
      "9 fold: ls 0.01460890871899025 0.016802466571254636 auc 0.9955921176302356 0.9917872498012862\n",
      "identity_hate 0.075 0.4 3\n",
      "this class avg train 0.014590632894089139 avg val 0.01751227327065676\n",
      "this class auc train 0.9955967486091553 auc val 0.9910271188979991\n",
      "========================\n",
      "all loss avg 0.03190564882613571 0.035317175827348904\n",
      "all auc avg 0.9945452538170337 0.9919169385652727\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.075 3 0.4 toxic\n",
      "FIND BETTER PARAMS 0.075 3 0.4 severe_toxic\n",
      "FIND BETTER PARAMS 0.075 3 0.4 threat\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 3 feature fraction 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.06961927374839544 0.07848020982257312 auc 0.9907464076670605 0.9868798143044297\n",
      "1 fold: ls 0.07025314591686407 0.07155496883031816 auc 0.9905164868820234 0.989769348271607\n",
      "2 fold: ls 0.06972492896278615 0.07579979331020929 auc 0.9906578647992063 0.9883981039047169\n",
      "3 fold: ls 0.06801320800003104 0.07328281171805215 auc 0.9912390716036341 0.9889827514038606\n",
      "4 fold: ls 0.06752274231925584 0.0781123645898261 auc 0.9914192325833151 0.9877575269219812\n",
      "5 fold: ls 0.06660156611439788 0.07635827612904408 auc 0.9917237221673589 0.9876871746547616\n",
      "6 fold: ls 0.06804542071738172 0.07780160136982822 auc 0.9912297705700504 0.9876479188149342\n",
      "7 fold: ls 0.06915665370364422 0.0709781963177084 auc 0.9908552870736735 0.990008560270255\n",
      "8 fold: ls 0.06751038102547219 0.07417674521321568 auc 0.9914069264026881 0.989468143060553\n",
      "9 fold: ls 0.07019342999384588 0.07802130515901899 auc 0.990462872511676 0.9875580282102225\n",
      "toxic 0.075 0.5 3\n",
      "this class avg train 0.06866407505020745 avg val 0.07545662724597943\n",
      "this class auc train 0.9910257642260685 auc val 0.988415736981732\n",
      "========================\n",
      "0 fold: ls 0.018115559672064997 0.02127004961565215 auc 0.9940927388316252 0.9910855013292821\n",
      "1 fold: ls 0.018127061877643763 0.020558522775801693 auc 0.9940621078460661 0.9916488637802252\n",
      "2 fold: ls 0.01795771490342239 0.020974031063347446 auc 0.9942215610083508 0.9913149607545259\n",
      "3 fold: ls 0.017838217360148595 0.019732635832759905 auc 0.9943195634975504 0.992687761109001\n",
      "4 fold: ls 0.01802196848850629 0.02112074499583181 auc 0.9941686362332383 0.9910993480187364\n",
      "5 fold: ls 0.017959986210252157 0.01992169546345349 auc 0.9942158674847188 0.9922707356476141\n",
      "6 fold: ls 0.018180917366483695 0.01906438542203148 auc 0.9940411044879066 0.9930330693312917\n",
      "7 fold: ls 0.016548193978383825 0.019956483560096112 auc 0.9954450416097359 0.9923164297973941\n",
      "8 fold: ls 0.018146053973344185 0.021137379637467896 auc 0.9940765212183683 0.9910909761944291\n",
      "9 fold: ls 0.018071520347119226 0.01903187200933943 auc 0.9941340666707537 0.9930768639694744\n",
      "severe_toxic 0.075 0.5 3\n",
      "this class avg train 0.017896719417736913 avg val 0.02027678003757814\n",
      "this class auc train 0.9942777208888314 auc val 0.9919624509931975\n",
      "========================\n",
      "0 fold: ls 0.03562557882736089 0.03731074281301534 auc 0.9961579097662292 0.9956315676342754\n",
      "1 fold: ls 0.03518089873578969 0.036888405887512125 auc 0.9962595189679193 0.9955668872403829\n",
      "2 fold: ls 0.03452708690938163 0.03916285445685465 auc 0.9963867389380696 0.9953466973227124\n",
      "3 fold: ls 0.03522534503079477 0.03397566964341699 auc 0.9962443040651194 0.9964796971566936\n",
      "4 fold: ls 0.03390854535101683 0.042039693341440885 auc 0.9965371861291722 0.9945199708057549\n",
      "5 fold: ls 0.03544888314666902 0.03776538503002978 auc 0.9961959323472401 0.9955394200619594\n",
      "6 fold: ls 0.0358836391793528 0.03759665953381204 auc 0.9961020678926316 0.9952525678092727\n",
      "7 fold: ls 0.03542932450496728 0.038567269167808414 auc 0.9961975649785321 0.9954792774111095\n",
      "8 fold: ls 0.03508154865407292 0.038807199917786105 auc 0.9962867921221097 0.9951799737502388\n",
      "9 fold: ls 0.03341531850104481 0.03884716459790863 auc 0.9966339453421286 0.9952750897563596\n",
      "obscene 0.075 0.5 3\n",
      "this class avg train 0.034972616884045064 avg val 0.038096104438958486\n",
      "this class auc train 0.9963001960549154 auc val 0.9954271148948759\n",
      "========================\n",
      "0 fold: ls 0.004979229334930636 0.00661638574875607 auc 0.998586213219739 0.9966753090299602\n",
      "1 fold: ls 0.004942932634125985 0.006238962643457722 auc 0.9986573938799088 0.9968520846427823\n",
      "2 fold: ls 0.004827431757642542 0.007408545779286801 auc 0.9986969188397545 0.9938220196941128\n",
      "3 fold: ls 0.005154097697212538 0.0065792973251657914 auc 0.9984919631789443 0.9914670940976805\n",
      "4 fold: ls 0.0049434309722400736 0.006742589037970065 auc 0.9986185038863638 0.9963228361304922\n",
      "5 fold: ls 0.005004085510622766 0.006980185377403838 auc 0.9985022849116569 0.9957230707984999\n",
      "6 fold: ls 0.004894865920909082 0.006341522271592617 auc 0.9986618291767042 0.9951508056236511\n",
      "7 fold: ls 0.004999038663066933 0.007524702117608785 auc 0.9985202809460325 0.9956458084522388\n",
      "8 fold: ls 0.005217341891532456 0.007024833481084234 auc 0.9982871162936972 0.9943989953498822\n",
      "9 fold: ls 0.0052798356505082845 0.007588903219700406 auc 0.9982833974242802 0.991240071523813\n",
      "threat 0.075 0.5 3\n",
      "this class avg train 0.005024229003279129 avg val 0.006904592700202633\n",
      "this class auc train 0.9985305901757082 auc val 0.9947298095343114\n",
      "========================\n",
      "0 fold: ls 0.051511591209235146 0.05019786022280348 auc 0.9910955548080601 0.9913693035613304\n",
      "1 fold: ls 0.05097544098993058 0.053882688649872085 auc 0.9912926273719739 0.9898041318525409\n",
      "2 fold: ls 0.05034339978256096 0.05525350972090367 auc 0.9915451710727339 0.9889684255259344\n",
      "3 fold: ls 0.05029931613816547 0.05176998166175806 auc 0.9915467705459642 0.9905400386148188\n",
      "4 fold: ls 0.04947813695725209 0.055260107286229564 auc 0.9918891223933937 0.9890431594224529\n",
      "5 fold: ls 0.04786518853284779 0.052784412147698814 auc 0.9925150692806807 0.9902771414985077\n",
      "6 fold: ls 0.04943805922086835 0.056176982866211526 auc 0.9918764155602497 0.989149491030498\n",
      "7 fold: ls 0.04925810572690038 0.055592667587738814 auc 0.991942022532387 0.9894266235315907\n",
      "8 fold: ls 0.04965245551552178 0.05243007260898855 auc 0.991820339067975 0.9903754421907919\n",
      "9 fold: ls 0.05108531633725072 0.054909964959548946 auc 0.9912729959252027 0.9891574411566156\n",
      "insult 0.075 0.5 3\n",
      "this class avg train 0.049990701041053326 avg val 0.05382582477117535\n",
      "this class auc train 0.9916796088558619 auc val 0.9898111198385082\n",
      "========================\n",
      "0 fold: ls 0.01486617081147804 0.01701756303950752 auc 0.9954108460788696 0.9928526493399461\n",
      "1 fold: ls 0.015243007881302936 0.01789447659898126 auc 0.9950261362895668 0.9909245685470836\n",
      "2 fold: ls 0.014498213592814464 0.017837714974082552 auc 0.9957124009087666 0.9919096833149718\n",
      "3 fold: ls 0.014178625794022476 0.018161692394947266 auc 0.9959854389563677 0.9896663837320201\n",
      "4 fold: ls 0.015023551329844636 0.018817189016735746 auc 0.9952483459932804 0.9885247805462926\n",
      "5 fold: ls 0.014858620455967756 0.016555559743456412 auc 0.9954187221813603 0.9932915759716038\n",
      "6 fold: ls 0.015038442799061837 0.0166038675635546 auc 0.9952548095144879 0.990093214827661\n",
      "7 fold: ls 0.015199345468101515 0.018744150091989497 auc 0.9951279968790391 0.9881792398294675\n",
      "8 fold: ls 0.013480203612435666 0.016788780736499444 auc 0.9965248934111353 0.9929515319025941\n",
      "9 fold: ls 0.014959377235498408 0.01677715954435925 auc 0.9953317589696385 0.9918956391357757\n",
      "identity_hate 0.075 0.5 3\n",
      "this class avg train 0.014734555898052776 avg val 0.017519815370411355\n",
      "this class auc train 0.9955041349182512 auc val 0.9910289267147416\n",
      "========================\n",
      "all loss avg 0.031880482882395776 0.0353466240940509\n",
      "all auc avg 0.9945530025199395 0.9918958598262277\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 3 feature fraction 0.6\n",
      "0 fold: ls 0.07082284118654894 0.07817477066963145 auc 0.9903521126339739 0.9871175510218874\n",
      "1 fold: ls 0.06707347959925575 0.07147235791620792 auc 0.9915680539796914 0.9897574342554691\n",
      "2 fold: ls 0.06919122216434534 0.07586913941176292 auc 0.9908438016044517 0.9884224755422917\n",
      "3 fold: ls 0.07130706627433414 0.07364133639810579 auc 0.9901667613679072 0.9888556836652045\n",
      "4 fold: ls 0.06688349876702637 0.07798252890944413 auc 0.991589401461219 0.9877516793430694\n",
      "5 fold: ls 0.06882012252091892 0.07658339839468495 auc 0.9910336054175106 0.9876106121680774\n",
      "6 fold: ls 0.06785561899966842 0.07800263001276543 auc 0.9913254563306406 0.9875449288979735\n",
      "7 fold: ls 0.06891653264152021 0.07112164232366547 auc 0.9909594554391673 0.9899847603344194\n",
      "8 fold: ls 0.06645773590490239 0.07438430144975128 auc 0.9917426648787662 0.9893549006991877\n",
      "9 fold: ls 0.06745228549762616 0.07776469117988045 auc 0.9913917396934994 0.9876445693102409\n",
      "toxic 0.075 0.6 3\n",
      "this class avg train 0.06847804035561465 avg val 0.07549967966658998\n",
      "this class auc train 0.9910973052806827 auc val 0.9884044595237821\n",
      "========================\n",
      "0 fold: ls 0.017865538369161445 0.021145593638636 auc 0.9942835042670906 0.9911946923661222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold: ls 0.017701619891605118 0.020534606069154655 auc 0.9944201955609162 0.9916255222180024\n",
      "2 fold: ls 0.017474518333012987 0.02101472987690864 auc 0.994632872480651 0.9913576876819852\n",
      "3 fold: ls 0.018086028493014723 0.019907372101776795 auc 0.994100046744173 0.9925089410051906\n",
      "4 fold: ls 0.01799546415962841 0.02117145604587149 auc 0.994201039056749 0.9910158722623117\n",
      "5 fold: ls 0.018138033991044335 0.019839229649998482 auc 0.9940560576092952 0.992367475860729\n",
      "6 fold: ls 0.018210874408977534 0.019075343669859298 auc 0.9940167178330912 0.9930083850806796\n",
      "7 fold: ls 0.014661468591008139 0.019878272339190862 auc 0.9969250088666722 0.9923701777624363\n",
      "8 fold: ls 0.016887175577657967 0.021220692576432717 auc 0.9951184127599677 0.9910276730356015\n",
      "9 fold: ls 0.01699569352617669 0.018927392538466162 auc 0.9950815560462731 0.9932174049447332\n",
      "severe_toxic 0.075 0.6 3\n",
      "this class avg train 0.017401641534128737 avg val 0.02027146885062951\n",
      "this class auc train 0.9946835411224878 auc val 0.9919693832217792\n",
      "========================\n",
      "0 fold: ls 0.03560548262054693 0.03728724237729501 auc 0.9961669625484951 0.9956241286059221\n",
      "1 fold: ls 0.0354126026731818 0.036873835760585366 auc 0.996209902469206 0.9955846626028692\n",
      "2 fold: ls 0.03413936410449518 0.039025498807388 auc 0.996482590880757 0.9953726181787427\n",
      "3 fold: ls 0.03552953890540508 0.034067403243809136 auc 0.9961745176587373 0.9964233134215217\n",
      "4 fold: ls 0.035381974097674046 0.04219510844642597 auc 0.9962282214140812 0.9944789751316403\n",
      "5 fold: ls 0.034384321942354815 0.03757435414216671 auc 0.9964293570447542 0.9955800633377292\n",
      "6 fold: ls 0.03621693287378969 0.037629600673492754 auc 0.9960531387498545 0.9953976776165967\n",
      "7 fold: ls 0.03550409273188275 0.03838261793762637 auc 0.9961763035456168 0.99551161974809\n",
      "8 fold: ls 0.035420777205241165 0.03893088218050631 auc 0.9962172111845754 0.9951491193173809\n",
      "9 fold: ls 0.03523514679127402 0.03891374341447612 auc 0.9962475092595049 0.9952853606185976\n",
      "obscene 0.075 0.6 3\n",
      "this class avg train 0.03528302339458455 avg val 0.03808802869837717\n",
      "this class auc train 0.9962385714755582 auc val 0.9954407538579089\n",
      "========================\n",
      "0 fold: ls 0.004884910057906114 0.0065825192694863 auc 0.9986780943365858 0.9966831657238635\n",
      "1 fold: ls 0.004879977731085857 0.006256458631998023 auc 0.9986963747320269 0.9968795830714435\n",
      "2 fold: ls 0.004739475164847149 0.007472774029945563 auc 0.9987801104749833 0.9937342866121935\n",
      "3 fold: ls 0.004630655764741085 0.006538865418506465 auc 0.9988648124254497 0.9918232866092568\n",
      "4 fold: ls 0.0047343133760293435 0.0066332548023574495 auc 0.998783830270759 0.9965428373876423\n",
      "5 fold: ls 0.004763186649728789 0.006958743066341842 auc 0.9987417312444941 0.9957898568944203\n",
      "6 fold: ls 0.004308155316284374 0.006327812708368224 auc 0.9990875701975276 0.9951010434345339\n",
      "7 fold: ls 0.005126059225121098 0.0076019288373051245 auc 0.9984081711741211 0.9956837848597231\n",
      "8 fold: ls 0.005027471733204271 0.007093155532537935 auc 0.9985083606666185 0.9941997236944697\n",
      "9 fold: ls 0.005227620655186135 0.007557832263375911 auc 0.9982984997610849 0.9895235267605784\n",
      "threat 0.075 0.6 3\n",
      "this class avg train 0.004832182567413422 avg val 0.006902334456022283\n",
      "this class auc train 0.9986847555283649 auc val 0.9945961095048126\n",
      "========================\n",
      "0 fold: ls 0.05117826734720558 0.050276708996193645 auc 0.9912372910744405 0.9913071484261282\n",
      "1 fold: ls 0.050095332722194415 0.053787483618417294 auc 0.991645310185988 0.989874401453577\n",
      "2 fold: ls 0.051584111434013265 0.055195272844597736 auc 0.9910870103352711 0.989075210223223\n",
      "3 fold: ls 0.049455371500880876 0.05192061750973204 auc 0.9919008782137153 0.9904930249055544\n",
      "4 fold: ls 0.04999084082112809 0.0552627190465786 auc 0.9917020634060952 0.9890942755613322\n",
      "5 fold: ls 0.04911766714258698 0.05254800239325642 auc 0.9920541722529642 0.9903889946534694\n",
      "6 fold: ls 0.04980874895895826 0.05618580467970079 auc 0.9917404117358009 0.989149491030498\n",
      "7 fold: ls 0.050353410785965384 0.05564192990310788 auc 0.991528598868396 0.9894147287448328\n",
      "8 fold: ls 0.05151741769710696 0.05251258064887641 auc 0.9910860258238376 0.9902120982881307\n",
      "9 fold: ls 0.04971436520066084 0.054810486586331635 auc 0.9917991295631622 0.989039456599232\n",
      "insult 0.075 0.6 3\n",
      "this class avg train 0.05028155336107006 avg val 0.053814160622679255\n",
      "this class auc train 0.9915780891459672 auc val 0.9898048829885976\n",
      "========================\n",
      "0 fold: ls 0.015262082434751939 0.01715699692596806 auc 0.9950502958008979 0.9925670243480733\n",
      "1 fold: ls 0.01467158340414984 0.01795455259427724 auc 0.9955395328525337 0.9906506017181441\n",
      "2 fold: ls 0.01372021736092021 0.01765047959912986 auc 0.9962543420427473 0.9922813993562003\n",
      "3 fold: ls 0.014799552279461309 0.018160523754237476 auc 0.9954656565460304 0.9886126651591766\n",
      "4 fold: ls 0.015526258960672107 0.018975552519806194 auc 0.994808795169227 0.9888754222160643\n",
      "5 fold: ls 0.01503018522533105 0.016516702901649177 auc 0.995263550472747 0.9934672459108194\n",
      "6 fold: ls 0.014972366262993721 0.016539866316361763 auc 0.995300113426379 0.9902666377628441\n",
      "7 fold: ls 0.015411390828348527 0.01863796785686008 auc 0.9948974622756636 0.9879249765156441\n",
      "8 fold: ls 0.013075538692589693 0.016828958268496192 auc 0.9968121884071853 0.9927735927451407\n",
      "9 fold: ls 0.015208829184618227 0.016794201692331572 auc 0.9951434239772537 0.9919046715803165\n",
      "identity_hate 0.075 0.6 3\n",
      "this class avg train 0.014767800463383662 avg val 0.017521580242911762\n",
      "this class auc train 0.9954535360970664 auc val 0.9909324237312424\n",
      "========================\n",
      "all loss avg 0.03184070694603251 0.035349542089534995\n",
      "all auc avg 0.9946226331083546 0.9918580021380203\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 4 feature fraction 0.4\n",
      "0 fold: ls 0.06632752846492469 0.07814935966481097 auc 0.9918802507127804 0.9869734503171937\n",
      "1 fold: ls 0.06796750072552221 0.0714790301166033 auc 0.9913505209991651 0.9897640934203826\n",
      "2 fold: ls 0.06525600635299793 0.07548990269534661 auc 0.992209256588738 0.9884611621194085\n",
      "3 fold: ls 0.06870886067909415 0.07350442282059183 auc 0.9910946428958416 0.9888499758095641\n",
      "4 fold: ls 0.06291286473236725 0.07784031488570053 auc 0.9928225331960021 0.9878339987485274\n",
      "5 fold: ls 0.06135678771571592 0.07611345297275852 auc 0.9933719486411077 0.9876890785176632\n",
      "6 fold: ls 0.06591701506970438 0.07775485441848974 auc 0.9919557852854525 0.9876965126489932\n",
      "7 fold: ls 0.0662956080690814 0.07064216352976395 auc 0.9918415624163844 0.9901257919541983\n",
      "8 fold: ls 0.06377519658195129 0.07419723655090384 auc 0.9925907461751742 0.9894375431430503\n",
      "9 fold: ls 0.06749342302144092 0.0774300015616834 auc 0.9914338783426797 0.9877185077775698\n",
      "toxic 0.075 0.4 4\n",
      "this class avg train 0.06560107914128001 avg val 0.07526007392166527\n",
      "this class auc train 0.9920551125253325 auc val 0.9884550114456552\n",
      "========================\n",
      "0 fold: ls 0.016540638391540834 0.021321308081284008 auc 0.9955041290686165 0.9910467305988099\n",
      "1 fold: ls 0.016488145522810138 0.020507808506189683 auc 0.995569689523507 0.9917125585517155\n",
      "2 fold: ls 0.016731286147665166 0.021003384486805863 auc 0.995382808407756 0.9914617356627421\n",
      "3 fold: ls 0.016514738580711254 0.01977000064297982 auc 0.9955335175620019 0.9926901348271935\n",
      "4 fold: ls 0.016335231528680563 0.02123561931854235 auc 0.9956502848689011 0.9910293233320673\n",
      "5 fold: ls 0.015901936081957037 0.019831721764680007 auc 0.9960226060933232 0.9923539401930506\n",
      "6 fold: ls 0.016452829538702418 0.01913202512584497 auc 0.9956003173527127 0.9929311472642485\n",
      "7 fold: ls 0.015015054825729738 0.020127990614325252 auc 0.9967016596306343 0.9921611578983829\n",
      "8 fold: ls 0.016623362297362863 0.02126312809108518 auc 0.9954517933678526 0.9910276730356015\n",
      "9 fold: ls 0.0153321507266278 0.019120377695387818 auc 0.9965435798386753 0.9930235141375063\n",
      "severe_toxic 0.075 0.4 4\n",
      "this class avg train 0.016193537364178782 avg val 0.020331336432712496\n",
      "this class auc train 0.9957960385713982 auc val 0.9919437915501318\n",
      "========================\n",
      "0 fold: ls 0.034271317076253985 0.03712578779183704 auc 0.996507766321232 0.9957404123649178\n",
      "1 fold: ls 0.03185850732080625 0.03703944881554967 auc 0.9970020709555653 0.9955249937649195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 fold: ls 0.03205555753515958 0.039199960227586886 auc 0.9969475499623852 0.9953255534220229\n",
      "3 fold: ls 0.03420541777880034 0.03400154791465471 auc 0.9965055855038353 0.9964713962179043\n",
      "4 fold: ls 0.03355764637581773 0.042098294235386885 auc 0.9966525189359123 0.9945379822767125\n",
      "5 fold: ls 0.03135351755001003 0.037756127784878066 auc 0.9970974846900085 0.9955298661512776\n",
      "6 fold: ls 0.03432763707179457 0.03739669567255683 auc 0.9964916010523255 0.9954819399763815\n",
      "7 fold: ls 0.032686551111762156 0.03829958173382139 auc 0.9968221583677686 0.9955135775166724\n",
      "8 fold: ls 0.03369929889903022 0.03891375548836076 auc 0.9966152343170609 0.9951164637374272\n",
      "9 fold: ls 0.03104298927861889 0.038840849506296675 auc 0.9971561963600445 0.9952331438685931\n",
      "obscene 0.075 0.4 4\n",
      "this class avg train 0.032905843999805375 avg val 0.038067204917092895\n",
      "this class auc train 0.9967798166466137 auc val 0.9954475329296828\n",
      "========================\n",
      "0 fold: ls 0.0036958800651039343 0.006830283842789769 auc 0.9994455136206407 0.9967617326628955\n",
      "1 fold: ls 0.0039509082185859995 0.00621353979084199 auc 0.9993273285496247 0.9967486381730568\n",
      "2 fold: ls 0.004295404118786092 0.007425949240646108 auc 0.9990671557247685 0.994808034778965\n",
      "3 fold: ls 0.004055248310964135 0.006526147387191119 auc 0.9992895951736845 0.9914003080017599\n",
      "4 fold: ls 0.003853731342028167 0.006849789981501106 auc 0.999384772756213 0.9961879544073585\n",
      "5 fold: ls 0.003976525991094072 0.007056824113265014 auc 0.9992936312878924 0.9958370000209525\n",
      "6 fold: ls 0.003792866784537535 0.006308719380982788 auc 0.9994017942760917 0.9947906845181973\n",
      "7 fold: ls 0.003914789003249099 0.007650444044533414 auc 0.9993349913073306 0.9954781884467911\n",
      "8 fold: ls 0.004148998419400058 0.007075624900951024 auc 0.9991846196505643 0.9941716384275996\n",
      "9 fold: ls 0.0042196017337805085 0.0076209861681666305 auc 0.9990734991842144 0.9904964806485823\n",
      "threat 0.075 0.4 4\n",
      "this class avg train 0.003990395398752959 avg val 0.006955830885086896\n",
      "this class auc train 0.9992802901531025 auc val 0.9946680660086159\n",
      "========================\n",
      "0 fold: ls 0.0490886214086416 0.05004723728119092 auc 0.9921131240750358 0.991406613373309\n",
      "1 fold: ls 0.047058329625377496 0.05398006609913104 auc 0.9928396289942901 0.9898155088355658\n",
      "2 fold: ls 0.04952647696676915 0.05498373166679226 auc 0.9919656496467795 0.9888337421239489\n",
      "3 fold: ls 0.04807866554523642 0.05197774417662616 auc 0.9924893154258294 0.990487336414042\n",
      "4 fold: ls 0.048991017122879274 0.055222602099566594 auc 0.9921677495191605 0.989029857513972\n",
      "5 fold: ls 0.046610234311700235 0.05257885894069444 auc 0.9930030848270747 0.9904332506886038\n",
      "6 fold: ls 0.0459216574415277 0.05650606853842974 auc 0.9932348574429555 0.9890449162782899\n",
      "7 fold: ls 0.048328868616411814 0.055481654317200486 auc 0.9923753782753408 0.9894876052552508\n",
      "8 fold: ls 0.0476132367713897 0.05213003468739784 auc 0.9926511194005758 0.9904816576105735\n",
      "9 fold: ls 0.04815915813914342 0.05466044408450728 auc 0.9924536313270482 0.9892417517402199\n",
      "insult 0.075 0.4 4\n",
      "this class avg train 0.04793762659490768 avg val 0.05375684418915368\n",
      "this class auc train 0.992529353893409 auc val 0.9898262239833775\n",
      "========================\n",
      "0 fold: ls 0.013146093180986591 0.017219670119408968 auc 0.9968411397251417 0.992733377365318\n",
      "1 fold: ls 0.013340111136842522 0.017992898329297093 auc 0.9967093211629716 0.990817851517153\n",
      "2 fold: ls 0.01201863209430831 0.01794711799985472 auc 0.9975529810802848 0.992029403680482\n",
      "3 fold: ls 0.0127876518098759 0.018189713625207854 auc 0.9970590449564544 0.989488820942724\n",
      "4 fold: ls 0.013607617281102503 0.018900231146865308 auc 0.9964986548926683 0.9887115353486711\n",
      "5 fold: ls 0.013274196018692563 0.016467175273232586 auc 0.996758015295981 0.9934956963122861\n",
      "6 fold: ls 0.012539599302108562 0.016516658305902366 auc 0.9972532684706598 0.9909323289255004\n",
      "7 fold: ls 0.014075137532499447 0.018909582090360935 auc 0.9962310010815074 0.9893595545198353\n",
      "8 fold: ls 0.012888722970829582 0.01683054133455585 auc 0.9970304612996692 0.9926358479658934\n",
      "9 fold: ls 0.013581075825801855 0.016989038639364705 auc 0.9965674539873468 0.9916725377556181\n",
      "identity_hate 0.075 0.4 4\n",
      "this class avg train 0.013125883715304782 avg val 0.017596262686405042\n",
      "this class auc train 0.9968501341952685 auc val 0.991187695433348\n",
      "========================\n",
      "all loss avg 0.029959061035704934 0.035327925505352714\n",
      "all auc avg 0.9955484576641875 0.9919213868918019\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 4 feature fraction 0.5\n",
      "0 fold: ls 0.06609160354977195 0.07806065847257103 auc 0.9919177369701789 0.9870840739955533\n",
      "1 fold: ls 0.06714806461937545 0.07152068440027999 auc 0.9916266526592937 0.9898226215909153\n",
      "2 fold: ls 0.06816594826725636 0.07602299624985576 auc 0.9912652779089575 0.9883851026779809\n",
      "3 fold: ls 0.06525654198153714 0.07351596711909317 auc 0.9921720279909595 0.9888624787314428\n",
      "4 fold: ls 0.0667595481801262 0.07858380055761477 auc 0.991675868656929 0.9876238032181811\n",
      "5 fold: ls 0.0666189648450391 0.07647622425467 auc 0.9917963173167664 0.9876156438057456\n",
      "6 fold: ls 0.06334450327179836 0.07830552013431955 auc 0.9927224636237274 0.9874188659758485\n",
      "7 fold: ls 0.06643613988299754 0.07101008011864134 auc 0.9918296920040043 0.9900116429286108\n",
      "8 fold: ls 0.06641458061608872 0.07419745813143126 auc 0.9918304965311758 0.989381783293379\n",
      "9 fold: ls 0.06803579358867975 0.07782337498717376 auc 0.9912652003813951 0.9875706308429126\n",
      "toxic 0.075 0.5 4\n",
      "this class avg train 0.06642716888026705 avg val 0.07555167644256507\n",
      "this class auc train 0.9918101734043387 auc val 0.9883776647060568\n",
      "========================\n",
      "0 fold: ls 0.016405880164499995 0.021334433758357967 auc 0.995611669584522 0.9910040036713509\n",
      "1 fold: ls 0.01595693937999674 0.020612787411079782 auc 0.9959598271646825 0.9917699234080264\n",
      "2 fold: ls 0.01671972735413536 0.021082336659048486 auc 0.9954098981680862 0.9912690688694771\n",
      "3 fold: ls 0.016559183172225656 0.01980946470941503 auc 0.9954903048115129 0.9926715407013547\n",
      "4 fold: ls 0.016447511526780333 0.021156470645993165 auc 0.9955983673211718 0.991144448664388\n",
      "5 fold: ls 0.015552446882219755 0.019756263965687536 auc 0.9962960236082111 0.9924638179659714\n",
      "6 fold: ls 0.01654798036047516 0.019143088431354562 auc 0.9955298806218635 0.9929785251001005\n",
      "7 fold: ls 0.016200309740268894 0.02012291891782114 auc 0.9957791128218243 0.9921615560314572\n",
      "8 fold: ls 0.016654160256527595 0.021369835409533734 auc 0.9954290622039647 0.9909177883070706\n",
      "9 fold: ls 0.01603711437176244 0.01898020709972597 auc 0.9959652110630444 0.9931620644473933\n",
      "severe_toxic 0.075 0.5 4\n",
      "this class avg train 0.016308125320889193 avg val 0.02033678070080174\n",
      "this class auc train 0.9957069357368884 auc val 0.9919542737166589\n",
      "========================\n",
      "0 fold: ls 0.03288889205143138 0.03725288095241464 auc 0.9967779985194454 0.9956072929101752\n",
      "1 fold: ls 0.034018208449639285 0.03698524821780402 auc 0.9965493390180042 0.9955116035138838\n",
      "2 fold: ls 0.03224490572450762 0.03892335393206173 auc 0.9969073022410202 0.9953874189092253\n",
      "3 fold: ls 0.03367962404556918 0.034119162636288315 auc 0.9966155297087456 0.9964087476232689\n",
      "4 fold: ls 0.033250555679908034 0.04205438727810622 auc 0.9967080772289039 0.9945020376455406\n",
      "5 fold: ls 0.03272870448735164 0.037828923671715246 auc 0.9968085703502709 0.995506059685316\n",
      "6 fold: ls 0.034473737988242735 0.03761150993589293 auc 0.9964723420946281 0.9954050388264666\n",
      "7 fold: ls 0.03357714905749301 0.03835514272968437 auc 0.9966369197409867 0.9955251675066799\n",
      "8 fold: ls 0.03342252908810424 0.03885668643725306 auc 0.99667538931077 0.9951649380875263\n",
      "9 fold: ls 0.03127845077241431 0.03877868093320041 auc 0.9971119789940804 0.9952745409316597\n",
      "obscene 0.075 0.5 4\n",
      "this class avg train 0.03315627573446615 avg val 0.03807659767244209\n",
      "this class auc train 0.9967263447206856 auc val 0.9954292845639742\n",
      "========================\n",
      "0 fold: ls 0.0037849972127015825 0.006729445222364536 auc 0.9994195913539821 0.9968036350303793\n",
      "1 fold: ls 0.0038779738740813067 0.0062675270230870325 auc 0.9993879275326468 0.9967237586423633\n",
      "2 fold: ls 0.0038574681235186655 0.007447606492739607 auc 0.9993794410763003 0.9944296040226273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold: ls 0.004243084901703566 0.006614018390508404 auc 0.9992046012676484 0.9916517380099313\n",
      "4 fold: ls 0.0041577372443671184 0.006742590776972027 auc 0.9992149473632237 0.9962809311291304\n",
      "5 fold: ls 0.003852628818361974 0.007007071731492735 auc 0.9993686932670144 0.9960425964338845\n",
      "6 fold: ls 0.003724607362743395 0.00638623183367754 auc 0.9994299252612349 0.9943546105977749\n",
      "7 fold: ls 0.00411641667304455 0.007636264306235014 auc 0.9992056732335949 0.9954559264148177\n",
      "8 fold: ls 0.004089325784215237 0.007100953024221226 auc 0.9992176276549326 0.9936059209092137\n",
      "9 fold: ls 0.004251305090536355 0.007520533655341987 auc 0.9991096832164944 0.9906496122227082\n",
      "threat 0.075 0.5 4\n",
      "this class avg train 0.003995554508527375 avg val 0.00694522424566401\n",
      "this class auc train 0.9992938111227072 auc val 0.9945998333412829\n",
      "========================\n",
      "0 fold: ls 0.04868122179519886 0.050178694537088814 auc 0.9922524678477054 0.9913614400583572\n",
      "1 fold: ls 0.04803293462770985 0.05390630820152473 auc 0.9925012716948757 0.9898408560845109\n",
      "2 fold: ls 0.049267611855588055 0.05514907011819915 auc 0.9920613147812954 0.9889602274058136\n",
      "3 fold: ls 0.048542648131584515 0.05214134626115801 auc 0.992309955891364 0.9904147244929714\n",
      "4 fold: ls 0.0488221438273527 0.05532264835608459 auc 0.9922140217961245 0.9889246134833499\n",
      "5 fold: ls 0.04836338565495194 0.05279794908863773 auc 0.9923841402335115 0.9903138681514831\n",
      "6 fold: ls 0.04767141317529112 0.05633230326324427 auc 0.9926103849946746 0.9890816429312654\n",
      "7 fold: ls 0.0457366865969783 0.05547221695713317 auc 0.9932850413329651 0.9895057824998035\n",
      "8 fold: ls 0.04788182969167283 0.05243293920395222 auc 0.9925535122883149 0.990410623954442\n",
      "9 fold: ls 0.04839686998018637 0.05474825552067629 auc 0.9923619541981105 0.989199366091632\n",
      "insult 0.075 0.5 4\n",
      "this class avg train 0.04813967453365146 avg val 0.053848173150769896\n",
      "this class auc train 0.9924534065058939 auc val 0.989801314515363\n",
      "========================\n",
      "0 fold: ls 0.012538983559935813 0.017142867132782888 auc 0.9972221619515806 0.9927275482838512\n",
      "1 fold: ls 0.014100092633528783 0.01805917062213467 auc 0.9961478112138548 0.9910868860463897\n",
      "2 fold: ls 0.012671607716465286 0.01799940770605604 auc 0.9971658731246283 0.9918576699726526\n",
      "3 fold: ls 0.013706777951918051 0.01832887147331571 auc 0.9964465399311426 0.9885543743445087\n",
      "4 fold: ls 0.013803818584785212 0.018996983383540937 auc 0.9964087139283547 0.9880470200614564\n",
      "5 fold: ls 0.01337539892750126 0.01663793093853135 auc 0.9967200914681189 0.9932649319448333\n",
      "6 fold: ls 0.01302999143687004 0.016614023192993405 auc 0.9968748769594511 0.98985385504733\n",
      "7 fold: ls 0.013682450269456164 0.01888511102406119 auc 0.996484937337826 0.9890260315051667\n",
      "8 fold: ls 0.011967320226225917 0.01680698601252312 auc 0.9975791006690352 0.9929542416359564\n",
      "9 fold: ls 0.012878611340006473 0.016939376835420294 auc 0.997058996988717 0.9916287303995953\n",
      "identity_hate 0.075 0.5 4\n",
      "this class avg train 0.013175505264669301 avg val 0.017641072832135958\n",
      "this class auc train 0.9968109103572708 auc val 0.990900128924174\n",
      "========================\n",
      "all loss avg 0.03020038404041175 0.03539992084072979\n",
      "all auc avg 0.9954669303079642 0.9918437499612516\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 4 feature fraction 0.6\n",
      "0 fold: ls 0.06724235681103982 0.07812967305033981 auc 0.9915744893154447 0.9870177088486258\n",
      "1 fold: ls 0.06534965505794602 0.07177783227140373 auc 0.9921725184114947 0.9895987015081422\n",
      "2 fold: ls 0.06717853032008385 0.07592873194966972 auc 0.991565704828958 0.9883745476750907\n",
      "3 fold: ls 0.06594962434720983 0.07344984368453451 auc 0.9919502843318944 0.9888275067905361\n",
      "4 fold: ls 0.06266191610187079 0.07788315138677246 auc 0.9929023403324575 0.987861514100462\n",
      "5 fold: ls 0.06671976061005037 0.07665053743277403 auc 0.9917758758470961 0.9875766599463329\n",
      "6 fold: ls 0.06679091616945156 0.07794372828330333 auc 0.9917030459955 0.9875107046958144\n",
      "7 fold: ls 0.06636125830638824 0.07110807205103761 auc 0.991834357478333 0.9900271922200232\n",
      "8 fold: ls 0.06636239527563133 0.07406068068535479 auc 0.9918237100815284 0.9894428924619619\n",
      "9 fold: ls 0.06586464203872304 0.07771365308080033 auc 0.9919306123288193 0.9876269346911175\n",
      "toxic 0.075 0.6 4\n",
      "this class avg train 0.06604810550383948 avg val 0.07546459038759903\n",
      "this class auc train 0.9919232938951525 auc val 0.9883864362938107\n",
      "========================\n",
      "0 fold: ls 0.015956423348270913 0.021335064944805155 auc 0.9959701347033063 0.9910138941638182\n",
      "1 fold: ls 0.016366719693574623 0.02065126530551105 auc 0.9956426779740154 0.9916571717938979\n",
      "2 fold: ls 0.016332151461004172 0.021003513505651446 auc 0.9957027905786058 0.9913280162045829\n",
      "3 fold: ls 0.01484605834787919 0.019914034087195536 auc 0.9968454103981058 0.9926054722116724\n",
      "4 fold: ls 0.01663079594644276 0.02138098874280181 auc 0.9954672072005926 0.9909359570831751\n",
      "5 fold: ls 0.01598431435033682 0.019695166163776704 auc 0.9959476235818956 0.9924888987619642\n",
      "6 fold: ls 0.01668021628849681 0.019222321187264947 auc 0.9954504954237824 0.992929554731951\n",
      "7 fold: ls 0.014392292518309945 0.01991268428852612 auc 0.997178267142202 0.9923486785764194\n",
      "8 fold: ls 0.016662333435402864 0.021372084450237687 auc 0.9954319862515495 0.9909134088432523\n",
      "9 fold: ls 0.016813998207217316 0.018938578634780504 auc 0.9953572393668064 0.9932389041307501\n",
      "severe_toxic 0.075 0.6 4\n",
      "this class avg train 0.01606653035969354 avg val 0.020342570131055095\n",
      "this class auc train 0.995899383262086 auc val 0.9919459956501484\n",
      "========================\n",
      "0 fold: ls 0.03381177790150515 0.03731825557290372 auc 0.9965910393481286 0.9956066664656824\n",
      "1 fold: ls 0.03395347122851591 0.037027100258779824 auc 0.9965695863088616 0.9955332941544506\n",
      "2 fold: ls 0.032255916301924425 0.0390748147511284 auc 0.9969077450868192 0.9953556247474479\n",
      "3 fold: ls 0.03286455255131168 0.03390565852077752 auc 0.9967854596977254 0.9964066332332001\n",
      "4 fold: ls 0.03296325852819667 0.04195276221625999 auc 0.9967623055341299 0.9945476144981378\n",
      "5 fold: ls 0.03318455804257978 0.03766550403270246 auc 0.9967091804757525 0.9955550822106183\n",
      "6 fold: ls 0.03410370198577091 0.03761796629809698 auc 0.9965369676070095 0.9952673685397553\n",
      "7 fold: ls 0.03387866032511722 0.038151364458222856 auc 0.9965853939554294 0.99559838805166\n",
      "8 fold: ls 0.03361510521700528 0.03893259181834083 auc 0.9966377082579061 0.9951292283885842\n",
      "9 fold: ls 0.03258101692873006 0.038826863037710796 auc 0.9968421927826496 0.9952505494519279\n",
      "obscene 0.075 0.6 4\n",
      "this class avg train 0.0333212019010657 avg val 0.03804728809649234\n",
      "this class auc train 0.9966927579054412 auc val 0.9954250449741465\n",
      "========================\n",
      "0 fold: ls 0.0038189816197351976 0.0067268957089499214 auc 0.9993885366084613 0.996687094070815\n",
      "1 fold: ls 0.00372614001331268 0.0062784145449125426 auc 0.9994492574066461 0.9968756547244919\n",
      "2 fold: ls 0.003886487511390008 0.0073815877218578905 auc 0.9993599019241761 0.9944846008799497\n",
      "3 fold: ls 0.004352179736931002 0.006595854183756574 auc 0.9991473729038193 0.9918665011419113\n",
      "4 fold: ls 0.004074531207904193 0.006589282819167416 auc 0.9992710225515647 0.9964498606658705\n",
      "5 fold: ls 0.00393191044301733 0.007112656231511235 auc 0.9993400506617601 0.9959155718985062\n",
      "6 fold: ls 0.0036341699671678753 0.006283987736213136 auc 0.999483336776618 0.9950329478073208\n",
      "7 fold: ls 0.00397420371705901 0.007768946962434256 auc 0.9992975780716046 0.9952568776583486\n",
      "8 fold: ls 0.0033615636949797393 0.0070346221972817265 auc 0.9995972845220622 0.9946637992946586\n",
      "9 fold: ls 0.004177367995985432 0.007671810087366028 auc 0.9991369711297766 0.9902637741516578\n",
      "threat 0.075 0.6 4\n",
      "this class avg train 0.0038937535907482466 avg val 0.006944405819345073\n",
      "this class auc train 0.9993471312556487 auc val 0.994749668229353\n",
      "========================\n",
      "0 fold: ls 0.047549363760413084 0.05029703538725029 auc 0.9926642309458484 0.9912489250424128\n",
      "1 fold: ls 0.047711984363687066 0.053915701711633575 auc 0.9926087179623186 0.9898701350849425\n",
      "2 fold: ls 0.04922256155213863 0.05525286878668848 auc 0.992083649544438 0.988622933320841\n",
      "3 fold: ls 0.04895854730585025 0.05208073486700845 auc 0.9921722673875026 0.9904634949422617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 fold: ls 0.04906175569002327 0.05538255397868476 auc 0.9921445655931496 0.9889894498297189\n",
      "5 fold: ls 0.04732577879850735 0.052616517580792485 auc 0.9927620600289375 0.9903700875382702\n",
      "6 fold: ls 0.04714915509885523 0.05636839477573091 auc 0.9927965962053757 0.9890780455597895\n",
      "7 fold: ls 0.04770373880017654 0.05565706785162574 auc 0.9926041309978773 0.9894467273965336\n",
      "8 fold: ls 0.0479588478005031 0.05244785736044169 auc 0.9925249512571385 0.9903615370175396\n",
      "9 fold: ls 0.048762506051208764 0.054680146101464655 auc 0.9922361285267065 0.9892831321955606\n",
      "insult 0.075 0.6 4\n",
      "this class avg train 0.04814042392213633 avg val 0.0538698878401321\n",
      "this class auc train 0.9924597298449293 auc val 0.9897734467927872\n",
      "========================\n",
      "0 fold: ls 0.01321070400361695 0.017166885989177913 auc 0.9967830307371676 0.9927602808182416\n",
      "1 fold: ls 0.014246445075526703 0.018091283431349196 auc 0.9960170819694258 0.9910685020202251\n",
      "2 fold: ls 0.013356461675451054 0.018084146922217607 auc 0.9966845419632315 0.9917684401871225\n",
      "3 fold: ls 0.012404857969245826 0.018409019055591894 auc 0.9973077845491349 0.9883221078676009\n",
      "4 fold: ls 0.013612884433371985 0.018847626515448888 auc 0.9964952257648811 0.9888565897990178\n",
      "5 fold: ls 0.013523935956196978 0.016475061101268042 auc 0.9966023687759337 0.9935033734047454\n",
      "6 fold: ls 0.013101417796979951 0.016459691094670544 auc 0.9968546823436638 0.9909490389479009\n",
      "7 fold: ls 0.013971902994905914 0.018701491066728797 auc 0.9963011977103697 0.9897662403352843\n",
      "8 fold: ls 0.011017397263476046 0.01665332958038904 auc 0.9981392076258068 0.9930386949924128\n",
      "9 fold: ls 0.013902196922592642 0.01692600196530897 auc 0.99635005574136 0.9916874412891106\n",
      "identity_hate 0.075 0.6 4\n",
      "this class avg train 0.013234820409136405 avg val 0.01758145367221509\n",
      "this class auc train 0.9967535177180975 auc val 0.9911720709661662\n",
      "========================\n",
      "all loss avg 0.030117472614436615 0.03537503265780645\n",
      "all auc avg 0.9955126356468925 0.9919087771510687\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 3 feature fraction 0.4\n",
      "0 fold: ls 0.07056951763620127 0.07837469046063279 auc 0.9904318117060698 0.9869300977945933\n",
      "1 fold: ls 0.0704102889862547 0.07143925377540922 auc 0.9904609473858519 0.9898366194273662\n",
      "2 fold: ls 0.06938634457105818 0.07585168777822719 auc 0.9907993218886716 0.9884332570473898\n",
      "3 fold: ls 0.06766208741156768 0.07319205597563908 auc 0.9913545920771062 0.9890791507435613\n",
      "4 fold: ls 0.06720758979796919 0.07806455541153383 auc 0.9915172234047362 0.9877700833511178\n",
      "5 fold: ls 0.06761592518928848 0.07648443799307708 auc 0.9914375029878022 0.987583096816143\n",
      "6 fold: ls 0.0696185707308287 0.07793032603588217 auc 0.9906838197097008 0.9875999142717733\n",
      "7 fold: ls 0.07079164012020081 0.07081040791505225 auc 0.9903061858096904 0.990079234746383\n",
      "8 fold: ls 0.06906701346390874 0.07430190975768253 auc 0.9908828407306148 0.9893919379326687\n",
      "9 fold: ls 0.06908360960211166 0.07780264468767613 auc 0.9908360746515056 0.9875806041493579\n",
      "toxic 0.05 0.4 3\n",
      "this class avg train 0.06914125875093895 avg val 0.07542519697908122\n",
      "this class auc train 0.990871032035175 auc val 0.9884283996280354\n",
      "========================\n",
      "0 fold: ls 0.018017587368754747 0.021161899377905184 auc 0.994150616420708 0.9911440530446891\n",
      "1 fold: ls 0.01783245155079553 0.02052201799822376 auc 0.9942993258242367 0.9917620110140524\n",
      "2 fold: ls 0.01805362630875031 0.02108675339955462 auc 0.994151001176667 0.9913133782757311\n",
      "3 fold: ls 0.018031189604010726 0.019804011089447755 auc 0.9941480334093646 0.992592812381314\n",
      "4 fold: ls 0.01688688870782839 0.021080233793066266 auc 0.9951414438876565 0.9909723540954551\n",
      "5 fold: ls 0.017131616351787064 0.01986808554629004 auc 0.9949262127810206 0.9923455799277194\n",
      "6 fold: ls 0.018153891273046476 0.019122419989540427 auc 0.9940544953523905 0.9929793213662494\n",
      "7 fold: ls 0.01679380576589617 0.020077466369814702 auc 0.9952320734773094 0.9922089338673095\n",
      "8 fold: ls 0.017108536923446882 0.02097463049040317 auc 0.9949402025901636 0.9912414704965475\n",
      "9 fold: ls 0.01828519024200673 0.01898699888842632 auc 0.9939447039777489 0.9931497223220872\n",
      "severe_toxic 0.05 0.4 3\n",
      "this class avg train 0.017629478409632304 avg val 0.020268451694267227\n",
      "this class auc train 0.9944988108897267 auc val 0.9919709636791154\n",
      "========================\n",
      "0 fold: ls 0.03497548208203579 0.03721199623531843 auc 0.996296568899506 0.995635482912356\n",
      "1 fold: ls 0.03570960313118609 0.0369494949496091 auc 0.996139060640729 0.9955552197117025\n",
      "2 fold: ls 0.03486581372870308 0.03914510215602867 auc 0.996317938298701 0.9953350290219615\n",
      "3 fold: ls 0.03559774030878055 0.03393941380595931 auc 0.9961615445974147 0.9964700649352684\n",
      "4 fold: ls 0.03510422556757808 0.04192461445813625 auc 0.9962783239048433 0.994547379565908\n",
      "5 fold: ls 0.03542546163131076 0.037469223852200965 auc 0.99619488276402 0.9956235258002575\n",
      "6 fold: ls 0.033105829027861126 0.03725175191568601 auc 0.9967107376878909 0.9953900814744974\n",
      "7 fold: ls 0.035546546830750606 0.03838503211152426 auc 0.9961686001559203 0.9955170231893773\n",
      "8 fold: ls 0.03542713585608593 0.038794960951923425 auc 0.9962163438643096 0.995193051644369\n",
      "9 fold: ls 0.03518542495294952 0.039073736575007026 auc 0.9962548732614848 0.9952287532709952\n",
      "obscene 0.05 0.4 3\n",
      "this class avg train 0.03509432631172415 avg val 0.038014532701139345\n",
      "this class auc train 0.9962738874074819 auc val 0.9954495611526692\n",
      "========================\n",
      "0 fold: ls 0.00506762409476767 0.006640865536967374 auc 0.9984918145895259 0.9966844751728472\n",
      "1 fold: ls 0.005033593723057275 0.006302319091695864 auc 0.9985895265921688 0.9967368531322021\n",
      "2 fold: ls 0.004897357503643501 0.007287254792768902 auc 0.9986577918094408 0.9943994866959983\n",
      "3 fold: ls 0.005207643454222019 0.006570279516415062 auc 0.9984710760848944 0.9908954836884782\n",
      "4 fold: ls 0.0048588260827097714 0.006755934862437735 auc 0.9987105873853646 0.9962390261277684\n",
      "5 fold: ls 0.00496205086161433 0.00688319115266074 auc 0.9985959844805318 0.9963870031638277\n",
      "6 fold: ls 0.0048976576274675915 0.006356087900793757 auc 0.9986503136637328 0.9947631843610535\n",
      "7 fold: ls 0.005123194881846145 0.007551330292760838 auc 0.9983932448604106 0.995541045948834\n",
      "8 fold: ls 0.004815352464711284 0.006980800303370831 auc 0.9987113104705991 0.9945206981729865\n",
      "9 fold: ls 0.005089412053077975 0.007553732365685261 auc 0.9984669912826459 0.9907880324665685\n",
      "threat 0.05 0.4 3\n",
      "this class avg train 0.004995271274711756 avg val 0.0068881795815556365\n",
      "this class auc train 0.9985738641219314 auc val 0.9946955288930563\n",
      "========================\n",
      "0 fold: ls 0.049340827492490164 0.050053043378342175 auc 0.9919507439614956 0.9913775016814511\n",
      "1 fold: ls 0.05119716280177411 0.053825041986922166 auc 0.9912162582081132 0.9898883717194972\n",
      "2 fold: ls 0.05143376768775322 0.05520194336316133 auc 0.9911305928810406 0.9891327643726431\n",
      "3 fold: ls 0.04932843770984457 0.05181361973711916 auc 0.9919273852461753 0.9904578064507493\n",
      "4 fold: ls 0.04914372919911306 0.0553068152933952 auc 0.992023526239706 0.9890913474682704\n",
      "5 fold: ls 0.04925264918854865 0.05269415549761076 auc 0.9920099891951104 0.9902942080980679\n",
      "6 fold: ls 0.04867973681168139 0.05622416571338911 auc 0.9921846508058049 0.9891608687635384\n",
      "7 fold: ls 0.049930710431703246 0.05559831749332365 auc 0.9916961436254359 0.9894317332639303\n",
      "8 fold: ls 0.050919128731654544 0.05234784121456105 auc 0.9913264442905704 0.9904551875217321\n",
      "9 fold: ls 0.05115526149389137 0.05481887760812033 auc 0.9912371887436726 0.9892151141191705\n",
      "insult 0.05 0.4 3\n",
      "this class avg train 0.050038141154845436 avg val 0.05378838212859449\n",
      "this class auc train 0.9916702923197125 auc val 0.9898504903459051\n",
      "========================\n",
      "0 fold: ls 0.01453329553981296 0.017104803293573945 auc 0.9956997487055126 0.9927051287397481\n",
      "1 fold: ls 0.015617960194719296 0.01795009635844597 auc 0.9946720079842988 0.9910438405217117\n",
      "2 fold: ls 0.015033753705012778 0.0177429657802077 auc 0.9952257759966123 0.9921240141565969\n",
      "3 fold: ls 0.015459221288010895 0.018239478537209364 auc 0.9949050525091165 0.98976861685313\n",
      "4 fold: ls 0.014995142764813396 0.018873843871155975 auc 0.9953005832251648 0.9885790358430219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold: ls 0.015225525120347432 0.01648194753164859 auc 0.995075861122598 0.9935363397429529\n",
      "6 fold: ls 0.014929549026047869 0.01660500624739647 auc 0.9953149352136844 0.9904368993424381\n",
      "7 fold: ls 0.01530657321175264 0.018733163090437883 auc 0.9949995987732736 0.9881711106293809\n",
      "8 fold: ls 0.014983140549707242 0.016769288799966767 auc 0.9953577845620728 0.9929379832357829\n",
      "9 fold: ls 0.015187936719845115 0.016724422181596477 auc 0.9951386870028919 0.9919313172917118\n",
      "identity_hate 0.05 0.4 3\n",
      "this class avg train 0.01512720981200696 avg val 0.017522501569163913\n",
      "this class auc train 0.9951690035095228 auc val 0.9911234286356475\n",
      "========================\n",
      "all loss avg 0.03200428095230993 0.03531787410896697\n",
      "all auc avg 0.994509481713925 0.9919197287224049\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 3 feature fraction 0.5\n",
      "0 fold: ls 0.06849146334705691 0.07813722148395294 auc 0.991118156224512 0.9870697137555695\n",
      "1 fold: ls 0.06922922958231303 0.07134048396590319 auc 0.9908736179420566 0.9898532446894293\n",
      "2 fold: ls 0.06669423696929605 0.07574200372432176 auc 0.991691250527693 0.9884068468899434\n",
      "3 fold: ls 0.06840455229077352 0.07324773939758118 auc 0.9911478808006013 0.9890171344390266\n",
      "4 fold: ls 0.06686920174038494 0.0781075497338538 auc 0.9916224024352722 0.9878030836414115\n",
      "5 fold: ls 0.06455351215202035 0.0762870286976564 auc 0.9923976173313516 0.9876515905505301\n",
      "6 fold: ls 0.06803441802533583 0.07776232606327961 auc 0.9912473035788641 0.987641935245815\n",
      "7 fold: ls 0.06909008400122273 0.07101894945332227 auc 0.9908956001511147 0.9900097842669549\n",
      "8 fold: ls 0.06938740386567625 0.07413784294171498 auc 0.9907705084843907 0.9894982896459446\n",
      "9 fold: ls 0.06665717322439152 0.07773941690571737 auc 0.9916413559975388 0.9876506439605305\n",
      "toxic 0.05 0.5 3\n",
      "this class avg train 0.06774112751984711 avg val 0.07535205623673034\n",
      "this class auc train 0.9913405693473395 auc val 0.9884602267085155\n",
      "========================\n",
      "0 fold: ls 0.017856382341255778 0.021196726810314488 auc 0.9942895990955637 0.9911361406507153\n",
      "1 fold: ls 0.01785518380553797 0.02051996456736083 auc 0.9942878885244845 0.991782187618686\n",
      "2 fold: ls 0.01805089903874209 0.021010373833904798 auc 0.9941588041255445 0.9913782599063173\n",
      "3 fold: ls 0.017835410956414686 0.019896634434861872 auc 0.9943213573915761 0.9925219964552475\n",
      "4 fold: ls 0.017737536760156936 0.02108722417384571 auc 0.9944172547510375 0.9910522692745918\n",
      "5 fold: ls 0.017308260768127057 0.019822727379304534 auc 0.9947753465378308 0.9923738455866956\n",
      "6 fold: ls 0.018088320477320494 0.019134359666873192 auc 0.9941311426231685 0.9929566277810092\n",
      "7 fold: ls 0.017426940383167975 0.020011354237614336 auc 0.9946864741160273 0.9922961250106003\n",
      "8 fold: ls 0.01736970995529232 0.02100718106272375 auc 0.9947174411023837 0.991220369443605\n",
      "9 fold: ls 0.01834291962599808 0.019010454286642452 auc 0.9939146822865079 0.9931501204551616\n",
      "severe_toxic 0.05 0.5 3\n",
      "this class avg train 0.01778715641120134 avg val 0.020269700045344594\n",
      "this class auc train 0.9943699990554125 auc val 0.9919867942182631\n",
      "========================\n",
      "0 fold: ls 0.03534927381096532 0.03721022448549603 auc 0.9962182929117283 0.9956688410816034\n",
      "1 fold: ls 0.035331722614698864 0.036854162529215154 auc 0.9962206140015899 0.9955754225465987\n",
      "2 fold: ls 0.03376200959593932 0.039116070120397604 auc 0.996563800871621 0.9953451311078464\n",
      "3 fold: ls 0.03593331527271625 0.034002173340205305 auc 0.99608795677562 0.9964704173336131\n",
      "4 fold: ls 0.03546903188129695 0.04221038475509438 auc 0.9962142475986058 0.9945045435893259\n",
      "5 fold: ls 0.0346738233501278 0.03742498721872806 auc 0.9963623688823512 0.9956468624017591\n",
      "6 fold: ls 0.03602363943844129 0.03777821751841174 auc 0.9960797336706025 0.9951757449701009\n",
      "7 fold: ls 0.034340841005918096 0.0384515249212199 auc 0.9964347524149696 0.9954984635432166\n",
      "8 fold: ls 0.034942631490302876 0.038928492140211345 auc 0.9963158550863122 0.995147553102515\n",
      "9 fold: ls 0.03511342901058562 0.03886548911195249 auc 0.9962694108087828 0.995296415516121\n",
      "obscene 0.05 0.5 3\n",
      "this class avg train 0.03509397174709924 avg val 0.0380841726140932\n",
      "this class auc train 0.9962767033022182 auc val 0.9954329395192699\n",
      "========================\n",
      "0 fold: ls 0.004979576949524014 0.006660664711768712 auc 0.9986072141538175 0.9965299601927509\n",
      "1 fold: ls 0.005019192495477189 0.0062458026280754735 auc 0.9985740966715386 0.9969463649696209\n",
      "2 fold: ls 0.004704456902732125 0.007349231500934095 auc 0.9988036938905148 0.9944086528388855\n",
      "3 fold: ls 0.0051724743798293605 0.006458114083420427 auc 0.9985017570496377 0.9918710845014352\n",
      "4 fold: ls 0.005038105532743746 0.006735459355959634 auc 0.9985196393906557 0.9964289081651896\n",
      "5 fold: ls 0.004995401138868495 0.006957797520026615 auc 0.9985536255837342 0.9962547405032791\n",
      "6 fold: ls 0.004976257508659203 0.006391105279797391 auc 0.9986079710088435 0.9949727093678631\n",
      "7 fold: ls 0.004972245685322977 0.007540442366200741 auc 0.9985622500370316 0.9955384268862489\n",
      "8 fold: ls 0.00517076483019247 0.007023609494936622 auc 0.9983312241915324 0.9942879916760619\n",
      "9 fold: ls 0.005277426072392981 0.007554961254324703 auc 0.9983169320659296 0.9900511285596403\n",
      "threat 0.05 0.5 3\n",
      "this class avg train 0.005030590149574256 avg val 0.006891718819544442\n",
      "this class auc train 0.9985378404043237 auc val 0.9947289967660975\n",
      "========================\n",
      "0 fold: ls 0.04847141863020415 0.050030477935659776 auc 0.9922970252662091 0.9913887113559021\n",
      "1 fold: ls 0.05038908153522791 0.05390830900113722 auc 0.9915099676795229 0.9898415253188065\n",
      "2 fold: ls 0.05158233290212519 0.055261820424148074 auc 0.9911049155494873 0.9891484913785891\n",
      "3 fold: ls 0.04894742972421192 0.0518743468336028 auc 0.9920842870605769 0.9904182379730231\n",
      "4 fold: ls 0.050057556687644375 0.05529354624601613 auc 0.9916785829390927 0.9890752011265295\n",
      "5 fold: ls 0.04800601502939368 0.05258494010317294 auc 0.9924674238226102 0.9903705058372791\n",
      "6 fold: ls 0.04968134382269554 0.056285096869868295 auc 0.9917848970174873 0.9891361891220172\n",
      "7 fold: ls 0.04741312357955504 0.05547330182972083 auc 0.9926548964073755 0.9894984110826576\n",
      "8 fold: ls 0.05085259086338667 0.052451854847341155 auc 0.9913508569161659 0.99046004595576\n",
      "9 fold: ls 0.051062158639625356 0.05485014633145953 auc 0.9912761194974288 0.9892173758039766\n",
      "insult 0.05 0.5 3\n",
      "this class avg train 0.049646305141406985 avg val 0.05380138404221267\n",
      "this class auc train 0.9918208972155955 auc val 0.9898554694954541\n",
      "========================\n",
      "0 fold: ls 0.014960286133489818 0.017105833997448708 auc 0.995296542745584 0.9926701542509473\n",
      "1 fold: ls 0.0147835576803484 0.017992431133207292 auc 0.9954664540822338 0.9905165328444079\n",
      "2 fold: ls 0.01518831791809636 0.01782366191482154 auc 0.9950808383807278 0.9919123736602641\n",
      "3 fold: ls 0.014391915671053109 0.018163077965105964 auc 0.9957988960720625 0.9893000483813761\n",
      "4 fold: ls 0.014743156186354191 0.018909996145474197 auc 0.995496599283398 0.988367395346689\n",
      "5 fold: ls 0.014858451113943108 0.016405468399400453 auc 0.9954156706154781 0.9934726650349082\n",
      "6 fold: ls 0.014956934460318672 0.01659710124697003 auc 0.9953309287496304 0.9900385685381892\n",
      "7 fold: ls 0.015133893971961696 0.018724885061670773 auc 0.9951554024692798 0.9886389912565937\n",
      "8 fold: ls 0.013144573219345167 0.016560971847177863 auc 0.9967603926746273 0.9930680504371703\n",
      "9 fold: ls 0.015071695258177696 0.016880358394184353 auc 0.9952458242571405 0.9916991834670135\n",
      "identity_hate 0.05 0.5 3\n",
      "this class avg train 0.014723278161308823 avg val 0.01751637861054612\n",
      "this class auc train 0.995504754933016 auc val 0.990968396321756\n",
      "========================\n",
      "all loss avg 0.031670404855072956 0.035319235061411894\n",
      "all auc avg 0.9946417940429843 0.9919054705048926\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 3 feature fraction 0.6\n",
      "0 fold: ls 0.07039966413629377 0.07846651320544207 auc 0.9905177872098321 0.9869306413998925\n",
      "1 fold: ls 0.07176226748500597 0.07152525370829216 auc 0.9900306208510913 0.9897737424144409\n",
      "2 fold: ls 0.0694205904215845 0.07597153774510206 auc 0.9907906470683856 0.9883714672450626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold: ls 0.0665333324130331 0.07302716424674889 auc 0.991738939658409 0.9891501365355311\n",
      "4 fold: ls 0.06816725795753126 0.07819660633695175 auc 0.9911647930312595 0.9877842263326724\n",
      "5 fold: ls 0.06980775600733378 0.07671841633335064 auc 0.9906886905494074 0.9876456523114799\n",
      "6 fold: ls 0.06925027616904056 0.07798349729060562 auc 0.9908400292622995 0.9875269781906159\n",
      "7 fold: ls 0.07158440763155928 0.07118364109136627 auc 0.9900607409622522 0.9899797283479856\n",
      "8 fold: ls 0.06991973579023937 0.07433905542779407 auc 0.9905886098142526 0.9893620633465439\n",
      "9 fold: ls 0.07021564971809863 0.07798751259156836 auc 0.9904586806341834 0.9874957403781506\n",
      "toxic 0.05 0.6 3\n",
      "this class avg train 0.06970609377297203 avg val 0.07553991979772219\n",
      "this class auc train 0.9906879539041373 auc val 0.9884020376502374\n",
      "========================\n",
      "0 fold: ls 0.017822169135592737 0.021269788641738945 auc 0.9943041266963633 0.9910617641473604\n",
      "1 fold: ls 0.017911115735389685 0.020538599537768817 auc 0.9942413109973594 0.9916615236105837\n",
      "2 fold: ls 0.018127007174932493 0.02104927859837903 auc 0.9941020710016395 0.9912789593619445\n",
      "3 fold: ls 0.018115065094719766 0.019858956912687558 auc 0.9940852789772333 0.9925251614128371\n",
      "4 fold: ls 0.017999217024915772 0.021123676375798723 auc 0.9941952015491403 0.9910289277123687\n",
      "5 fold: ls 0.018094610229561586 0.019907934882144717 auc 0.994104459018788 0.9923053710325564\n",
      "6 fold: ls 0.01794001996166928 0.019114565053781212 auc 0.9942483396258641 0.9929685717732409\n",
      "7 fold: ls 0.016904882346614383 0.0201237284197569 auc 0.995148980567299 0.9921623522976061\n",
      "8 fold: ls 0.018007112800940486 0.02106757623770655 auc 0.9941811355104352 0.9911622420147446\n",
      "9 fold: ls 0.018366640690702016 0.019006949840615028 auc 0.9938993836891354 0.9931827673672614\n",
      "severe_toxic 0.05 0.6 3\n",
      "this class avg train 0.017928784019503822 avg val 0.020306105450037748\n",
      "this class auc train 0.9942510287633258 auc val 0.9919337640730503\n",
      "========================\n",
      "0 fold: ls 0.03433123841426897 0.03716476968900027 auc 0.9964451844011669 0.9956523186081029\n",
      "1 fold: ls 0.035305511572140014 0.03694891850643251 auc 0.99623156339613 0.9955194340700452\n",
      "2 fold: ls 0.03401260476077235 0.03911046434145347 auc 0.996513148207803 0.9953490466450111\n",
      "3 fold: ls 0.0358143411946046 0.03395775810803268 auc 0.9961173064292972 0.9964780526310844\n",
      "4 fold: ls 0.035411609761827396 0.04220231416975015 auc 0.9962301866631785 0.9944903301894181\n",
      "5 fold: ls 0.03295366593183783 0.037498907916656984 auc 0.9967439883489398 0.9956172609407941\n",
      "6 fold: ls 0.03579196273235003 0.0376697666313018 auc 0.9961238649949193 0.9952302492474336\n",
      "7 fold: ls 0.035433675474805054 0.03839206346396674 auc 0.9961980576203107 0.9955123245447797\n",
      "8 fold: ls 0.03538248847221191 0.03882201649654812 auc 0.9962266990107831 0.9951867867849055\n",
      "9 fold: ls 0.03484127435991202 0.038906972618898986 auc 0.9963291015700059 0.995277363458687\n",
      "obscene 0.05 0.6 3\n",
      "this class avg train 0.03492783726747302 avg val 0.03806739519420417\n",
      "this class auc train 0.9963159100642534 auc val 0.9954313167120261\n",
      "========================\n",
      "0 fold: ls 0.004979347511870508 0.006606355894404364 auc 0.9985998402759586 0.9967381625811857\n",
      "1 fold: ls 0.004955427369155704 0.006294647775590027 auc 0.9986142875542747 0.9968219673161534\n",
      "2 fold: ls 0.0049772165145532165 0.0073990159496990495 auc 0.9985933840723263 0.9940681961030798\n",
      "3 fold: ls 0.005208104737463809 0.006635329533871397 auc 0.9984861485757797 0.9901405388983175\n",
      "4 fold: ls 0.004946238507096662 0.0066489690744236125 auc 0.9986329267009176 0.9964655750413812\n",
      "5 fold: ls 0.005031664785127921 0.006942649852086701 auc 0.9984931325963406 0.9959915247134745\n",
      "6 fold: ls 0.004863020644783148 0.006409071863363874 auc 0.9987001682012021 0.9949268757726234\n",
      "7 fold: ls 0.0052238532009930725 0.00757619301581666 auc 0.9982831734479882 0.995651046577409\n",
      "8 fold: ls 0.004793647566732829 0.006972988757653498 auc 0.9987033136860358 0.9945728565257455\n",
      "9 fold: ls 0.005082352403277548 0.007522729374879571 auc 0.9984667806277336 0.9898585438725305\n",
      "threat 0.05 0.6 3\n",
      "this class avg train 0.0050060873241054415 avg val 0.0069007951091788755\n",
      "this class auc train 0.9985573155738556 auc val 0.9945235287401901\n",
      "========================\n",
      "0 fold: ls 0.04990856957246007 0.050099197448356704 auc 0.991735059956006 0.99138411037012\n",
      "1 fold: ls 0.05069242760231274 0.053915391780364516 auc 0.9914133044241153 0.9898787514764982\n",
      "2 fold: ls 0.0516517053700313 0.055256071954229435 auc 0.9910784147165358 0.9890930704134865\n",
      "3 fold: ls 0.050902051846620916 0.05193720575181819 auc 0.9913391169706718 0.9904557987478627\n",
      "4 fold: ls 0.049730878838340674 0.05532983371002108 auc 0.9917972303329713 0.9890602260220133\n",
      "5 fold: ls 0.04804442724815778 0.052758202749005924 auc 0.9924630625002245 0.9903008172224075\n",
      "6 fold: ls 0.049813675542155975 0.05630494430431879 auc 0.9917315630352769 0.9891045657169494\n",
      "7 fold: ls 0.04945542214108037 0.055585992174453064 auc 0.9918849846675322 0.9894348326097756\n",
      "8 fold: ls 0.051592068517775695 0.052473457366623316 auc 0.9910657161475047 0.9901981931148784\n",
      "9 fold: ls 0.05104967286968634 0.05481762315481342 auc 0.9912820437987122 0.9892187160616395\n",
      "insult 0.05 0.6 3\n",
      "this class avg train 0.050284089954862186 avg val 0.05384779203940045\n",
      "this class auc train 0.9915790496549551 auc val 0.9898129081755631\n",
      "========================\n",
      "0 fold: ls 0.015247348919470898 0.01709942469506084 auc 0.995096855797718 0.9927270998929691\n",
      "1 fold: ls 0.01567984216512537 0.018023484654086215 auc 0.9945998462416894 0.9906967859789964\n",
      "2 fold: ls 0.014874892974464012 0.017828129789185517 auc 0.9953233922048067 0.9919321028590747\n",
      "3 fold: ls 0.014736034909302033 0.018205073465032036 auc 0.9955026266563076 0.98891801934986\n",
      "4 fold: ls 0.015021445718282546 0.01889474417002458 auc 0.9952778854003946 0.9887812601308315\n",
      "5 fold: ls 0.014955011898299097 0.016473419622376043 auc 0.9953489054638496 0.9933891202052042\n",
      "6 fold: ls 0.014980313014218753 0.01652387724609077 auc 0.9952952403958956 0.9899902449598961\n",
      "7 fold: ls 0.0148803439041313 0.018765609200191595 auc 0.9953826134159666 0.9877836187585809\n",
      "8 fold: ls 0.01293214169557291 0.01669784543799629 auc 0.9969255259332686 0.992858497723824\n",
      "9 fold: ls 0.015060525695090398 0.016923346900377213 auc 0.9952616067672649 0.9914656947756341\n",
      "identity_hate 0.05 0.6 3\n",
      "this class avg train 0.01483679008939573 avg val 0.01754349551804211\n",
      "this class auc train 0.9954014498277161 auc val 0.9908542444634871\n",
      "========================\n",
      "all loss avg 0.032114947071385375 0.03536758385143093\n",
      "all auc avg 0.9944654512980406 0.9918262999690923\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 4 feature fraction 0.4\n",
      "0 fold: ls 0.06691232326676365 0.07780399534436962 auc 0.9916889967753638 0.9872018551436841\n",
      "1 fold: ls 0.06784431015812813 0.07144853138361781 auc 0.9913659906477246 0.9898470385289315\n",
      "2 fold: ls 0.06477841770362731 0.07600056080519035 auc 0.9923142815591837 0.9883448758858501\n",
      "3 fold: ls 0.06664188258312889 0.07330917432839118 auc 0.9917314513033199 0.9890109735789705\n",
      "4 fold: ls 0.06517323173060012 0.078013548288811 auc 0.9921810929528173 0.9877868101466101\n",
      "5 fold: ls 0.06282984578932926 0.07622044149497496 auc 0.9929436101527602 0.9877006376852799\n",
      "6 fold: ls 0.06344178102385438 0.07762124057917091 auc 0.9927258635884526 0.9876991871230693\n",
      "7 fold: ls 0.06604402768109709 0.07078475265855964 auc 0.9919350710765908 0.9901229359618979\n",
      "8 fold: ls 0.0646583404162518 0.07395945990874625 auc 0.9923284742335207 0.9895006923061336\n",
      "9 fold: ls 0.06626154057080555 0.07759882215487013 auc 0.9918169278279544 0.9876580332739422\n",
      "toxic 0.05 0.4 4\n",
      "this class avg train 0.06545857009235863 avg val 0.0752760526946702\n",
      "this class auc train 0.9921031760117689 auc val 0.9884873039634368\n",
      "========================\n",
      "0 fold: ls 0.015584693873693033 0.021267650255484077 auc 0.996273067528886 0.9911238764400557\n",
      "1 fold: ls 0.01622833304749579 0.020684755583207086 auc 0.9957518702448025 0.9915744872768706\n",
      "2 fold: ls 0.016437326416117056 0.02132287318082637 auc 0.9956147182240958 0.9909945087985821\n",
      "3 fold: ls 0.016218774273544317 0.02008029421008604 auc 0.9957748232659035 0.992453554247373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 fold: ls 0.01654437499871801 0.021213404341519547 auc 0.9955255332631818 0.9910530605139891\n",
      "5 fold: ls 0.015864456927957824 0.01974344935655945 auc 0.9960539137040779 0.9924789460651416\n",
      "6 fold: ls 0.016746579200130687 0.019140144088081484 auc 0.9953838839545138 0.992980117632398\n",
      "7 fold: ls 0.015104627983725773 0.020148477082327556 auc 0.996656442197966 0.9921002435380016\n",
      "8 fold: ls 0.01617572175306264 0.02117403061046551 auc 0.995783871133765 0.9910650975445938\n",
      "9 fold: ls 0.01676547005493644 0.019020745927220875 auc 0.9953819541810658 0.9931628607135419\n",
      "severe_toxic 0.05 0.4 4\n",
      "this class avg train 0.016167035852938157 avg val 0.0203795824635778\n",
      "this class auc train 0.9958200077698258 auc val 0.9918986752770549\n",
      "========================\n",
      "0 fold: ls 0.03285726014331015 0.03711731370247829 auc 0.9967867563913145 0.9956462890798587\n",
      "1 fold: ls 0.03357447895290844 0.037057298069595915 auc 0.9966411707313872 0.9955063570412557\n",
      "2 fold: ls 0.028880456483688803 0.038674211891549376 auc 0.9976191265835459 0.9954366763667575\n",
      "3 fold: ls 0.03330532486510591 0.034053813098079616 auc 0.9966921405816116 0.996382121970549\n",
      "4 fold: ls 0.03270356977908835 0.04202435089983766 auc 0.996814841259506 0.9945167600652799\n",
      "5 fold: ls 0.033446130476534365 0.037911087233949446 auc 0.9966523903365864 0.9954898493614541\n",
      "6 fold: ls 0.0343000769046998 0.037412954102312886 auc 0.996503517278586 0.9953972860628804\n",
      "7 fold: ls 0.03326947522558224 0.03838757216960975 auc 0.9966939864170491 0.9955106800191704\n",
      "8 fold: ls 0.03247685693125721 0.0388128391207417 auc 0.9968699475210324 0.9952005694757252\n",
      "9 fold: ls 0.03264724317506897 0.03888461951399664 auc 0.9968268252503574 0.9952489813813573\n",
      "obscene 0.05 0.4 4\n",
      "this class avg train 0.03274608729372443 avg val 0.03803360598021513\n",
      "this class auc train 0.9968100702350975 auc val 0.9954335570824288\n",
      "========================\n",
      "0 fold: ls 0.0038149429798278994 0.0067598195514120794 auc 0.9993818773795575 0.9967303058872826\n",
      "1 fold: ls 0.003821536189456578 0.006262871398870115 auc 0.9993984279996861 0.9968272051120888\n",
      "2 fold: ls 0.004193415836272534 0.007471514599345478 auc 0.999147732394501 0.9948486276974647\n",
      "3 fold: ls 0.004181473325044833 0.006565558795226286 auc 0.9992333575662605 0.9902780396840363\n",
      "4 fold: ls 0.004064888031297189 0.006823025691472433 auc 0.9992617403009821 0.9961984306576991\n",
      "5 fold: ls 0.00385595191476974 0.006994333149314066 auc 0.999373809468123 0.9961552161250445\n",
      "6 fold: ls 0.003779329076194518 0.006325595886903766 auc 0.9994110684057202 0.9950054476501771\n",
      "7 fold: ls 0.004380027967635897 0.007602697557076164 auc 0.9990085127089685 0.9958579525216336\n",
      "8 fold: ls 0.004293656688295615 0.0070802924611768035 auc 0.9990603494564068 0.9940646469347606\n",
      "9 fold: ls 0.004347770535838388 0.007634126741919082 auc 0.9990867056268066 0.9905473016076809\n",
      "threat 0.05 0.4 4\n",
      "this class avg train 0.004073299254463319 avg val 0.006951983583271627\n",
      "this class auc train 0.9992363581307012 auc val 0.9946513173877868\n",
      "========================\n",
      "0 fold: ls 0.046751008944652346 0.04984577355188391 auc 0.9929626690924765 0.9914604867341031\n",
      "1 fold: ls 0.04835405393668089 0.05374352032817098 auc 0.9923799550600925 0.9899031785282868\n",
      "2 fold: ls 0.04937215589199727 0.05507876172810055 auc 0.992035048496421 0.9891306311883259\n",
      "3 fold: ls 0.048916890796210706 0.052118556119587 auc 0.9921754653007115 0.9904516996878021\n",
      "4 fold: ls 0.04895135155066733 0.055117005709278556 auc 0.9921777585525534 0.9890534495780703\n",
      "5 fold: ls 0.047890232057131825 0.052757349633449045 auc 0.9925603956228792 0.9903444039791279\n",
      "6 fold: ls 0.0482958448867935 0.05645447277328737 auc 0.9923987601176855 0.9890489319487747\n",
      "7 fold: ls 0.0474280868651304 0.05538754360539882 auc 0.9926973820518311 0.9895464090602089\n",
      "8 fold: ls 0.04837050338137346 0.052212706722038475 auc 0.9923837711646296 0.9905003374517497\n",
      "9 fold: ls 0.04860003599735807 0.05457074657695786 auc 0.9922826701144595 0.9893219996677836\n",
      "insult 0.05 0.4 4\n",
      "this class avg train 0.04829301643079957 avg val 0.05372864367481526\n",
      "this class auc train 0.9924053875573741 auc val 0.9898761527824232\n",
      "========================\n",
      "0 fold: ls 0.013603279416951525 0.0170974141336759 auc 0.9965390596884766 0.9928477170402434\n",
      "1 fold: ls 0.01407264263769009 0.018085867911619112 auc 0.9961724709221079 0.9909245685470836\n",
      "2 fold: ls 0.013432972745670943 0.017855996637523974 auc 0.9966575896857527 0.9920652749510469\n",
      "3 fold: ls 0.013746728007137492 0.018354205178804484 auc 0.9964271517426728 0.98880054093876\n",
      "4 fold: ls 0.013943940570492613 0.018972092319135058 auc 0.9963084300032432 0.9885250047417338\n",
      "5 fold: ls 0.01313582891133645 0.016555277595912774 auc 0.9968973877235476 0.9934686006918416\n",
      "6 fold: ls 0.013735756952859538 0.01663078199615903 auc 0.9964243035106645 0.991224528506395\n",
      "7 fold: ls 0.013851503962913592 0.01885139515671921 auc 0.9963578775800336 0.9888218982585447\n",
      "8 fold: ls 0.01176587600294156 0.01660359086657203 auc 0.9977183554979862 0.9929813389695787\n",
      "9 fold: ls 0.013917910375037309 0.016900122225752122 auc 0.996323338761695 0.9917113772671436\n",
      "identity_hate 0.05 0.4 4\n",
      "this class avg train 0.013520643958303111 avg val 0.01759067440218737\n",
      "this class auc train 0.996582596511618 auc val 0.9911370849912371\n",
      "========================\n",
      "all loss avg 0.030043108813764534 0.035326757133122895\n",
      "all auc avg 0.9954929327027309 0.9919140152473946\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.05 4 0.4 toxic\n",
      "FIND BETTER PARAMS 0.05 4 0.4 insult\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 4 feature fraction 0.5\n",
      "0 fold: ls 0.06765704608342538 0.07794120997991291 auc 0.9914547855799842 0.9870914126670909\n",
      "1 fold: ls 0.0672461070079988 0.07155735843515221 auc 0.9915818260402256 0.9897681251596842\n",
      "2 fold: ls 0.0663111247589173 0.07611033376222799 auc 0.9918571542275775 0.988298080529689\n",
      "3 fold: ls 0.06384909800211472 0.07307658378539202 auc 0.9925961774091077 0.9890512003711012\n",
      "4 fold: ls 0.0614874099388986 0.07796142179850696 auc 0.9932528452528153 0.9878282418297538\n",
      "5 fold: ls 0.06746488571866376 0.07664915501920296 auc 0.9915041438629643 0.9875428890448645\n",
      "6 fold: ls 0.06674801527129562 0.07807437683610643 auc 0.9916981782329374 0.9875253463081288\n",
      "7 fold: ls 0.06889048387764773 0.07107265525836937 auc 0.9910553329227707 0.9900375735253684\n",
      "8 fold: ls 0.06112089945017959 0.07407001372631897 auc 0.9933962272543091 0.9894428924619619\n",
      "9 fold: ls 0.06787690402914329 0.07790490046202664 auc 0.991311499017909 0.9875222603066527\n",
      "toxic 0.05 0.5 4\n",
      "this class avg train 0.06586519741382849 avg val 0.07544180090632165\n",
      "this class auc train 0.9919708169800601 auc val 0.9884108022204297\n",
      "========================\n",
      "0 fold: ls 0.015600171302991989 0.021259083882150902 auc 0.996259010457667 0.9910886662868716\n",
      "1 fold: ls 0.016133054061101847 0.020531973393600206 auc 0.9958416115089184 0.9917177016077985\n",
      "2 fold: ls 0.01654743913322358 0.02114247956184713 auc 0.9955408842907476 0.9912722338270666\n",
      "3 fold: ls 0.01601219616372346 0.019931410775015326 auc 0.9959529799790153 0.9925572066084314\n",
      "4 fold: ls 0.01647313965330878 0.021243843696856064 auc 0.9955830702084539 0.9910229934168883\n",
      "5 fold: ls 0.01626998442013955 0.01974510339319802 auc 0.9957304882564916 0.9924845195753622\n",
      "6 fold: ls 0.016589087093433104 0.01912204125669318 auc 0.9955213484763143 0.9929833026969933\n",
      "7 fold: ls 0.015794862847651754 0.020043969283099126 auc 0.9961175358199748 0.992232025585624\n",
      "8 fold: ls 0.01636202134262514 0.021124504077204828 auc 0.9956511134959324 0.9911355670987605\n",
      "9 fold: ls 0.01631550121738036 0.01902996525338746 auc 0.9957343190576922 0.9931298156683679\n",
      "severe_toxic 0.05 0.5 4\n",
      "this class avg train 0.016209745723557954 avg val 0.020317437457305222\n",
      "this class auc train 0.9957932361551208 auc val 0.9919624032372164\n",
      "========================\n",
      "0 fold: ls 0.03237488634353311 0.03716671511945204 auc 0.9968919011335501 0.9956356395234793\n",
      "1 fold: ls 0.033979031865750804 0.0371335660387201 auc 0.9965667450163981 0.995360865307778\n",
      "2 fold: ls 0.03301812194242915 0.039139541674772106 auc 0.9967489046141477 0.995319210251816\n",
      "3 fold: ls 0.033988585021559395 0.03405904693590655 auc 0.9965534476589721 0.9964360780726786\n",
      "4 fold: ls 0.0325726510738485 0.04202658454227129 auc 0.9968438379902211 0.99451629020082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold: ls 0.03305838139808371 0.03757879506952878 auc 0.9967376357356217 0.9955494438371011\n",
      "6 fold: ls 0.034369530778807174 0.03750568713800894 auc 0.9964979585002047 0.9954744221450251\n",
      "7 fold: ls 0.03372839105790439 0.03837946160459001 auc 0.9966109315576597 0.9955363659429709\n",
      "8 fold: ls 0.032308930427461635 0.03886685264388981 auc 0.9969061704702608 0.9951658778164458\n",
      "9 fold: ls 0.03324655142934531 0.038879050676179604 auc 0.9967062536154742 0.9952615259459229\n",
      "obscene 0.05 0.5 4\n",
      "this class avg train 0.033264506133872315 avg val 0.038073530144331916\n",
      "this class auc train 0.9967063786292512 auc val 0.9954255719044036\n",
      "========================\n",
      "0 fold: ls 0.003946354090892078 0.006654386465549525 auc 0.9993233898593585 0.9968429184998953\n",
      "1 fold: ls 0.0038432936144718235 0.006218776454716906 auc 0.9994001821380316 0.9969817200921851\n",
      "2 fold: ls 0.004198176740596978 0.00756835366228326 auc 0.9991401311283382 0.9944387701655142\n",
      "3 fold: ls 0.0036097312203227415 0.00653086733816286 auc 0.9995228046137414 0.9915299515997235\n",
      "4 fold: ls 0.003989059599255242 0.006731166047661655 auc 0.9993245640022143 0.9962940264420558\n",
      "5 fold: ls 0.0038375549989489 0.007094359309192556 auc 0.9993964019625423 0.9959024765855804\n",
      "6 fold: ls 0.003905671686722292 0.006361781501681186 auc 0.9993533121798721 0.9950722337460975\n",
      "7 fold: ls 0.00402881152828025 0.007669338460359369 auc 0.9992515403825812 0.9954939028223019\n",
      "8 fold: ls 0.003783643279268414 0.007106886447601213 auc 0.9994215173039076 0.9943976579562217\n",
      "9 fold: ls 0.004112053357548857 0.0076711604741621885 auc 0.999203813553939 0.9891724609247007\n",
      "threat 0.05 0.5 4\n",
      "this class avg train 0.0039254350116307585 avg val 0.006960707616137071\n",
      "this class auc train 0.9993337657124526 auc val 0.9946126118834275\n",
      "========================\n",
      "0 fold: ls 0.0489265619180393 0.05004633303450634 auc 0.9921723893111726 0.9914158153448732\n",
      "1 fold: ls 0.04873059337107819 0.053918739865260794 auc 0.9922470784081905 0.9898752379964464\n",
      "2 fold: ls 0.04950409453365899 0.05516352384529653 auc 0.9920038474026657 0.9887582859571222\n",
      "3 fold: ls 0.0464756985883561 0.05203962689018734 auc 0.9930494668631282 0.9903636117236464\n",
      "4 fold: ls 0.04842548224639022 0.05529250153676049 auc 0.9923574902909302 0.9890465058145236\n",
      "5 fold: ls 0.044982497661457864 0.05264535939518187 auc 0.993571979604076 0.990404137077589\n",
      "6 fold: ls 0.04722244784847369 0.056450646006680566 auc 0.9927868082861716 0.9890728586520801\n",
      "7 fold: ls 0.046007349461014604 0.05563077921605343 auc 0.9932114687323809 0.9894268748299025\n",
      "8 fold: ls 0.04838535826312247 0.05230349480874827 auc 0.9923667038668089 0.990392949306513\n",
      "9 fold: ls 0.0477851751811101 0.05461119364140446 auc 0.992586942311025 0.9892869016702375\n",
      "insult 0.05 0.5 4\n",
      "this class avg train 0.04764452590727015 avg val 0.05381021982400801\n",
      "this class auc train 0.992635417507655 auc val 0.9898043178372934\n",
      "========================\n",
      "0 fold: ls 0.013584304392679368 0.017098539051557032 auc 0.9965389513124767 0.992741000010313\n",
      "1 fold: ls 0.01396299886752163 0.018174682675596177 auc 0.996263829111034 0.9906819890798886\n",
      "2 fold: ls 0.013449297475193937 0.018036843686860173 auc 0.9966330855943198 0.991728085007737\n",
      "3 fold: ls 0.012233356896458424 0.018225300305798137 auc 0.9974280763511253 0.9893408519516438\n",
      "4 fold: ls 0.013456947416324886 0.019031598396687156 auc 0.9966224925350612 0.9886274620582846\n",
      "5 fold: ls 0.012879818478508043 0.016693782120660326 auc 0.9970426772456505 0.9931520335263144\n",
      "6 fold: ls 0.013160828920988448 0.01658566419148051 auc 0.9968257051663841 0.9903696076306091\n",
      "7 fold: ls 0.013863663178299195 0.01880935358338336 auc 0.9963378634468567 0.9890456770720428\n",
      "8 fold: ls 0.011218127261461468 0.01665841302227068 auc 0.9980280581042938 0.9928833369463111\n",
      "9 fold: ls 0.01350020542428161 0.016956603887439654 auc 0.996643470486234 0.991509953753884\n",
      "identity_hate 0.05 0.5 4\n",
      "this class avg train 0.013130954831171701 avg val 0.017627078092173322\n",
      "this class auc train 0.9968364209353435 auc val 0.9910079997037029\n",
      "========================\n",
      "all loss avg 0.030006727503555226 0.03537179567337953\n",
      "all auc avg 0.9955460059866472 0.9918706177977455\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 4 feature fraction 0.6\n",
      "0 fold: ls 0.06828903664656823 0.07815505724901771 auc 0.9912825948175258 0.9870130882035838\n",
      "1 fold: ls 0.06473662690240359 0.07130319043516115 auc 0.9923247681098675 0.9897876949504504\n",
      "2 fold: ls 0.06888253580859627 0.07617834524957454 auc 0.9910602977917643 0.9882485671470326\n",
      "3 fold: ls 0.059859394678738305 0.07309854072714884 auc 0.9937324731170263 0.9890343939072719\n",
      "4 fold: ls 0.06549825888527622 0.07832634517489558 auc 0.9920809814194839 0.9876765220885267\n",
      "5 fold: ls 0.06401390682010048 0.07645609995709506 auc 0.9925864337037916 0.9875695884555556\n",
      "6 fold: ls 0.06615871954913682 0.07797856744816951 auc 0.9919052059846416 0.987531919168146\n",
      "7 fold: ls 0.0681919910613359 0.07114184144000578 auc 0.991278332692966 0.989987298994242\n",
      "8 fold: ls 0.0660544088755692 0.074154888363183 auc 0.9919032116886943 0.9894095725517923\n",
      "9 fold: ls 0.06841220908530357 0.0782282904010594 auc 0.9911314183665776 0.9874218925772442\n",
      "toxic 0.05 0.6 4\n",
      "this class avg train 0.06600970883130286 avg val 0.07550211664453106\n",
      "this class auc train 0.991928571769234 auc val 0.9883680538043846\n",
      "========================\n",
      "0 fold: ls 0.016109523621020954 0.02135995117537445 auc 0.9958393078745136 0.9910241802759843\n",
      "1 fold: ls 0.016504848885037997 0.020711101005121163 auc 0.9955652292951912 0.9916377864286621\n",
      "2 fold: ls 0.0165826340601 0.021257594247150652 auc 0.9955233178530735 0.9910396094442334\n",
      "3 fold: ls 0.01640854318455014 0.019834565969257752 auc 0.9956316229795472 0.9926699582225598\n",
      "4 fold: ls 0.016449344722160766 0.021321447136600793 auc 0.995586871205222 0.990917758577035\n",
      "5 fold: ls 0.015085272706355166 0.01971497232035391 auc 0.996663334567744 0.9925211454996691\n",
      "6 fold: ls 0.016502526303094758 0.019308237128134405 auc 0.9955948561918133 0.992832012128726\n",
      "7 fold: ls 0.015546042227474598 0.020137626512149107 auc 0.9963163661578394 0.9921225389901672\n",
      "8 fold: ls 0.016166763143391542 0.021207719690860678 auc 0.9957912228848954 0.9910248861040808\n",
      "9 fold: ls 0.016356957392292697 0.01892361331654673 auc 0.9957028500363649 0.9932237750739235\n",
      "severe_toxic 0.05 0.6 4\n",
      "this class avg train 0.016171245624547866 avg val 0.02037768285015497\n",
      "this class auc train 0.9958214979046204 auc val 0.9919013650745041\n",
      "========================\n",
      "0 fold: ls 0.03351071627501648 0.037384826427554294 auc 0.9966556721041014 0.9956042389932724\n",
      "1 fold: ls 0.03390287134716342 0.0370248846898517 auc 0.9965841756712351 0.9954969603738621\n",
      "2 fold: ls 0.033140720957732225 0.03915586192671802 auc 0.9967233563758829 0.9953423119210878\n",
      "3 fold: ls 0.03346922739848998 0.033991614455294576 auc 0.9966625883598234 0.9964088259340123\n",
      "4 fold: ls 0.03298561885080029 0.04212611166966984 auc 0.9967607700775165 0.9944871586043146\n",
      "5 fold: ls 0.03384265713661003 0.03783830786467506 auc 0.9965778157808661 0.9954554709451481\n",
      "6 fold: ls 0.03430140948248265 0.03741329335622441 auc 0.9965154982879659 0.9955057464423429\n",
      "7 fold: ls 0.03322286877093591 0.03842482777627516 auc 0.9967111544270598 0.9955018309051783\n",
      "8 fold: ls 0.032836223176812715 0.038939306083315285 auc 0.9967963645337987 0.9951338487224385\n",
      "9 fold: ls 0.03344424063216331 0.038746471915812764 auc 0.9966694558416321 0.9952848117938978\n",
      "obscene 0.05 0.6 4\n",
      "this class avg train 0.033465655402820704 avg val 0.03810455061653911\n",
      "this class auc train 0.9966656851459883 auc val 0.9954221204635555\n",
      "========================\n",
      "0 fold: ls 0.0038227531389114933 0.006731186116093258 auc 0.9993899821483938 0.9967643515608632\n",
      "1 fold: ls 0.0036439281956221494 0.006273414165601306 auc 0.9994972282177841 0.9969110098470564\n",
      "2 fold: ls 0.004198456796982314 0.0075048603347842155 auc 0.9991629186848056 0.9944846008799497\n",
      "3 fold: ls 0.0042481650060605045 0.006661560363709725 auc 0.9992117558282465 0.991260188153456\n",
      "4 fold: ls 0.004198586163448486 0.0067492178532756 auc 0.9992226054229781 0.9962704548787898\n",
      "5 fold: ls 0.003949968397032589 0.007041396840551902 auc 0.9993163537175779 0.9959862865883042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fold: ls 0.0042210360921609204 0.006459649166626927 auc 0.9991572642259627 0.9941974668426677\n",
      "7 fold: ls 0.00408061850244914 0.0076289121528927105 auc 0.999215385894747 0.9957139040794519\n",
      "8 fold: ls 0.004255438775326833 0.007217201995839656 auc 0.999103752470496 0.9938653752793482\n",
      "9 fold: ls 0.004221652970011515 0.007595792457694835 auc 0.9991527540439911 0.9801310110829813\n",
      "threat 0.05 0.6 4\n",
      "this class avg train 0.004084060403800594 avg val 0.006986319144707013\n",
      "this class auc train 0.9992430000654983 auc val 0.9935584649192869\n",
      "========================\n",
      "0 fold: ls 0.04882326381997676 0.05017206073345681 auc 0.9922173930942987 0.9913672122041566\n",
      "1 fold: ls 0.048753144858656165 0.05408061509492768 auc 0.9922485611240078 0.9897597114261718\n",
      "2 fold: ls 0.04952517165495439 0.05508197843804442 auc 0.9919988939952588 0.9890663010416632\n",
      "3 fold: ls 0.04729200169449892 0.052139512120979184 auc 0.9927737736804646 0.9903744867809497\n",
      "4 fold: ls 0.048734877664425996 0.05532769868744674 auc 0.9922610736555902 0.9890333712256463\n",
      "5 fold: ls 0.046127950458828185 0.05271674185881749 auc 0.9931834091308123 0.9903815489311122\n",
      "6 fold: ls 0.04804965275872543 0.056363162314851785 auc 0.9924802742766524 0.9890684246825864\n",
      "7 fold: ls 0.04573935595371619 0.055520930675690965 auc 0.9932898369745309 0.9894812390313522\n",
      "8 fold: ls 0.04782528525154327 0.05244421668984007 auc 0.9925782529225701 0.9903434435390912\n",
      "9 fold: ls 0.04852291444773771 0.05469200193771536 auc 0.9923177024723847 0.9892853938803667\n",
      "insult 0.05 0.6 4\n",
      "this class avg train 0.0479393618563063 avg val 0.05385389185517705\n",
      "this class auc train 0.992534917132657 auc val 0.9898161132743096\n",
      "========================\n",
      "0 fold: ls 0.013721079829554332 0.017208470842495528 auc 0.9964318146895342 0.9926284538989157\n",
      "1 fold: ls 0.01421338239607552 0.01806160115957559 auc 0.9960490112062785 0.9910250081046652\n",
      "2 fold: ls 0.01350341313497842 0.01801588811563258 auc 0.9965733954282979 0.9917836854771126\n",
      "3 fold: ls 0.01198519067820125 0.01821470818285146 auc 0.9975521418610046 0.9883283853399498\n",
      "4 fold: ls 0.013920298247354685 0.01905421884939413 auc 0.9962780347036182 0.9887088450033786\n",
      "5 fold: ls 0.013196921655631185 0.016682892182148235 auc 0.9968456166172006 0.9932599644144186\n",
      "6 fold: ls 0.012422222489923229 0.01644949175866929 auc 0.9973026485128927 0.9911942698171833\n",
      "7 fold: ls 0.013895383171712765 0.01897240801113772 auc 0.9962955277797444 0.9894577823542164\n",
      "8 fold: ls 0.0124962584913912 0.016826639590847712 auc 0.9972456465511855 0.9926828166775056\n",
      "9 fold: ls 0.013751926710510747 0.01695502720793353 auc 0.9964737862891526 0.9914480815087795\n",
      "identity_hate 0.05 0.6 4\n",
      "this class avg train 0.013310607680533335 avg val 0.017644134590068576\n",
      "this class auc train 0.9967047623638908 auc val 0.9910517292596127\n",
      "========================\n",
      "all loss avg 0.030163439966551943 0.03541144928352963\n",
      "all auc avg 0.9954830723969815 0.9916863077992756\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "[0.9884873039634368, 0.9920148292218363, 0.9954573112511824, 0.994769628570376, 0.9898761527824232, 0.9912880359235366]\n",
      "0.9919822102854652\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999429      0.354925  0.977820  0.159519  0.932712   \n",
      "1  0000247867823ef7  0.000217      0.000021  0.000064  0.000053  0.000085   \n",
      "2  00013b17ad220c46  0.000277      0.000023  0.000125  0.000056  0.000226   \n",
      "3  00017563c3f7919a  0.000084      0.000021  0.000059  0.000054  0.000083   \n",
      "4  00017695ad8997eb  0.001733      0.000035  0.000162  0.000076  0.000200   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.450806  \n",
      "1       0.000043  \n",
      "2       0.000056  \n",
      "3       0.000042  \n",
      "4       0.000062  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "# find best params for each column, early stopping = 30\n",
    "\n",
    "best_pred = np.zeros((153164,6))\n",
    "val_auc_res = [0,0,0,0,0,0]\n",
    "for lr in [0.095,0.075,0.05]:\n",
    "    for max_d in [3,4]:\n",
    "        for s_rate in [0.4,0.5,0.6]:\n",
    "            print('learning rate',lr,'max depth',max_d,'feature fraction',s_rate)\n",
    "            lgb_res,tmp_auc_res = simple_ens('lgb',k=10,rnd=666,lr=lr,\n",
    "                                 feature_fraction=s_rate,bagging_fraction=0.9,\n",
    "                                 bag_frec=3,met='binary_logloss',max_d=max_d)\n",
    "            # check for each cls\n",
    "            for i in range(6):\n",
    "                # find better params for this class\n",
    "                if tmp_auc_res[i] > val_auc_res[i]:\n",
    "                    val_auc_res[i] = tmp_auc_res[i]\n",
    "                    best_pred[:,i] = lgb_res[:,i]\n",
    "                    print('FIND BETTER PARAMS',lr,max_d,s_rate,list_classes[i])\n",
    "            print('TEST PARAM DONE ------------------------------------------')\n",
    "\n",
    "print(val_auc_res)\n",
    "print(np.mean(val_auc_res))\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = best_pred\n",
    "sample_submission.to_csv(\"../results/lgb_grid_search_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "                \n",
    "            \n",
    "# best auc params\n",
    "# toxic 0.05,4,0.5\n",
    "# severe toxic 0.075 3 0.5\n",
    "# obs 0.075 3 0.6\n",
    "# threat 0.095 3 0.5\n",
    "# insult 0.075 0.5 4\n",
    "# hate 0.05 0.5 3\n",
    "\n",
    "# TEST PARAM DONE ------------------------------------------\n",
    "# [0.9884873039634368, 0.9920148292218363, 0.9954573112511824, \n",
    "#  0.994769628570376, 0.9898761527824232, 0.9912880359235366]\n",
    "# 0.9919822102854652 PUB 9870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def special_ens(model_name,k=3,rnd=233):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    params_list = [\n",
    "        [0.05,4,0.5],\n",
    "        [0.075,3,0.5],\n",
    "        [0.075,3,0.6],\n",
    "        [0.095,3,0.5],\n",
    "        [0.075,4,0.5],\n",
    "        [0.05,3,0.5],\n",
    "    ]\n",
    "    \n",
    "    for i in range(6):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        \n",
    "        # special params\n",
    "        params = {\n",
    "                'application': 'binary',\n",
    "                #'num_leaves': 8,\n",
    "                #'lambda_l1': 1,\n",
    "                'lambda_l2': 1.0,\n",
    "                'max_depth': params_list[i][1],\n",
    "                'metric': 'binary_logloss', # or auc\n",
    "                'data_random_seed': 2,\n",
    "                'learning_rate':params_list[i][0],\n",
    "                'feature_fraction': params_list[i][2],\n",
    "\n",
    "                }\n",
    "        print(params)\n",
    "            \n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = test_x\n",
    "            s_round = 30\n",
    "            # train for each class\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_auc_l = train_auc_l/k\n",
    "        val_auc_l = val_auc_l/k\n",
    "        print(list_classes[i])\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/6\n",
    "        all_val_loss_l += val_loss_l/6\n",
    "        all_train_auc_l += train_auc_l/6\n",
    "        all_val_auc_l += val_auc_l/6\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')\n",
    "\n",
    "lgb_res = special_ens('lgb',10,666)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10_stratified_special.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# best params changed when base models changed\n",
    "# all loss avg 0.03111512578966158 0.03534320053008906 all auc avg 0.9948524214184179 0.9918450388634261"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
