{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/fasttext_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lgb1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 37) (153164, 37)\n",
      "file path ../features/pool_gru_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/tilli_lr_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/wordbatch_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "(159571, 217)\n",
      "(159571, 217)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat or 'tfidf' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss'):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for i in range(6):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = test_x\n",
    "\n",
    "            # share params\n",
    "            params = {\n",
    "                    'application': 'binary',\n",
    "                    #'num_leaves': 8,\n",
    "                    #'lambda_l1': 1,\n",
    "                    'lambda_l2': 1.0,\n",
    "                    'max_depth': 3,\n",
    "                    #'scale_pos_weight':0.9,\n",
    "                    'metric': met, # or auc\n",
    "                    'data_random_seed': 2,\n",
    "                    'learning_rate':lr,\n",
    "                    # 'bagging_fraction': bagging_fraction,\n",
    "                    # 'bagging_freq':bag_frec,\n",
    "                    'feature_fraction': feature_fraction,\n",
    "\n",
    "                    }\n",
    "            if met == 'auc':\n",
    "                s_round = 100\n",
    "            else:\n",
    "                s_round = 50\n",
    "            # train for each class\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_auc_l = train_auc_l/k\n",
    "        val_auc_l = val_auc_l/k\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/6\n",
    "        all_val_loss_l += val_loss_l/6\n",
    "        all_train_auc_l += train_auc_l/6\n",
    "        all_val_auc_l += val_auc_l/6\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.07133962781015392 0.07867731357447029 auc 0.9901785840557712 0.9867917049455398\n",
      "1 fold: ls 0.07031379104401782 0.07192475190436497 auc 0.9904897297278498 0.989718339974378\n",
      "2 fold: ls 0.07044510547166037 0.07619551096328572 auc 0.9904409942920555 0.9881916244919556\n",
      "3 fold: ls 0.06938250039375353 0.0734897574112091 auc 0.9907808823003494 0.9888950497489449\n",
      "4 fold: ls 0.0645193643981223 0.07762425176309679 auc 0.9922955400622832 0.9878692202122065\n",
      "5 fold: ls 0.06766842877967498 0.07671020264662948 auc 0.9913911354583347 0.9875699057660392\n",
      "6 fold: ls 0.06978165189967536 0.07834710896012417 auc 0.9906364663750916 0.98750150269179\n",
      "7 fold: ls 0.0729094386718389 0.07128892390514657 auc 0.9895745321273073 0.9899826750067082\n",
      "8 fold: ls 0.06773516599512525 0.07446469819249199 auc 0.9913256367087062 0.9892464183249896\n",
      "9 fold: ls 0.06927103427348853 0.07820885644636913 auc 0.9907672914946568 0.9873755620354848\n",
      "this class avg train 0.06933661087375109 avg val 0.07569313757671883\n",
      "this class auc train 0.9907880792602406 auc val 0.9883142003198037\n",
      "========================\n",
      "0 fold: ls 0.018070858553828312 0.02128030505194125 auc 0.9940865974403289 0.9910617641473605\n",
      "1 fold: ls 0.017740579332929496 0.020491969862342776 auc 0.99437171140872 0.991797616786935\n",
      "2 fold: ls 0.017720151843921443 0.02111660363568222 auc 0.994395301605295 0.9911551303962527\n",
      "3 fold: ls 0.018091541291987392 0.019847478022858855 auc 0.9940822572950831 0.9925231833143436\n",
      "4 fold: ls 0.018347992005215575 0.021143762213395107 auc 0.9939264384836735 0.9910324882896571\n",
      "5 fold: ls 0.018169812392025673 0.019872096703468532 auc 0.9940227932728684 0.9923173142687435\n",
      "6 fold: ls 0.01733363646285652 0.019200927969944607 auc 0.9947744037044126 0.9928113092088579\n",
      "7 fold: ls 0.017642758264988123 0.0201296720175907 auc 0.9944585575862324 0.9921301035185807\n",
      "8 fold: ls 0.01746320689213949 0.02127216367447531 auc 0.9946295433503621 0.990797153985531\n",
      "9 fold: ls 0.01836270552140084 0.018926448095674765 auc 0.9938759521252398 0.993292253962718\n",
      "this class avg train 0.017894324256129284 avg val 0.02032814272473741\n",
      "this class auc train 0.9942623556272215 auc val 0.991891831787898\n",
      "========================\n",
      "0 fold: ls 0.03548872963702112 0.036955216235337665 auc 0.9961806560601056 0.9957917808133363\n",
      "1 fold: ls 0.03605453669637947 0.03744525975584178 auc 0.9960611859244748 0.9953527998349319\n",
      "2 fold: ls 0.03396317105722409 0.03922321548595466 auc 0.9965226988833054 0.9953042528998468\n",
      "3 fold: ls 0.036193740275619765 0.034123190261384675 auc 0.9960205397876452 0.9964194761951003\n",
      "4 fold: ls 0.03516033054987981 0.04229433145269975 auc 0.9962594280226865 0.9944155825849437\n",
      "5 fold: ls 0.033548487375694463 0.03789615420807827 auc 0.9966101053311633 0.9954471700063587\n",
      "6 fold: ls 0.03617661410399047 0.03785254218562151 auc 0.9960297549446053 0.9954650248558299\n",
      "7 fold: ls 0.0356985386368672 0.03848966380336173 auc 0.9961304936616776 0.9954731691731326\n",
      "8 fold: ls 0.03539609020984743 0.038853786397295545 auc 0.9962125965959816 0.9951311861571666\n",
      "9 fold: ls 0.03466433718237058 0.0391590850081084 auc 0.9963651036797243 0.9950863724631754\n",
      "this class avg train 0.03523445757248944 avg val 0.038229244479368395\n",
      "this class auc train 0.996239256289137 auc val 0.9953886814983821\n",
      "========================\n",
      "0 fold: ls 0.005140249292181743 0.006600877654294545 auc 0.9984722998004343 0.9962549759061388\n",
      "1 fold: ls 0.004917154864703565 0.006145051899022223 auc 0.9985909315270473 0.9969673161533628\n",
      "2 fold: ls 0.005151486739408011 0.007216239282109307 auc 0.9984316866251336 0.994581500104756\n",
      "3 fold: ls 0.003101691877127634 0.006363211050837063 auc 0.9997276231981227 0.991501141911287\n",
      "4 fold: ls 0.0046964323735129545 0.006746971755844804 auc 0.9988060004755631 0.9960989062794645\n",
      "5 fold: ls 0.0050540887022848 0.006976138204519 auc 0.9985287754640637 0.9958553334590483\n",
      "6 fold: ls 0.0045399221668269854 0.006265551486773135 auc 0.9989444140179363 0.9947815177991494\n",
      "7 fold: ls 0.004941815667604628 0.007556847577024322 auc 0.9986327317980183 0.995901167054288\n",
      "8 fold: ls 0.004593490452861455 0.006945932726301116 auc 0.9988896298540402 0.9955344425676353\n",
      "9 fold: ls 0.005089009171760131 0.007683592506705634 auc 0.9984540765160866 0.9878792012550102\n",
      "this class avg train 0.004722534130827191 avg val 0.0068500414143431165\n",
      "this class auc train 0.9987478169276447 auc val 0.994535550249014\n",
      "========================\n",
      "0 fold: ls 0.048993873980669685 0.050001021117443895 auc 0.9920877763506921 0.9914133057162648\n",
      "1 fold: ls 0.05149350101454443 0.05413906533955209 auc 0.9911014954872186 0.9897591258461631\n",
      "2 fold: ls 0.05190856137633132 0.05491722685046812 auc 0.9909982514533848 0.9893549919859193\n",
      "3 fold: ls 0.0513286732910237 0.05240397069067461 auc 0.9911720112816674 0.9903581323678513\n",
      "4 fold: ls 0.048931069190138454 0.05511464133714339 auc 0.9921069586159222 0.9893494379567197\n",
      "5 fold: ls 0.05011642847719317 0.05263259194681122 auc 0.991659325856419 0.9904304899151456\n",
      "6 fold: ls 0.050375802223267596 0.05615114860880179 auc 0.9915200383829433 0.9892001888703684\n",
      "7 fold: ls 0.048534262568200495 0.055397684300827 auc 0.9922388708857189 0.9895117298931823\n",
      "8 fold: ls 0.050312780876485524 0.052556759154993846 auc 0.9915702461537109 0.9903377474440239\n",
      "9 fold: ls 0.048246822583274396 0.054658945770622636 auc 0.9923702804525693 0.9893298736815529\n",
      "this class avg train 0.05002417755811287 avg val 0.05379730551173385\n",
      "this class auc train 0.9916825254920244 auc val 0.9899045023677193\n",
      "========================\n",
      "0 fold: ls 0.014807050978040798 0.01683500861051526 auc 0.9954508090340634 0.9931566583579836\n",
      "1 fold: ls 0.015297099460555663 0.017804526149965947 auc 0.9950195253535814 0.9910998893819694\n",
      "2 fold: ls 0.0153531236358835 0.017738797509569394 auc 0.9949278003535793 0.9922870042422262\n",
      "3 fold: ls 0.013606811484017475 0.017896436710953163 auc 0.9964142244311117 0.9899434892971338\n",
      "4 fold: ls 0.015309771008937401 0.018809103464013037 auc 0.994985439712221 0.9890745077676993\n",
      "5 fold: ls 0.014420070750759411 0.016466076398666107 auc 0.9957811227024644 0.9935643385507456\n",
      "6 fold: ls 0.01449601748137035 0.016558124756142458 auc 0.9957297397857255 0.9898786942698172\n",
      "7 fold: ls 0.015406261101966943 0.018695046279169073 auc 0.9949540727289387 0.9889280294818991\n",
      "8 fold: ls 0.013278006169941937 0.016698368398052187 auc 0.9966915815968824 0.9929668870583134\n",
      "9 fold: ls 0.014892530047482061 0.016795269548117334 auc 0.995407878204781 0.9918613158465206\n",
      "this class avg train 0.014686674211895553 avg val 0.017429675782516398\n",
      "this class auc train 0.9955362193903348 auc val 0.9912760814254309\n",
      "========================\n",
      "all loss avg 0.031983129767200906 0.03538792458156967\n",
      "all auc avg 0.9945427088311004 0.9918851412747082\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999179      0.358277  0.978005  0.143746  0.921974   \n",
      "1  0000247867823ef7  0.000271      0.000024  0.000058  0.000023  0.000085   \n",
      "2  00013b17ad220c46  0.000332      0.000027  0.000133  0.000028  0.000182   \n",
      "3  00017563c3f7919a  0.000085      0.000025  0.000055  0.000024  0.000079   \n",
      "4  00017695ad8997eb  0.001503      0.000038  0.000227  0.000046  0.000171   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.462356  \n",
      "1       0.000035  \n",
      "2       0.000044  \n",
      "3       0.000037  \n",
      "4       0.000053  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lgb_res = simple_ens('lgb',10,666,0.05,0.6)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# add 7 base fasttext NN models\n",
    "# all loss avg 0.0319116484218 0.0358161833583 all auc avg 0.994546891137 0.991249510282 PUB 9866\n",
    "\n",
    "# rm tfidf test\n",
    "# all loss avg 0.0319555637279 0.0357756335619 all auc avg 0.994512718368 0.991251471241\n",
    "\n",
    "# change to stratified\n",
    "# all loss avg 0.0316412744167 0.0357232681944 all auc avg 0.994584962017 0.991293307537 pub 9866\n",
    "\n",
    "# change to 5 fold, add word batch, tilli, lgb feat\n",
    "# all loss avg 0.031983129767200906 0.035387924581 all auc avg 0.9945427088311004 0.99188514127 PUB 9870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.0686201101797 0.0794303344952 auc 0.991016347103 0.986465315264\n",
      "1 fold: ls 0.0670001086008 0.0792713469368 auc 0.99153500109 0.987289013193\n",
      "2 fold: ls 0.0698991214456 0.0722008373659 auc 0.99063457416 0.989268370688\n",
      "3 fold: ls 0.0700451029387 0.0776201333408 auc 0.990613346476 0.987199997826\n",
      "4 fold: ls 0.0696584506044 0.0740838661402 auc 0.990686057353 0.988955283337\n",
      "5 fold: ls 0.064768140106 0.0744467437862 auc 0.992270587779 0.989214299352\n",
      "6 fold: ls 0.069487408526 0.0746101969135 auc 0.990813428748 0.98816944126\n",
      "7 fold: ls 0.0706074471573 0.0779201995632 auc 0.990372870091 0.987011128351\n",
      "8 fold: ls 0.0686602041564 0.0741641202932 auc 0.991020361167 0.989122885325\n",
      "9 fold: ls 0.068904949978 0.0782649871536 auc 0.99097985563 0.987282787619\n",
      "this class avg train 0.0687651043693 avg val 0.0762012765989\n",
      "this class auc train 0.99099424296 auc val 0.987997852222\n",
      "========================\n",
      "0 fold: ls 0.0167041834625 0.0191065057084 auc 0.99535173385 0.99319850614\n",
      "1 fold: ls 0.0174750960995 0.0196947563071 auc 0.994656286229 0.992753829599\n",
      "2 fold: ls 0.0181510065225 0.0210666462609 auc 0.994054150505 0.991313378276\n",
      "3 fold: ls 0.0180216362672 0.0195010853086 auc 0.994137711167 0.99314628434\n",
      "4 fold: ls 0.0182584875051 0.0205743645713 auc 0.993973310092 0.991671018483\n",
      "5 fold: ls 0.0155307671066 0.0198575956464 auc 0.99629447586 0.992218981624\n",
      "6 fold: ls 0.0184590070096 0.0215113751025 auc 0.993884756104 0.989984564381\n",
      "7 fold: ls 0.0173068369061 0.0205956470137 auc 0.994773896772 0.991830707447\n",
      "8 fold: ls 0.0183913534973 0.021248943683 auc 0.993899035938 0.991043996492\n",
      "9 fold: ls 0.0172586013156 0.0198060481671 auc 0.994840518037 0.992299310075\n",
      "this class avg train 0.0175556975692 avg val 0.0202962967769\n",
      "this class auc train 0.994586587455 auc val 0.991946057686\n",
      "========================\n",
      "0 fold: ls 0.0364267301038 0.0387559610078 auc 0.995931458709 0.995238395409\n",
      "1 fold: ls 0.0319691592716 0.039832140532 auc 0.996975032507 0.994857203935\n",
      "2 fold: ls 0.036522954014 0.0412866868501 auc 0.995901622154 0.994719232492\n",
      "3 fold: ls 0.0336458947335 0.0347248236526 auc 0.99660543998 0.995958852403\n",
      "4 fold: ls 0.0348180410248 0.0363186834175 auc 0.996315039979 0.995814447392\n",
      "5 fold: ls 0.0362545306095 0.0405996239091 auc 0.9959539118 0.994668682907\n",
      "6 fold: ls 0.035188679669 0.0382778602638 auc 0.996239824361 0.995206834335\n",
      "7 fold: ls 0.0345932860266 0.0426330164138 auc 0.996365501678 0.993944386843\n",
      "8 fold: ls 0.0338694023021 0.0393108192892 auc 0.996528984296 0.995135571559\n",
      "9 fold: ls 0.0339137126056 0.0380045383664 auc 0.996537031905 0.995017769376\n",
      "this class avg train 0.034720239036 avg val 0.0389744153702\n",
      "this class auc train 0.996335384737 auc val 0.995056137665\n",
      "========================\n",
      "0 fold: ls 0.0046474740233 0.00668287008027 auc 0.998848456902 0.996337471192\n",
      "1 fold: ls 0.00554990392111 0.00771368535532 auc 0.998163547089 0.978602948879\n",
      "2 fold: ls 0.00507820007015 0.0071647661591 auc 0.998539241293 0.99483291431\n",
      "3 fold: ls 0.00530709105585 0.00742989614545 auc 0.998312514455 0.992732101326\n",
      "4 fold: ls 0.00485392901841 0.00742122691802 auc 0.998697699431 0.993215318373\n",
      "5 fold: ls 0.00543937590351 0.00599689604758 auc 0.998150996798 0.996677719111\n",
      "6 fold: ls 0.00509295216977 0.00653233143976 auc 0.998504916101 0.997432009135\n",
      "7 fold: ls 0.00512213254898 0.00762295594528 auc 0.998505785043 0.990388040313\n",
      "8 fold: ls 0.0046371370849 0.00758060094317 auc 0.99886778656 0.992485185022\n",
      "9 fold: ls 0.00516038791203 0.0069544327228 auc 0.998464925244 0.993727623732\n",
      "this class avg train 0.0050888583708 avg val 0.00710996617567\n",
      "this class auc train 0.998505586892 auc val 0.992643133139\n",
      "========================\n",
      "0 fold: ls 0.0521778753462 0.0540147854533 auc 0.990817329643 0.98984194359\n",
      "1 fold: ls 0.0500430794989 0.0524012174452 auc 0.991685979479 0.990491017203\n",
      "2 fold: ls 0.0516877855013 0.059442600249 auc 0.991112667518 0.9863262467\n",
      "3 fold: ls 0.0469085119614 0.0551143759435 auc 0.99284313585 0.98952757078\n",
      "4 fold: ls 0.043019082703 0.052978922789 auc 0.994224680275 0.989933299713\n",
      "5 fold: ls 0.0487077973479 0.0543968249255 auc 0.992209950299 0.989606189888\n",
      "6 fold: ls 0.047774027976 0.051930953032 auc 0.99255553576 0.990748062523\n",
      "7 fold: ls 0.0486768620161 0.054928525333 auc 0.992207452305 0.98983623978\n",
      "8 fold: ls 0.0500506240366 0.0513863657544 auc 0.991707143021 0.990827779152\n",
      "9 fold: ls 0.0489619095237 0.0545337730013 auc 0.992115755547 0.98948835915\n",
      "this class avg train 0.0488007555911 avg val 0.0541128343926\n",
      "this class auc train 0.99214796297 auc val 0.989662670848\n",
      "========================\n",
      "0 fold: ls 0.0152351230703 0.0182641565585 auc 0.995179546686 0.990755076794\n",
      "1 fold: ls 0.0151708461871 0.0178481417942 auc 0.995283595982 0.988741801733\n",
      "2 fold: ls 0.0151828198178 0.0190425215232 auc 0.995227262693 0.98888752877\n",
      "3 fold: ls 0.0153479664319 0.0168578271411 auc 0.995093501699 0.992684054368\n",
      "4 fold: ls 0.0145799620868 0.0183592890659 auc 0.995768231222 0.991252342282\n",
      "5 fold: ls 0.0150934640895 0.0167504663955 auc 0.995317032011 0.992213621872\n",
      "6 fold: ls 0.0159760700792 0.0192252056969 auc 0.994429173764 0.988490181733\n",
      "7 fold: ls 0.0140991124735 0.0171060650701 auc 0.996161720749 0.992655719344\n",
      "8 fold: ls 0.0158959773128 0.0178060754592 auc 0.994554986804 0.987812748392\n",
      "9 fold: ls 0.0147730983825 0.0178780464959 auc 0.995539608297 0.98833143652\n",
      "this class avg train 0.0151354439932 avg val 0.01791377952\n",
      "this class auc train 0.995255465991 auc val 0.990182451181\n",
      "========================\n",
      "all loss avg 0.0316776831549 0.0357680948057\n",
      "all auc avg 0.994637538501 0.991248050457\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999465      0.349601  0.980386  0.196994  0.926430   \n",
      "1  0000247867823ef7  0.000494      0.000038  0.000058  0.000039  0.000085   \n",
      "2  00013b17ad220c46  0.000308      0.000037  0.000144  0.000046  0.000406   \n",
      "3  00017563c3f7919a  0.000076      0.000038  0.000032  0.000040  0.000080   \n",
      "4  00017695ad8997eb  0.002139      0.000042  0.000175  0.000042  0.000308   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.426216  \n",
      "1       0.000054  \n",
      "2       0.000089  \n",
      "3       0.000058  \n",
      "4       0.000083  \n",
      "save done\n",
      "0 fold: ls 0.068607655112 0.0799297649627 auc 0.991095507636 0.986343955381\n",
      "1 fold: ls 0.0707673919298 0.0726933012036 auc 0.9903615291 0.98909722562\n",
      "2 fold: ls 0.0699454114826 0.078931201164 auc 0.990567201345 0.986581692098\n",
      "3 fold: ls 0.0636381880879 0.0752898775786 auc 0.992639877152 0.988241228475\n",
      "4 fold: ls 0.0683048086145 0.0764566248576 auc 0.99115155096 0.988421839084\n",
      "5 fold: ls 0.0683931394303 0.0762583583086 auc 0.991134326505 0.988113775935\n",
      "6 fold: ls 0.0682705322875 0.0811072462168 auc 0.991164165294 0.986485021223\n",
      "7 fold: ls 0.0668459180657 0.0729079411228 auc 0.9916684548 0.989255439634\n",
      "8 fold: ls 0.0662518468875 0.0727633634505 auc 0.991858522666 0.989216407739\n",
      "9 fold: ls 0.0661265668073 0.0746113612332 auc 0.991859524968 0.988695846476\n",
      "this class avg train 0.0677151458705 avg val 0.0760949040098\n",
      "this class auc train 0.991350066043 auc val 0.988045243167\n",
      "========================\n",
      "0 fold: ls 0.0173092036496 0.0215107952939 auc 0.994761687305 0.990656649576\n",
      "1 fold: ls 0.0178761561878 0.0211281262209 auc 0.994259340613 0.991301509685\n",
      "2 fold: ls 0.0160719322016 0.0193181780956 auc 0.995844253336 0.993005839347\n",
      "3 fold: ls 0.0181019815855 0.0207651270216 auc 0.994100813805 0.991572113559\n",
      "4 fold: ls 0.0176358180137 0.0191152920899 auc 0.994509333959 0.993192176225\n",
      "5 fold: ls 0.0181375887111 0.0189189292191 auc 0.994055560469 0.993410518488\n",
      "6 fold: ls 0.0184907277736 0.02130335435 auc 0.993845950026 0.990179649587\n",
      "7 fold: ls 0.0177955858031 0.0206964157213 auc 0.99436238238 0.991532505774\n",
      "8 fold: ls 0.0183816993033 0.0210605008796 auc 0.993891667044 0.99110729965\n",
      "9 fold: ls 0.0175513723692 0.0194757517114 auc 0.994586735686 0.992692665553\n",
      "this class avg train 0.0177352065598 avg val 0.0203292470603\n",
      "this class auc train 0.994421772462 auc val 0.991865092744\n",
      "========================\n",
      "0 fold: ls 0.0364599989381 0.0356173359545 auc 0.995927275332 0.995946121075\n",
      "1 fold: ls 0.0340753790544 0.0402700187374 auc 0.996490165972 0.99498539014\n",
      "2 fold: ls 0.0350133059089 0.0381589469921 auc 0.996249106718 0.99544544717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold: ls 0.034414264336 0.037421854421 auc 0.996419213652 0.995236592418\n",
      "4 fold: ls 0.0320155405969 0.0386453957241 auc 0.996962081203 0.995393409681\n",
      "5 fold: ls 0.0356729810932 0.0390272613711 auc 0.996108160407 0.995201822448\n",
      "6 fold: ls 0.0365249266294 0.0422090860706 auc 0.995908828551 0.99374602573\n",
      "7 fold: ls 0.0340004000368 0.0397186817864 auc 0.996499957591 0.994818726291\n",
      "8 fold: ls 0.0361224978512 0.0408816310811 auc 0.99601036352 0.994276894259\n",
      "9 fold: ls 0.0341345725078 0.0375733025407 auc 0.996476650376 0.995397948086\n",
      "this class avg train 0.0348433866953 avg val 0.0389523514679\n",
      "this class auc train 0.996305180332 auc val 0.99504483773\n",
      "========================\n",
      "0 fold: ls 0.00534640842443 0.00707302416963 auc 0.99817954548 0.993452755081\n",
      "1 fold: ls 0.00529885923134 0.00899561553353 auc 0.998370616623 0.983454457364\n",
      "2 fold: ls 0.00401269486746 0.00712250367626 auc 0.999262685303 0.99430389692\n",
      "3 fold: ls 0.0047144734144 0.00563793709381 auc 0.998821901304 0.998054036499\n",
      "4 fold: ls 0.00532660315635 0.00561831582726 auc 0.998344405442 0.997667724768\n",
      "5 fold: ls 0.0052613913921 0.00769807284952 auc 0.998335334336 0.994844375301\n",
      "6 fold: ls 0.00509211444443 0.00709698582287 auc 0.998567398722 0.991831143797\n",
      "7 fold: ls 0.00519537217095 0.00684504531394 auc 0.998407188539 0.995821285645\n",
      "8 fold: ls 0.00503098254766 0.00643372094786 auc 0.998578508752 0.996724722925\n",
      "9 fold: ls 0.0051415795858 0.00771319570416 auc 0.998428101145 0.994294678644\n",
      "this class avg train 0.00504204792349 avg val 0.00702344169388\n",
      "this class auc train 0.998529568565 auc val 0.994044907695\n",
      "========================\n",
      "0 fold: ls 0.0515827058937 0.0535838616909 auc 0.991093015593 0.990074627989\n",
      "1 fold: ls 0.051739104162 0.0546519448018 auc 0.991042685915 0.988587087459\n",
      "2 fold: ls 0.0454205412691 0.0528749632029 auc 0.993415026057 0.990610140907\n",
      "3 fold: ls 0.0512196484133 0.0556264340516 auc 0.991235772195 0.989362562699\n",
      "4 fold: ls 0.0492901853018 0.0521994843322 auc 0.992014156268 0.990113000967\n",
      "5 fold: ls 0.0494442907895 0.0519143195947 auc 0.991923624989 0.990725056077\n",
      "6 fold: ls 0.0483103297253 0.0553008431828 auc 0.992334881882 0.989218092068\n",
      "7 fold: ls 0.0514375149999 0.0530815300721 auc 0.991143453683 0.990383064906\n",
      "8 fold: ls 0.050348411674 0.0555078010786 auc 0.991576407551 0.98895095771\n",
      "9 fold: ls 0.0513856122094 0.0559302829452 auc 0.991168144729 0.988814754025\n",
      "this class avg train 0.0500178344438 avg val 0.0540671464953\n",
      "this class auc train 0.991694716886 auc val 0.989683934481\n",
      "========================\n",
      "0 fold: ls 0.0160298738649 0.0186147275777 auc 0.99415149751 0.988473215595\n",
      "1 fold: ls 0.0152290358549 0.0177323740863 auc 0.995132828293 0.992581372856\n",
      "2 fold: ls 0.015720985053 0.0173571642224 auc 0.994720154717 0.993002860285\n",
      "3 fold: ls 0.0151727856519 0.0170790387055 auc 0.995248309868 0.989259244811\n",
      "4 fold: ls 0.0153604844742 0.0160829757939 auc 0.995126331291 0.993801444446\n",
      "5 fold: ls 0.0158071061123 0.0183897748061 auc 0.994679313052 0.986124558567\n",
      "6 fold: ls 0.015168909023 0.0172966556346 auc 0.995284944557 0.98899261146\n",
      "7 fold: ls 0.0152150388383 0.0184936633565 auc 0.995227870402 0.987439030999\n",
      "8 fold: ls 0.0132420268847 0.0186888555834 auc 0.996777105364 0.99143408122\n",
      "9 fold: ls 0.0155826600953 0.0195621589229 auc 0.994859063906 0.988010333117\n",
      "this class avg train 0.0152528905853 avg val 0.0179297388689\n",
      "this class auc train 0.995120741896 auc val 0.989911875336\n",
      "========================\n",
      "all loss avg 0.031767752013 0.0357328049327\n",
      "all auc avg 0.994570341031 0.991432648525\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999477      0.351174  0.980180  0.190994  0.923879   \n",
      "1  0000247867823ef7  0.000401      0.000032  0.000058  0.000036  0.000048   \n",
      "2  00013b17ad220c46  0.000292      0.000032  0.000146  0.000043  0.000399   \n",
      "3  00017563c3f7919a  0.000063      0.000033  0.000034  0.000037  0.000045   \n",
      "4  00017695ad8997eb  0.002118      0.000038  0.000193  0.000042  0.000326   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.434534  \n",
      "1       0.000058  \n",
      "2       0.000095  \n",
      "3       0.000060  \n",
      "4       0.000082  \n",
      "save done\n",
      "0 fold: ls 0.0676478559653 0.0790606351244 auc 0.991396496036 0.98643922221\n",
      "1 fold: ls 0.0694913123768 0.0724420236811 auc 0.990786605925 0.989536685204\n",
      "2 fold: ls 0.070173814386 0.0761893120119 auc 0.990512561839 0.988165214335\n",
      "3 fold: ls 0.0701767989655 0.0736743836052 auc 0.990535508093 0.988858401692\n",
      "4 fold: ls 0.0706063190609 0.0798433408704 auc 0.990356540795 0.9871134773\n",
      "5 fold: ls 0.0652778917318 0.0768992252024 auc 0.992170155943 0.987334189407\n",
      "6 fold: ls 0.068927364863 0.0786077853327 auc 0.990945209132 0.987026579558\n",
      "7 fold: ls 0.0704904576878 0.0714440448684 auc 0.990449995601 0.989779718221\n",
      "8 fold: ls 0.0664662840012 0.0745531169053 auc 0.991742453397 0.988977773716\n",
      "9 fold: ls 0.0678723652636 0.0787237802995 auc 0.991301402705 0.987173149248\n",
      "this class avg train 0.0687130464302 avg val 0.0761437647901\n",
      "this class auc train 0.991019692947 auc val 0.988040441089\n",
      "========================\n",
      "0 fold: ls 0.0179192554763 0.021073129555 auc 0.994240999762 0.991308630839\n",
      "1 fold: ls 0.0178744707805 0.0205761725235 auc 0.994260899242 0.991865267755\n",
      "2 fold: ls 0.0175015137334 0.0209588059121 auc 0.994595146791 0.991358478921\n",
      "3 fold: ls 0.0172857418173 0.0201787494775 auc 0.994797128966 0.992269591087\n",
      "4 fold: ls 0.0183857944591 0.0210236236606 auc 0.993920561765 0.99118915369\n",
      "5 fold: ls 0.018127005033 0.0199172756649 auc 0.99406218003 0.992292233473\n",
      "6 fold: ls 0.0184959687058 0.0195502667643 auc 0.993825567406 0.992576808828\n",
      "7 fold: ls 0.0174010658417 0.0202254620271 auc 0.994705269816 0.992080735017\n",
      "8 fold: ls 0.0180708736917 0.0210896301286 auc 0.994118243998 0.990887928326\n",
      "9 fold: ls 0.0180733090377 0.0186582122145 auc 0.994125284732 0.993499283161\n",
      "this class avg train 0.0179134998576 avg val 0.0203251327928\n",
      "this class auc train 0.994265128251 auc val 0.99193281111\n",
      "========================\n",
      "0 fold: ls 0.0337437138791 0.0375798269357 auc 0.996571979434 0.995491478985\n",
      "1 fold: ls 0.0365282236284 0.0389485129873 auc 0.995917818861 0.994537482327\n",
      "2 fold: ls 0.0359594678861 0.040111201367 auc 0.996049154105 0.995000955391\n",
      "3 fold: ls 0.036352708672 0.0347037766758 auc 0.99594975021 0.996241554186\n",
      "4 fold: ls 0.0333158909714 0.0426451353392 auc 0.996652572116 0.994412841709\n",
      "5 fold: ls 0.0360539192543 0.0386405778607 auc 0.9960131724 0.995115210766\n",
      "6 fold: ls 0.0342720780009 0.0388076570929 auc 0.996436394715 0.994815593862\n",
      "7 fold: ls 0.0362812004466 0.0393199898794 auc 0.995942291932 0.995094458419\n",
      "8 fold: ls 0.0358869650984 0.0394478526479 auc 0.996065329579 0.994973624942\n",
      "9 fold: ls 0.034725117603 0.0396398583284 auc 0.996321465901 0.99485633651\n",
      "this class avg train 0.035311928544 avg val 0.0389844389114\n",
      "this class auc train 0.996191992925 auc val 0.99505395371\n",
      "========================\n",
      "0 fold: ls 0.00377865828057 0.00658377623126 auc 0.999413183876 0.996962078357\n",
      "1 fold: ls 0.00422665122648 0.00629469621382 auc 0.999158923147 0.996114864865\n",
      "2 fold: ls 0.00498487558199 0.00769375463036 auc 0.998624511907 0.991466320972\n",
      "3 fold: ls 0.00520705605812 0.00677631971296 auc 0.998488463048 0.990816911811\n",
      "4 fold: ls 0.00478864205457 0.00732195069387 auc 0.99872739776 0.995372116412\n",
      "5 fold: ls 0.00514827061222 0.00666826659901 auc 0.998465383296 0.995825214239\n",
      "6 fold: ls 0.00315121328005 0.00633628362203 auc 0.999708222239 0.994970090305\n",
      "7 fold: ls 0.00539044011924 0.00765610645011 auc 0.998083828387 0.995503069541\n",
      "8 fold: ls 0.00538745425761 0.00688762898773 auc 0.998230774207 0.994800213448\n",
      "9 fold: ls 0.0051593160344 0.00756855788984 auc 0.998517183867 0.990002982388\n",
      "this class avg train 0.00472225775053 avg val 0.0069787341031\n",
      "this class auc train 0.998741787173 auc val 0.994183386234\n",
      "========================\n",
      "0 fold: ls 0.0489982221937 0.0499630894399 auc 0.992115655024 0.991367881438\n",
      "1 fold: ls 0.0517475752416 0.0543001503367 auc 0.991007693822 0.989526525101\n",
      "2 fold: ls 0.0516007794526 0.0553861933674 auc 0.991072173878 0.988901962195\n",
      "3 fold: ls 0.0483123202113 0.0521203504643 auc 0.992350968224 0.990417485084\n",
      "4 fold: ls 0.0486034249178 0.055636586391 auc 0.99224516325 0.988857518322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold: ls 0.0471479450083 0.0532214287679 auc 0.992797657863 0.990232299845\n",
      "6 fold: ls 0.0500588056685 0.0564641601017 auc 0.991662678216 0.988940174206\n",
      "7 fold: ls 0.0467136652514 0.0558244867396 auc 0.992936720931 0.989251971205\n",
      "8 fold: ls 0.0513266940686 0.0532900755642 auc 0.991197151025 0.990162676287\n",
      "9 fold: ls 0.0515648355983 0.0549728513341 auc 0.991097675555 0.989316052274\n",
      "this class avg train 0.0496074267612 avg val 0.0541179372507\n",
      "this class auc train 0.991848353779 auc val 0.989697454596\n",
      "========================\n",
      "0 fold: ls 0.0151310989899 0.0172610237061 auc 0.995314508152 0.992524875605\n",
      "1 fold: ls 0.0142515362292 0.018592272802 auc 0.995962677218 0.989179431234\n",
      "2 fold: ls 0.0150166476656 0.0178492368463 auc 0.995353101123 0.992341035344\n",
      "3 fold: ls 0.0155334030559 0.0185983350783 auc 0.994893978705 0.988174138877\n",
      "4 fold: ls 0.0153116284233 0.0191693899836 auc 0.995055008767 0.988475233354\n",
      "5 fold: ls 0.0154819862724 0.0170451455379 auc 0.994951471634 0.992459740424\n",
      "6 fold: ls 0.0147454443793 0.0170099803494 auc 0.995656747065 0.989670044801\n",
      "7 fold: ls 0.01534452866 0.0195225941166 auc 0.995104159291 0.986490624323\n",
      "8 fold: ls 0.0138765984926 0.0171321008576 auc 0.996323197152 0.992431714719\n",
      "9 fold: ls 0.0155492757128 0.0169129211337 auc 0.994988694847 0.991519437821\n",
      "this class avg train 0.0150242147881 avg val 0.0179093000412\n",
      "this class auc train 0.995360354395 auc val 0.99032662765\n",
      "========================\n",
      "all loss avg 0.0318820623553 0.0357432179815\n",
      "all auc avg 0.994571218245 0.991539112398\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999358      0.349618  0.979421  0.168217  0.927857   \n",
      "1  0000247867823ef7  0.000489      0.000033  0.000061  0.000028  0.000047   \n",
      "2  00013b17ad220c46  0.000306      0.000033  0.000155  0.000035  0.000447   \n",
      "3  00017563c3f7919a  0.000073      0.000033  0.000031  0.000031  0.000042   \n",
      "4  00017695ad8997eb  0.002110      0.000040  0.000187  0.000037  0.000348   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.442885  \n",
      "1       0.000030  \n",
      "2       0.000070  \n",
      "3       0.000034  \n",
      "4       0.000056  \n",
      "save done\n",
      "0 fold: ls 0.0665567091213 0.0823448242689 auc 0.991712719645 0.986032197742\n",
      "1 fold: ls 0.0691957172164 0.0720656456315 auc 0.990886769773 0.989538723723\n",
      "2 fold: ls 0.0674933624924 0.0755804402111 auc 0.991441225578 0.988139393083\n",
      "3 fold: ls 0.0655992690781 0.0809070337124 auc 0.992023952882 0.986163704924\n",
      "4 fold: ls 0.0711457008029 0.0743942057472 auc 0.990180090626 0.988882165936\n",
      "5 fold: ls 0.0706074126656 0.0763352773051 auc 0.990374275776 0.987455583332\n",
      "6 fold: ls 0.0708333119499 0.0775290898001 auc 0.99024789662 0.987820581048\n",
      "7 fold: ls 0.0681858743187 0.0723475177078 auc 0.991287078989 0.988874232662\n",
      "8 fold: ls 0.0693679559916 0.0765814223575 auc 0.990774455311 0.988332364789\n",
      "9 fold: ls 0.0644734024251 0.0733475402894 auc 0.992370864088 0.989307844826\n",
      "this class avg train 0.0683458716062 avg val 0.0761432997031\n",
      "this class auc train 0.991129932929 auc val 0.988054679206\n",
      "========================\n",
      "0 fold: ls 0.0181067929566 0.0209248184524 auc 0.994068776132 0.991424943031\n",
      "1 fold: ls 0.0172667158963 0.0201646799983 auc 0.994825625413 0.992055165211\n",
      "2 fold: ls 0.0178347909606 0.0196139220261 auc 0.994298240175 0.992723762502\n",
      "3 fold: ls 0.0170974328196 0.0203054618361 auc 0.994951501879 0.992125585517\n",
      "4 fold: ls 0.0180002176881 0.0216039504096 auc 0.994164700449 0.99063845107\n",
      "5 fold: ls 0.0183209685962 0.0191055309207 auc 0.993923590465 0.993217436169\n",
      "6 fold: ls 0.0183707031006 0.0209081152267 auc 0.993912181907 0.991500256995\n",
      "7 fold: ls 0.0182699854862 0.0197608127664 auc 0.993935393066 0.992508728072\n",
      "8 fold: ls 0.0184478675962 0.0200835641155 auc 0.993829358382 0.99175864536\n",
      "9 fold: ls 0.0182630736996 0.0214037847584 auc 0.99399349443 0.990715934838\n",
      "this class avg train 0.01799785488 avg val 0.020387464051\n",
      "this class auc train 0.99419028623 auc val 0.991866890877\n",
      "========================\n",
      "0 fold: ls 0.0345667312087 0.0360390969276 auc 0.996376814985 0.996007590941\n",
      "1 fold: ls 0.0365513530916 0.0377894499755 auc 0.995907362112 0.995055708534\n",
      "2 fold: ls 0.0359771353967 0.0388962990023 auc 0.996029767514 0.995128601903\n",
      "3 fold: ls 0.0338282302402 0.0381170371823 auc 0.9965544605 0.995202214001\n",
      "4 fold: ls 0.0353524321157 0.0397788648823 auc 0.996187838808 0.994826322434\n",
      "5 fold: ls 0.0336470160442 0.0405783040911 auc 0.99659486051 0.994766414715\n",
      "6 fold: ls 0.0344953425077 0.0379677373786 auc 0.996394902095 0.995233773231\n",
      "7 fold: ls 0.0354508693839 0.0417811563471 auc 0.996153548717 0.994246744622\n",
      "8 fold: ls 0.0357308536684 0.0400447188898 auc 0.996099686388 0.994848719306\n",
      "9 fold: ls 0.0342380154056 0.0396340820628 auc 0.996456236709 0.995128553562\n",
      "this class avg train 0.0349837979063 avg val 0.0390626746739\n",
      "this class auc train 0.996275547834 auc val 0.995044464325\n",
      "========================\n",
      "0 fold: ls 0.00514462785819 0.00727853886116 auc 0.998437874835 0.996058558559\n",
      "1 fold: ls 0.00482918818 0.00739146018892 auc 0.998695513905 0.992626492772\n",
      "2 fold: ls 0.00475878614278 0.00790618278457 auc 0.998754399355 0.993933322858\n",
      "3 fold: ls 0.0053416456316 0.00749767557951 auc 0.998292845504 0.992954721646\n",
      "4 fold: ls 0.00418747899389 0.00652390354304 auc 0.999187750288 0.996563789888\n",
      "5 fold: ls 0.00507236506751 0.00716140506649 auc 0.998508521804 0.99404294215\n",
      "6 fold: ls 0.00559105401119 0.00622418704838 auc 0.99811407082 0.990823459467\n",
      "7 fold: ls 0.00495285795847 0.00634154436154 auc 0.998601539213 0.996287478786\n",
      "8 fold: ls 0.00416942053369 0.00666036693149 auc 0.999196562164 0.994298690825\n",
      "9 fold: ls 0.00470602739633 0.00745097179123 auc 0.99882550974 0.994831642199\n",
      "this class avg train 0.00487534517737 avg val 0.00704362361563\n",
      "this class auc train 0.998661458763 auc val 0.994242109915\n",
      "========================\n",
      "0 fold: ls 0.0501058684595 0.0553626292297 auc 0.991656067883 0.989392301798\n",
      "1 fold: ls 0.0497412825551 0.0514351105377 auc 0.991811944712 0.990800538064\n",
      "2 fold: ls 0.0511130938168 0.054215799076 auc 0.991279253482 0.988683373543\n",
      "3 fold: ls 0.0491860151153 0.051950540913 auc 0.992008898452 0.990587219633\n",
      "4 fold: ls 0.0511698826786 0.0537562699776 auc 0.991236461502 0.989994706008\n",
      "5 fold: ls 0.0465063273527 0.0549035119993 auc 0.993004236894 0.989363241824\n",
      "6 fold: ls 0.0505857221629 0.0551414578484 auc 0.991489726624 0.989430504305\n",
      "7 fold: ls 0.0503403604178 0.0544338102629 auc 0.991558655309 0.989047246847\n",
      "8 fold: ls 0.0496149414196 0.0540243613187 auc 0.991837084556 0.990200203501\n",
      "9 fold: ls 0.0475399587397 0.0550554500511 auc 0.992643593281 0.989468087753\n",
      "this class avg train 0.0495903452718 avg val 0.0540278941214\n",
      "this class auc train 0.99185259227 auc val 0.989696742328\n",
      "========================\n",
      "0 fold: ls 0.0160233586349 0.0170848146571 auc 0.994378270121 0.986631001656\n",
      "1 fold: ls 0.0151880095355 0.0185182112721 auc 0.99524187678 0.986756326907\n",
      "2 fold: ls 0.0136869032672 0.0173041641375 auc 0.996390873571 0.993177284339\n",
      "3 fold: ls 0.015217956051 0.0199052989246 auc 0.995233734685 0.987603785675\n",
      "4 fold: ls 0.0145690170523 0.0171210363386 auc 0.995777187526 0.99278673588\n",
      "5 fold: ls 0.0153594135758 0.0194586698516 auc 0.99507931253 0.989550573976\n",
      "6 fold: ls 0.0151879502026 0.0188666394181 auc 0.995188025395 0.989935824482\n",
      "7 fold: ls 0.0145059019864 0.0156407742894 auc 0.995835558129 0.990741744346\n",
      "8 fold: ls 0.0151014079516 0.0186204718099 auc 0.995275206826 0.991009104704\n",
      "9 fold: ls 0.0152478287823 0.016864548191 auc 0.995180806091 0.992783980056\n",
      "this class avg train 0.015008774704 avg val 0.017938462889\n",
      "this class auc train 0.995358085165 auc val 0.990097636202\n",
      "========================\n",
      "all loss avg 0.0318003315909 0.035767236509\n",
      "all auc avg 0.994577983865 0.991500420475\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999436      0.355888  0.978453  0.179008  0.926853   \n",
      "1  0000247867823ef7  0.000446      0.000037  0.000059  0.000031  0.000033   \n",
      "2  00013b17ad220c46  0.000326      0.000037  0.000145  0.000038  0.000332   \n",
      "3  00017563c3f7919a  0.000073      0.000037  0.000026  0.000033  0.000023   \n",
      "4  00017695ad8997eb  0.002185      0.000044  0.000188  0.000038  0.000315   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.428361  \n",
      "1       0.000037  \n",
      "2       0.000068  \n",
      "3       0.000043  \n",
      "4       0.000067  \n",
      "save done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.0713002624315 0.0745211933959 auc 0.990129096623 0.988552578411\n",
      "1 fold: ls 0.0700230176996 0.0769229482502 auc 0.990577017869 0.987693999141\n",
      "2 fold: ls 0.0671226651999 0.0743063235485 auc 0.991564980808 0.988630223367\n",
      "3 fold: ls 0.0704626287644 0.0749775225588 auc 0.990467728786 0.988610653577\n",
      "4 fold: ls 0.0684948920808 0.0756727906381 auc 0.991097624006 0.988742413333\n",
      "5 fold: ls 0.0702684492237 0.080350797028 auc 0.990507487591 0.986199305797\n",
      "6 fold: ls 0.0659937793439 0.0789634133154 auc 0.991852464011 0.986878531552\n",
      "7 fold: ls 0.0700270946978 0.0776834570371 auc 0.990566359715 0.987416679258\n",
      "8 fold: ls 0.0704257264783 0.0764521456008 auc 0.990463456605 0.987522350973\n",
      "9 fold: ls 0.0658498602048 0.0728265957378 auc 0.991960824338 0.989627035966\n",
      "this class avg train 0.0689968376125 avg val 0.0762677187111\n",
      "this class auc train 0.990918704035 auc val 0.987987377137\n",
      "========================\n",
      "0 fold: ls 0.0180050671276 0.0194959889691 auc 0.994169655714 0.992781127358\n",
      "1 fold: ls 0.0183171389827 0.0203495184265 auc 0.99393005813 0.992133893531\n",
      "2 fold: ls 0.0183077506759 0.0222772720053 auc 0.993944990093 0.989747515508\n",
      "3 fold: ls 0.0155880006609 0.0204789526732 auc 0.996242260095 0.992088001646\n",
      "4 fold: ls 0.0173801214185 0.0204706363361 auc 0.994717656029 0.991879114445\n",
      "5 fold: ls 0.0163631162243 0.0200048587873 auc 0.995602301909 0.992218981624\n",
      "6 fold: ls 0.0180870872818 0.0193983067723 auc 0.994083417465 0.992948266986\n",
      "7 fold: ls 0.0179089609383 0.018739205489 auc 0.994278275604 0.993542679667\n",
      "8 fold: ls 0.0168320784953 0.0215818195808 auc 0.995177366359 0.99064745595\n",
      "9 fold: ls 0.0182441963428 0.0204718719187 auc 0.993984920652 0.991532505774\n",
      "this class avg train 0.0175033518148 avg val 0.0203268430958\n",
      "this class auc train 0.994613090205 auc val 0.991951954249\n",
      "========================\n",
      "0 fold: ls 0.0336704275003 0.0364575063439 auc 0.996587410983 0.99587635082\n",
      "1 fold: ls 0.0326976308322 0.0389397256623 auc 0.996805999536 0.995078730369\n",
      "2 fold: ls 0.0336069579461 0.0379782343561 auc 0.996615413196 0.995467374178\n",
      "3 fold: ls 0.0321092963696 0.037340794038 auc 0.996945716213 0.995568081794\n",
      "4 fold: ls 0.035874435009 0.0381833809961 auc 0.996063221227 0.995376142162\n",
      "5 fold: ls 0.0328830344905 0.0396151463326 auc 0.996766927375 0.995058592098\n",
      "6 fold: ls 0.0344518303676 0.0395638224176 auc 0.996384322624 0.994605916847\n",
      "7 fold: ls 0.032481259406 0.0420721333564 auc 0.996851223266 0.994038359734\n",
      "8 fold: ls 0.0361007100209 0.0398991034044 auc 0.996006303456 0.99472162097\n",
      "9 fold: ls 0.0361409262532 0.0391020183744 auc 0.995993272819 0.995298846026\n",
      "this class avg train 0.0340016508195 avg val 0.0389151865282\n",
      "this class auc train 0.99650198107 auc val 0.9951090015\n",
      "========================\n",
      "0 fold: ls 0.00432357219235 0.00698939099307 auc 0.999068666233 0.993794521265\n",
      "1 fold: ls 0.00462719613506 0.00719082565194 auc 0.998855838901 0.991322281584\n",
      "2 fold: ls 0.00506313708386 0.00640020166685 auc 0.998527514553 0.996337471192\n",
      "3 fold: ls 0.00523294217919 0.00672652814594 auc 0.998382866281 0.994985804681\n",
      "4 fold: ls 0.0049847609151 0.00616584633076 auc 0.998625788382 0.997149150376\n",
      "5 fold: ls 0.00506695270875 0.0080333601417 auc 0.998502755927 0.994806398894\n",
      "6 fold: ls 0.00439920944366 0.00604523187094 auc 0.999061932345 0.993356747753\n",
      "7 fold: ls 0.00495936424821 0.00722579228012 auc 0.998670161276 0.991929358644\n",
      "8 fold: ls 0.00535491281681 0.0085622668848 auc 0.99816392368 0.993506953778\n",
      "9 fold: ls 0.00471147202698 0.00690029158157 auc 0.99882282794 0.991166514872\n",
      "this class avg train 0.004872351975 avg val 0.00702397355477\n",
      "this class auc train 0.998668227552 auc val 0.993835520304\n",
      "========================\n",
      "0 fold: ls 0.049291095268 0.0576659024118 auc 0.991960172381 0.988651961358\n",
      "1 fold: ls 0.0473432255905 0.0559218810366 auc 0.992711607591 0.989097085819\n",
      "2 fold: ls 0.050707454214 0.0551110980477 auc 0.991413626799 0.989592570161\n",
      "3 fold: ls 0.0496718801962 0.0539725437517 auc 0.991840631389 0.989287817594\n",
      "4 fold: ls 0.0504680345103 0.055327035133 auc 0.991536972217 0.989112262419\n",
      "5 fold: ls 0.0507508958644 0.055780658537 auc 0.99140422621 0.98923390377\n",
      "6 fold: ls 0.0512882354721 0.0496535618482 auc 0.991236573093 0.991108970907\n",
      "7 fold: ls 0.0465789288843 0.0515269075347 auc 0.993005706576 0.990736892929\n",
      "8 fold: ls 0.0515323469073 0.0538380003086 auc 0.991113652934 0.989812408323\n",
      "9 fold: ls 0.0459502241604 0.0526112337823 auc 0.99321820195 0.990509970554\n",
      "this class avg train 0.0493582321067 avg val 0.0541408822392\n",
      "this class auc train 0.991944137114 auc val 0.989714384383\n",
      "========================\n",
      "0 fold: ls 0.0134752966628 0.0196104209787 auc 0.996550594785 0.988080873573\n",
      "1 fold: ls 0.0151880280275 0.0176347411112 auc 0.99524374696 0.990446583867\n",
      "2 fold: ls 0.0149944371362 0.0171299512024 auc 0.995405730176 0.992118633466\n",
      "3 fold: ls 0.0155481361437 0.0181030265531 auc 0.994929609399 0.990495010082\n",
      "4 fold: ls 0.0152396400196 0.0198400012583 auc 0.995148170444 0.987179159509\n",
      "5 fold: ls 0.0159273215226 0.0185602125277 auc 0.994499423382 0.983070430549\n",
      "6 fold: ls 0.0154301247383 0.0170096070375 auc 0.995015017542 0.993279861262\n",
      "7 fold: ls 0.0151582886993 0.0176315231225 auc 0.995261001456 0.989561655466\n",
      "8 fold: ls 0.0152865732231 0.0174206540146 auc 0.995132664437 0.991869445047\n",
      "9 fold: ls 0.0148442284974 0.0157737925039 auc 0.99555215878 0.994279752872\n",
      "this class avg train 0.015109207467 avg val 0.017871393031\n",
      "this class auc train 0.995273811736 auc val 0.990038140569\n",
      "========================\n",
      "all loss avg 0.0316402719659 0.0357576661933\n",
      "all auc avg 0.994653325285 0.991439396357\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999348      0.353274  0.979649  0.188311  0.928347   \n",
      "1  0000247867823ef7  0.000393      0.000026  0.000047  0.000026  0.000033   \n",
      "2  00013b17ad220c46  0.000313      0.000026  0.000143  0.000035  0.000419   \n",
      "3  00017563c3f7919a  0.000088      0.000027  0.000022  0.000028  0.000026   \n",
      "4  00017695ad8997eb  0.002276      0.000032  0.000168  0.000035  0.000321   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.439195  \n",
      "1       0.000044  \n",
      "2       0.000083  \n",
      "3       0.000048  \n",
      "4       0.000074  \n",
      "save done\n",
      "0 fold: ls 0.0686970038147 0.0741216813711 auc 0.99102628924 0.989030407468\n",
      "1 fold: ls 0.0684330725579 0.0750303270386 auc 0.99114605704 0.987946186699\n",
      "2 fold: ls 0.0687679320565 0.0764140196524 auc 0.991017833752 0.988216766237\n",
      "3 fold: ls 0.0695899377289 0.0734964619613 auc 0.990771586971 0.988986556641\n",
      "4 fold: ls 0.0701661597798 0.0734732762947 auc 0.990582318986 0.988572652224\n",
      "5 fold: ls 0.0709657008583 0.0746447887595 auc 0.990263192545 0.987994875164\n",
      "6 fold: ls 0.0698714836784 0.0789246591355 auc 0.990607483033 0.987452727537\n",
      "7 fold: ls 0.0693495241475 0.0778803500066 auc 0.990821431474 0.987319212854\n",
      "8 fold: ls 0.0691820291689 0.0779092884854 auc 0.990803277301 0.987784603599\n",
      "9 fold: ls 0.065240140283 0.0805640588005 auc 0.9921140062 0.986745203735\n",
      "this class avg train 0.0690262984074 avg val 0.0762458911506\n",
      "this class auc train 0.990915347654 auc val 0.988004919216\n",
      "========================\n",
      "0 fold: ls 0.0183669172525 0.0206036340362 auc 0.993887489908 0.991455010128\n",
      "1 fold: ls 0.0158761377748 0.0199242158098 auc 0.996009254827 0.992519227117\n",
      "2 fold: ls 0.0181476606946 0.021053040499 auc 0.994071770857 0.991121107102\n",
      "3 fold: ls 0.0170310328994 0.0197261099839 auc 0.995034572406 0.992550481074\n",
      "4 fold: ls 0.0184327018657 0.019973953776 auc 0.993815839525 0.99223952399\n",
      "5 fold: ls 0.0180625862747 0.0212012339639 auc 0.994133907863 0.991130952807\n",
      "6 fold: ls 0.0181115958026 0.0195326865134 auc 0.99410404498 0.992644889584\n",
      "7 fold: ls 0.0179462963109 0.0201706630566 auc 0.994195070042 0.992034551581\n",
      "8 fold: ls 0.0181172427059 0.0200966508498 auc 0.994058252043 0.992147621374\n",
      "9 fold: ls 0.0182397828843 0.0208363002123 auc 0.99398205538 0.991294820329\n",
      "this class avg train 0.0178331954465 avg val 0.0203118488701\n",
      "this class auc train 0.994329225783 auc val 0.991913818509\n",
      "========================\n",
      "0 fold: ls 0.0333340458824 0.0379236648279 auc 0.9966753639 0.99530401547\n",
      "1 fold: ls 0.0368368638776 0.0408499778363 auc 0.995820188532 0.994668996518\n",
      "2 fold: ls 0.0364913942452 0.0395652755138 auc 0.995900668778 0.994924524106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold: ls 0.0344202729367 0.0366884972097 auc 0.996415733252 0.995703716001\n",
      "4 fold: ls 0.0329938976553 0.0373351584105 auc 0.996749302015 0.995341058949\n",
      "5 fold: ls 0.0356999499202 0.0427748949979 auc 0.996094779308 0.994205239928\n",
      "6 fold: ls 0.0338227045117 0.0389521266285 auc 0.996543826399 0.994898055074\n",
      "7 fold: ls 0.0334576228473 0.0372640887143 auc 0.996641026217 0.995731046451\n",
      "8 fold: ls 0.0353406227497 0.0409626934516 auc 0.996198989724 0.994038281424\n",
      "9 fold: ls 0.0305495793496 0.0372661136498 auc 0.99728777726 0.995600778014\n",
      "this class avg train 0.0342946953976 avg val 0.038958249124\n",
      "this class auc train 0.996432765539 auc val 0.995041571194\n",
      "========================\n",
      "0 fold: ls 0.00491689034836 0.00771127436019 auc 0.998647664909 0.994066886654\n",
      "1 fold: ls 0.005444802568 0.00739306230796 auc 0.998273659875 0.988899800964\n",
      "2 fold: ls 0.00512184742316 0.00676702169781 auc 0.998504061074 0.995839880578\n",
      "3 fold: ls 0.00389091029882 0.00681826025854 auc 0.99935543987 0.996422360509\n",
      "4 fold: ls 0.00529784387646 0.0077908435556 auc 0.998309225469 0.992666624762\n",
      "5 fold: ls 0.00548481493847 0.00715731690586 auc 0.99804393826 0.995387830788\n",
      "6 fold: ls 0.00497002125939 0.00583762354799 auc 0.998640828389 0.996854505835\n",
      "7 fold: ls 0.00399534344729 0.00710921440009 auc 0.999282976596 0.991110901586\n",
      "8 fold: ls 0.00521920922516 0.0079877218995 auc 0.998338273029 0.990338668197\n",
      "9 fold: ls 0.0039995972072 0.00529419735262 auc 0.999308201165 0.998367042341\n",
      "this class avg train 0.00483412805923 avg val 0.00698665362861\n",
      "this class auc train 0.998670426864 auc val 0.993995450221\n",
      "========================\n",
      "0 fold: ls 0.0509710668767 0.0538656782214 auc 0.991348069578 0.989522467868\n",
      "1 fold: ls 0.0502577404213 0.0523853992656 auc 0.991634105091 0.989787066378\n",
      "2 fold: ls 0.0498839865798 0.050570932768 auc 0.99176638969 0.991247168302\n",
      "3 fold: ls 0.0502955644256 0.0543438371687 auc 0.991582562892 0.989810405924\n",
      "4 fold: ls 0.0503184275791 0.0544380566947 auc 0.991579504151 0.989767402326\n",
      "5 fold: ls 0.0488777916999 0.0562274026437 auc 0.992089611485 0.989239425317\n",
      "6 fold: ls 0.0499926843802 0.0557755356278 auc 0.991717990344 0.988845554971\n",
      "7 fold: ls 0.0496095232791 0.0556003086027 auc 0.991851671901 0.989181272613\n",
      "8 fold: ls 0.051360175402 0.0506079330896 auc 0.991166574936 0.991253143428\n",
      "9 fold: ls 0.0507232397656 0.0577402738805 auc 0.991411524055 0.988111537583\n",
      "this class avg train 0.0502290200409 avg val 0.0541555357963\n",
      "this class auc train 0.991614800412 auc val 0.989676544471\n",
      "========================\n",
      "0 fold: ls 0.0143954240963 0.0179700635405 auc 0.995930711855 0.990512497326\n",
      "1 fold: ls 0.0149932216388 0.0188327177288 auc 0.995389037493 0.986058182304\n",
      "2 fold: ls 0.014777929812 0.018156358817 auc 0.995572020643 0.991717323627\n",
      "3 fold: ls 0.0157596242096 0.017734877184 auc 0.994697242919 0.989775791107\n",
      "4 fold: ls 0.0158476839564 0.0188242568089 auc 0.994552791606 0.985891829287\n",
      "5 fold: ls 0.0142612180123 0.0172833895502 auc 0.996031367765 0.989425934122\n",
      "6 fold: ls 0.0157207923739 0.0168274990535 auc 0.994729505158 0.991282336151\n",
      "7 fold: ls 0.014812082683 0.0173095144045 auc 0.995527696445 0.992609653877\n",
      "8 fold: ls 0.0150418682362 0.0190944162783 auc 0.995327538453 0.989096936195\n",
      "9 fold: ls 0.0145020470976 0.0163505610738 auc 0.995811265169 0.993806452778\n",
      "this class avg train 0.0150111892116 avg val 0.0178383654439\n",
      "this class auc train 0.995356917751 auc val 0.990017693677\n",
      "========================\n",
      "all loss avg 0.0318714210939 0.0357494240023\n",
      "all auc avg 0.994553247334 0.991441666215\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999437      0.361043  0.979030  0.189841  0.929412   \n",
      "1  0000247867823ef7  0.000497      0.000030  0.000068  0.000041  0.000034   \n",
      "2  00013b17ad220c46  0.000314      0.000030  0.000154  0.000046  0.000328   \n",
      "3  00017563c3f7919a  0.000080      0.000031  0.000038  0.000042  0.000027   \n",
      "4  00017695ad8997eb  0.002235      0.000036  0.000171  0.000044  0.000315   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.433176  \n",
      "1       0.000040  \n",
      "2       0.000079  \n",
      "3       0.000044  \n",
      "4       0.000068  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "for r in [9,42,666,2333,2017,2018]:\n",
    "    lgb_res = simple_ens('lgb',10,r,0.05,0.6)\n",
    "    sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "    sample_submission[list_classes] = lgb_res\n",
    "    out_f = \"../results/lgb_log_csv_fold10_stratified_rnd{}.gz\".format(r)\n",
    "    sample_submission.to_csv(out_f, index=False, compression='gzip')\n",
    "    print(sample_submission.head())\n",
    "    print('save done')\n",
    "    \n",
    "# rnd 9 all loss avg 0.0316776831549 0.0357680948057 all auc avg 0.994637538501 0.991248050457\n",
    "# rnd 42 all loss avg 0.031767752013 0.0357328049327 all auc avg 0.994570341031 0.991432648525\n",
    "# rnd 666 all loss avg 0.0318820623553 0.0357432179815 all auc avg 0.994571218245 0.991539112398 PUB 9866\n",
    "# rnd 2333 all loss avg 0.0318003315909 0.035767236509 all auc avg 0.994577983865 0.991500420475\n",
    "# rnd 2017 all loss avg 0.0316402719659 0.0357576661933 all auc avg 0.994653325285 0.991439396357\n",
    "# rnd 2018 all loss avg 0.0318714210939 0.0357494240023 all auc avg 0.994553247334 0.991441666215"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
