{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/fasttext_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lgb1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 37) (153164, 37)\n",
      "file path ../features/pool_gru_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/tilli_lr_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/wordbatch_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "(159571, 271)\n",
      "(159571, 271)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat or 'tfidf' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss',max_d=3):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    cls_auc_res = [0,0,0,0,0,0]\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for i in range(6):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = test_x\n",
    "\n",
    "            # share params\n",
    "            params = {\n",
    "                    'application': 'binary',\n",
    "                    #'num_leaves': 8,\n",
    "                    #'lambda_l1': 1,\n",
    "                    'lambda_l2': 1.0,\n",
    "                    'max_depth': max_d,\n",
    "                    'metric': met, # or auc\n",
    "                    'data_random_seed': 2,\n",
    "                    'learning_rate':lr,\n",
    "                    # 'bagging_fraction': bagging_fraction,\n",
    "                    # 'bagging_freq':bag_frec,\n",
    "                    'feature_fraction': feature_fraction,\n",
    "\n",
    "                    }\n",
    "            if met == 'auc':\n",
    "                s_round = 60\n",
    "            else:\n",
    "                s_round = 30\n",
    "            # train for each class\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_auc_l = train_auc_l/k\n",
    "        val_auc_l = val_auc_l/k\n",
    "        print(list_classes[i], lr, feature_fraction, max_d)\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        cls_auc_res[i] = val_auc_l\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/6\n",
    "        all_val_loss_l += val_loss_l/6\n",
    "        all_train_auc_l += train_auc_l/6\n",
    "        all_val_auc_l += val_auc_l/6\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred, cls_auc_res\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_res,tmp_auc_res = simple_ens('lgb',10,666,0.05,0.6)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# add 7 base fasttext NN models\n",
    "# all loss avg 0.0319116484218 0.0358161833583 all auc avg 0.994546891137 0.991249510282 PUB 9866\n",
    "\n",
    "# rm tfidf test\n",
    "# all loss avg 0.0319555637279 0.0357756335619 all auc avg 0.994512718368 0.991251471241\n",
    "\n",
    "# change to stratified\n",
    "# all loss avg 0.0316412744167 0.0357232681944 all auc avg 0.994584962017 0.991293307537 pub 9866\n",
    "\n",
    "# change to base model 5 fold, add word batch, tilli, lgb feat\n",
    "# feat dim 217\n",
    "# all loss avg 0.031983129767200906 0.035387924581 all auc avg 0.9945427088311004 0.99188514127 PUB 9870\n",
    "\n",
    "# add more base models\n",
    "# feat dim 247, all loss avg 0.031885221777487156 0.0353958  all auc avg 0.9945986685511962 0.9919487331094685\n",
    "\n",
    "# change early stopping to 30, and test later part\n",
    "# all loss avg 0.03208696729295824 0.035406264613808025 all auc avg 0.9945261773637045 0.991946174432887\n",
    "\n",
    "# add fasttext lstm v1\n",
    "# all loss avg 0.031977558955160815 0.03537909655655411 all auc avg 0.9945299073418443 0.9919307178575658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.095 max depth 3 feature fraction 0.4\n",
      "0 fold: ls 0.07055900792121056 0.07845851850483938 auc 0.9904317585515335 0.9869234386296798\n",
      "1 fold: ls 0.07112099324841784 0.07132731780698526 auc 0.99019070161143 0.9898649322033591\n",
      "2 fold: ls 0.06935924063822202 0.07556019794440967 auc 0.9908043936706946 0.9885162021559386\n",
      "3 fold: ls 0.06497260357247332 0.07280091655739042 auc 0.992192585088142 0.9892247916632692\n",
      "4 fold: ls 0.06894506079113848 0.07792721171645994 auc 0.9909000263031499 0.9878534906782339\n",
      "5 fold: ls 0.06577492446228168 0.07645398182283704 auc 0.9919903108446425 0.9876221260056249\n",
      "6 fold: ls 0.06797329110174438 0.07772442055333846 auc 0.9912493848473811 0.9876035860073693\n",
      "7 fold: ls 0.07310551182282535 0.07122791366621857 auc 0.9894850349134301 0.9899879336591975\n",
      "8 fold: ls 0.0704343227293608 0.07448200464055142 auc 0.9904142517680505 0.9892556209668459\n",
      "9 fold: ls 0.06958413131063694 0.0776744481375048 auc 0.9906593620485566 0.9876591212710091\n",
      "toxic 0.095 0.4 3\n",
      "this class avg train 0.06918290875983113 avg val 0.0753636931350535\n",
      "this class auc train 0.9908317809647013 auc val 0.9884511243240528\n",
      "========================\n",
      "0 fold: ls 0.0173626262569297 0.02123369200332841 auc 0.9947173251883356 0.9911215027218636\n",
      "1 fold: ls 0.017957597326474017 0.020465733507910026 auc 0.9941950054951483 0.9917521205215851\n",
      "2 fold: ls 0.01809987325505951 0.020987466155493108 auc 0.9941158535972697 0.9913418628940371\n",
      "3 fold: ls 0.01813292551800216 0.019753649343837335 auc 0.9940495040250621 0.9926248575769084\n",
      "4 fold: ls 0.016990016919460005 0.020981375232007583 auc 0.9950395791348167 0.9912164514495505\n",
      "5 fold: ls 0.01724012973424655 0.019908817037307912 auc 0.9948294442475909 0.9923169161608706\n",
      "6 fold: ls 0.016811855881870636 0.018962973333904225 auc 0.9952142083792096 0.9930533741180855\n",
      "7 fold: ls 0.01697999780678863 0.019816391357856428 auc 0.9950624958600481 0.9924509987765371\n",
      "8 fold: ls 0.01811298513440045 0.021171274060080483 auc 0.9940965291486598 0.9910794303352718\n",
      "9 fold: ls 0.018224596911183798 0.01905961631974591 auc 0.993996070726569 0.993072484505656\n",
      "severe_toxic 0.095 0.4 3\n",
      "this class avg train 0.017591260474441546 avg val 0.02023409883514714\n",
      "this class auc train 0.9945316015802709 auc val 0.9920029999060367\n",
      "========================\n",
      "0 fold: ls 0.03539338693966496 0.03725131251832009 auc 0.9962086077642176 0.9956512223302404\n",
      "1 fold: ls 0.03420304709400305 0.03690920361374102 auc 0.9964650555604032 0.9955566292118114\n",
      "2 fold: ls 0.03492724574341849 0.039237561229174725 auc 0.9963021258996296 0.9953174874154636\n",
      "3 fold: ls 0.03582668954614773 0.03388668210861935 auc 0.9961037106765017 0.9964871366773065\n",
      "4 fold: ls 0.03458082386780181 0.041948888480961406 auc 0.9963891136744943 0.99453672930482\n",
      "5 fold: ls 0.03552231381693149 0.03774828154788253 auc 0.9961716643007614 0.9955292396653312\n",
      "6 fold: ls 0.036000173698471534 0.03730905838521062 auc 0.9960806710920049 0.9955060596853161\n",
      "7 fold: ls 0.0355504700677173 0.0385655493092969 auc 0.996162569040917 0.9954580551996768\n",
      "8 fold: ls 0.03333348066309105 0.038686749572848275 auc 0.996664331702565 0.9952571881431269\n",
      "9 fold: ls 0.034517271114544175 0.0389283295976646 auc 0.9963979419852574 0.9952733648787317\n",
      "obscene 0.095 0.4 3\n",
      "this class avg train 0.03498549025517916 avg val 0.03804716163637196\n",
      "this class auc train 0.9962945791696752 auc val 0.9954573112511824\n",
      "========================\n",
      "0 fold: ls 0.005041276160286182 0.006636722844114922 auc 0.998526174586466 0.9967041169076053\n",
      "1 fold: ls 0.005122367268918162 0.006186816321047197 auc 0.9984779439029805 0.9969293421328305\n",
      "2 fold: ls 0.004371900357069308 0.007073806339137408 auc 0.9990235621384831 0.9953082442908024\n",
      "3 fold: ls 0.005215352706267624 0.006629164795256937 auc 0.998461233488476 0.9883805288411172\n",
      "4 fold: ls 0.0038583659528688146 0.006872901223354544 auc 0.9993433721320039 0.9961093825298049\n",
      "5 fold: ls 0.004881359813429125 0.0068849645804210415 auc 0.9986538137949673 0.9959443815869424\n",
      "6 fold: ls 0.0050223007160047775 0.0064039370589696505 auc 0.9985280526991455 0.9948116370188782\n",
      "7 fold: ls 0.005035967051101942 0.007565942768361033 auc 0.9984531612600602 0.9954231881325035\n",
      "8 fold: ls 0.0048519202369824025 0.0070100178355797455 auc 0.9986433337507542 0.9945795434940479\n",
      "9 fold: ls 0.0052181238125438584 0.007611001749782194 auc 0.9983084977673173 0.9907465732630933\n",
      "threat 0.095 0.4 3\n",
      "this class avg train 0.004861893407547219 avg val 0.006887527551602467\n",
      "this class auc train 0.9986419145520653 auc val 0.9944936938197625\n",
      "========================\n",
      "0 fold: ls 0.05061749578548859 0.0501484820351916 auc 0.9914450128443281 0.9913594323554705\n",
      "1 fold: ls 0.0509141123840465 0.05395330902283659 auc 0.9913171867254682 0.9898476320817536\n",
      "2 fold: ls 0.051629986925511226 0.055248032565830246 auc 0.9910685998611004 0.9890951199435164\n",
      "3 fold: ls 0.05086054257267935 0.051947248520800515 auc 0.9913377856261903 0.9905387419733711\n",
      "4 fold: ls 0.049748895432873905 0.05533610485546489 auc 0.9917857840573518 0.989095781437764\n",
      "5 fold: ls 0.04851206445541918 0.05273276563948131 auc 0.9922797144082939 0.9903355360401408\n",
      "6 fold: ls 0.05004023483398414 0.056110456808808884 auc 0.9916573564935981 0.9892575376644793\n",
      "7 fold: ls 0.04752931200953754 0.055501782302452264 auc 0.9926120202518228 0.9894813227974562\n",
      "8 fold: ls 0.04972964530070382 0.0522948464177982 auc 0.9917736859056229 0.9903643012989694\n",
      "9 fold: ls 0.050550955845766195 0.054928881705518726 auc 0.9914698605240029 0.9891704667857764\n",
      "insult 0.095 0.4 3\n",
      "this class avg train 0.050013324554601044 avg val 0.053820190987418325\n",
      "this class auc train 0.9916747006697779 auc val 0.9898545872378698\n",
      "========================\n",
      "0 fold: ls 0.01454592970860193 0.017053729695258486 auc 0.9956521244007974 0.9929140788907885\n",
      "1 fold: ls 0.015760753915519708 0.018035453127468844 auc 0.9945163883852586 0.990869864859472\n",
      "2 fold: ls 0.014556949722228589 0.017858196303342354 auc 0.9956584018721681 0.9920092260907893\n",
      "3 fold: ls 0.014936781205722373 0.018311036256926684 auc 0.9953415521319461 0.9886359814850437\n",
      "4 fold: ls 0.015052183508962981 0.018933349730195604 auc 0.9951790909505618 0.9887234177070456\n",
      "5 fold: ls 0.014817776378815234 0.0164196628127401 auc 0.9954435900831272 0.9935169212149676\n",
      "6 fold: ls 0.014327081039620762 0.01664445600192914 auc 0.995878524096511 0.9891055170171255\n"
     ]
    }
   ],
   "source": [
    "# find best params for each column, early stopping = 30\n",
    "\n",
    "best_pred = np.zeros((153164,6))\n",
    "val_auc_res = [0,0,0,0,0,0]\n",
    "for lr in [0.095,0.075,0.05]:\n",
    "    for max_d in [3,4]:\n",
    "        for s_rate in [0.4,0.5,0.6]:\n",
    "            print('learning rate',lr,'max depth',max_d,'feature fraction',s_rate)\n",
    "            lgb_res,tmp_auc_res = simple_ens('lgb',k=10,rnd=666,lr=lr,\n",
    "                                 feature_fraction=s_rate,bagging_fraction=0.9,\n",
    "                                 bag_frec=3,met='binary_logloss',max_d=max_d)\n",
    "            # check for each cls\n",
    "            for i in range(6):\n",
    "                # find better params for this class\n",
    "                if tmp_auc_res[i] > val_auc_res[i]:\n",
    "                    val_auc_res[i] = tmp_auc_res[i]\n",
    "                    best_pred[:,i] = lgb_res[:,i]\n",
    "                    print('FIND BETTER PARAMS',lr,max_d,s_rate,list_classes[i])\n",
    "            print('TEST PARAM DONE ------------------------------------------')\n",
    "\n",
    "print(val_auc_res)\n",
    "print(np.mean(val_auc_res))\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = best_pred\n",
    "sample_submission.to_csv(\"../results/lgb_grid_search_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "                \n",
    "            \n",
    "# best auc params\n",
    "# toxic 0.05,4,0.5\n",
    "# severe toxic 0.075 3 0.5\n",
    "# obs 0.075 3 0.6\n",
    "# threat 0.095 3 0.5\n",
    "# insult 0.075 0.5 4\n",
    "# hate 0.05 0.5 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def special_ens(model_name,k=3,rnd=233):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    params_list = [\n",
    "        [0.05,4,0.5],\n",
    "        [0.075,3,0.5],\n",
    "        [0.075,3,0.6],\n",
    "        [0.095,3,0.5],\n",
    "        [0.075,4,0.5],\n",
    "        [0.05,3,0.5],\n",
    "    ]\n",
    "    \n",
    "    for i in range(6):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        \n",
    "        # special params\n",
    "        params = {\n",
    "                'application': 'binary',\n",
    "                #'num_leaves': 8,\n",
    "                #'lambda_l1': 1,\n",
    "                'lambda_l2': 1.0,\n",
    "                'max_depth': params_list[i][1],\n",
    "                'metric': 'binary_logloss', # or auc\n",
    "                'data_random_seed': 2,\n",
    "                'learning_rate':params_list[i][0],\n",
    "                'feature_fraction': params_list[i][2],\n",
    "\n",
    "                }\n",
    "        print(params)\n",
    "            \n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = test_x\n",
    "            s_round = 30\n",
    "            # train for each class\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_auc_l = train_auc_l/k\n",
    "        val_auc_l = val_auc_l/k\n",
    "        print(list_classes[i])\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/6\n",
    "        all_val_loss_l += val_loss_l/6\n",
    "        all_train_auc_l += train_auc_l/6\n",
    "        all_val_auc_l += val_auc_l/6\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')\n",
    "\n",
    "lgb_res = special_ens('lgb',10,666)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10_stratified_special.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# best params changed when base models changed\n",
    "# all loss avg 0.03111512578966158 0.03534320053008906 all auc avg 0.9948524214184179 0.9918450388634261"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
