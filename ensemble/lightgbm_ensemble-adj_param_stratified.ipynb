{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/fasttext_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lgb1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_5_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 37) (153164, 37)\n",
      "file path ../features/pool_gru_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/tilli_lr_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/wordbatch_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "(159571, 295)\n",
      "(159571, 295)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import lightgbm as lgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(7200)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat or 'tfidf' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,feature_fraction=0.9,bagging_fraction=0.9,\n",
    "               bag_frec=3,met='binary_logloss',max_d=3):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    cls_auc_res = [0,0,0,0,0,0]\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for i in range(6):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = test_x\n",
    "\n",
    "            # share params\n",
    "            params = {\n",
    "                    'application': 'binary',\n",
    "                    #'num_leaves': 8,\n",
    "                    #'lambda_l1': 1,\n",
    "                    'lambda_l2': 1.0,\n",
    "                    'max_depth': max_d,\n",
    "                    'metric': met, # or auc\n",
    "                    'data_random_seed': 2,\n",
    "                    'learning_rate':lr,\n",
    "                    # 'bagging_fraction': bagging_fraction,\n",
    "                    # 'bagging_freq':bag_frec,\n",
    "                    'feature_fraction': feature_fraction,\n",
    "\n",
    "                    }\n",
    "            if met == 'auc':\n",
    "                s_round = 60\n",
    "            else:\n",
    "                s_round = 30\n",
    "            # train for each class\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_auc_l = train_auc_l/k\n",
    "        val_auc_l = val_auc_l/k\n",
    "        print(list_classes[i], lr, feature_fraction, max_d)\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        cls_auc_res[i] = val_auc_l\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/6\n",
    "        all_val_loss_l += val_loss_l/6\n",
    "        all_train_auc_l += train_auc_l/6\n",
    "        all_val_auc_l += val_auc_l/6\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred, cls_auc_res\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.07082459202841758 0.07788605946484535 auc 0.9903426793823865 0.9871873590023756\n",
      "1 fold: ls 0.06982598330960191 0.07139385538410228 auc 0.990686271422562 0.989887401222387\n",
      "2 fold: ls 0.06790106411808906 0.07565829379748586 auc 0.991320182628064 0.9884964511634059\n",
      "3 fold: ls 0.06983979218949386 0.07339745823793384 auc 0.9906588669020915 0.9889679834599027\n",
      "4 fold: ls 0.06741270193086214 0.07812503238333891 auc 0.9914377720980595 0.9878862189881131\n",
      "5 fold: ls 0.06807489243581936 0.07668913324607354 auc 0.9913034267747648 0.9875417104630684\n",
      "6 fold: ls 0.0688250142078539 0.07813235678803032 auc 0.9910154667707481 0.9874609776100283\n",
      "7 fold: ls 0.07193139366832126 0.07072960517919263 auc 0.9899497335563221 0.9901281492811761\n",
      "8 fold: ls 0.06672564410504497 0.0739717223905832 auc 0.9916703648527927 0.989441759131684\n",
      "9 fold: ls 0.06778541274279691 0.07780505430228057 auc 0.9912947133249533 0.9876472439696968\n",
      "toxic 0.05 0.6 3\n",
      "this class avg train 0.06891464907363011 avg val 0.07537885711738664\n",
      "this class auc train 0.9909679477712745 auc val 0.9884645254291836\n",
      "========================\n",
      "0 fold: ls 0.017381943163945143 0.02128573297742876 auc 0.9947101839216806 0.9910400050639321\n",
      "1 fold: ls 0.017859798697693663 0.020422923519407533 auc 0.9942941230414267 0.9918391568552982\n",
      "2 fold: ls 0.017267848644403762 0.021014631510461422 auc 0.9948282329315516 0.9913110045575388\n",
      "3 fold: ls 0.01801815952504452 0.01983723083089505 auc 0.9941751452257691 0.9925275351310291\n",
      "4 fold: ls 0.018142523805520873 0.021083257634571095 auc 0.9941011519985523 0.9911464267628814\n",
      "5 fold: ls 0.01792633683948203 0.01998809719105914 auc 0.9942422526691894 0.992201862985602\n",
      "6 fold: ls 0.018130080968998985 0.019186175478658644 auc 0.994091156149999 0.9929331379296205\n",
      "7 fold: ls 0.016973915611325302 0.020114920494496626 auc 0.9950829543973375 0.9921882309474414\n",
      "8 fold: ls 0.017211989789014562 0.02099263490377291 auc 0.9948639373557532 0.9912629696825646\n",
      "9 fold: ls 0.01772016499612809 0.01908788335614364 auc 0.994447179759533 0.9930382450612587\n",
      "severe_toxic 0.05 0.6 3\n",
      "this class avg train 0.01766327620415569 avg val 0.02030134878968948\n",
      "this class auc train 0.9944836317450791 auc val 0.9919488574977168\n",
      "========================\n",
      "0 fold: ls 0.03537622020878226 0.03720101652483477 auc 0.9962224153723095 0.9956607756087572\n",
      "1 fold: ls 0.03575205506312102 0.03699134562435597 auc 0.9961353853803399 0.9954530309537969\n",
      "2 fold: ls 0.03349529086450946 0.03895426626580067 auc 0.9966260158718254 0.9953802143208422\n",
      "3 fold: ls 0.03564296319815929 0.03385222277729969 auc 0.996155787602027 0.9964903474177815\n",
      "4 fold: ls 0.03523832109156944 0.042033118941546 auc 0.9962625008697376 0.9945260790437318\n",
      "5 fold: ls 0.034441778741143014 0.037479055190590665 auc 0.9964217145705279 0.9956160079689013\n",
      "6 fold: ls 0.03598896416585049 0.037587581958066774 auc 0.9960965622944223 0.9954031593686274\n",
      "7 fold: ls 0.03525056937791429 0.03836545303468943 auc 0.9962400385318388 0.9955185894042432\n",
      "8 fold: ls 0.03521562812440149 0.038895043060498416 auc 0.9962621551986172 0.9951675223420551\n",
      "9 fold: ls 0.03529600646507145 0.038818082471377684 auc 0.9962391504356745 0.995291005672652\n",
      "obscene 0.05 0.6 3\n",
      "this class avg train 0.03516977973005222 avg val 0.038017718584906005\n",
      "this class auc train 0.9962661726127319 auc val 0.9954506732101388\n",
      "========================\n",
      "0 fold: ls 0.004980505361827912 0.006610459378095535 auc 0.9985747788364507 0.996815420071234\n",
      "1 fold: ls 0.004698205729974276 0.0062445822181258145 auc 0.9988378589831942 0.9969214854389272\n",
      "2 fold: ls 0.00510920160246212 0.007324324176049543 auc 0.9984329697448492 0.9942331866750471\n",
      "3 fold: ls 0.005097765051668755 0.006527840850586299 auc 0.9985354671302757 0.9919254300500765\n",
      "4 fold: ls 0.005090601530855629 0.0067762984427114075 auc 0.9983980362233534 0.9962900978481781\n",
      "5 fold: ls 0.004914789247336507 0.0069736137019638135 auc 0.9986067772285847 0.9960845014352463\n",
      "6 fold: ls 0.00490086773261629 0.006301519877133354 auc 0.9986231653140405 0.9950630670270497\n",
      "7 fold: ls 0.004926786087376352 0.007478283142835504 auc 0.9985849968295795 0.995520093448153\n",
      "8 fold: ls 0.0046582078218919114 0.007026097276324503 auc 0.9988287505843244 0.9948256239275775\n",
      "9 fold: ls 0.004961004167453472 0.007412105951946705 auc 0.9985585775569163 0.9894747118919707\n",
      "threat 0.05 0.6 3\n",
      "this class avg train 0.004933793433346323 avg val 0.006867512501577249\n",
      "this class auc train 0.998598137843157 auc val 0.9947153617813459\n",
      "========================\n",
      "0 fold: ls 0.05067154422964428 0.050178711359788235 auc 0.9914357590444249 0.9913417813009245\n",
      "1 fold: ls 0.0512921454337875 0.054010597915508926 auc 0.9911920672087575 0.9893845219492118\n",
      "2 fold: ls 0.05140987913964329 0.055307640254450285 auc 0.9911799843664097 0.9889892554433845\n",
      "3 fold: ls 0.05057531041473272 0.05174864814253419 auc 0.9914660121299834 0.9905737512924587\n",
      "4 fold: ls 0.04957071912174118 0.05516895886178398 auc 0.9918605010215036 0.9891384479366648\n",
      "5 fold: ls 0.04697470719616327 0.05240652911659543 auc 0.9928441869015209 0.9904090730058933\n",
      "6 fold: ls 0.049252075366518176 0.05619891775392033 auc 0.991956079696063 0.989157773350873\n",
      "7 fold: ls 0.049324092048565187 0.05547220484515399 auc 0.991934240720648 0.9894958980995398\n",
      "8 fold: ls 0.0510255948304278 0.0524112498472526 auc 0.9912768065076918 0.9905087978282465\n",
      "9 fold: ls 0.05106735485000941 0.054882388949251286 auc 0.9912909749321319 0.9892235744956673\n",
      "insult 0.05 0.6 3\n",
      "this class avg train 0.05011634226312328 avg val 0.05377858470462392\n",
      "this class auc train 0.9916436612529136 auc val 0.9898222874702866\n",
      "========================\n",
      "0 fold: ls 0.014251098458792721 0.01708267501100955 auc 0.9958894094839649 0.9928746204931672\n",
      "1 fold: ls 0.014801582519849818 0.017614323674739914 auc 0.9954777724270293 0.9915074766937629\n",
      "2 fold: ls 0.014688958985968443 0.017724149219356465 auc 0.9955365205555147 0.9923105447635343\n",
      "3 fold: ls 0.015247138338296775 0.01817099078023645 auc 0.995088766501941 0.9883214352812777\n",
      "4 fold: ls 0.014731391772465303 0.018999442648654892 auc 0.9955083483533206 0.9893664102319212\n",
      "5 fold: ls 0.014336217322956932 0.016340046282493425 auc 0.9958681853487242 0.9937806519206279\n",
      "6 fold: ls 0.013958275254359572 0.016580176342816957 auc 0.99616914274925 0.9903036707854614\n",
      "7 fold: ls 0.015147368098357273 0.018544729918189725 auc 0.9951772908449502 0.9883865344316786\n",
      "8 fold: ls 0.014109343851479092 0.01675355756413769 auc 0.9960665758700303 0.9928295939012934\n",
      "9 fold: ls 0.015265503788550305 0.01676131431347292 auc 0.9951020545862713 0.99186447720211\n",
      "identity_hate 0.05 0.6 3\n",
      "this class avg train 0.01465368783910762 avg val 0.017457140575510798\n",
      "this class auc train 0.9955884066720996 auc val 0.9911545415704834\n",
      "========================\n",
      "all loss avg 0.031908588090569207 0.03530019371228235\n",
      "all auc avg 0.9945913263162094 0.9919260411598592\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999193      0.340420  0.976751  0.164673  0.928969   \n",
      "1  0000247867823ef7  0.000230      0.000017  0.000081  0.000039  0.000085   \n",
      "2  00013b17ad220c46  0.000505      0.000018  0.000150  0.000040  0.000248   \n",
      "3  00017563c3f7919a  0.000063      0.000018  0.000077  0.000041  0.000083   \n",
      "4  00017695ad8997eb  0.001803      0.000027  0.000197  0.000064  0.000217   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.413758  \n",
      "1       0.000029  \n",
      "2       0.000042  \n",
      "3       0.000031  \n",
      "4       0.000047  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "lgb_res,tmp_auc_res = simple_ens('lgb',10,666,0.05,0.6)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# add 7 base fasttext NN models\n",
    "# all loss avg 0.0319116484218 0.0358161833583 all auc avg 0.994546891137 0.991249510282 PUB 9866\n",
    "\n",
    "# rm tfidf test\n",
    "# all loss avg 0.0319555637279 0.0357756335619 all auc avg 0.994512718368 0.991251471241\n",
    "\n",
    "# change to stratified\n",
    "# all loss avg 0.0316412744167 0.0357232681944 all auc avg 0.994584962017 0.991293307537 pub 9866\n",
    "\n",
    "# change to base model 5 fold, add word batch, tilli, lgb feat\n",
    "# feat dim 217\n",
    "# all loss avg 0.031983129767200906 0.035387924581 all auc avg 0.9945427088311004 0.99188514127 PUB 9870\n",
    "\n",
    "# add more base models\n",
    "# feat dim 247, all loss avg 0.031885221777487156 0.0353958  all auc avg 0.9945986685511962 0.9919487331094685\n",
    "\n",
    "# change early stopping to 30, and test later part\n",
    "# all loss avg 0.03208696729295824 0.035406264613808025 all auc avg 0.9945261773637045 0.991946174432887\n",
    "\n",
    "# add fasttext lstm v1\n",
    "# all loss avg 0.031977558955160815 0.03537909655655411 all auc avg 0.9945299073418443 0.9919307178575658\n",
    "\n",
    "# add muse base model, feat dim 295, lower loss, but lower auc\n",
    "# all loss avg 0.03196610276261484 0.03530962013098028 all auc avg 0.9945635742334386 0.9918682952070021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate 0.095 max depth 3 feature fraction 0.4\n",
      "0 fold: ls 0.07032462456130593 0.07805699435609477 auc 0.9905121746503449 0.9870612878734342\n",
      "1 fold: ls 0.06974897663322285 0.07138105109791182 auc 0.9906984488470143 0.9899317956551441\n",
      "2 fold: ls 0.06815247974063551 0.07585130986072906 auc 0.9912312411011892 0.9884968588673801\n",
      "3 fold: ls 0.06864901949572397 0.0730807203164039 auc 0.9910716888088433 0.9891643608741898\n",
      "4 fold: ls 0.06727486101688862 0.07794403552131811 auc 0.9915146906352263 0.9878843151252116\n",
      "5 fold: ls 0.06704811250215989 0.07621279001221803 auc 0.9916172994110399 0.9877310088315667\n",
      "6 fold: ls 0.06929262102619256 0.07806146016691114 auc 0.9908240006973146 0.9874999161393723\n",
      "7 fold: ls 0.06995425345665494 0.07066819701767738 auc 0.9906007045766996 0.990189530449026\n",
      "8 fold: ls 0.06724442290862763 0.07405331140650659 auc 0.9915008233395682 0.9894236711804492\n",
      "9 fold: ls 0.06669899870358421 0.07776443032831963 auc 0.9916431737366077 0.987679249216744\n",
      "toxic 0.095 0.4 3\n",
      "this class avg train 0.06843883700449961 avg val 0.07530743000840903\n",
      "this class auc train 0.9911214245803845 auc val 0.9885061994212517\n",
      "========================\n",
      "0 fold: ls 0.018002547351737883 0.02123325378602072 auc 0.9941647813216226 0.9911005348778327\n",
      "1 fold: ls 0.018215475384347382 0.020580944891354768 auc 0.99400939137832 0.991715723509305\n",
      "2 fold: ls 0.018048883437247996 0.02099324612127644 auc 0.9941431737210406 0.9912852892771238\n",
      "3 fold: ls 0.01716053866358284 0.019882253547704926 auc 0.9949039073217492 0.9925219964552475\n",
      "4 fold: ls 0.018219769555563394 0.021124254586529386 auc 0.9940184564247702 0.9911337669325231\n",
      "5 fold: ls 0.01817983711374826 0.019934616977126122 auc 0.9940255850967308 0.9922456548516212\n",
      "6 fold: ls 0.018134067976173035 0.01926395588480971 auc 0.9940882492450718 0.9928188737372711\n",
      "7 fold: ls 0.017778395744093557 0.020257086389793476 auc 0.9943712843167352 0.9920401254437691\n",
      "8 fold: ls 0.01766880120758937 0.02104607402526404 auc 0.994455231910671 0.9911307895018677\n",
      "9 fold: ls 0.018266311671516523 0.01907671269208909 auc 0.9939511079848128 0.9930362543958869\n",
      "severe_toxic 0.095 0.4 3\n",
      "this class avg train 0.017967462810560025 avg val 0.02033923989019687\n",
      "this class auc train 0.9942131168721524 auc val 0.9919029008982448\n",
      "========================\n",
      "0 fold: ls 0.035358140881557636 0.03713726904097877 auc 0.9962259692843222 0.9956989104172629\n",
      "1 fold: ls 0.034635985506564854 0.0367922636621172 auc 0.9963818840600366 0.995606744771244\n",
      "2 fold: ls 0.03210049387533819 0.039080157859939776 auc 0.9969310196309867 0.9953378482087201\n",
      "3 fold: ls 0.035384994298766966 0.033588659335240384 auc 0.9962065761170128 0.9965644293809379\n",
      "4 fold: ls 0.034732233440242746 0.04192766785696639 auc 0.9963651661594181 0.9945753365012638\n",
      "5 fold: ls 0.03496413530286767 0.03739909409156419 auc 0.9962997617992396 0.9956240739754606\n",
      "6 fold: ls 0.0359047069043397 0.037496379791205084 auc 0.9961099709497023 0.9954709764723203\n",
      "7 fold: ls 0.03543053912618764 0.03826299800998392 auc 0.996202902334014 0.9955468595825723\n",
      "8 fold: ls 0.03489323588416826 0.03881636692909731 auc 0.9963320247594506 0.9952367490391272\n",
      "9 fold: ls 0.03501062010342673 0.03901160479138591 auc 0.9962974050376561 0.9951760660998196\n",
      "obscene 0.095 0.4 3\n",
      "this class avg train 0.03484150853234604 avg val 0.037951246136847895\n",
      "this class auc train 0.9963352680131837 auc val 0.9954837994448729\n",
      "========================\n",
      "0 fold: ls 0.00495705858341805 0.00669777093063318 auc 0.9985839555787203 0.9965810287031218\n",
      "1 fold: ls 0.00520239600914658 0.006152749536161126 auc 0.9983809627913147 0.9969385082757176\n",
      "2 fold: ls 0.004779329449249468 0.007275165083357486 auc 0.9987068102309794 0.9945513827781269\n",
      "3 fold: ls 0.00516169150522085 0.006541752622031404 auc 0.9984848167393006 0.9918854893456535\n",
      "4 fold: ls 0.003989286489285928 0.006823047725769915 auc 0.9992960188484098 0.9960635489345654\n",
      "5 fold: ls 0.004650743532952356 0.006823793808106081 auc 0.9988066501518943 0.9960727156536133\n",
      "6 fold: ls 0.004712546036647532 0.006335164182366264 auc 0.998782433466647 0.9952097345318164\n",
      "7 fold: ls 0.004943679607700142 0.0073622411334277795 auc 0.9985560618699765 0.9959299767427242\n",
      "8 fold: ls 0.005253738805446529 0.007106288585442391 auc 0.9980862082219455 0.9946758358376029\n",
      "9 fold: ls 0.005347096066629677 0.007511517196660653 auc 0.9982538571238564 0.9894352587789863\n",
      "threat 0.095 0.4 3\n",
      "this class avg train 0.004899756608569711 avg val 0.006862949080395628\n",
      "this class auc train 0.9985937775023045 auc val 0.9947343479581929\n",
      "========================\n",
      "0 fold: ls 0.04802762075922582 0.049879094061724194 auc 0.9924662403380297 0.9914736204571539\n",
      "1 fold: ls 0.04963118671867438 0.05396658319310486 auc 0.9918160658357068 0.9897478325174253\n",
      "2 fold: ls 0.05115161734678048 0.05539559523911268 auc 0.9912493703004083 0.9887652292629387\n",
      "3 fold: ls 0.051238149931453855 0.05185675857541278 auc 0.9912036194764905 0.9904926066341195\n",
      "4 fold: ls 0.048903570945018904 0.05502072407092688 auc 0.9921095282934332 0.9892975688796246\n",
      "5 fold: ls 0.048816967098655524 0.05250378226275848 auc 0.9921620470462282 0.9904639538358521\n",
      "6 fold: ls 0.049889107885938595 0.056297299089355636 auc 0.9917096231348882 0.9891174493264214\n",
      "7 fold: ls 0.04770541017963539 0.0554935373654312 auc 0.9925476690852355 0.9894716059294004\n",
      "8 fold: ls 0.04957966939934645 0.052440157222569846 auc 0.9918515701412942 0.9903950434591112\n",
      "9 fold: ls 0.05118894809043755 0.05491879655950306 auc 0.9912335661850449 0.9891730635349982\n",
      "insult 0.095 0.4 3\n",
      "this class avg train 0.04961322483551669 avg val 0.05377723276398997\n",
      "this class auc train 0.991834929983676 auc val 0.9898397973837045\n",
      "========================\n",
      "0 fold: ls 0.01458560358637654 0.017098672272191688 auc 0.9956590660225257 0.9928871754378649\n",
      "1 fold: ls 0.01331775601951396 0.017710516705862735 auc 0.9966387878392302 0.9912653456174499\n",
      "2 fold: ls 0.014142467792895482 0.017794859819269118 auc 0.9959937172154264 0.9920536167881133\n",
      "3 fold: ls 0.015066082351330027 0.017995019637231102 auc 0.9952450252414928 0.9897838621431201\n",
      "4 fold: ls 0.015271884135162563 0.01890844454100813 auc 0.9950460107805998 0.9894946500241908\n",
      "5 fold: ls 0.015096732129586475 0.01632220737998123 auc 0.9952571724501522 0.9938321335994725\n",
      "6 fold: ls 0.014045735380287593 0.01659036591427166 auc 0.9960525704194556 0.990082375894212\n",
      "7 fold: ls 0.015325949724346723 0.018717930871803415 auc 0.9949942592646583 0.98778678011417\n",
      "8 fold: ls 0.014689689555408596 0.016913661922252365 auc 0.9955673026596195 0.9925401040537611\n",
      "9 fold: ls 0.015253750555549565 0.016803768685278695 auc 0.9951066971543446 0.9919629308476046\n",
      "identity_hate 0.095 0.4 3\n",
      "this class avg train 0.014679565123045754 avg val 0.017485544774915016\n",
      "this class auc train 0.9955560609047506 auc val 0.9911688974519958\n",
      "========================\n",
      "all loss avg 0.03174005915242298 0.035287273775792403\n",
      "all auc avg 0.9946090963094086 0.9919393237597104\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.095 3 0.4 toxic\n",
      "FIND BETTER PARAMS 0.095 3 0.4 severe_toxic\n",
      "FIND BETTER PARAMS 0.095 3 0.4 obscene\n",
      "FIND BETTER PARAMS 0.095 3 0.4 threat\n",
      "FIND BETTER PARAMS 0.095 3 0.4 insult\n",
      "FIND BETTER PARAMS 0.095 3 0.4 identity_hate\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 3 feature fraction 0.5\n",
      "0 fold: ls 0.07080900482874483 0.07787315164029524 auc 0.9903672513256064 0.98714015594224\n",
      "1 fold: ls 0.07084527138479328 0.07129405258686765 auc 0.9903255675384232 0.9899145814873405\n",
      "2 fold: ls 0.06893166762132152 0.07592374549565435 auc 0.9909768152357435 0.9884087495084901\n",
      "3 fold: ls 0.060562129021655337 0.07249664651035026 auc 0.9935116658170781 0.9891823451495005\n",
      "4 fold: ls 0.06584522072920715 0.07786941828213276 auc 0.9919263140756662 0.9879326823089252\n",
      "5 fold: ls 0.06969418994686713 0.07663304387224837 auc 0.9907456484906383 0.9875478753524639\n",
      "6 fold: ls 0.06710725173598034 0.07810399566908072 auc 0.9916116027776957 0.9874133357074202\n",
      "7 fold: ls 0.07130288605244096 0.07074300184646834 auc 0.9901115526157553 0.9900983653614736\n",
      "8 fold: ls 0.06815747780002332 0.07431892115603163 auc 0.9912105193885872 0.9892992768491496\n",
      "9 fold: ls 0.06972986036882624 0.07792940496709458 auc 0.9906370901292824 0.9876710892387435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic 0.095 0.5 3\n",
      "this class avg train 0.06829849594898602 avg val 0.07531853820262238\n",
      "this class auc train 0.9911424027394478 auc val 0.9884608456905746\n",
      "========================\n",
      "0 fold: ls 0.017842469680742313 0.021186128634271842 auc 0.9942820118060772 0.9911127990884923\n",
      "1 fold: ls 0.018097047918148472 0.020467768860946287 auc 0.9941101190180066 0.9918363875174073\n",
      "2 fold: ls 0.017929866923086842 0.021078370672597376 auc 0.9942357259092655 0.9912841024180276\n",
      "3 fold: ls 0.016913751360810816 0.019734735555816205 auc 0.9951219365154628 0.9926814311938219\n",
      "4 fold: ls 0.018107165914831837 0.021094702022251197 auc 0.9941034678863316 0.9910985567793393\n",
      "5 fold: ls 0.017462436858332694 0.019882285176737846 auc 0.9946358165689045 0.992271133755487\n",
      "6 fold: ls 0.01822093995974973 0.019126004205842095 auc 0.9940124272708062 0.9929884784269603\n",
      "7 fold: ls 0.01765011661513987 0.020214662092221416 auc 0.9944722031416281 0.9920751611543152\n",
      "8 fold: ls 0.017601558304689537 0.020983408587054095 auc 0.9945110533014986 0.9912442574280682\n",
      "9 fold: ls 0.018182065567263456 0.019157457625328878 auc 0.994045853004043 0.9929351285949923\n",
      "severe_toxic 0.095 0.5 3\n",
      "this class avg train 0.01780074191027956 avg val 0.020292552343306725\n",
      "this class auc train 0.9943530614422024 auc val 0.991952743635691\n",
      "========================\n",
      "0 fold: ls 0.035544516435248794 0.03706295914410323 auc 0.9961808924718828 0.9957206010578298\n",
      "1 fold: ls 0.03490242987650238 0.03687922653525654 auc 0.9963192600789805 0.9954905393178097\n",
      "2 fold: ls 0.03334112754685577 0.03915346584271782 auc 0.9966541356131525 0.9953433299607507\n",
      "3 fold: ls 0.03562450096645957 0.03379120281799673 auc 0.9961579442997449 0.9965144671267162\n",
      "4 fold: ls 0.03519020401173152 0.042066834534339806 auc 0.9962727801136013 0.9945395484915784\n",
      "5 fold: ls 0.033769901114472575 0.03743767964439052 auc 0.9965624631485578 0.9956387963951998\n",
      "6 fold: ls 0.031485546128000926 0.0372903216743883 auc 0.9970711431002632 0.9953868707340221\n",
      "7 fold: ls 0.035390810120383434 0.03822923965299337 auc 0.9962085897117212 0.9955617386237984\n",
      "8 fold: ls 0.034837708464923574 0.03890629693693954 auc 0.9963439540390264 0.9951476314132583\n",
      "9 fold: ls 0.034677785234222464 0.0387719202849614 auc 0.9963701560985697 0.9952888887773818\n",
      "obscene 0.095 0.5 3\n",
      "this class avg train 0.0344764529898801 avg val 0.03795891470680872\n",
      "this class auc train 0.99641413186755 auc val 0.9954632411898343\n",
      "========================\n",
      "0 fold: ls 0.004893688011262022 0.006616347668793322 auc 0.9986544946790326 0.9966805468258957\n",
      "1 fold: ls 0.005020634881746092 0.006254078912985664 auc 0.9985753960332759 0.9968389901529435\n",
      "2 fold: ls 0.004745393694196382 0.007281927516491683 auc 0.9987461484075754 0.9945068615126755\n",
      "3 fold: ls 0.005106185360703896 0.006611076645338569 auc 0.9985105601639264 0.9913302480776081\n",
      "4 fold: ls 0.005167780250831118 0.006741059846984108 auc 0.9982839368176774 0.9962416451903534\n",
      "5 fold: ls 0.004711588772261755 0.007005413188036009 auc 0.9987490725870372 0.9958527143964633\n",
      "6 fold: ls 0.005124836425801525 0.00635831499317704 auc 0.9983947472369264 0.9950931862467786\n",
      "7 fold: ls 0.005000321212352669 0.007544432654656426 auc 0.9985029670718049 0.9955881890753661\n",
      "8 fold: ls 0.004957366808860144 0.007157456916608041 auc 0.998548984656285 0.9943936457752403\n",
      "9 fold: ls 0.005139774891805221 0.0073685404931202745 auc 0.998394493584294 0.9893924621818508\n",
      "threat 0.095 0.5 3\n",
      "this class avg train 0.004986757030982082 avg val 0.006893864883619113\n",
      "this class auc train 0.9985360801237837 auc val 0.9945918489435174\n",
      "========================\n",
      "0 fold: ls 0.0504253611497079 0.05003776388859885 auc 0.9915391900967693 0.9914151461105776\n",
      "1 fold: ls 0.051415350777085284 0.053993240896766825 auc 0.9911240492996665 0.9895324227285351\n",
      "2 fold: ls 0.05101236816661042 0.055376789067558656 auc 0.9912987726349174 0.9888221978323501\n",
      "3 fold: ls 0.050612342774080984 0.0516979280889262 auc 0.9914364632052818 0.9905314222232633\n",
      "4 fold: ls 0.050739620945006704 0.05536909774692461 auc 0.991412215251873 0.9889870236954675\n",
      "5 fold: ls 0.04825478199248212 0.052574517166608034 auc 0.9923717919359915 0.9904184429036912\n",
      "6 fold: ls 0.048487097287324366 0.056443379818737725 auc 0.9922526842319676 0.9890546208152948\n",
      "7 fold: ls 0.04998065131279566 0.05558548858055145 auc 0.9916669343251765 0.9894350839080874\n",
      "8 fold: ls 0.05087052066624191 0.05248211176322897 auc 0.9913399003938429 0.990418665500419\n",
      "9 fold: ls 0.05039029694930711 0.05473373753363155 auc 0.9915357644370946 0.9893090159216746\n",
      "insult 0.095 0.5 3\n",
      "this class avg train 0.05021883920206425 avg val 0.05382940545515329\n",
      "this class auc train 0.9915977765812581 auc val 0.9897924041639362\n",
      "========================\n",
      "0 fold: ls 0.014718048590249774 0.017115771180526543 auc 0.9955168294700198 0.9929521921157637\n",
      "1 fold: ls 0.015037555464785166 0.017611223375397833 auc 0.9952531312105005 0.9914751925502546\n",
      "2 fold: ls 0.01464997523490409 0.01769444646609614 auc 0.995580854676032 0.9922764670564977\n",
      "3 fold: ls 0.015148078028969243 0.018025237442516655 auc 0.9951599000619888 0.989187950660861\n",
      "4 fold: ls 0.01447799927754758 0.018942461772683467 auc 0.9957012187286888 0.9893099129807815\n",
      "5 fold: ls 0.01521919337356733 0.01643118064794192 auc 0.9951189690027824 0.9936521735203534\n",
      "6 fold: ls 0.012858140893130927 0.016704546852977894 auc 0.9969526705178878 0.9900092130934316\n",
      "7 fold: ls 0.01465470676661805 0.018602914852749022 auc 0.9955306757963102 0.9868334055928896\n",
      "8 fold: ls 0.014156751702708296 0.016891506627368987 auc 0.9960334114961871 0.9927483019004263\n",
      "9 fold: ls 0.015160404325551989 0.01687640653872662 auc 0.9951876644300706 0.9916973769781053\n",
      "identity_hate 0.095 0.5 3\n",
      "this class avg train 0.014608085365803245 avg val 0.01748956957569851\n",
      "this class auc train 0.9956035325390467 auc val 0.9910142186449367\n",
      "========================\n",
      "all loss avg 0.031731562074665876 0.035297140861201455\n",
      "all auc avg 0.9946078308822148 0.9918792170447484\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.095 3 0.5 severe_toxic\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 3 feature fraction 0.6\n",
      "0 fold: ls 0.07031911221013332 0.0782698556221364 auc 0.99052179841898 0.9869772555542871\n",
      "1 fold: ls 0.06867487291947107 0.07124056228639762 auc 0.991076549931047 0.9899263596021534\n",
      "2 fold: ls 0.06814636228636264 0.07593359888765322 auc 0.9912174178444442 0.9883616823496796\n",
      "3 fold: ls 0.06731398592011241 0.0732221521535312 auc 0.9915003233507927 0.989069275247295\n",
      "4 fold: ls 0.06914636170698106 0.07846415065925699 auc 0.9908621114093694 0.987715641938147\n",
      "5 fold: ls 0.06874084615829737 0.07681385136260477 auc 0.9910582348805907 0.9874360007419626\n",
      "6 fold: ls 0.06820666260881665 0.07813570972892377 auc 0.9912268383312606 0.9875214932522566\n",
      "7 fold: ls 0.07099269089815982 0.0708624894560404 auc 0.9902772130406694 0.9900738400942604\n",
      "8 fold: ls 0.06966908138071402 0.07433788676059436 auc 0.9906732093710633 0.9893204927919516\n",
      "9 fold: ls 0.06757838015106447 0.0775505337139897 auc 0.9913735273355311 0.9877649743189627\n",
      "toxic 0.095 0.6 3\n",
      "this class avg train 0.06887883562401129 avg val 0.07548307906311284\n",
      "this class auc train 0.990978722391375 auc val 0.9884167015890956\n",
      "========================\n",
      "0 fold: ls 0.017748187959704877 0.02137833074045112 auc 0.9943725838489837 0.990916571717939\n",
      "1 fold: ls 0.016564107194704313 0.02036638654635733 auc 0.9954254427989687 0.9919586340043043\n",
      "2 fold: ls 0.018022722895898145 0.02104095364099581 auc 0.9941805563159457 0.9912583871376124\n",
      "3 fold: ls 0.017904608110927245 0.01977261130166828 auc 0.9942590195741774 0.9925979554373972\n",
      "4 fold: ls 0.017771079907650963 0.02098393969648553 auc 0.9943786884801566 0.9911594822129384\n",
      "5 fold: ls 0.016752154790927717 0.019883293278204747 auc 0.9952442798859651 0.9922918353648779\n",
      "6 fold: ls 0.018378844035625466 0.01924584012883547 auc 0.9939023910010568 0.9928885470252891\n",
      "7 fold: ls 0.017970930069902958 0.020248962980129546 auc 0.994201927105071 0.9920747630212408\n",
      "8 fold: ls 0.018065435777763632 0.020963719852998566 auc 0.9941513317758397 0.9913063661876726\n",
      "9 fold: ls 0.01826472561727042 0.019146209486344146 auc 0.9939729183430961 0.9930171440083162\n",
      "severe_toxic 0.095 0.6 3\n",
      "this class avg train 0.01774427963603757 avg val 0.020303024765247056\n",
      "this class auc train 0.9944089139129261 auc val 0.9919469686117587\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.03581681017570127 0.03722214042156464 auc 0.996131063250916 0.9957113610015595\n",
      "1 fold: ls 0.03544066955716216 0.0368681308233893 auc 0.9962031988174622 0.9955860721029781\n",
      "2 fold: ls 0.034362875880456945 0.03898989419179695 auc 0.9964254415336992 0.9954020630182214\n",
      "3 fold: ls 0.035632861539899065 0.033742809850886415 auc 0.9961600647382544 0.9965342014340264\n",
      "4 fold: ls 0.03524006625201157 0.04213699024641663 auc 0.9962659416268901 0.9945094771661536\n",
      "5 fold: ls 0.03222712711150447 0.03759990237522869 auc 0.9969063894758798 0.9955722322633999\n",
      "6 fold: ls 0.03585500576261543 0.03760058301718717 auc 0.996124129928869 0.9952542123348818\n",
      "7 fold: ls 0.03535871901453186 0.03842921659266206 auc 0.9962144975454159 0.9955120896125498\n",
      "8 fold: ls 0.034077808183623826 0.03885094447785947 auc 0.9965091045808782 0.9951542878264383\n",
      "9 fold: ls 0.0351975065174004 0.03852646900785779 auc 0.9962578669114952 0.9953594519530633\n",
      "obscene 0.095 0.6 3\n",
      "this class avg train 0.0349209449994907 avg val 0.03799670810048491\n",
      "this class auc train 0.9963197698409759 auc val 0.9954595448713273\n",
      "========================\n",
      "0 fold: ls 0.003993257734452604 0.006571223785031457 auc 0.9992740465973857 0.99679708778546\n",
      "1 fold: ls 0.0050227756853038355 0.006358200474585483 auc 0.9985738936462674 0.9967447098261052\n",
      "2 fold: ls 0.005105603753984493 0.007289487489555846 auc 0.9984342203805212 0.9945605489210141\n",
      "3 fold: ls 0.00520874402143954 0.0065453885891530355 auc 0.9984514396177824 0.9913197718272675\n",
      "4 fold: ls 0.004661090672740019 0.006801530295390865 auc 0.9988245974605452 0.9961827162821884\n",
      "5 fold: ls 0.004841989410081609 0.006987532311975548 auc 0.9986488112872167 0.9959286672114317\n",
      "6 fold: ls 0.004671892971693649 0.0063659999338148325 auc 0.9987841226251081 0.9949242567100384\n",
      "7 fold: ls 0.004578358501246137 0.007610057043536856 auc 0.9988804696250329 0.995276520627737\n",
      "8 fold: ls 0.004715044506268134 0.0071157991484999735 auc 0.9987575492238955 0.9943388126351603\n",
      "9 fold: ls 0.00509885740567727 0.00747430551669679 auc 0.9984033410906193 0.9888768969257331\n",
      "threat 0.095 0.6 3\n",
      "this class avg train 0.004789761466288729 avg val 0.00691195245882407\n",
      "this class auc train 0.9987032491554373 auc val 0.9944949988752135\n",
      "========================\n",
      "0 fold: ls 0.05010779573795484 0.050168240299671214 auc 0.991653374713483 0.991361774675505\n",
      "1 fold: ls 0.050807680493772295 0.05403850309937736 auc 0.9913619983238264 0.9897484180974339\n",
      "2 fold: ls 0.051689685756406915 0.05541556581500174 auc 0.9910917126625778 0.9887089717549666\n",
      "3 fold: ls 0.05032029304308791 0.051863389976884035 auc 0.9915516526590216 0.9904034311642335\n",
      "4 fold: ls 0.05028567371600127 0.055182627652189474 auc 0.991577868525865 0.9890759540647454\n",
      "5 fold: ls 0.0455748886304692 0.052262431639288724 auc 0.9933337161501882 0.9905497051326627\n",
      "6 fold: ls 0.05017634082212809 0.05646039808431288 auc 0.9915981733178254 0.989030275812981\n",
      "7 fold: ls 0.04966004868966552 0.055668633923681855 auc 0.9918109094647027 0.989425031975616\n",
      "8 fold: ls 0.049636121136278445 0.05229036562908495 auc 0.9918236072739407 0.9905927314643831\n",
      "9 fold: ls 0.04994849937835784 0.0547921366635301 auc 0.9917092588063222 0.9890932344379542\n",
      "insult 0.095 0.6 3\n",
      "this class avg train 0.04982070274041223 avg val 0.05381422927830223\n",
      "this class auc train 0.9917512271897753 auc val 0.9897989528580482\n",
      "========================\n",
      "0 fold: ls 0.014658268691811175 0.01714644755927387 auc 0.9955756137238384 0.9928643075028798\n",
      "1 fold: ls 0.01457681031436039 0.017694671345981162 auc 0.9956376603731372 0.9914855055405419\n",
      "2 fold: ls 0.014176198693023782 0.01791431961537374 auc 0.9959657701018473 0.9917670950144762\n",
      "3 fold: ls 0.01306370819401908 0.018012488552167125 auc 0.9967789541322534 0.9899251052709693\n",
      "4 fold: ls 0.013703964288162547 0.01882525494438563 auc 0.9962964308348593 0.989386139430732\n",
      "5 fold: ls 0.014724470659706886 0.016432624224574952 auc 0.9955677740981588 0.993519179183338\n",
      "6 fold: ls 0.014529595022199216 0.01666266029347309 auc 0.9956583852915003 0.9908984572584725\n",
      "7 fold: ls 0.0154558139200324 0.018621187304232494 auc 0.9948484126554409 0.98664801466869\n",
      "8 fold: ls 0.013245378444656754 0.016920130223867017 auc 0.9967171657010847 0.9926484933882507\n",
      "9 fold: ls 0.014878398476172002 0.0169634776764746 auc 0.9953827078222551 0.9915402124430956\n",
      "identity_hate 0.095 0.6 3\n",
      "this class avg train 0.014301260670414423 avg val 0.017519326173980367\n",
      "this class auc train 0.9958428874734375 auc val 0.9910682509701445\n",
      "========================\n",
      "all loss avg 0.03174263085610916 0.03533805330665858\n",
      "all auc avg 0.9946674616606546 0.9918642362959313\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 4 feature fraction 0.4\n",
      "0 fold: ls 0.06781900269599246 0.0777701279157749 auc 0.991424187031417 0.9871859999891279\n",
      "1 fold: ls 0.06475567671008807 0.0715911235802156 auc 0.9923550415764822 0.9897877855513336\n",
      "2 fold: ls 0.06916428909367756 0.07589206967983053 auc 0.9909574071158223 0.9884236533537728\n",
      "3 fold: ls 0.06513830521377499 0.07313823766548098 auc 0.9922099957165501 0.9890305433697368\n",
      "4 fold: ls 0.06383160135929303 0.07816354772619659 auc 0.9925959652981707 0.987796420121256\n",
      "5 fold: ls 0.0690448441926233 0.07650052098557357 auc 0.9910382888311549 0.9876097055666956\n",
      "6 fold: ls 0.068113119059296 0.07836595121122461 auc 0.99129200049871 0.9874532261682148\n",
      "7 fold: ls 0.06443633579514355 0.07075208130882406 auc 0.99244157072461 0.9901130533218749\n",
      "8 fold: ls 0.06573889199689815 0.07419182746624842 auc 0.9920483191858053 0.9892904368729822\n",
      "9 fold: ls 0.06719166855119311 0.07781367902044906 auc 0.9915667156814683 0.9875637401948231\n",
      "toxic 0.095 0.4 4\n",
      "this class avg train 0.06652337346679801 avg val 0.07541791665598183\n",
      "this class auc train 0.9917929491660191 auc val 0.9884254564509819\n",
      "========================\n",
      "0 fold: ls 0.015988807589558514 0.021346932402843962 auc 0.9959424469783008 0.9910324882896568\n",
      "1 fold: ls 0.016521280286192517 0.020904536404190682 auc 0.9955439672397703 0.9914862640840612\n",
      "2 fold: ls 0.016177093309161183 0.021042549412264286 auc 0.9957951418114888 0.9913466103304216\n",
      "3 fold: ls 0.016289200291256457 0.019979259955553677 auc 0.9957100004641577 0.9924863906823649\n",
      "4 fold: ls 0.016838701936676293 0.021193857471337858 auc 0.9953136356580647 0.9911100297506013\n",
      "5 fold: ls 0.014947222620759452 0.01994963153507472 auc 0.9967716965171086 0.9922970107672254\n",
      "6 fold: ls 0.01656376763554879 0.019132853719596908 auc 0.9955026580817021 0.9929012872836694\n",
      "7 fold: ls 0.015743107810186636 0.020180484970994828 auc 0.9961256491948897 0.9921372699139197\n",
      "8 fold: ls 0.016575676225815697 0.021185118089611866 auc 0.9954571418770027 0.9911295951026448\n",
      "9 fold: ls 0.017061263743807217 0.019145037498376906 auc 0.9951519291043943 0.9931003538208631\n",
      "severe_toxic 0.095 0.4 4\n",
      "this class avg train 0.01627061214489628 avg val 0.020406026145984572\n",
      "this class auc train 0.9957314266926881 auc val 0.9919027300025428\n",
      "========================\n",
      "0 fold: ls 0.03276874666881565 0.03747708051479348 auc 0.9968079710849658 0.9955757357688451\n",
      "1 fold: ls 0.0324809222048989 0.0367908906954641 auc 0.9968711761845417 0.9955115252083222\n",
      "2 fold: ls 0.029690663875860775 0.038843718985352126 auc 0.9974450267855959 0.9954257911734397\n",
      "3 fold: ls 0.03254399149457381 0.03376549602080037 auc 0.9968523603545721 0.9964445356329544\n",
      "4 fold: ls 0.033526147325678025 0.04196283655370933 auc 0.9966628629628952 0.9945869264912715\n",
      "5 fold: ls 0.03126701760992477 0.03735969931906723 auc 0.9971179285986373 0.9956158513474146\n",
      "6 fold: ls 0.03404437426132769 0.037544327264050534 auc 0.9965478410184355 0.9954604045219756\n",
      "7 fold: ls 0.0334487412420775 0.038054354554211654 auc 0.9966632888877303 0.9955979181872002\n",
      "8 fold: ls 0.03176982261602551 0.03897022818321905 auc 0.9970256513304462 0.995162432143741\n",
      "9 fold: ls 0.033522941307112676 0.038623786107934634 auc 0.9966477210627811 0.9952944554279077\n",
      "obscene 0.095 0.4 4\n",
      "this class avg train 0.03250633686062953 avg val 0.037939241819860255\n",
      "this class auc train 0.99686418282706 auc val 0.9954675575903073\n",
      "========================\n",
      "0 fold: ls 0.004044737886193261 0.006695966966584744 auc 0.9992483192349877 0.9967787554996858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold: ls 0.003974395158865864 0.006295550305220559 auc 0.9993185903419417 0.9968429184998953\n",
      "2 fold: ls 0.003800983484315241 0.007470415894276413 auc 0.9993937340554103 0.9943706788183533\n",
      "3 fold: ls 0.004138734992535417 0.006512420880988574 auc 0.9992476829293646 0.9919149537997359\n",
      "4 fold: ls 0.003389169733367736 0.00688753627567146 auc 0.9995937655110224 0.9959902151821819\n",
      "5 fold: ls 0.003983060077070462 0.006978652700091342 auc 0.999263575636618 0.9959312862740168\n",
      "6 fold: ls 0.003486393333997919 0.006222674983988498 auc 0.999545413350069 0.995166519999162\n",
      "7 fold: ls 0.004049546513380976 0.007573689534726002 auc 0.9992079308588462 0.9957230707985\n",
      "8 fold: ls 0.003963451177583543 0.007162302425739552 auc 0.9992941440008463 0.9939536432609402\n",
      "9 fold: ls 0.004355945431126567 0.007603329627634998 auc 0.9990487229256584 0.9819097446514281\n",
      "threat 0.095 0.4 4\n",
      "this class avg train 0.003918641778843698 avg val 0.0069402539594922135\n",
      "this class auc train 0.9993161878844766 auc val 0.99385817867839\n",
      "========================\n",
      "0 fold: ls 0.04757974224085217 0.049893565650371195 auc 0.9926651634552737 0.9914929445974388\n",
      "1 fold: ls 0.04894458512136642 0.05387176588529991 auc 0.9921540609804914 0.9898260911028647\n",
      "2 fold: ls 0.049389747642100586 0.0551966858184366 auc 0.992041737766248 0.9890593159087031\n",
      "3 fold: ls 0.04868852760438999 0.05174879917070561 auc 0.992249192957264 0.9905209654373948\n",
      "4 fold: ls 0.04921221526421886 0.05501662466506402 auc 0.9920774786183743 0.9890315725399083\n",
      "5 fold: ls 0.0471406428202419 0.05256712886957447 auc 0.9928368994324883 0.9904464689372829\n",
      "6 fold: ls 0.04633185108226225 0.05615299936642194 auc 0.9930845442241164 0.9891747562906315\n",
      "7 fold: ls 0.043393831590443716 0.05552994106539108 auc 0.9940965636831395 0.9894596273765386\n",
      "8 fold: ls 0.04844681394056125 0.05236654671716523 auc 0.9923307597997754 0.9904850920208346\n",
      "9 fold: ls 0.04902749501168301 0.05451255374352323 auc 0.9921569400046334 0.9893996508461256\n",
      "insult 0.095 0.4 4\n",
      "this class avg train 0.047815545231812015 avg val 0.05368566109519533\n",
      "this class auc train 0.9925693340921804 auc val 0.9898896485057722\n",
      "========================\n",
      "0 fold: ls 0.0128767507563318 0.017066043096785416 auc 0.9970126155666084 0.9930346960380629\n",
      "1 fold: ls 0.01353775455758599 0.01793961245282984 auc 0.9966039602391022 0.9908420646247843\n",
      "2 fold: ls 0.01349747879771401 0.017996984867884015 auc 0.9965972381482453 0.9917644046691839\n",
      "3 fold: ls 0.013703309035584274 0.01817622096650427 auc 0.9964228139238106 0.9890942369665101\n",
      "4 fold: ls 0.01386009105775498 0.01926047527157713 auc 0.9963065848323753 0.9860097560888118\n",
      "5 fold: ls 0.013645637885471993 0.016640600909949472 auc 0.9965186520231117 0.9933855074558116\n",
      "6 fold: ls 0.013823576018843525 0.0165545563253007 auc 0.9963784109477976 0.9917867981790591\n",
      "7 fold: ls 0.014013882882027567 0.018853284429219196 auc 0.9962292628951354 0.9863239757207891\n",
      "8 fold: ls 0.012331862895307582 0.01701007001010904 auc 0.9973601280593538 0.9923436483849988\n",
      "9 fold: ls 0.013628651816874721 0.0169590134636661 auc 0.9965329290522859 0.9916851831779753\n",
      "identity_hate 0.095 0.4 4\n",
      "this class avg train 0.013491899570349644 avg val 0.017645686179382516\n",
      "this class auc train 0.9965962595687827 auc val 0.9906270271305987\n",
      "========================\n",
      "all loss avg 0.03008773484222153 0.035339130975982784\n",
      "all auc avg 0.9954783900385344 0.9916950997264322\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.095 4 0.4 insult\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 4 feature fraction 0.5\n",
      "0 fold: ls 0.06876368151979119 0.07769564747596891 auc 0.9911424363773047 0.9872156717783686\n",
      "1 fold: ls 0.06848752641886581 0.0716349899268877 auc 0.9912062450407237 0.9897798579740557\n",
      "2 fold: ls 0.067721452996483 0.07578821444451929 auc 0.9914122227846308 0.9884383306968477\n",
      "3 fold: ls 0.06691954379682245 0.07333923061998891 auc 0.9916686718795756 0.9889957979310383\n",
      "4 fold: ls 0.06485842348442203 0.07777513678134874 auc 0.9923019735318201 0.9879992721804108\n",
      "5 fold: ls 0.06334332390308894 0.07643587531544414 auc 0.9927983616679438 0.987471539516125\n",
      "6 fold: ls 0.06321415588273714 0.07790983418518278 auc 0.9928087772419621 0.9874241242638623\n",
      "7 fold: ls 0.06542880065941839 0.07085532532205441 auc 0.9921164130676361 0.990050040158425\n",
      "8 fold: ls 0.06737227140574086 0.07393431637883122 auc 0.991491047607112 0.9894161912006152\n",
      "9 fold: ls 0.06666124793922053 0.07769840248629262 auc 0.991707765015964 0.9875996894312373\n",
      "toxic 0.095 0.5 4\n",
      "this class avg train 0.06627704280065903 avg val 0.07530669729365187\n",
      "this class auc train 0.9918653914214675 auc val 0.9884390515130985\n",
      "========================\n",
      "0 fold: ls 0.016540336714357895 0.02149362332293323 auc 0.9955038987051761 0.990894417014812\n",
      "1 fold: ls 0.01676619193906269 0.020611426765998905 auc 0.9953908490720984 0.9918478604886695\n",
      "2 fold: ls 0.016239123303929494 0.021144800801264484 auc 0.9957551002343187 0.9912378149132801\n",
      "3 fold: ls 0.016273830728608135 0.019923765780536517 auc 0.995700658491444 0.9925560197493354\n",
      "4 fold: ls 0.014703019010187765 0.021174023639357102 auc 0.9969102430025512 0.990869492973794\n",
      "5 fold: ls 0.016355255149948487 0.01986123102080337 auc 0.9956570045136641 0.9923519496536859\n",
      "6 fold: ls 0.016601248280633637 0.01928351496653219 auc 0.9955002581096478 0.9928487337178503\n",
      "7 fold: ls 0.01609591965184498 0.020342409210042812 auc 0.9958642604017875 0.9919346201790563\n",
      "8 fold: ls 0.016521934163064442 0.02111521789265345 auc 0.9955146383503664 0.9911590569501494\n",
      "9 fold: ls 0.017130276153567277 0.019164975422118483 auc 0.9951126332354281 0.9931262324706984\n",
      "severe_toxic 0.095 0.5 4\n",
      "this class avg train 0.016322713509520477 avg val 0.02041149888222405\n",
      "this class auc train 0.9956909544116481 auc val 0.9918826198111331\n",
      "========================\n",
      "0 fold: ls 0.032410103846890984 0.037196691635236874 auc 0.9968838085021828 0.9956314893287138\n",
      "1 fold: ls 0.031636082551684576 0.03696703507285746 auc 0.9970520162068521 0.9954584340375483\n",
      "2 fold: ls 0.03078426832487701 0.038845861945418364 auc 0.9972154368619661 0.9954091892958611\n",
      "3 fold: ls 0.03361420101242307 0.03369311266167274 auc 0.9966251785258388 0.9964984917350841\n",
      "4 fold: ls 0.03280315198376251 0.04194250955099738 auc 0.9967999387248385 0.9945541926005744\n",
      "5 fold: ls 0.03239947965808576 0.03754762277719344 auc 0.9968741516553866 0.9955680034832618\n",
      "6 fold: ls 0.03423518175399308 0.03728506376740835 auc 0.9965234289020353 0.9955563351825111\n",
      "7 fold: ls 0.033787115930304784 0.03835041820314343 auc 0.9966067810869339 0.9955584495725798\n",
      "8 fold: ls 0.032580053856657555 0.03904233232923559 auc 0.9968510323006311 0.9951576551884\n",
      "9 fold: ls 0.032879833867126396 0.03858338056024369 auc 0.9967840928662814 0.9953237783475797\n",
      "obscene 0.095 0.5 4\n",
      "this class avg train 0.032712947278580574 avg val 0.03794540285034073\n",
      "this class auc train 0.9968215865632948 auc val 0.9954716018772114\n",
      "========================\n",
      "0 fold: ls 0.003534059936758014 0.006765516698635834 auc 0.9995284778675655 0.9966334066624764\n",
      "1 fold: ls 0.004024340518443172 0.006393052960232537 auc 0.9992714884789655 0.9967316153362666\n",
      "2 fold: ls 0.00407597425818482 0.007364219889283397 auc 0.9992231278593063 0.9946941127173685\n",
      "3 fold: ls 0.004140823188514235 0.006678872614063872 auc 0.9992535056534834 0.9920216806000796\n",
      "4 fold: ls 0.004066352819485825 0.006883125125229663 auc 0.9992674493317429 0.9958265237706119\n",
      "5 fold: ls 0.003923256130317969 0.007212968111645777 auc 0.9993004447684163 0.9956615228277494\n",
      "6 fold: ls 0.003731274694430632 0.006387724730418177 auc 0.999437965005834 0.9947487795168354\n",
      "7 fold: ls 0.00412412277153844 0.0076494380787684065 auc 0.9991915508943445 0.9955554507930522\n",
      "8 fold: ls 0.0041922636682483385 0.0071618232417530224 auc 0.9991285611375003 0.9942278089613401\n",
      "9 fold: ls 0.004238872081161581 0.007557943258395621 auc 0.9991026991959333 0.9810364265911308\n",
      "threat 0.095 0.5 4\n",
      "this class avg train 0.004005134006708303 avg val 0.00700546847084263\n",
      "this class auc train 0.9992705270193092 auc val 0.9937137327776911\n",
      "========================\n",
      "0 fold: ls 0.04898421283909842 0.050089660761025966 auc 0.9921474259563647 0.9914449270367309\n",
      "1 fold: ls 0.04928199446503803 0.0541997095013948 auc 0.9920737236144728 0.9897465358759774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 fold: ls 0.04886998732871722 0.05536650805100901 auc 0.9921997859731232 0.9888806721789265\n",
      "3 fold: ls 0.047109248296996996 0.051901707142502786 auc 0.9928260029909157 0.9905126000087\n",
      "4 fold: ls 0.04670165460059791 0.05481334293433445 auc 0.9929561605732272 0.9892579141335873\n",
      "5 fold: ls 0.04472935265535438 0.05228664806020755 auc 0.9936474100231216 0.990556063277597\n",
      "6 fold: ls 0.04206670002549743 0.056356832352222545 auc 0.9945210673130226 0.9891096689648573\n",
      "7 fold: ls 0.046964666554243806 0.055650454411322485 auc 0.9928636943227899 0.9894277124909417\n",
      "8 fold: ls 0.048746503973445016 0.05245977685282157 auc 0.9922357452472966 0.9904578680370578\n",
      "9 fold: ls 0.04827139923617239 0.0547917573083341 auc 0.9924165369052357 0.9892906711449142\n",
      "insult 0.095 0.5 4\n",
      "this class avg train 0.04717257199751616 avg val 0.05379163973751753\n",
      "this class auc train 0.992788755291957 auc val 0.9898684633149291\n",
      "========================\n",
      "0 fold: ls 0.013696294960621367 0.01731555032692072 auc 0.9964553239448667 0.9926880898862298\n",
      "1 fold: ls 0.01352833977421872 0.017876820974506758 auc 0.9965680933409251 0.9912375453827621\n",
      "2 fold: ls 0.013209040346318639 0.017934071380879355 auc 0.9968169357518617 0.9919110284876178\n",
      "3 fold: ls 0.013214173546361053 0.01814040134531715 auc 0.996802043777946 0.9888095087564013\n",
      "4 fold: ls 0.013895320614652942 0.019045414177931118 auc 0.9962434710963097 0.9888913400923773\n",
      "5 fold: ls 0.012920788854432347 0.01663973115474152 auc 0.996984805784214 0.9934907287818712\n",
      "6 fold: ls 0.011134887742767186 0.016569095838596067 auc 0.9980711851182369 0.98919177686249\n",
      "7 fold: ls 0.013962950118306934 0.018802973095025093 auc 0.9962501016950094 0.9864057193438832\n",
      "8 fold: ls 0.012214095830230155 0.01688710354790529 auc 0.9974757174530849 0.9924619734084833\n",
      "9 fold: ls 0.013821483645603963 0.016846778393024047 auc 0.9963913223960872 0.992013512537033\n",
      "identity_hate 0.095 0.5 4\n",
      "this class avg train 0.013159737543351332 avg val 0.01760579402348471\n",
      "this class auc train 0.9968059000358542 auc val 0.9907101223539149\n",
      "========================\n",
      "all loss avg 0.02994169118938931 0.03534441687634359\n",
      "all auc avg 0.9955405191239218 0.9916809319413298\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.095 max depth 4 feature fraction 0.6\n",
      "0 fold: ls 0.06721356141430446 0.07752118963296395 auc 0.9916007624835795 0.9873532492194734\n",
      "1 fold: ls 0.06738511367142995 0.07135151065048888 auc 0.9915937220253971 0.9898445470046442\n",
      "2 fold: ls 0.0659126613225689 0.07567406312857639 auc 0.9919927341039184 0.9884623399308897\n",
      "3 fold: ls 0.06334374653233257 0.07325054498144246 auc 0.9927755571826886 0.9890181310487415\n",
      "4 fold: ls 0.06254474976553039 0.07819907895308514 auc 0.9929402135449197 0.9878301456926551\n",
      "5 fold: ls 0.059000619822902174 0.07618420798269583 auc 0.9939787256928293 0.9876378102095282\n",
      "6 fold: ls 0.06291279759338513 0.07777077407225783 auc 0.9928619581284188 0.9875715829785954\n",
      "7 fold: ls 0.06898079274104194 0.07111539202645706 auc 0.9910230097288762 0.9899634537251953\n",
      "8 fold: ls 0.06123915344034773 0.07406478409980018 auc 0.9933576714924777 0.9893859086155904\n",
      "9 fold: ls 0.0670660904820733 0.07802522212636137 auc 0.9915770195597172 0.9874656844591814\n",
      "toxic 0.095 0.6 4\n",
      "this class avg train 0.06455992867859164 avg val 0.07531567676541291\n",
      "this class auc train 0.9923701373942823 auc val 0.9884532852884496\n",
      "========================\n",
      "0 fold: ls 0.015552318713294001 0.021333779940828673 auc 0.9962688964802082 0.9909917394606911\n",
      "1 fold: ls 0.015050323478589998 0.0207251428332916 auc 0.9966791370075779 0.9916666666666666\n",
      "2 fold: ls 0.01649764733413609 0.02117221006158915 auc 0.9955735297310733 0.9912204076465376\n",
      "3 fold: ls 0.016333146807596885 0.01975208581870219 auc 0.995680861939612 0.9926802443347258\n",
      "4 fold: ls 0.01634989586992629 0.02125827096986992 auc 0.9956705593023379 0.9909818489682238\n",
      "5 fold: ls 0.015289173719927523 0.019683116780011854 auc 0.9964926243344145 0.9925820560042232\n",
      "6 fold: ls 0.01624149180313134 0.01940244195282698 auc 0.9957666941909176 0.992724118065567\n",
      "7 fold: ls 0.015122534233288208 0.020222659341045876 auc 0.9966492692202644 0.992054458234447\n",
      "8 fold: ls 0.016375584249082645 0.021119952742264424 auc 0.9956192673361393 0.9911885187976541\n",
      "9 fold: ls 0.016505727790401596 0.019210038520425556 auc 0.9955637153299302 0.992923582735835\n",
      "severe_toxic 0.095 0.6 4\n",
      "this class avg train 0.015931784399937456 avg val 0.02038796989608562\n",
      "this class auc train 0.9959964554872475 auc val 0.9919013640914572\n",
      "========================\n",
      "0 fold: ls 0.03158916799882079 0.03718303392888674 auc 0.9970548492805011 0.9956408076905457\n",
      "1 fold: ls 0.033912670140955614 0.03702459578651819 auc 0.9965843888769481 0.9954397973138844\n",
      "2 fold: ls 0.03178087122747637 0.03891813939583975 auc 0.997004540735838 0.9953979908595699\n",
      "3 fold: ls 0.03263265065034506 0.0337200578450317 auc 0.9968382753441909 0.9965024072722489\n",
      "4 fold: ls 0.03308211579344935 0.041912098834701955 auc 0.996744384782952 0.9945702463029498\n",
      "5 fold: ls 0.03294384089038599 0.03755135123002325 auc 0.9967625646666062 0.9955718407096833\n",
      "6 fold: ls 0.03403484637161347 0.0374248905448328 auc 0.9965614986536134 0.9953725398679993\n",
      "7 fold: ls 0.03308474209508115 0.03814017863090592 auc 0.9967435324498256 0.9955813946203652\n",
      "8 fold: ls 0.0329090284804621 0.039081156953658325 auc 0.9967855380176157 0.995126252580339\n",
      "9 fold: ls 0.033223894152036186 0.03873383005265286 auc 0.9967141043937433 0.9952848117938978\n",
      "obscene 0.095 0.6 4\n",
      "this class avg train 0.03291938278006261 avg val 0.03796893332030514\n",
      "this class auc train 0.9967793677201836 auc val 0.9954488089011484\n",
      "========================\n",
      "0 fold: ls 0.004014143772276451 0.006586405567533611 auc 0.9992698074297179 0.9967983972344436\n",
      "1 fold: ls 0.004092407929061125 0.006382061714822976 auc 0.9992261894803999 0.9967879216425728\n",
      "2 fold: ls 0.003945684134654817 0.0074379458228073115 auc 0.9993045491141683 0.994521265451498\n",
      "3 fold: ls 0.004148654443608201 0.006597002094909666 auc 0.99924394729046 0.9915410826157101\n",
      "4 fold: ls 0.0038635932935610915 0.006873881742387858 auc 0.9993828968158063 0.9957139040794518\n",
      "5 fold: ls 0.004180206645008954 0.007132041994122152 auc 0.9991382449513653 0.9960609298719802\n",
      "6 fold: ls 0.003989845676908337 0.006377802747610135 auc 0.9992916254122196 0.9952071154692312\n",
      "7 fold: ls 0.004087307097678967 0.007782698457063629 auc 0.9992107244670705 0.9952005678127684\n",
      "8 fold: ls 0.003918733017113207 0.007232152401749913 auc 0.9993338686560786 0.9943668979020306\n",
      "9 fold: ls 0.004009149916962505 0.007601459971454237 auc 0.9992455718392883 0.9891316704180559\n",
      "threat 0.095 0.6 4\n",
      "this class avg train 0.004024972592683365 avg val 0.007000345251446149\n",
      "this class auc train 0.9992647425456574 auc val 0.9945329752497744\n",
      "========================\n",
      "0 fold: ls 0.04650999302596036 0.05008995209536856 auc 0.9930424190550511 0.9913787564957554\n",
      "1 fold: ls 0.04802290790377074 0.05403694926670291 auc 0.9924997373164862 0.9896881870108315\n",
      "2 fold: ls 0.04936117586040201 0.05543086008689344 auc 0.9920658378394772 0.9887052073120539\n",
      "3 fold: ls 0.04606089580848246 0.05164251790335963 auc 0.9931991999790342 0.990582953264023\n",
      "4 fold: ls 0.04813303414338547 0.055098364248283384 auc 0.9924594647450604 0.9892226933570436\n",
      "5 fold: ls 0.04627155157814753 0.05252790254557184 auc 0.9931264923754739 0.9904829446108531\n",
      "6 fold: ls 0.04603469351965588 0.05651668072969619 auc 0.9931925512725961 0.9890644926719033\n",
      "7 fold: ls 0.045832516708310664 0.055490945831560196 auc 0.9932685127958245 0.9895036883472051\n",
      "8 fold: ls 0.048714658541124986 0.05247509686307037 auc 0.9922506006819998 0.9902863150562117\n",
      "9 fold: ls 0.04859020518602483 0.05483373914415864 auc 0.9923070109397345 0.9892247472211223\n",
      "insult 0.095 0.6 4\n",
      "this class avg train 0.047353163227526494 avg val 0.053814300871466526\n",
      "this class auc train 0.9927411827000739 auc val 0.9898139985347003\n",
      "========================\n",
      "0 fold: ls 0.013241272691680918 0.01720005694477017 auc 0.9967502539444196 0.9928490622128897\n",
      "1 fold: ls 0.013793331145225038 0.01787482037895288 auc 0.996401711171447 0.9913043556241892\n",
      "2 fold: ls 0.01265567323215967 0.01803534210728395 auc 0.997159551191309 0.9917760628321176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold: ls 0.01273558447274439 0.018207468746216548 auc 0.9971037319936888 0.9885651357256781\n",
      "4 fold: ls 0.012606068449153261 0.019166561425998065 auc 0.9971508727747128 0.988395643972259\n",
      "5 fold: ls 0.013439279879236918 0.016715047321237228 auc 0.9966402648370452 0.9933331225896188\n",
      "6 fold: ls 0.013812373499356689 0.01691815304710283 auc 0.9963448384055889 0.9915591805766313\n",
      "7 fold: ls 0.013798544763413852 0.01868890310215368 auc 0.9963665823951707 0.9886703790013729\n",
      "8 fold: ls 0.012382770860050848 0.016869542042234748 auc 0.9973075826297982 0.9926186863212659\n",
      "9 fold: ls 0.013358529255443114 0.01689854143687423 auc 0.9967279307946372 0.9920631909820075\n",
      "identity_hate 0.095 0.6 4\n",
      "this class avg train 0.013182342824846469 avg val 0.017657443655282434\n",
      "this class auc train 0.9967953320137818 auc val 0.9911134819838031\n",
      "========================\n",
      "all loss avg 0.02966192908394134 0.0353574449599998\n",
      "all auc avg 0.9956578696435378 0.9918773190082222\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 3 feature fraction 0.4\n",
      "0 fold: ls 0.07024855757397477 0.0779792170459262 auc 0.9905416997570439 0.9870877886317635\n",
      "1 fold: ls 0.0715547616582014 0.07124905292762622 auc 0.9900766798161142 0.9899571639024337\n",
      "2 fold: ls 0.07034888863255626 0.07598981356786497 auc 0.9904660155309855 0.9883772204011445\n",
      "3 fold: ls 0.06673069215455199 0.07330330181218402 auc 0.9917150934144866 0.9889792632698584\n",
      "4 fold: ls 0.06949201134430112 0.07804043376412098 auc 0.9907710936767015 0.9878424301413771\n",
      "5 fold: ls 0.06935622654223922 0.07660565240160422 auc 0.9908604998249707 0.9875515017579907\n",
      "6 fold: ls 0.06712554717674861 0.07795823842713312 auc 0.9915863209600214 0.9875458808294242\n",
      "7 fold: ls 0.07252422955082424 0.07080328504448921 auc 0.9896920490420295 0.9901654131807127\n",
      "8 fold: ls 0.06958691159781813 0.07429012940482066 auc 0.9907296527147686 0.9892940181966602\n",
      "9 fold: ls 0.06974110575049122 0.07771805167111916 auc 0.990628184662484 0.9875870414653362\n",
      "toxic 0.075 0.4 3\n",
      "this class avg train 0.06967089319817069 avg val 0.07539371760668886\n",
      "this class auc train 0.9907067289399605 auc val 0.9884387721776701\n",
      "========================\n",
      "0 fold: ls 0.018015388320956387 0.021222682359097845 auc 0.9941430732433697 0.9911084472718065\n",
      "1 fold: ls 0.017507088314775106 0.020585958456219175 auc 0.9945978596883732 0.9916737878212432\n",
      "2 fold: ls 0.01714175993900575 0.02104767740042688 auc 0.9949246473834168 0.9913723256108368\n",
      "3 fold: ls 0.01651013453970197 0.01971213617583037 auc 0.9954811588927909 0.9927217844030891\n",
      "4 fold: ls 0.01763964581595879 0.021083140263911077 auc 0.9944954802938046 0.991011520445626\n",
      "5 fold: ls 0.01657286367146235 0.019986240932234473 auc 0.9954173925571974 0.9922169910847722\n",
      "6 fold: ls 0.01794991418145226 0.019174098868264447 auc 0.9942410564453639 0.9929434893895546\n",
      "7 fold: ls 0.01784392359114425 0.02021316314474845 auc 0.994317498004252 0.992093475275737\n",
      "8 fold: ls 0.018018712373623427 0.02098326145553839 auc 0.9941662067046755 0.9912124067821173\n",
      "9 fold: ls 0.01766295442030583 0.018930407783881036 auc 0.9944756708563518 0.9931827673672615\n",
      "severe_toxic 0.075 0.4 3\n",
      "this class avg train 0.01748623851683861 avg val 0.02029387668401521\n",
      "this class auc train 0.9946260044069595 auc val 0.9919536995452045\n",
      "========================\n",
      "0 fold: ls 0.035435815459146855 0.03701790080880802 auc 0.9962133007072059 0.9957466768098471\n",
      "1 fold: ls 0.03582282859826941 0.036955749746384124 auc 0.9961195109821712 0.9955345470434365\n",
      "2 fold: ls 0.03352744980845759 0.039055595750654815 auc 0.9966234129441158 0.9953672147374555\n",
      "3 fold: ls 0.03565432799206053 0.03389535634105853 auc 0.9961530096632047 0.9964134462678667\n",
      "4 fold: ls 0.03354827099139257 0.04198493122263386 auc 0.9966170593638854 0.9945389220056321\n",
      "5 fold: ls 0.03390783833075505 0.0374626386583495 auc 0.996537555006186 0.9956409890960122\n",
      "6 fold: ls 0.034242008154669844 0.037418396316794666 auc 0.9964629678806068 0.9954159240197844\n",
      "7 fold: ls 0.034531322453972724 0.0382261902944275 auc 0.996396658974042 0.9955470162040589\n",
      "8 fold: ls 0.03484953660209311 0.039037070640028565 auc 0.9963453724992604 0.9951354932480477\n",
      "9 fold: ls 0.03465687150607394 0.038757495523250016 auc 0.9963750707505409 0.9952707775622901\n",
      "obscene 0.075 0.4 3\n",
      "this class avg train 0.03461762698968916 avg val 0.03798113253023897\n",
      "this class auc train 0.996384391877122 auc val 0.9954611006994429\n",
      "========================\n",
      "0 fold: ls 0.004979549916463532 0.006657060140389971 auc 0.9985481744048801 0.9966844751728472\n",
      "1 fold: ls 0.005082818429122339 0.006157325510783375 auc 0.9984746224095398 0.9969581500104756\n",
      "2 fold: ls 0.005038270218507756 0.007384015835718756 auc 0.9984995782759062 0.9944846008799497\n",
      "3 fold: ls 0.005277776624117088 0.006528562549210022 auc 0.9983606798343065 0.989889108890146\n",
      "4 fold: ls 0.004855718271253204 0.006825024829708425 auc 0.9986339012154144 0.9961892639386511\n",
      "5 fold: ls 0.005038626423931589 0.0069221965488485745 auc 0.9984216357160862 0.9961093825298049\n",
      "6 fold: ls 0.005001650750533506 0.006356750280650526 auc 0.99851978556783 0.9949805665556184\n",
      "7 fold: ls 0.004928687914524051 0.007394637913184503 auc 0.9985838761379081 0.9957531900182287\n",
      "8 fold: ls 0.0051989721900373735 0.007075061171140541 auc 0.9981431660694438 0.9944859259378138\n",
      "9 fold: ls 0.005114919056612839 0.007484736417421734 auc 0.9983738494028678 0.9897214610223305\n",
      "threat 0.075 0.4 3\n",
      "this class avg train 0.005051698979510328 avg val 0.006878537119705643\n",
      "this class auc train 0.9984559269034182 auc val 0.9945256124955867\n",
      "========================\n",
      "0 fold: ls 0.04883701913402039 0.05010511748437728 auc 0.9921453697859978 0.9913577592697317\n",
      "1 fold: ls 0.051495373926751555 0.05403061168319473 auc 0.9911189486539294 0.9894734464562372\n",
      "2 fold: ls 0.051175514118988026 0.055193718929180687 auc 0.9912358393561663 0.9891682756174522\n",
      "3 fold: ls 0.05052775247487193 0.05180882863120454 auc 0.9914724725346165 0.9905013066799622\n",
      "4 fold: ls 0.05046847820289306 0.055151398020644025 auc 0.9915090431182741 0.9891388662356738\n",
      "5 fold: ls 0.0483721303387811 0.052187949337376416 auc 0.9923271878312597 0.9905840056513868\n",
      "6 fold: ls 0.0506743083819988 0.05628309524910466 auc 0.9914021700549446 0.9891113003309917\n",
      "7 fold: ls 0.0505284007627522 0.05555694772327192 auc 0.9914623328544062 0.9894547689425107\n",
      "8 fold: ls 0.050575282490221314 0.052451390584139376 auc 0.9914566502980875 0.9903844889300163\n",
      "9 fold: ls 0.0499097347112562 0.05478170024627614 auc 0.9917302007387168 0.9891980258339691\n",
      "insult 0.075 0.4 3\n",
      "this class avg train 0.05025639945425346 avg val 0.053755075788876984\n",
      "this class auc train 0.9915860215226399 auc val 0.9898372243947933\n",
      "========================\n",
      "0 fold: ls 0.014338995317688397 0.017108565611417475 auc 0.9958238336674945 0.9928530977308283\n",
      "1 fold: ls 0.015093863426842056 0.017759552083903264 auc 0.9952331316702372 0.9910711923655176\n",
      "2 fold: ls 0.015229686741391173 0.017844295995600935 auc 0.9950684724012681 0.9921603338180439\n",
      "3 fold: ls 0.01484005416662131 0.018071403682340698 auc 0.9954544743659526 0.9889431292392554\n",
      "4 fold: ls 0.01419316682722699 0.018872439513136677 auc 0.9959363613017072 0.9891067919112079\n",
      "5 fold: ls 0.014618534291066567 0.016510863082465705 auc 0.9956065364818866 0.9935422104607159\n",
      "6 fold: ls 0.014794827597270657 0.016757793009434554 auc 0.9954237578978496 0.9897996603800853\n",
      "7 fold: ls 0.015438873063228548 0.018635178285779364 auc 0.9948898125896339 0.9883086295975144\n",
      "8 fold: ls 0.01349076239712339 0.01669937508101378 auc 0.996514022804672 0.9930391466146399\n",
      "9 fold: ls 0.01527103651899859 0.016776153629229386 auc 0.9950885017305505 0.9920442228484717\n",
      "identity_hate 0.075 0.4 3\n",
      "this class avg train 0.014730980034745766 avg val 0.017503561997432186\n",
      "this class auc train 0.9955038904911253 auc val 0.9910868414966281\n",
      "========================\n",
      "all loss avg 0.031968972862201336 0.035300983621159646\n",
      "all auc avg 0.994543827356871 0.9918838751348876\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.075 3 0.4 severe_toxic\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 3 feature fraction 0.5\n",
      "0 fold: ls 0.07150430225221728 0.07818262228727743 auc 0.9901000591394011 0.9870585245464973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 fold: ls 0.0688021127503177 0.07149996883852526 auc 0.9910324431363013 0.9898141051078966\n",
      "2 fold: ls 0.0706557989325837 0.07606968283748021 auc 0.9903446125289351 0.9883347285869343\n",
      "3 fold: ls 0.06427469504055372 0.07284701797892582 auc 0.9924519064863594 0.9891775886031338\n",
      "4 fold: ls 0.0689821532451226 0.07784881959891785 auc 0.9909276168182799 0.9879288745831221\n",
      "5 fold: ls 0.06827246198709776 0.0764624398636682 auc 0.9912484829643569 0.987557575987248\n",
      "6 fold: ls 0.06989416741637729 0.07843507866220957 auc 0.9906353932909475 0.987387044267351\n",
      "7 fold: ls 0.07224264416472494 0.07079870856127723 auc 0.9898011889154842 0.990123706626487\n",
      "8 fold: ls 0.06476516202839776 0.07412789170483244 auc 0.9922963412616278 0.9894753057079092\n",
      "9 fold: ls 0.07023636705115283 0.07775099606121887 auc 0.9904529655819864 0.9876012307604153\n",
      "toxic 0.075 0.5 3\n",
      "this class avg train 0.06896298648685455 avg val 0.07540232263943328\n",
      "this class auc train 0.9909291010123681 auc val 0.9884458684776993\n",
      "========================\n",
      "0 fold: ls 0.017973804533624026 0.021326542723046838 auc 0.9941837642493878 0.9910008387137611\n",
      "1 fold: ls 0.017719180757537027 0.020577488745439347 auc 0.994413691469735 0.9917105804532219\n",
      "2 fold: ls 0.018269765543342236 0.02098448189372382 auc 0.9940104574219009 0.9913284118242817\n",
      "3 fold: ls 0.01658619631601573 0.019667014080815712 auc 0.9954016197882783 0.9927099158121281\n",
      "4 fold: ls 0.018171460727000807 0.02099396158208288 auc 0.9940706116879646 0.9912267375617166\n",
      "5 fold: ls 0.018092225356101756 0.019953376471734702 auc 0.9941043904476756 0.9922368964784173\n",
      "6 fold: ls 0.01744004589968488 0.019093412403276312 auc 0.9946882349118508 0.9929757381685799\n",
      "7 fold: ls 0.017321416370523972 0.02014196800068831 auc 0.9947629940413494 0.9921468251077049\n",
      "8 fold: ls 0.018104520535729394 0.021053075877608653 auc 0.9941208129475299 0.9911741860069763\n",
      "9 fold: ls 0.017902928898862313 0.019175360282989207 auc 0.9942738968792939 0.9929299528650253\n",
      "severe_toxic 0.075 0.5 3\n",
      "this class avg train 0.017758154493842212 avg val 0.02029666820614058\n",
      "this class auc train 0.9944030473844967 auc val 0.9919440082991813\n",
      "========================\n",
      "0 fold: ls 0.03532087418600357 0.0370902922884113 auc 0.9962317761183835 0.9957120657516141\n",
      "1 fold: ls 0.035712575185737734 0.03694328821535814 auc 0.9961428533818172 0.9955129347084313\n",
      "2 fold: ls 0.033670898265344695 0.03902740043439507 auc 0.9965837569730326 0.9953756722977312\n",
      "3 fold: ls 0.03582833401493498 0.03383093230632265 auc 0.9961112182664725 0.9964925401185938\n",
      "4 fold: ls 0.034621330031809006 0.042012257211547 auc 0.9963781324523551 0.994531952349479\n",
      "5 fold: ls 0.031913065714583036 0.03734313813597886 auc 0.9969754473139005 0.9956570427983874\n",
      "6 fold: ls 0.03426196912570855 0.03754047490625058 auc 0.9964605215926776 0.9953264931509423\n",
      "7 fold: ls 0.03481958896912586 0.038365976050281206 auc 0.9963359528403646 0.9955040236059904\n",
      "8 fold: ls 0.03487775081916944 0.03893603944403434 auc 0.996335855665686 0.9951575768776567\n",
      "9 fold: ls 0.03525261894106263 0.03875944310144348 auc 0.9962480622605727 0.9952784611080865\n",
      "obscene 0.075 0.5 3\n",
      "this class avg train 0.03462790052534795 avg val 0.03798492420940226\n",
      "this class auc train 0.9963803576865262 auc val 0.9954548762766914\n",
      "========================\n",
      "0 fold: ls 0.004847197922436931 0.006561770499699778 auc 0.9986752844668288 0.996924104336895\n",
      "1 fold: ls 0.005119680719009042 0.006173873441785896 auc 0.9984530854887445 0.997032788602556\n",
      "2 fold: ls 0.00418347573900108 0.007291366930230342 auc 0.9991495027748681 0.9946888749214331\n",
      "3 fold: ls 0.00421807999756938 0.006517937618694971 auc 0.9991495655614373 0.9917931673895279\n",
      "4 fold: ls 0.0047196261479208294 0.006686150331029246 auc 0.998757843217509 0.9964943847298176\n",
      "5 fold: ls 0.004713623374276731 0.006871097835323056 auc 0.9987710397679875 0.9961499779998743\n",
      "6 fold: ls 0.0046729214933283495 0.00634808387707014 auc 0.9987609291800824 0.9950669956209273\n",
      "7 fold: ls 0.00510833600298394 0.007451015616247673 auc 0.9983241274197197 0.9956575942338719\n",
      "8 fold: ls 0.0048464272224251915 0.007121867294235852 auc 0.9986317477305661 0.9940913948079704\n",
      "9 fold: ls 0.0051764150776392485 0.007461403120051951 auc 0.9982788926499975 0.9804412864122142\n",
      "threat 0.075 0.5 3\n",
      "this class avg train 0.004760578369659071 avg val 0.006848456656436891\n",
      "this class auc train 0.9986952018257741 auc val 0.9938340569055087\n",
      "========================\n",
      "0 fold: ls 0.04803992506265644 0.05014669991512877 auc 0.9924579789761353 0.9913385187837336\n",
      "1 fold: ls 0.05092143030134955 0.05400287996864745 auc 0.9913162815972062 0.989754692168955\n",
      "2 fold: ls 0.05149175129300151 0.05526669060283496 auc 0.9911475480205572 0.9889168944851747\n",
      "3 fold: ls 0.049704842926002725 0.05158502969366102 auc 0.9917881876785849 0.9905837898068924\n",
      "4 fold: ls 0.04988781025628761 0.05521129488372406 auc 0.9917260067663526 0.9891313368535147\n",
      "5 fold: ls 0.049193441773843015 0.052458332119532707 auc 0.9920215852910915 0.9904683878053456\n",
      "6 fold: ls 0.04967565885336376 0.05625820536503555 auc 0.9917925822854109 0.9891359381426118\n",
      "7 fold: ls 0.050510778621795274 0.05563622438236715 auc 0.9914716849753179 0.9894327384571774\n",
      "8 fold: ls 0.051337545854790806 0.05252357539913767 auc 0.9911574165211505 0.9903782064722216\n",
      "9 fold: ls 0.04962476662716403 0.05469200799103598 auc 0.9918355586697725 0.9892918438703693\n",
      "insult 0.075 0.5 3\n",
      "this class avg train 0.05003879515702547 avg val 0.053778094032110535\n",
      "this class auc train 0.9916714830781579 auc val 0.9898432346845996\n",
      "========================\n",
      "0 fold: ls 0.014576528052832568 0.0170975951252173 auc 0.9956546726262276 0.9928311265776072\n",
      "1 fold: ls 0.015429827829226167 0.017652365139253445 auc 0.9948867175130547 0.9915195832475786\n",
      "2 fold: ls 0.015296690850034678 0.01783530081990777 auc 0.9950196587394272 0.9920668443191341\n",
      "3 fold: ls 0.014340882326246104 0.018018097866322413 auc 0.9958421714424284 0.9893668586228034\n",
      "4 fold: ls 0.014341345440596384 0.018896940703950215 auc 0.9958328483275771 0.9893013935540224\n",
      "5 fold: ls 0.015130385883064049 0.016349221169457064 auc 0.9951847928615684 0.9938109086967909\n",
      "6 fold: ls 0.013758811087181024 0.016585172621830988 auc 0.9963167303214951 0.9904676096538766\n",
      "7 fold: ls 0.015348696888773161 0.01858291012265651 auc 0.9949293299513668 0.9873934171544188\n",
      "8 fold: ls 0.014649789072972727 0.016746746496350905 auc 0.9956396151000082 0.9930359852590506\n",
      "9 fold: ls 0.015314366482148253 0.016735643972384178 auc 0.9950369836635471 0.992035642026158\n",
      "identity_hate 0.075 0.5 3\n",
      "this class avg train 0.014818732391307512 avg val 0.017449999403733076\n",
      "this class auc train 0.99543435205467 auc val 0.9911829369111439\n",
      "========================\n",
      "all loss avg 0.03182785790400613 0.03529341085787611\n",
      "all auc avg 0.9945855905069988 0.9917841635924707\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.075 3 0.5 identity_hate\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 3 feature fraction 0.6\n",
      "0 fold: ls 0.07051194033659473 0.07813526439110358 auc 0.9904409749885661 0.9870358290252612\n",
      "1 fold: ls 0.07035479027449197 0.07142062974975726 auc 0.9904938366151625 0.9898440486997867\n",
      "2 fold: ls 0.06912154918357763 0.0761025422487251 auc 0.9908849815425854 0.9883318293586727\n",
      "3 fold: ls 0.06837811314060566 0.07325383842115799 auc 0.9911258812571665 0.989053873097155\n",
      "4 fold: ls 0.06802589456083495 0.07811971586750424 auc 0.9912916099811226 0.987810291122396\n",
      "5 fold: ls 0.06887728380682638 0.07648669429133008 auc 0.9910160349234843 0.98753024195559\n",
      "6 fold: ls 0.06782213295349775 0.07800727742470955 auc 0.9913742360615091 0.9875381747176797\n",
      "7 fold: ls 0.06748765811750988 0.07075683272342743 auc 0.9914421706232609 0.990028008217823\n",
      "8 fold: ls 0.06547090467416762 0.07419590201774323 auc 0.9920689577135092 0.9893511833758764\n",
      "9 fold: ls 0.06957314162667838 0.07815881757397208 auc 0.9906754240586915 0.987460425806692\n",
      "toxic 0.075 0.6 3\n",
      "this class avg train 0.0685623408674785 avg val 0.07546375147094304\n",
      "this class auc train 0.9910814107765059 auc val 0.9883983905376933\n",
      "========================\n",
      "0 fold: ls 0.017804073292634885 0.02138197152741151 auc 0.9943261925731514 0.9909050987466768\n",
      "1 fold: ls 0.0171991697373115 0.020465503387094793 auc 0.9948688308119238 0.9918803013039627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 fold: ls 0.018059656201069627 0.021016969834946612 auc 0.9941494033366329 0.9913335548803647\n",
      "3 fold: ls 0.01744052671186783 0.019648157525793717 auc 0.9946685347017772 0.9927518515001899\n",
      "4 fold: ls 0.017655721583216294 0.021149157854617465 auc 0.9944725444274275 0.9909996518546651\n",
      "5 fold: ls 0.01681546745080757 0.01987478009929238 auc 0.9951999241721048 0.9923065653561752\n",
      "6 fold: ls 0.018250208791637156 0.019151445057618816 auc 0.9939923409740801 0.9929530445833398\n",
      "7 fold: ls 0.016562258603434587 0.020180336908364137 auc 0.99543319358443 0.9920942715418858\n",
      "8 fold: ls 0.017991358692230914 0.021081844869346833 auc 0.9941921925245435 0.9911491036232897\n",
      "9 fold: ls 0.018178330957416507 0.01907461925137082 auc 0.9940423975340746 0.9930736789048791\n",
      "severe_toxic 0.075 0.6 3\n",
      "this class avg train 0.017595677202162686 avg val 0.020302478631585706\n",
      "this class auc train 0.9945345554640147 auc val 0.9919447122295428\n",
      "========================\n",
      "0 fold: ls 0.035427750598728706 0.037094285331594104 auc 0.9962045699090782 0.9957005548340568\n",
      "1 fold: ls 0.0347595354257749 0.03686508401596794 auc 0.9963587742044904 0.9955924931590303\n",
      "2 fold: ls 0.0349237398148973 0.039015205964151485 auc 0.9963115320217543 0.995382798575371\n",
      "3 fold: ls 0.03508117436945474 0.033875678932859296 auc 0.996280128163055 0.9964773478343947\n",
      "4 fold: ls 0.03535825871180014 0.04212682518497048 auc 0.9962403692158199 0.9945271753941378\n",
      "5 fold: ls 0.03394272067969666 0.03752236896230555 auc 0.9965286666655578 0.9956232908680276\n",
      "6 fold: ls 0.036229318880440925 0.03762315899342537 auc 0.9960580129543805 0.9955098969117375\n",
      "7 fold: ls 0.03518100108757928 0.03831405844461443 auc 0.9962506146177559 0.9955304143264806\n",
      "8 fold: ls 0.0353194537592486 0.03895168252093478 auc 0.9962538566744462 0.9951581250528597\n",
      "9 fold: ls 0.035365585778138774 0.03870883599531895 auc 0.9962243726422831 0.9953144483276841\n",
      "obscene 0.075 0.6 3\n",
      "this class avg train 0.03515885391057601 avg val 0.03800971843461424\n",
      "this class auc train 0.9962710897068622 auc val 0.995481654528378\n",
      "========================\n",
      "0 fold: ls 0.004921892790526186 0.00650300409782271 auc 0.9986225791063607 0.9969175570919757\n",
      "1 fold: ls 0.004999181831471684 0.006287052444873143 auc 0.9986043474369846 0.9968010161324115\n",
      "2 fold: ls 0.004024883983850395 0.007328495618757201 auc 0.9992531918415026 0.994848627697465\n",
      "3 fold: ls 0.0040760036947484575 0.00646293118306863 auc 0.9992267633514983 0.9915391183187714\n",
      "4 fold: ls 0.00502343913061404 0.00677167514648134 auc 0.9985164722185407 0.996549385044105\n",
      "5 fold: ls 0.004943159847763528 0.006912106138105642 auc 0.9985373999173612 0.9959745008066713\n",
      "6 fold: ls 0.004711528276445487 0.006311298149464165 auc 0.998757031122095 0.9952464014080081\n",
      "7 fold: ls 0.00490597906767318 0.007525161371187978 auc 0.9986155478590566 0.9954153309447482\n",
      "8 fold: ls 0.004932976646272301 0.007092453715338819 auc 0.9985724240663579 0.99466781147564\n",
      "9 fold: ls 0.005250552687224448 0.007465648776336055 auc 0.9982343229317773 0.9890179919569144\n",
      "threat 0.075 0.6 3\n",
      "this class avg train 0.00477895979565897 avg val 0.006865982664143568\n",
      "this class auc train 0.9986940079851536 auc val 0.9946977740876711\n",
      "========================\n",
      "0 fold: ls 0.049862520474039815 0.050186219504488844 auc 0.991755237806766 0.9913308225893344\n",
      "1 fold: ls 0.05141876430356442 0.05403160767435089 auc 0.9911440830118505 0.9894721498147894\n",
      "2 fold: ls 0.05133759231700461 0.05530067472926551 auc 0.9911846779110791 0.9889999213649703\n",
      "3 fold: ls 0.047876845979772195 0.05156961382582523 auc 0.9924931017757341 0.9905944975556218\n",
      "4 fold: ls 0.04894331432271328 0.05511652394763862 auc 0.9920942703811679 0.9891767641258739\n",
      "5 fold: ls 0.04628199644021695 0.05230271207515815 auc 0.993087009543996 0.9905021863652593\n",
      "6 fold: ls 0.05007751129478382 0.05632045602433287 auc 0.991631206641051 0.9891171983470162\n",
      "7 fold: ls 0.04951549671066661 0.05548699480640363 auc 0.9918634187438612 0.9894847572077171\n",
      "8 fold: ls 0.049888820895607 0.052418991552903915 auc 0.9917189678626415 0.9904828303360285\n",
      "9 fold: ls 0.05107764599290329 0.05487340420774733 auc 0.9912745579695903 0.9892661276764633\n",
      "insult 0.075 0.6 3\n",
      "this class avg train 0.049628050873127195 avg val 0.053760719834811496\n",
      "this class auc train 0.9918246531647739 auc val 0.9898427255383074\n",
      "========================\n",
      "0 fold: ls 0.01469840573869737 0.01708464405479063 auc 0.9955117997120823 0.9929006271643267\n",
      "1 fold: ls 0.015098560551977362 0.01775770846232993 auc 0.9952226275348758 0.9911671480142785\n",
      "2 fold: ls 0.014906508697472247 0.017879537601044024 auc 0.9953512920775653 0.9918771749760222\n",
      "3 fold: ls 0.014832494179587515 0.018011251436213557 auc 0.9954379456365533 0.9895953137772133\n",
      "4 fold: ls 0.014903960787788892 0.01894375501803734 auc 0.9953706941603943 0.9891825699702762\n",
      "5 fold: ls 0.015120968308988457 0.016467179086347063 auc 0.9951938448222382 0.9936230457283755\n",
      "6 fold: ls 0.012791089574875212 0.016600038136515716 auc 0.9969992572446413 0.9903068321410506\n",
      "7 fold: ls 0.01515380197321299 0.01847700211050808 auc 0.9951501434836754 0.9860920677072044\n",
      "8 fold: ls 0.014855711156105128 0.016896069904212253 auc 0.9954825980055283 0.992789851145314\n",
      "9 fold: ls 0.014985193755445584 0.016909771355990748 auc 0.995329040623859 0.9917682816677506\n",
      "identity_hate 0.075 0.6 3\n",
      "this class avg train 0.014734669472415075 avg val 0.017502695716598935\n",
      "this class auc train 0.9955049243301414 auc val 0.9909302912291812\n",
      "========================\n",
      "all loss avg 0.0317430920202364 0.035317557792116164\n",
      "all auc avg 0.9946517735712419 0.9918825913584624\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 4 feature fraction 0.4\n",
      "0 fold: ls 0.0666569541341171 0.07784832369967518 auc 0.9917852733484549 0.9871772117034596\n",
      "1 fold: ls 0.06566374245466841 0.07110622330050258 auc 0.9920906878425029 0.9899895537181697\n",
      "2 fold: ls 0.06620095549839083 0.0760311835757675 auc 0.9919058264374498 0.988347639212787\n",
      "3 fold: ls 0.06437003608620404 0.07307643760002984 auc 0.9924750371023697 0.9891182450246525\n",
      "4 fold: ls 0.06488828976825718 0.0776932327552214 auc 0.9922867713199532 0.9879300984949873\n",
      "5 fold: ls 0.06638667057466173 0.07638214201310023 auc 0.9919085723805201 0.9875520003887507\n",
      "6 fold: ls 0.06376159364513975 0.07776973213907762 auc 0.9926485036209469 0.9874980576065396\n",
      "7 fold: ls 0.06995107616539327 0.07065769037167016 auc 0.9907066364120438 0.9901576158684009\n",
      "8 fold: ls 0.062018642514285946 0.07386047801031355 auc 0.9931231915447438 0.9894189111932821\n",
      "9 fold: ls 0.06770182746001267 0.07821128276828092 auc 0.991418865910413 0.9873434661220153\n",
      "toxic 0.075 0.4 4\n",
      "this class avg train 0.06575997883011309 avg val 0.07526367262336389\n",
      "this class auc train 0.9920349365919398 auc val 0.9884532799333045\n",
      "========================\n",
      "0 fold: ls 0.016325063454420245 0.02133526638150634 auc 0.9956511107463417 0.991033675148753\n",
      "1 fold: ls 0.015896719391580875 0.02093054903750986 auc 0.9960331170482032 0.9914617356627422\n",
      "2 fold: ls 0.016574850540916286 0.021240777685677784 auc 0.9955130519759229 0.9911460311431827\n",
      "3 fold: ls 0.016047658994344606 0.019816478829115643 auc 0.9959056353906472 0.9926600677300924\n",
      "4 fold: ls 0.016526855516759097 0.02115894965972674 auc 0.995547378579229 0.9910443568806178\n",
      "5 fold: ls 0.016490330580853155 0.01997524595934116 auc 0.9955437421787297 0.9922556075484437\n",
      "6 fold: ls 0.016768778714448287 0.01921828947216103 auc 0.9953878169699417 0.9929215920704633\n",
      "7 fold: ls 0.014588228253230038 0.02008160231236379 auc 0.9970281390943868 0.9922057488027143\n",
      "8 fold: ls 0.016444403589172863 0.021262686298265235 auc 0.9955610312795509 0.9910304599671222\n",
      "9 fold: ls 0.017008927147677332 0.019040220014934828 auc 0.9952059431693279 0.9931736103065505\n",
      "severe_toxic 0.075 0.4 4\n",
      "this class avg train 0.01626718161834028 avg val 0.020406006565060236\n",
      "this class auc train 0.9957376966432282 auc val 0.9918932885260683\n",
      "========================\n",
      "0 fold: ls 0.03365631357911028 0.03708882380901531 auc 0.9966252789286707 0.9957104213348201\n",
      "1 fold: ls 0.03364888655068834 0.036995826863948554 auc 0.9966282899154773 0.9955397935160646\n",
      "2 fold: ls 0.032003776826866115 0.03897764727696861 auc 0.9969676153248781 0.9953808408067887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold: ls 0.03243663087247771 0.0339214712083175 auc 0.9968765524984412 0.9963964528365717\n",
      "4 fold: ls 0.032595949733118745 0.041904201289198154 auc 0.9968436977879486 0.9945689933310571\n",
      "5 fold: ls 0.033026136464971136 0.037621519171438626 auc 0.9967488320957308 0.9955458415429096\n",
      "6 fold: ls 0.03326378541015158 0.03726381742106681 auc 0.9966989123513792 0.9954078580132252\n",
      "7 fold: ls 0.03349157134599186 0.03826414192345008 auc 0.9966597867316515 0.9955396549941893\n",
      "8 fold: ls 0.03314531405549431 0.03914503142491475 auc 0.9967446738897073 0.995125704405136\n",
      "9 fold: ls 0.03291372353530127 0.03876502699144607 auc 0.9967766781080848 0.9953088816771581\n",
      "obscene 0.075 0.4 4\n",
      "this class avg train 0.033018208837417136 avg val 0.037994750737976445\n",
      "this class auc train 0.9967570317631969 auc val 0.995452444245792\n",
      "========================\n",
      "0 fold: ls 0.004020943607377256 0.00664914174639347 auc 0.9992557743229554 0.9969241043368948\n",
      "1 fold: ls 0.003921230271897287 0.006291593886704784 auc 0.9993578960344942 0.9966556672952022\n",
      "2 fold: ls 0.0041407138880116216 0.007342135238031792 auc 0.9991875415897269 0.9947268489419652\n",
      "3 fold: ls 0.004217687670470159 0.006573597661434314 auc 0.9992115771672554 0.9905340530517317\n",
      "4 fold: ls 0.0038304425675048863 0.006958206261542798 auc 0.9994165338078569 0.9962010497202842\n",
      "5 fold: ls 0.003909499488294734 0.007056963333508528 auc 0.9993311500960222 0.9957780711127873\n",
      "6 fold: ls 0.004211029266456111 0.006355500783359773 auc 0.999150994849366 0.9952306870324974\n",
      "7 fold: ls 0.00403666436037761 0.00742927625985023 auc 0.9992289235252996 0.9956968801726487\n",
      "8 fold: ls 0.00434145467760518 0.007078505348526704 auc 0.9989511086800454 0.9950516434561997\n",
      "9 fold: ls 0.004170464575433785 0.007554620918292879 auc 0.9990861060705173 0.9875669198352867\n",
      "threat 0.075 0.4 4\n",
      "this class avg train 0.0040800130373428636 avg val 0.006928954143764527\n",
      "this class auc train 0.9992177606143541 auc val 0.9944365924955498\n",
      "========================\n",
      "0 fold: ls 0.047661976180548904 0.05010739224393553 auc 0.9926209805904171 0.9913684670184608\n",
      "1 fold: ls 0.04280955751863802 0.05394125824519123 auc 0.9943089843539653 0.9896949630080742\n",
      "2 fold: ls 0.049237483466440704 0.05515779237587575 auc 0.992095305137315 0.9890870891319697\n",
      "3 fold: ls 0.047124175832095605 0.051747683049049135 auc 0.9928255137463586 0.9905291635575156\n",
      "4 fold: ls 0.04888974946309448 0.05500801195976054 auc 0.9921886349941773 0.9891081630884253\n",
      "5 fold: ls 0.043509457406556526 0.052170547045606024 auc 0.9940676447714799 0.9905900291571141\n",
      "6 fold: ls 0.047728071026183615 0.05644944236816043 auc 0.9925938184790449 0.989022328131813\n",
      "7 fold: ls 0.046199740929557635 0.05522580451891913 auc 0.9931349698813151 0.9896071394855571\n",
      "8 fold: ls 0.04731336000207761 0.052136552513829974 auc 0.9927530794718492 0.9905407127138433\n",
      "9 fold: ls 0.04836912966061161 0.05469503225219933 auc 0.9923674776573157 0.9893225022644072\n",
      "insult 0.075 0.4 4\n",
      "this class avg train 0.04688427014858047 avg val 0.053663951657252705\n",
      "this class auc train 0.9928956409083239 auc val 0.989887055755718\n",
      "========================\n",
      "0 fold: ls 0.013334665016814799 0.017340064499837896 auc 0.9966874875673276 0.9926544605700752\n",
      "1 fold: ls 0.013324590781561878 0.017818275216544915 auc 0.9967455298623787 0.991243822855111\n",
      "2 fold: ls 0.012800617462708911 0.01793254275111551 auc 0.9970449449609984 0.9920603426513442\n",
      "3 fold: ls 0.013423167713884812 0.018168391545582637 auc 0.9966669044639885 0.9893592359778083\n",
      "4 fold: ls 0.014067962978654952 0.01902141455038038 auc 0.9962046391419344 0.9867915255916855\n",
      "5 fold: ls 0.013901216748451397 0.016785537984415493 auc 0.996319833759354 0.9933678953025226\n",
      "6 fold: ls 0.01200256596079829 0.01649905260077176 auc 0.9975726865947235 0.9898746296697738\n",
      "7 fold: ls 0.01384968603409135 0.01878792874339203 auc 0.9963474206952467 0.9889201260929259\n",
      "8 fold: ls 0.010492685447736088 0.016724603222532632 auc 0.9984056388320832 0.9926394609437098\n",
      "9 fold: ls 0.013877447766881327 0.016960798440793273 auc 0.996376425639082 0.9917307970229063\n",
      "identity_hate 0.075 0.4 4\n",
      "this class avg train 0.013107460591158382 avg val 0.017603860955536652\n",
      "this class auc train 0.9968371511517118 auc val 0.9908642296677863\n",
      "========================\n",
      "all loss avg 0.029852852177158704 0.035310199447159074\n",
      "all auc avg 0.9955800362787923 0.9918311484373699\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 4 feature fraction 0.5\n",
      "0 fold: ls 0.06798366759887897 0.07778032089230755 auc 0.9913849556266716 0.9871512998508709\n",
      "1 fold: ls 0.06614964470608391 0.07113977341296261 auc 0.9919482818046882 0.9899197910381231\n",
      "2 fold: ls 0.06732053445489061 0.07622473143775485 auc 0.991558828590316 0.988255996419453\n",
      "3 fold: ls 0.05956467087975478 0.07259855828647971 auc 0.9938730590316215 0.9892192650093953\n",
      "4 fold: ls 0.06322439839506058 0.07795340332613429 auc 0.9927820153178736 0.9878442433441406\n",
      "5 fold: ls 0.06549993136146955 0.076363477626726 auc 0.9921511050625271 0.987552091048889\n",
      "6 fold: ls 0.06595528032395694 0.07801888508731449 auc 0.9920033957014815 0.9874375419643114\n",
      "7 fold: ls 0.06661666322471668 0.07065385810017545 auc 0.991773833872692 0.9901507705535227\n",
      "8 fold: ls 0.06573144777229625 0.074168798215071 auc 0.9920143063729546 0.9893116074825729\n",
      "9 fold: ls 0.06884750492545041 0.07788120512868349 auc 0.9910276256895373 0.9875149163264523\n",
      "toxic 0.075 0.5 4\n",
      "this class avg train 0.06568937436425586 avg val 0.07527830115136094\n",
      "this class auc train 0.9920517407070364 auc val 0.9884357523037732\n",
      "========================\n",
      "0 fold: ls 0.016556649591870056 0.0214083431638599 auc 0.9955280623596774 0.9909798708697304\n",
      "1 fold: ls 0.016428772904530008 0.02073665215135702 auc 0.9956351960635494 0.9915812128117483\n",
      "2 fold: ls 0.016244416554798486 0.02109378738164332 auc 0.995745491138041 0.9913430497531333\n",
      "3 fold: ls 0.016262355009428325 0.0196497339733279 auc 0.9957440305358014 0.992811590074693\n",
      "4 fold: ls 0.016742947419290704 0.021165779765648696 auc 0.9953788334130702 0.9911167552854792\n",
      "5 fold: ls 0.01675899119224768 0.01998498648174956 auc 0.9953651291246943 0.99229900130659\n",
      "6 fold: ls 0.016793866584151745 0.019207055273035404 auc 0.9953634401109307 0.9929259715342815\n",
      "7 fold: ls 0.015967833742068747 0.020376463562269295 auc 0.9959655661609506 0.9918709188871543\n",
      "8 fold: ls 0.01618391291615913 0.021217133879964697 auc 0.9957741634916994 0.9910706714076352\n",
      "9 fold: ls 0.0163040293440089 0.01901714032322806 auc 0.9957186702603162 0.993140167128302\n",
      "severe_toxic 0.075 0.5 4\n",
      "this class avg train 0.01642437752585538 avg val 0.020385707595608385\n",
      "this class auc train 0.9956218582658731 auc val 0.9919139209058748\n",
      "========================\n",
      "0 fold: ls 0.0333648564404651 0.037120334082293795 auc 0.9966897975881621 0.9956846588050492\n",
      "1 fold: ls 0.034029056229411776 0.03704695546264594 auc 0.99656013467237 0.9954802812892385\n",
      "2 fold: ls 0.032504050946159053 0.039050156827559634 auc 0.9968597180731482 0.9953586788664364\n",
      "3 fold: ls 0.03217293308296391 0.033835474734969485 auc 0.9969357894089927 0.9964344335470695\n",
      "4 fold: ls 0.03333690127098921 0.04196116088823324 auc 0.9967016105199431 0.9945675837376778\n",
      "5 fold: ls 0.03396117628396066 0.03767052793456971 auc 0.9965696719626512 0.9955309625016837\n",
      "6 fold: ls 0.0341043126641189 0.03739828398959252 auc 0.9965424142235728 0.9953777866878\n",
      "7 fold: ls 0.03348254841794764 0.038465153360871925 auc 0.9966663704369914 0.9955015176622051\n",
      "8 fold: ls 0.03244627023881392 0.03904907797364152 auc 0.9968811902929284 0.9950909344351133\n",
      "9 fold: ls 0.033457680087775096 0.038785380435674414 auc 0.9966736531390714 0.9953026877984039\n",
      "obscene 0.075 0.5 4\n",
      "this class avg train 0.033285978566260525 avg val 0.038038250569005214\n",
      "this class auc train 0.9967080350317831 auc val 0.9954329525330676\n",
      "========================\n",
      "0 fold: ls 0.003771096647686404 0.0065533233551047934 auc 0.9994077021940859 0.9969987429289755\n",
      "1 fold: ls 0.003948818377598229 0.00625056570050508 auc 0.9993421575154515 0.996816729520218\n",
      "2 fold: ls 0.004257503566211239 0.007310861276076395 auc 0.9990662299295305 0.9948394615545777\n",
      "3 fold: ls 0.004199778444028834 0.006679629739977596 auc 0.999217667882861 0.9905818509439102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 fold: ls 0.0038260912471588305 0.00685523606064753 auc 0.9993999020937768 0.9962586690971568\n",
      "5 fold: ls 0.004145336918555467 0.007131077896117559 auc 0.9991592619806813 0.9960792633100761\n",
      "6 fold: ls 0.004027394095377868 0.006353699525694269 auc 0.9992756027697001 0.9950342573386133\n",
      "7 fold: ls 0.004013457869547737 0.007488159208825749 auc 0.9992335362272514 0.9955790223563181\n",
      "8 fold: ls 0.004117805195014508 0.007046894383062143 auc 0.9991799771403769 0.9943428248161417\n",
      "9 fold: ls 0.004259152926506829 0.007440235636093222 auc 0.999095925830285 0.9902483941245622\n",
      "threat 0.075 0.5 4\n",
      "this class avg train 0.004056643528768595 avg val 0.006910968278210435\n",
      "this class auc train 0.9992377963564 auc val 0.9946779215990549\n",
      "========================\n",
      "0 fold: ls 0.04548177242185399 0.04989953272550446 auc 0.9933959005724292 0.9914562203654689\n",
      "1 fold: ls 0.04895723207351132 0.05381707114238372 auc 0.9921790997626543 0.9898831014994195\n",
      "2 fold: ls 0.04920256680059794 0.05527010498663256 auc 0.9921052765303436 0.9886593647628065\n",
      "3 fold: ls 0.047170810842656515 0.05186502710201859 auc 0.9927990423610731 0.990533513580437\n",
      "4 fold: ls 0.04807829801901896 0.05494790776832441 auc 0.9924747794857385 0.9892640212991163\n",
      "5 fold: ls 0.047046115213610636 0.052657172428419566 auc 0.9928548287967857 0.9903986991904743\n",
      "6 fold: ls 0.047963815308160636 0.0564634075313574 auc 0.9925091518930228 0.9890665423370466\n",
      "7 fold: ls 0.04397629585083979 0.055452845525507694 auc 0.993893355345211 0.9895617382572278\n",
      "8 fold: ls 0.04479844102957869 0.05220488887119087 auc 0.993637289574051 0.990602364566335\n",
      "9 fold: ls 0.04817868848617051 0.05453889883276571 auc 0.9924317616725239 0.9894541825797832\n",
      "insult 0.075 0.5 4\n",
      "this class avg train 0.047085403604599896 avg val 0.05371168569141049\n",
      "this class auc train 0.9928280485993832 auc val 0.9898879748438114\n",
      "========================\n",
      "0 fold: ls 0.012510086697864194 0.017208241757408746 auc 0.9972509455055685 0.9927795616261703\n",
      "1 fold: ls 0.014066963161688458 0.01777522344437619 auc 0.9961839032006466 0.9915043379575885\n",
      "2 fold: ls 0.012342865237614777 0.017952663393903286 auc 0.9973417368046495 0.9920181939084305\n",
      "3 fold: ls 0.013418997300379168 0.017947941704168722 auc 0.9966661819573234 0.9891897442243891\n",
      "4 fold: ls 0.0139576429429399 0.019033494683816692 auc 0.9962584992349433 0.9896128010216139\n",
      "5 fold: ls 0.012281123137102867 0.016356456092957952 auc 0.9974315061599008 0.9937910385751317\n",
      "6 fold: ls 0.01079756156026872 0.01669590517806169 auc 0.9982496352168776 0.9903027675410072\n",
      "7 fold: ls 0.013768619392730809 0.01884633768672358 auc 0.9963880320592648 0.9885369246332827\n",
      "8 fold: ls 0.012686258351663024 0.01667505311450855 auc 0.9971427825698225 0.992915853746658\n",
      "9 fold: ls 0.013511646116147854 0.016968661596852664 auc 0.9966373229708547 0.9918599609798396\n",
      "identity_hate 0.075 0.5 4\n",
      "this class avg train 0.012934176389839975 avg val 0.01754599786527781\n",
      "this class auc train 0.9969550545679853 auc val 0.9912511184214111\n",
      "========================\n",
      "all loss avg 0.02991265899659671 0.03531181852514555\n",
      "all auc avg 0.9955670889214101 0.9919332734344989\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.075 4 0.5 identity_hate\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.075 max depth 4 feature fraction 0.6\n",
      "0 fold: ls 0.06713138450279835 0.07779251703200271 auc 0.991642278414333 0.9871900317284292\n",
      "1 fold: ls 0.0626438031087271 0.07131005979536266 auc 0.9929974695374654 0.9898314098765834\n",
      "2 fold: ls 0.06731422278308753 0.0758793049997802 auc 0.9915595954144389 0.9883860992876958\n",
      "3 fold: ls 0.06765646153822037 0.07338921302083154 auc 0.9914186298645518 0.988913215226022\n",
      "4 fold: ls 0.06505562187095401 0.07825748969896602 auc 0.992240797105477 0.9877678621777326\n",
      "5 fold: ls 0.06459583234628966 0.07600089697789561 auc 0.9924080510884953 0.9877361764594424\n",
      "6 fold: ls 0.0627399302610626 0.07809055904598335 auc 0.9929474565831513 0.9874465173179902\n",
      "7 fold: ls 0.06588755144929116 0.07083395136719361 auc 0.9919877704037225 0.9901227999622646\n",
      "8 fold: ls 0.068144038199108 0.07406691703626883 auc 0.9912633412410671 0.9893129674789064\n",
      "9 fold: ls 0.06826302662702091 0.07802421547586096 auc 0.9912217089180969 0.9874755670992045\n",
      "toxic 0.075 0.6 4\n",
      "this class avg train 0.06594318726865596 avg val 0.07536451244501455\n",
      "this class auc train 0.9919687098570801 auc val 0.9884182646614272\n",
      "========================\n",
      "0 fold: ls 0.016230319902316406 0.02143473371427226 auc 0.9957458930487243 0.990969980377263\n",
      "1 fold: ls 0.015746873930732347 0.02060441445076212 auc 0.996148436006237 0.991737878212432\n",
      "2 fold: ls 0.01643051613932075 0.021084833957994206 auc 0.9956105177673196 0.9912386061526774\n",
      "3 fold: ls 0.016636073769514707 0.01989214209755307 auc 0.9954294423004035 0.9925488985947589\n",
      "4 fold: ls 0.01641164284210541 0.020960118093327876 auc 0.9956052512669622 0.9913280162045829\n",
      "5 fold: ls 0.016426004862328862 0.0199488624454897 auc 0.9956178846940305 0.9922794940208177\n",
      "6 fold: ls 0.016469836536261277 0.019154791577441817 auc 0.9956096870395299 0.9929474707202983\n",
      "7 fold: ls 0.01556372198372325 0.020221649477907583 auc 0.9963250672810124 0.9920548563675214\n",
      "8 fold: ls 0.016390664577951505 0.021163862176734327 auc 0.9956144037193024 0.991114466045818\n",
      "9 fold: ls 0.01687223402447827 0.019226870043888258 auc 0.9953208675454248 0.9929765344347287\n",
      "severe_toxic 0.075 0.6 4\n",
      "this class avg train 0.01631778885687328 avg val 0.020369227803537122\n",
      "this class auc train 0.9957027450668947 auc val 0.9919196201130898\n",
      "========================\n",
      "0 fold: ls 0.03354420799470737 0.037263311082832894 auc 0.9966489162387138 0.995617472633185\n",
      "1 fold: ls 0.0339935343473121 0.03710554783619881 auc 0.9965647439768361 0.995438857647145\n",
      "2 fold: ls 0.03133898844424467 0.038896986806850865 auc 0.9970970118699305 0.9953918826215931\n",
      "3 fold: ls 0.032536523290718516 0.03382491987062625 auc 0.9968610374248791 0.9964402285420733\n",
      "4 fold: ls 0.032998460177143356 0.04184532969515557 auc 0.9967623181039887 0.9945646079294326\n",
      "5 fold: ls 0.03084275031017391 0.03779353065610214 auc 0.9972153000438863 0.9955015176622051\n",
      "6 fold: ls 0.03425973941877217 0.03758347483069255 auc 0.9965330883551627 0.9954017106198767\n",
      "7 fold: ls 0.03349299427955655 0.03827244227982631 auc 0.9966614517545028 0.9955555520750781\n",
      "8 fold: ls 0.03035509685201393 0.039098448270321946 auc 0.9973194461596393 0.9951092591490441\n",
      "9 fold: ls 0.03328323951224722 0.03863318080313496 auc 0.9967051345617401 0.9953320891216044\n",
      "obscene 0.075 0.6 4\n",
      "this class avg train 0.03266455346268898 avg val 0.03803171721317422\n",
      "this class auc train 0.996836844848928 auc val 0.9954353178001238\n",
      "========================\n",
      "0 fold: ls 0.003971801233839892 0.006556351220923708 auc 0.9993045978402335 0.9968808925204274\n",
      "1 fold: ls 0.003867737484797508 0.006325539723700379 auc 0.9993765418754241 0.996865179132621\n",
      "2 fold: ls 0.004088588568811538 0.007508660267741725 auc 0.9992254342263902 0.9939437984496123\n",
      "3 fold: ls 0.004191532398540469 0.0065865312694333225 auc 0.9992289722510244 0.9915188205837366\n",
      "4 fold: ls 0.004169389435294144 0.006983228938860668 auc 0.9991891470919189 0.9959915247134745\n",
      "5 fold: ls 0.003855582474688946 0.006990409113318971 auc 0.9993511114012998 0.9960570012781027\n",
      "6 fold: ls 0.004094165661726001 0.006354114271099448 auc 0.9992361349325766 0.9951442579671885\n",
      "7 fold: ls 0.003960733281249345 0.007717482714281182 auc 0.9992766747356467 0.9952424728141304\n",
      "8 fold: ls 0.0036728107674544497 0.007256370348305906 auc 0.9994454023301415 0.993977716346829\n",
      "9 fold: ls 0.004207216932746929 0.007605227620048155 auc 0.9991373600311536 0.9818682854479532\n",
      "threat 0.075 0.6 4\n",
      "this class avg train 0.004007955823914922 avg val 0.006988391548771346\n",
      "this class auc train 0.999277137671581 auc val 0.9937489949254076\n",
      "========================\n",
      "0 fold: ls 0.04540632966480251 0.049962757350474965 auc 0.9934335233238886 0.9914210855649508\n",
      "1 fold: ls 0.04909446240245829 0.05412131143018803 auc 0.9921391428961902 0.9898112424669313\n",
      "2 fold: ls 0.049088514076971734 0.055327577358688894 auc 0.9921323601171077 0.9889178146823312\n",
      "3 fold: ls 0.04591351635560059 0.05188608691753057 auc 0.9932547641085101 0.990547818463505\n",
      "4 fold: ls 0.046456172480919954 0.05479662609174813 auc 0.9930464278576601 0.9893040943441623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold: ls 0.045577312898151236 0.05240454250301547 auc 0.9933697536299729 0.9904949079625057\n",
      "6 fold: ls 0.046021455892807796 0.05659059509313515 auc 0.9931963226127307 0.9890097791615481\n",
      "7 fold: ls 0.04820294471174398 0.05557299914778152 auc 0.9924234798412851 0.989461637763033\n",
      "8 fold: ls 0.048620662974715345 0.05238741439767759 auc 0.9922969124054165 0.9904592082947207\n",
      "9 fold: ls 0.04825020192347496 0.05472684636871141 auc 0.9924237128049157 0.9892553218490564\n",
      "insult 0.075 0.6 4\n",
      "this class avg train 0.04726315733816464 avg val 0.053777675665895176\n",
      "this class auc train 0.9927716399597678 auc val 0.9898682910552745\n",
      "========================\n",
      "0 fold: ls 0.0127891071690513 0.01729337710678615 auc 0.9970721112116049 0.9927374128832565\n",
      "1 fold: ls 0.013883497530854907 0.017811511579273034 auc 0.9963207237320365 0.9913213944777076\n",
      "2 fold: ls 0.012555695570324292 0.018037975786009876 auc 0.9972148813074942 0.9918244890473801\n",
      "3 fold: ls 0.013489192862615447 0.018066121287063395 auc 0.9966166068846126 0.9888121991016937\n",
      "4 fold: ls 0.013273920956199031 0.019145282859216448 auc 0.9967164239592636 0.9884763543310299\n",
      "5 fold: ls 0.013232691275441077 0.016608126991012762 auc 0.9967865123120411 0.9935209855580344\n",
      "6 fold: ls 0.010145062839476134 0.01655290309615191 auc 0.9985968837594806 0.9909887817038803\n",
      "7 fold: ls 0.013731257173695966 0.018747547960607475 auc 0.9964475607775188 0.9859434839945083\n",
      "8 fold: ls 0.011957558400362176 0.016758964800108054 auc 0.9975993258280335 0.9928286906568393\n",
      "9 fold: ls 0.014134245116612829 0.016942301099130183 auc 0.9961883572056296 0.9918364766240335\n",
      "identity_hate 0.075 0.6 4\n",
      "this class avg train 0.012919222889463317 avg val 0.017596411256535927\n",
      "this class auc train 0.9969559386977714 auc val 0.9908290268378364\n",
      "========================\n",
      "all loss avg 0.029852644273293514 0.03535465598882139\n",
      "all auc avg 0.9955855026836704 0.9917032525655264\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 3 feature fraction 0.4\n",
      "0 fold: ls 0.06919542525665161 0.07802076930180919 auc 0.9909030403765728 0.9870861125154248\n",
      "1 fold: ls 0.07157083672481857 0.07133162403511908 auc 0.9900623468353441 0.9899179337200178\n",
      "2 fold: ls 0.07091596752361568 0.0759274197302243 auc 0.9903051699048487 0.9884146385658967\n",
      "3 fold: ls 0.0680186952780105 0.07310217096776497 auc 0.9912894892406142 0.9890859911102414\n",
      "4 fold: ls 0.06720199694319677 0.07760328470829143 auc 0.9915163936947333 0.9880299606371812\n",
      "5 fold: ls 0.0679728494607735 0.07642513366783885 auc 0.9913145973681011 0.9875989623403226\n",
      "6 fold: ls 0.0695845070892803 0.07804135923589171 auc 0.9907382020811415 0.9875440222965919\n",
      "7 fold: ls 0.070586302544801 0.07085816125331244 auc 0.9904008355221684 0.9900587441349592\n",
      "8 fold: ls 0.06741098398867235 0.07384610816762706 auc 0.9914549982998907 0.9894958416525442\n",
      "9 fold: ls 0.06952268571997103 0.07794800152057252 auc 0.9907220768438142 0.9875397589261433\n",
      "toxic 0.05 0.4 3\n",
      "this class avg train 0.06919802505297913 avg val 0.07531040325884515\n",
      "this class auc train 0.990870715016723 auc val 0.9884771965899324\n",
      "========================\n",
      "0 fold: ls 0.017856531160021116 0.021170473988793206 auc 0.9942978725740217 0.9911527566780606\n",
      "1 fold: ls 0.017814249257657063 0.020569418713348293 auc 0.9943177720541994 0.9917442081276111\n",
      "2 fold: ls 0.017783034123796677 0.02104504296332375 auc 0.99436795942545 0.9912670907709837\n",
      "3 fold: ls 0.017244563106581016 0.019833316985495023 auc 0.9948412558179635 0.992565514622104\n",
      "4 fold: ls 0.018169157558459426 0.021067807476292652 auc 0.9940636885313756 0.9911246676794531\n",
      "5 fold: ls 0.0176289479379352 0.019903330365245355 auc 0.9944986669971664 0.9922571999799353\n",
      "6 fold: ls 0.01817716556627936 0.019166466271861006 auc 0.9940604805888201 0.9929502576518192\n",
      "7 fold: ls 0.016741108384280164 0.020203072875952372 auc 0.9952742076805727 0.9921563803014902\n",
      "8 fold: ls 0.01759495512290533 0.02095614602561377 auc 0.9945262906750938 0.9912550070210768\n",
      "9 fold: ls 0.018298045690736543 0.019008950374307065 auc 0.993945928453287 0.9931298156683679\n",
      "severe_toxic 0.05 0.4 3\n",
      "this class avg train 0.01773077579086519 avg val 0.02029240260402325\n",
      "this class auc train 0.9944194122797951 auc val 0.9919602898500901\n",
      "========================\n",
      "0 fold: ls 0.03495028111010917 0.03709575906844718 auc 0.9963105887463918 0.9956840323605564\n",
      "1 fold: ls 0.03520779754901153 0.036963256538927396 auc 0.9962533079615762 0.9955496600168278\n",
      "2 fold: ls 0.034968050587689085 0.03921195446552259 auc 0.9962997584150467 0.995330095445134\n",
      "3 fold: ls 0.033661830526045385 0.033640913054363494 auc 0.9966027509967802 0.9965292678571989\n",
      "4 fold: ls 0.035190905988991564 0.04201128092555387 auc 0.9962741507116801 0.9945519998997622\n",
      "5 fold: ls 0.03545759969358872 0.037572897124517855 auc 0.9961941585467634 0.995599171159093\n",
      "6 fold: ls 0.036118763400504225 0.03758457447153957 auc 0.9960676351813875 0.9954144361156618\n",
      "7 fold: ls 0.03541113028786764 0.03837514978377418 auc 0.9962062391481024 0.9955080957646418\n",
      "8 fold: ls 0.03523643221658605 0.03881374470478069 auc 0.9962629978626212 0.9951935998195721\n",
      "9 fold: ls 0.03423396029851787 0.038878398470111035 auc 0.9964732042704251 0.995271953615218\n",
      "obscene 0.05 0.4 3\n",
      "this class avg train 0.035043675165891124 avg val 0.03801479286075379\n",
      "this class auc train 0.9962944791840774 auc val 0.9954632312053665\n",
      "========================\n",
      "0 fold: ls 0.004963772270647271 0.006627822328915353 auc 0.9985471998835771 0.9968285145610727\n",
      "1 fold: ls 0.005136041396909923 0.006221404915994172 auc 0.9984509740259213 0.9969620783574272\n",
      "2 fold: ls 0.0050238818612923985 0.007245529092569962 auc 0.9984941371986313 0.9941768803687407\n",
      "3 fold: ls 0.0050694493857288865 0.0065147656755846235 auc 0.9985583113742733 0.9911056634609341\n",
      "4 fold: ls 0.00502514686463109 0.006803431588778438 auc 0.9984867170425693 0.9963490267563434\n",
      "5 fold: ls 0.0051145861068127565 0.006943089549723323 auc 0.9983040930258547 0.9960897395604165\n",
      "6 fold: ls 0.004777107281995777 0.006276747732821072 auc 0.9987302319734309 0.9955030695413498\n",
      "7 fold: ls 0.005076638486304778 0.007335514554324846 auc 0.9983548002635088 0.9958540239277558\n",
      "8 fold: ls 0.004893273282195082 0.007095359379708454 auc 0.9986244801360844 0.9946062913672576\n",
      "9 fold: ls 0.004964719070113392 0.007443839011833088 auc 0.9985119904128033 0.9901808557447076\n",
      "threat 0.05 0.4 3\n",
      "this class avg train 0.0050044616006631355 avg val 0.006850750383025332\n",
      "this class auc train 0.9985062935336654 auc val 0.9947656143646005\n",
      "========================\n",
      "0 fold: ls 0.04958748987228216 0.05010841982266701 auc 0.9918682842970178 0.9913834411358246\n",
      "1 fold: ls 0.05070560747225813 0.053824657128459935 auc 0.9914135684198584 0.9898208627099304\n",
      "2 fold: ls 0.051369119690374394 0.05521128779588244 auc 0.9911770556152011 0.9889783385589378\n",
      "3 fold: ls 0.050832103721919215 0.05175137490304541 auc 0.9913690657636809 0.990576679192502\n",
      "4 fold: ls 0.049689247032842325 0.05508683045530084 auc 0.9918050762703171 0.9891946673234518\n",
      "5 fold: ls 0.04645340914818331 0.052164147785723924 auc 0.9930342924083776 0.9904850361058973\n",
      "6 fold: ls 0.049362267312436585 0.05608914669412654 auc 0.9919136944825475 0.9891928268078132\n",
      "7 fold: ls 0.049268274930201646 0.05542676625785114 auc 0.9919566827115418 0.9895130701508453\n",
      "8 fold: ls 0.05042338872663802 0.05242390691483573 auc 0.9915179434941807 0.99048115501395\n",
      "9 fold: ls 0.050992006412937885 0.05477779450552854 auc 0.9913062570363669 0.9893179788947951\n",
      "insult 0.05 0.4 3\n",
      "this class avg train 0.04986829143200737 avg val 0.053686433226342145\n",
      "this class auc train 0.991736192049909 auc val 0.9898944055893948\n",
      "========================\n",
      "0 fold: ls 0.014142690253234403 0.017073592165755748 auc 0.9959969546010603 0.9929015239460908\n",
      "1 fold: ls 0.015209619387590623 0.017772442727885952 auc 0.9950901753899379 0.9911075120269645\n",
      "2 fold: ls 0.015208181231218016 0.017794288269698155 auc 0.9951207179697678 0.9920004824685892\n",
      "3 fold: ls 0.014432230694963865 0.018023766985300633 auc 0.9957523332963706 0.988865557616659\n",
      "4 fold: ls 0.014906598563715439 0.018783353913490987 auc 0.9953696270736274 0.9898224237589773\n",
      "5 fold: ls 0.014942773191350962 0.016410174531540336 auc 0.9953662541295754 0.9937201383683018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fold: ls 0.014400192466395224 0.016618228197026925 auc 0.9958101850502089 0.9905082556543103\n",
      "7 fold: ls 0.015384518092343704 0.01868298475461082 auc 0.994877423152587 0.9879841390273865\n",
      "8 fold: ls 0.014107041613256485 0.016798038465261827 auc 0.9960904217878608 0.992676493966327\n",
      "9 fold: ls 0.015250027089136725 0.01679612185988656 auc 0.9951201805936767 0.9919236397138522\n",
      "identity_hate 0.05 0.4 3\n",
      "this class avg train 0.014798387258320545 avg val 0.017475299187045792\n",
      "this class auc train 0.9954594273044671 auc val 0.9911510166547457\n",
      "========================\n",
      "all loss avg 0.031940602716787746 0.035271680253339245\n",
      "all auc avg 0.9945477532281062 0.991951959042355\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.05 3 0.4 severe_toxic\n",
      "FIND BETTER PARAMS 0.05 3 0.4 threat\n",
      "FIND BETTER PARAMS 0.05 3 0.4 insult\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 3 feature fraction 0.5\n",
      "0 fold: ls 0.0699966105979119 0.07793535371791159 auc 0.9906222750397026 0.9871180040263033\n",
      "1 fold: ls 0.06870683736242793 0.07111667894177505 auc 0.9910699008581064 0.9899573904046416\n",
      "2 fold: ls 0.07060254319902032 0.0759464476989381 auc 0.9904142097213319 0.9883670731022286\n",
      "3 fold: ls 0.07067628231095631 0.07333282237679292 auc 0.9903679775844256 0.9890357529205196\n",
      "4 fold: ls 0.06849001776797937 0.07771013253931018 auc 0.991100167405882 0.9880248836694437\n",
      "5 fold: ls 0.067482357102019 0.07637502113989929 auc 0.9914589842525099 0.9876674560747098\n",
      "6 fold: ls 0.06811156187262964 0.07782902427900824 auc 0.9912485159737233 0.9875589812193897\n",
      "7 fold: ls 0.07092388059425578 0.07077638869986172 auc 0.9902773540287411 0.99008195473905\n",
      "8 fold: ls 0.06788866115480209 0.07415420225678908 auc 0.9912857068726508 0.9893632873432441\n",
      "9 fold: ls 0.06953935073752619 0.07773066151366856 auc 0.9906916737731835 0.987622446703217\n",
      "toxic 0.05 0.5 3\n",
      "this class avg train 0.06924181026995284 avg val 0.07529067331639547\n",
      "this class auc train 0.9908536765510256 auc val 0.9884797230202746\n",
      "========================\n",
      "0 fold: ls 0.01758306811863553 0.02121681867319509 auc 0.994522104425904 0.9911183377642739\n",
      "1 fold: ls 0.017287432499004367 0.020501123768594122 auc 0.9947795429226641 0.9918019686036206\n",
      "2 fold: ls 0.01798241910823361 0.021047277509495952 auc 0.9942137335527244 0.9912378149132802\n",
      "3 fold: ls 0.01770508716314516 0.019915660455818794 auc 0.9944511892463601 0.9925113147233826\n",
      "4 fold: ls 0.01792439484634579 0.02109500919499107 auc 0.9942577231671562 0.9910067730092417\n",
      "5 fold: ls 0.017808308802256007 0.019890643774512985 auc 0.9943486064645475 0.9922854656389114\n",
      "6 fold: ls 0.01802314578019103 0.01913391201136212 auc 0.9941892268447905 0.9929733493701336\n",
      "7 fold: ls 0.017837005528476637 0.02020158638306043 auc 0.994336893696774 0.992123335256316\n",
      "8 fold: ls 0.018067843087295553 0.021061781358533992 auc 0.994143553907222 0.9911849355999846\n",
      "9 fold: ls 0.01807345890443889 0.01900246829666595 auc 0.9941329156637477 0.9930967706231938\n",
      "severe_toxic 0.05 0.5 3\n",
      "this class avg train 0.017829216383802256 avg val 0.020306628142623052\n",
      "this class auc train 0.994337548989189 auc val 0.9919340065502338\n",
      "========================\n",
      "0 fold: ls 0.03531973908762843 0.037051014601140284 auc 0.996231509732107 0.9957012595841114\n",
      "1 fold: ls 0.034902731100361475 0.037100109126323 auc 0.9963243581611698 0.9954932017069047\n",
      "2 fold: ls 0.03414142747361229 0.039073110329023886 auc 0.9964816916523876 0.9953631425788041\n",
      "3 fold: ls 0.03570704980661552 0.033763389965224946 auc 0.9961430548183924 0.9965305991398348\n",
      "4 fold: ls 0.03520823871088018 0.04208663602807791 auc 0.9962726225069087 0.9945148806074408\n",
      "5 fold: ls 0.03531376929657553 0.037519489549772966 auc 0.9962291859090258 0.9956127972284262\n",
      "6 fold: ls 0.034066917095992535 0.03754281173557821 auc 0.9965105182065511 0.9952150569632348\n",
      "7 fold: ls 0.03535594704453672 0.038433011993362964 auc 0.9962181021941907 0.995500186379569\n",
      "8 fold: ls 0.034656288255614856 0.038898401247836466 auc 0.996386804688101 0.9951950877236947\n",
      "9 fold: ls 0.03484723002627255 0.03878697478841302 auc 0.9963327096119368 0.9953022173772326\n",
      "obscene 0.05 0.5 3\n",
      "this class avg train 0.034951933789809 avg val 0.03802549493647536\n",
      "this class auc train 0.996313055748077 auc val 0.9954428429289253\n",
      "========================\n",
      "0 fold: ls 0.00497346939471743 0.00653878124645254 auc 0.9985791154562489 0.9969267232348628\n",
      "1 fold: ls 0.005031130395941432 0.0061866431839213655 auc 0.9985556376138587 0.9969463649696209\n",
      "2 fold: ls 0.0047501614629153225 0.0072830590286785905 auc 0.9987661260942858 0.994244971715902\n",
      "3 fold: ls 0.005199363362740616 0.006530589768017579 auc 0.9984483292923465 0.9904443501581914\n",
      "4 fold: ls 0.0050983822215617996 0.00673782874554009 auc 0.9983879824821276 0.9964970037924026\n",
      "5 fold: ls 0.004858034960799221 0.007002514083471383 auc 0.998654885760914 0.9960805728413686\n",
      "6 fold: ls 0.004778180111366971 0.006280018758632605 auc 0.9987058285062382 0.9951442579671884\n",
      "7 fold: ls 0.005033464661239817 0.007467956276545724 auc 0.9984278726088665 0.9956287845454355\n",
      "8 fold: ls 0.004850242224085554 0.007101381215045575 auc 0.9986632244357624 0.9945768687067269\n",
      "9 fold: ls 0.0051898469358355286 0.007407976132493168 auc 0.9983217042099094 0.9888608482018074\n",
      "threat 0.05 0.5 3\n",
      "this class avg train 0.004976227573120369 avg val 0.006853674843879863\n",
      "this class auc train 0.9985510706460557 auc val 0.9945350746133508\n",
      "========================\n",
      "0 fold: ls 0.047252771669828955 0.04996484078900597 auc 0.9927547308564122 0.9914332990908452\n",
      "1 fold: ls 0.04999432565006635 0.05385573142966982 auc 0.9916862672398468 0.9897661528062667\n",
      "2 fold: ls 0.05153040960885175 0.055377547579597015 auc 0.9911429092382138 0.9889903011219713\n",
      "3 fold: ls 0.05042218545665887 0.051815626854246455 auc 0.9915221207829686 0.9904849104397204\n",
      "4 fold: ls 0.05092920891191684 0.05531063943938797 auc 0.9913298631321253 0.9890227464308219\n",
      "5 fold: ls 0.047975052719517526 0.052432725810578056 auc 0.9924870926529671 0.9904687224445528\n",
      "6 fold: ls 0.04945127180708636 0.05616921233078291 auc 0.9918788261182043 0.9891684818054991\n",
      "7 fold: ls 0.050091359370878406 0.055499945095439575 auc 0.9916330512889321 0.9894658260682294\n",
      "8 fold: ls 0.050620081728495414 0.05238728261997887 auc 0.9914465440155337 0.9905119809401958\n",
      "9 fold: ls 0.05055751982662432 0.05484822338505637 auc 0.9914770390064283 0.9891673674399311\n",
      "insult 0.05 0.5 3\n",
      "this class avg train 0.049882418674992476 avg val 0.0537661775333743\n",
      "this class auc train 0.9917358444331631 auc val 0.9898479788588034\n",
      "========================\n",
      "0 fold: ls 0.014779311249640109 0.0170782321389635 auc 0.9954688327964849 0.9928764140566955\n",
      "1 fold: ls 0.015263284244040241 0.01777565183537266 auc 0.9950840201889259 0.9910389082220091\n",
      "2 fold: ls 0.015239373283583938 0.017841343829550587 auc 0.99508483439836 0.9919769419472808\n",
      "3 fold: ls 0.014473959250423827 0.018017258114204463 auc 0.995746317038948 0.9895663925653204\n",
      "4 fold: ls 0.014778186100717948 0.01889345740550632 auc 0.9954653647644927 0.9888749738251822\n",
      "5 fold: ls 0.0140132304772859 0.016219286827367507 auc 0.9961311559128864 0.9938786477479022\n",
      "6 fold: ls 0.013996781801514436 0.01656485003689339 auc 0.9960786293317563 0.9902747669629308\n",
      "7 fold: ls 0.01533473853958492 0.018557430424020496 auc 0.9949775632348592 0.9882700158971025\n",
      "8 fold: ls 0.014045272141952562 0.016895160293909434 auc 0.9961162196945402 0.992675590721873\n",
      "9 fold: ls 0.014733057235745728 0.016798133168499776 auc 0.9955648508727722 0.9918581544909314\n",
      "identity_hate 0.05 0.5 3\n",
      "this class avg train 0.014665719432448963 avg val 0.017464080407428816\n",
      "this class auc train 0.9955717788234028 auc val 0.9911290806437227\n",
      "========================\n",
      "all loss avg 0.03192455435402099 0.03528445486336281\n",
      "all auc avg 0.994560495865152 0.9918947844358851\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 3 feature fraction 0.6\n",
      "0 fold: ls 0.07082459202841758 0.07788605946484535 auc 0.9903426793823865 0.9871873590023756\n",
      "1 fold: ls 0.06982598330960191 0.07139385538410228 auc 0.990686271422562 0.989887401222387\n",
      "2 fold: ls 0.06790106411808906 0.07565829379748586 auc 0.991320182628064 0.9884964511634059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 fold: ls 0.06983979218949386 0.07339745823793384 auc 0.9906588669020915 0.9889679834599027\n",
      "4 fold: ls 0.06741270193086214 0.07812503238333891 auc 0.9914377720980595 0.9878862189881131\n",
      "5 fold: ls 0.06807489243581936 0.07668913324607354 auc 0.9913034267747648 0.9875417104630684\n",
      "6 fold: ls 0.0688250142078539 0.07813235678803032 auc 0.9910154667707481 0.9874609776100283\n",
      "7 fold: ls 0.07193139366832126 0.07072960517919263 auc 0.9899497335563221 0.9901281492811761\n",
      "8 fold: ls 0.06672564410504497 0.0739717223905832 auc 0.9916703648527927 0.989441759131684\n",
      "9 fold: ls 0.06778541274279691 0.07780505430228057 auc 0.9912947133249533 0.9876472439696968\n",
      "toxic 0.05 0.6 3\n",
      "this class avg train 0.06891464907363011 avg val 0.07537885711738664\n",
      "this class auc train 0.9909679477712745 auc val 0.9884645254291836\n",
      "========================\n",
      "0 fold: ls 0.017381943163945143 0.02128573297742876 auc 0.9947101839216806 0.9910400050639321\n",
      "1 fold: ls 0.017859798697693663 0.020422923519407533 auc 0.9942941230414267 0.9918391568552982\n",
      "2 fold: ls 0.017267848644403762 0.021014631510461422 auc 0.9948282329315516 0.9913110045575388\n",
      "3 fold: ls 0.01801815952504452 0.01983723083089505 auc 0.9941751452257691 0.9925275351310291\n",
      "4 fold: ls 0.018142523805520873 0.021083257634571095 auc 0.9941011519985523 0.9911464267628814\n",
      "5 fold: ls 0.01792633683948203 0.01998809719105914 auc 0.9942422526691894 0.992201862985602\n",
      "6 fold: ls 0.018130080968998985 0.019186175478658644 auc 0.994091156149999 0.9929331379296205\n",
      "7 fold: ls 0.016973915611325302 0.020114920494496626 auc 0.9950829543973375 0.9921882309474414\n",
      "8 fold: ls 0.017211989789014562 0.02099263490377291 auc 0.9948639373557532 0.9912629696825646\n",
      "9 fold: ls 0.01772016499612809 0.01908788335614364 auc 0.994447179759533 0.9930382450612587\n",
      "severe_toxic 0.05 0.6 3\n",
      "this class avg train 0.01766327620415569 avg val 0.02030134878968948\n",
      "this class auc train 0.9944836317450791 auc val 0.9919488574977168\n",
      "========================\n",
      "0 fold: ls 0.03537622020878226 0.03720101652483477 auc 0.9962224153723095 0.9956607756087572\n",
      "1 fold: ls 0.03575205506312102 0.03699134562435597 auc 0.9961353853803399 0.9954530309537969\n",
      "2 fold: ls 0.03349529086450946 0.03895426626580067 auc 0.9966260158718254 0.9953802143208422\n",
      "3 fold: ls 0.03564296319815929 0.03385222277729969 auc 0.996155787602027 0.9964903474177815\n",
      "4 fold: ls 0.03523832109156944 0.042033118941546 auc 0.9962625008697376 0.9945260790437318\n",
      "5 fold: ls 0.034441778741143014 0.037479055190590665 auc 0.9964217145705279 0.9956160079689013\n",
      "6 fold: ls 0.03598896416585049 0.037587581958066774 auc 0.9960965622944223 0.9954031593686274\n",
      "7 fold: ls 0.03525056937791429 0.03836545303468943 auc 0.9962400385318388 0.9955185894042432\n",
      "8 fold: ls 0.03521562812440149 0.038895043060498416 auc 0.9962621551986172 0.9951675223420551\n",
      "9 fold: ls 0.03529600646507145 0.038818082471377684 auc 0.9962391504356745 0.995291005672652\n",
      "obscene 0.05 0.6 3\n",
      "this class avg train 0.03516977973005222 avg val 0.038017718584906005\n",
      "this class auc train 0.9962661726127319 auc val 0.9954506732101388\n",
      "========================\n",
      "0 fold: ls 0.004980505361827912 0.006610459378095535 auc 0.9985747788364507 0.996815420071234\n",
      "1 fold: ls 0.004698205729974276 0.0062445822181258145 auc 0.9988378589831942 0.9969214854389272\n",
      "2 fold: ls 0.00510920160246212 0.007324324176049543 auc 0.9984329697448492 0.9942331866750471\n",
      "3 fold: ls 0.005097765051668755 0.006527840850586299 auc 0.9985354671302757 0.9919254300500765\n",
      "4 fold: ls 0.005090601530855629 0.0067762984427114075 auc 0.9983980362233534 0.9962900978481781\n",
      "5 fold: ls 0.004914789247336507 0.0069736137019638135 auc 0.9986067772285847 0.9960845014352463\n",
      "6 fold: ls 0.00490086773261629 0.006301519877133354 auc 0.9986231653140405 0.9950630670270497\n",
      "7 fold: ls 0.004926786087376352 0.007478283142835504 auc 0.9985849968295795 0.995520093448153\n",
      "8 fold: ls 0.0046582078218919114 0.007026097276324503 auc 0.9988287505843244 0.9948256239275775\n",
      "9 fold: ls 0.004961004167453472 0.007412105951946705 auc 0.9985585775569163 0.9894747118919707\n",
      "threat 0.05 0.6 3\n",
      "this class avg train 0.004933793433346323 avg val 0.006867512501577249\n",
      "this class auc train 0.998598137843157 auc val 0.9947153617813459\n",
      "========================\n",
      "0 fold: ls 0.05067154422964428 0.050178711359788235 auc 0.9914357590444249 0.9913417813009245\n",
      "1 fold: ls 0.0512921454337875 0.054010597915508926 auc 0.9911920672087575 0.9893845219492118\n",
      "2 fold: ls 0.05140987913964329 0.055307640254450285 auc 0.9911799843664097 0.9889892554433845\n",
      "3 fold: ls 0.05057531041473272 0.05174864814253419 auc 0.9914660121299834 0.9905737512924587\n",
      "4 fold: ls 0.04957071912174118 0.05516895886178398 auc 0.9918605010215036 0.9891384479366648\n",
      "5 fold: ls 0.04697470719616327 0.05240652911659543 auc 0.9928441869015209 0.9904090730058933\n",
      "6 fold: ls 0.049252075366518176 0.05619891775392033 auc 0.991956079696063 0.989157773350873\n",
      "7 fold: ls 0.049324092048565187 0.05547220484515399 auc 0.991934240720648 0.9894958980995398\n",
      "8 fold: ls 0.0510255948304278 0.0524112498472526 auc 0.9912768065076918 0.9905087978282465\n",
      "9 fold: ls 0.05106735485000941 0.054882388949251286 auc 0.9912909749321319 0.9892235744956673\n",
      "insult 0.05 0.6 3\n",
      "this class avg train 0.05011634226312328 avg val 0.05377858470462392\n",
      "this class auc train 0.9916436612529136 auc val 0.9898222874702866\n",
      "========================\n",
      "0 fold: ls 0.014251098458792721 0.01708267501100955 auc 0.9958894094839649 0.9928746204931672\n",
      "1 fold: ls 0.014801582519849818 0.017614323674739914 auc 0.9954777724270293 0.9915074766937629\n",
      "2 fold: ls 0.014688958985968443 0.017724149219356465 auc 0.9955365205555147 0.9923105447635343\n",
      "3 fold: ls 0.015247138338296775 0.01817099078023645 auc 0.995088766501941 0.9883214352812777\n",
      "4 fold: ls 0.014731391772465303 0.018999442648654892 auc 0.9955083483533206 0.9893664102319212\n",
      "5 fold: ls 0.014336217322956932 0.016340046282493425 auc 0.9958681853487242 0.9937806519206279\n",
      "6 fold: ls 0.013958275254359572 0.016580176342816957 auc 0.99616914274925 0.9903036707854614\n",
      "7 fold: ls 0.015147368098357273 0.018544729918189725 auc 0.9951772908449502 0.9883865344316786\n",
      "8 fold: ls 0.014109343851479092 0.01675355756413769 auc 0.9960665758700303 0.9928295939012934\n",
      "9 fold: ls 0.015265503788550305 0.01676131431347292 auc 0.9951020545862713 0.99186447720211\n",
      "identity_hate 0.05 0.6 3\n",
      "this class avg train 0.01465368783910762 avg val 0.017457140575510798\n",
      "this class auc train 0.9955884066720996 auc val 0.9911545415704834\n",
      "========================\n",
      "all loss avg 0.031908588090569207 0.03530019371228235\n",
      "all auc avg 0.9945913263162094 0.9919260411598592\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 4 feature fraction 0.4\n",
      "0 fold: ls 0.06709615821294862 0.07791491173127793 auc 0.9916424031876125 0.9871340856830673\n",
      "1 fold: ls 0.06557434481955388 0.0711239924462109 auc 0.9921124957498473 0.9899339247758986\n",
      "2 fold: ls 0.06818572514895972 0.07605467478704567 auc 0.9913040275657499 0.9883056457034344\n",
      "3 fold: ls 0.06389991339773163 0.07300026147640579 auc 0.9926047912415575 0.989096047808274\n",
      "4 fold: ls 0.06349809630640632 0.07763532337562401 auc 0.9926930880851553 0.9879847212282346\n",
      "5 fold: ls 0.06356632522978384 0.07616394008139885 auc 0.9927322489426421 0.9876223526559704\n",
      "6 fold: ls 0.06522821476317142 0.07779376101651429 auc 0.9922249369442078 0.987628608205504\n",
      "7 fold: ls 0.06933423214916376 0.07109455603772251 auc 0.9909038832003341 0.9900530774835699\n",
      "8 fold: ls 0.06839139826851098 0.07434341116709728 auc 0.9911633135609683 0.98927672357662\n",
      "9 fold: ls 0.06609812411306382 0.07767662537672076 auc 0.9918976902153579 0.9876753958937994\n",
      "toxic 0.05 0.4 4\n",
      "this class avg train 0.06608725324092939 avg val 0.0752801457496018\n",
      "this class auc train 0.9919278878693433 auc val 0.9884710583014371\n",
      "========================\n",
      "0 fold: ls 0.016548636716302342 0.021121385170591308 auc 0.9955288661810442 0.9912215945056336\n",
      "1 fold: ls 0.016504857787311523 0.02075874478220114 auc 0.9955683490043374 0.9915218698569439\n",
      "2 fold: ls 0.015952867931068943 0.021215833433849925 auc 0.9959887990433349 0.9912330674768959\n",
      "3 fold: ls 0.016450424777669094 0.019828336148704977 auc 0.9956001367084484 0.9926173408026333\n",
      "4 fold: ls 0.016474095082442176 0.021127359038119246 auc 0.995577041548203 0.9910669072034435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 fold: ls 0.016036806926480903 0.01990583071404403 auc 0.9959163110732041 0.9923161199451248\n",
      "6 fold: ls 0.016406304032856905 0.01920265397853668 auc 0.99565220083021 0.9928857600937684\n",
      "7 fold: ls 0.014972232462173914 0.020161772078546098 auc 0.9967697796537657 0.9921026323364479\n",
      "8 fold: ls 0.015916623687241376 0.021188474891964428 auc 0.9959991192396433 0.9910913743275034\n",
      "9 fold: ls 0.01676455312752137 0.019114430297518553 auc 0.995401408648414 0.9930677069087633\n",
      "severe_toxic 0.05 0.4 4\n",
      "this class avg train 0.016202740253106855 avg val 0.020362482053407637\n",
      "this class auc train 0.9958002011930605 auc val 0.9919124373457159\n",
      "========================\n",
      "0 fold: ls 0.03286748363818009 0.037084155568726594 auc 0.9967921561523362 0.995658583053032\n",
      "1 fold: ls 0.03408370651813966 0.036977346407150946 auc 0.9965482019208672 0.9954867023452907\n",
      "2 fold: ls 0.032905865731366835 0.03889888872445383 auc 0.9967753351598176 0.9953962680232176\n",
      "3 fold: ls 0.03267631490363722 0.03378124228666281 auc 0.9968292250457649 0.9964753900658124\n",
      "4 fold: ls 0.03270590495196858 0.0419081335673047 auc 0.9968204527346037 0.9945666440087583\n",
      "5 fold: ls 0.02892427634075057 0.037492329633219024 auc 0.9976204106429808 0.9956042613574072\n",
      "6 fold: ls 0.03435518205148738 0.0374425667784475 auc 0.9964967924040613 0.9955267337215457\n",
      "7 fold: ls 0.033361761885928626 0.03798113787796165 auc 0.9966792806490193 0.9956112310135603\n",
      "8 fold: ls 0.033507560147089215 0.03891022069999543 auc 0.9966683656603676 0.9951651730197563\n",
      "9 fold: ls 0.03282219709197091 0.038712137123240994 auc 0.9967952790530882 0.9952627804023795\n",
      "obscene 0.05 0.4 4\n",
      "this class avg train 0.03282102532605191 avg val 0.037918815866716346\n",
      "this class auc train 0.9968025499422908 auc val 0.9954753767010761\n",
      "========================\n",
      "0 fold: ls 0.003980083578816319 0.006673424849531864 auc 0.9992785781214444 0.9969424366226691\n",
      "1 fold: ls 0.0038521550458762484 0.006196583368799612 auc 0.9993981031592518 0.9970419547454431\n",
      "2 fold: ls 0.003994536000246901 0.007393069911239093 auc 0.9992898500845153 0.9945998323905301\n",
      "3 fold: ls 0.004247962004128372 0.006553019379401281 auc 0.9992124055045776 0.9920557284136862\n",
      "4 fold: ls 0.0038277685674205763 0.006853575848772502 auc 0.9993973683560851 0.996132954093071\n",
      "5 fold: ls 0.0040822176709429826 0.007038446940088483 auc 0.99919603366103 0.996237716596476\n",
      "6 fold: ls 0.0036667373048576684 0.006313828613351917 auc 0.9994787403165744 0.9953053303161733\n",
      "7 fold: ls 0.004079451003649517 0.007508358982101902 auc 0.9992222156171795 0.9955580698556372\n",
      "8 fold: ls 0.0042692750048834004 0.007184124718585647 auc 0.9990774044022079 0.9946143157292208\n",
      "9 fold: ls 0.004270186689015875 0.007486385697680813 auc 0.9990792030710762 0.9810671866453218\n",
      "threat 0.05 0.4 4\n",
      "this class avg train 0.004027037286983786 avg val 0.006920081830955311\n",
      "this class auc train 0.9992629902293941 auc val 0.9939555525408228\n",
      "========================\n",
      "0 fold: ls 0.04662578983544215 0.04992058777099942 auc 0.9930135210787572 0.9914501136025217\n",
      "1 fold: ls 0.047776995729294496 0.05377898307623397 auc 0.9925972085745205 0.9898792534022198\n",
      "2 fold: ls 0.049241483215542746 0.05529287557225581 auc 0.9920920302468738 0.9889289407024953\n",
      "3 fold: ls 0.0478644007839393 0.051853086389217824 auc 0.9925643888923833 0.9905612031494166\n",
      "4 fold: ls 0.04825394892852435 0.05503026440426708 auc 0.9924134084160658 0.989143049225762\n",
      "5 fold: ls 0.04704140318776271 0.05255190096021709 auc 0.9928587912870367 0.9904659616710945\n",
      "6 fold: ls 0.045791636239593606 0.05596235289941624 auc 0.9932759526514963 0.9892769049085883\n",
      "7 fold: ls 0.04471884058496779 0.05491540302015688 auc 0.9936536708947068 0.9897364743500232\n",
      "8 fold: ls 0.04810131330134595 0.05234505275351955 auc 0.9924854564317979 0.9904196706936662\n",
      "9 fold: ls 0.04860979801735094 0.05468483286037954 auc 0.9922915124014392 0.9892734990936088\n",
      "insult 0.05 0.4 4\n",
      "this class avg train 0.0474025609823764 avg val 0.053633533970666336\n",
      "this class auc train 0.9927245940875077 auc val 0.9899135070799396\n",
      "========================\n",
      "0 fold: ls 0.013275056811190802 0.017161851340769873 auc 0.9967436930281264 0.9927768712808779\n",
      "1 fold: ls 0.013721399669992489 0.01780175019405752 auc 0.9964484573526768 0.9910366662675988\n",
      "2 fold: ls 0.01281414189813648 0.01778505934048001 auc 0.9970615264889617 0.9921571950818694\n",
      "3 fold: ls 0.013519007565385769 0.018129705342909405 auc 0.9965697828949726 0.9881207803615555\n",
      "4 fold: ls 0.013658955012141412 0.0190266222937784 auc 0.9964683763056584 0.9891211404194338\n",
      "5 fold: ls 0.013390534404708398 0.016463077781621666 auc 0.9966892842584155 0.9937427180520055\n",
      "6 fold: ls 0.012215952544886343 0.01658393273664983 auc 0.997452351896664 0.9905421273213383\n",
      "7 fold: ls 0.01358484537834479 0.018761913934634764 auc 0.9965354530321773 0.9866751120023125\n",
      "8 fold: ls 0.011610224073595361 0.016788042827777953 auc 0.9978130061322437 0.9927072042777657\n",
      "9 fold: ls 0.013534613512732519 0.016853719102639247 auc 0.9966454641249162 0.9918446058241203\n",
      "identity_hate 0.05 0.4 4\n",
      "this class avg train 0.013132473087111438 avg val 0.01753556748953187\n",
      "this class auc train 0.9968427395514812 auc val 0.9908724420888877\n",
      "========================\n",
      "all loss avg 0.02994551502942663 0.035275104493479884\n",
      "all auc avg 0.9955601604788463 0.9917667290096465\n",
      "=======================================================\n",
      "FIND BETTER PARAMS 0.05 4 0.4 insult\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 4 feature fraction 0.5\n",
      "0 fold: ls 0.067264566402172 0.07774020899970588 auc 0.9916054949158537 0.987196464391135\n",
      "1 fold: ls 0.06580705500580764 0.07138156198895095 auc 0.9920510116182186 0.9898353510150018\n",
      "2 fold: ls 0.06850507679428305 0.07616401241238943 auc 0.9911718996568857 0.9882864836166422\n",
      "3 fold: ls 0.06625393858844372 0.07341956114133712 auc 0.9918871014931974 0.9889863301387463\n",
      "4 fold: ls 0.06440112525776383 0.07772024618725268 auc 0.9924275736109777 0.9879902968267318\n",
      "5 fold: ls 0.06824277558037303 0.07675832242927207 auc 0.9913147545822014 0.9873848230939658\n",
      "6 fold: ls 0.06493381779223659 0.07796881259891172 auc 0.99229972609751 0.9875248476773688\n",
      "7 fold: ls 0.06714251417653379 0.07084740200338364 auc 0.9916255379191474 0.9900778747500496\n",
      "8 fold: ls 0.05622430850044299 0.07364552087798697 auc 0.9947001677450342 0.9894573537563076\n",
      "9 fold: ls 0.06718024290722233 0.07761638640047204 auc 0.9915586933482863 0.9876685052457099\n",
      "toxic 0.05 0.5 4\n",
      "this class avg train 0.0655955421005279 avg val 0.07532620350396625\n",
      "this class auc train 0.9920641960987313 auc val 0.9884408330511659\n",
      "========================\n",
      "0 fold: ls 0.015653884253189598 0.021218552955061365 auc 0.9962077178320369 0.9911108209899987\n",
      "1 fold: ls 0.016433946827915956 0.020603535132125046 auc 0.9956309269878758 0.9916706228636537\n",
      "2 fold: ls 0.01638072576454318 0.021251272507553463 auc 0.9956635699775266 0.9910894575262692\n",
      "3 fold: ls 0.01636464123028176 0.019896387876340155 auc 0.9956885227493456 0.9925560197493354\n",
      "4 fold: ls 0.016483349152656306 0.021121327283741057 auc 0.995580526407909 0.9910906443853652\n",
      "5 fold: ls 0.016385745792728938 0.019921781906208306 auc 0.995653874732176 0.9922986031987171\n",
      "6 fold: ls 0.01623658550263512 0.019359891940465602 auc 0.9957956750779515 0.9927384508562449\n",
      "7 fold: ls 0.01575033862987821 0.02026458934868797 auc 0.996138795164266 0.992020616923124\n",
      "8 fold: ls 0.016408342814802104 0.021100501463729163 auc 0.9956073556381055 0.9911897131968772\n",
      "9 fold: ls 0.016737375002447114 0.0190923931714377 auc 0.9954329168529583 0.9930808453002183\n",
      "severe_toxic 0.05 0.5 4\n",
      "this class avg train 0.01628349349710783 avg val 0.020383023358534983\n",
      "this class auc train 0.9957399881420154 auc val 0.9918845794989803\n",
      "========================\n",
      "0 fold: ls 0.03380405049010625 0.037197332450846596 auc 0.9965993853123615 0.9956606973031956\n",
      "1 fold: ls 0.03343950870423445 0.03697435192546261 auc 0.9966704761225672 0.9954655598436551\n",
      "2 fold: ls 0.032643300600106645 0.03891727244041233 auc 0.9968261444634161 0.9953891417455779\n",
      "3 fold: ls 0.03281204370636088 0.03381042216988515 auc 0.9968010298852844 0.9964370961123414\n",
      "4 fold: ls 0.033181701448520375 0.041893996504279774 auc 0.9967313445212297 0.994582306157417\n",
      "5 fold: ls 0.03390661996417558 0.03769089902416281 auc 0.9965803258850021 0.9955173364323504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 fold: ls 0.03378668535071335 0.03737461446181567 auc 0.9965997748409516 0.995399792006666\n",
      "7 fold: ls 0.03306711260919803 0.03819874128612743 auc 0.9967448962795189 0.995552576266833\n",
      "8 fold: ls 0.03293282398889468 0.03893084789625736 auc 0.996778744975779 0.9951533480975188\n",
      "9 fold: ls 0.0331108989032273 0.03884458638177997 auc 0.9967411381216362 0.9952608987176947\n",
      "obscene 0.05 0.5 4\n",
      "this class avg train 0.033268474576553755 avg val 0.037983306454102965\n",
      "this class auc train 0.9967073260407748 auc val 0.995441875268325\n",
      "========================\n",
      "0 fold: ls 0.0037978303461497567 0.006642016118303164 auc 0.9993994025209892 0.9969516027655563\n",
      "1 fold: ls 0.004033613942123863 0.006245028596867936 auc 0.9992937725327597 0.9968141106222502\n",
      "2 fold: ls 0.003974930035419054 0.007328402351658706 auc 0.9993007647231084 0.9943287764508695\n",
      "3 fold: ls 0.004126481753537429 0.006546484801636763 auc 0.9992737674340644 0.9906100058667001\n",
      "4 fold: ls 0.004103380829985995 0.006922180585549802 auc 0.9992539035802362 0.9961067634672198\n",
      "5 fold: ls 0.0038969663837459248 0.007075704381893961 auc 0.9993467748117888 0.995844857208708\n",
      "6 fold: ls 0.004029521298268384 0.006360116521349847 auc 0.9992790298123474 0.9948338990508517\n",
      "7 fold: ls 0.004053586132023451 0.007575760076267401 auc 0.9992461237061696 0.995505688603935\n",
      "8 fold: ls 0.003788020628306892 0.007034040836520545 auc 0.9994074034247693 0.9947132828600966\n",
      "9 fold: ls 0.00422874529427125 0.007547228258277643 auc 0.9991346215172909 0.9897950176736571\n",
      "threat 0.05 0.5 4\n",
      "this class avg train 0.004003307664383201 avg val 0.006927696252832577\n",
      "this class auc train 0.9992935564063524 auc val 0.9945504004569843\n",
      "========================\n",
      "0 fold: ls 0.043303842870144965 0.04985716656814955 auc 0.9941509428632246 0.9914788906772316\n",
      "1 fold: ls 0.04914062271426598 0.053985408204858275 auc 0.9921313382314328 0.9898772038721895\n",
      "2 fold: ls 0.04925860861676259 0.0552227927456499 auc 0.9920868505574012 0.9889828140632896\n",
      "3 fold: ls 0.04854014557590859 0.05202429067301191 auc 0.9923158774553708 0.9904731988395478\n",
      "4 fold: ls 0.048611695161179004 0.05508108958631548 auc 0.9922866417918371 0.989120544739087\n",
      "5 fold: ls 0.04502308072903013 0.05240240858662869 auc 0.9935688581743372 0.9904655433720857\n",
      "6 fold: ls 0.047679617165870644 0.056186083229938344 auc 0.9926080560629859 0.9891591119077011\n",
      "7 fold: ls 0.045383730339730505 0.05529133477765064 auc 0.9934222605272055 0.989605129099063\n",
      "8 fold: ls 0.04786495344890187 0.052317317834121295 auc 0.9925702288493173 0.990520022486173\n",
      "9 fold: ls 0.04833189814456923 0.05481755348767456 auc 0.9923922250067087 0.989234547855282\n",
      "insult 0.05 0.5 4\n",
      "this class avg train 0.04731381947663635 avg val 0.05371854456939986\n",
      "this class auc train 0.9927533279519821 auc val 0.9898917006911649\n",
      "========================\n",
      "0 fold: ls 0.013615451580052588 0.017160298126047503 auc 0.9965117072534602 0.9929069046366756\n",
      "1 fold: ls 0.01396557076868764 0.01779278070121135 auc 0.9962688699844588 0.9912245420471825\n",
      "2 fold: ls 0.013554181705517416 0.01799537653867796 auc 0.9965332740774123 0.9919092349240897\n",
      "3 fold: ls 0.013034467659851357 0.018089692101398977 auc 0.9969020248060325 0.9881324385244892\n",
      "4 fold: ls 0.013847048454738272 0.01910257116124413 auc 0.9963187840795278 0.9883207626949547\n",
      "5 fold: ls 0.013565099628242877 0.016590825070011975 auc 0.996559885647636 0.9935602742076789\n",
      "6 fold: ls 0.013527408944585772 0.016611283682258875 auc 0.9965697447281723 0.9909255545920949\n",
      "7 fold: ls 0.013681926201121464 0.018716258751232322 auc 0.9964647899251831 0.9875275489558495\n",
      "8 fold: ls 0.011342591585867052 0.01671547423299711 auc 0.9979646559515529 0.9926462352771154\n",
      "9 fold: ls 0.013704295913157152 0.016845565096664385 auc 0.9965093496933879 0.9919656405809668\n",
      "identity_hate 0.05 0.5 4\n",
      "this class avg train 0.013383804244182156 avg val 0.017562012546174458\n",
      "this class auc train 0.9966603086146824 auc val 0.9909119136441097\n",
      "========================\n",
      "all loss avg 0.029974740259898533 0.035316797780835185\n",
      "all auc avg 0.9955364505424231 0.9918535504351216\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "learning rate 0.05 max depth 4 feature fraction 0.6\n",
      "0 fold: ls 0.06761421209053677 0.07769886550950761 auc 0.9914697301176795 0.9871830554604246\n",
      "1 fold: ls 0.06460754317635592 0.07127026553689005 auc 0.9923902158913223 0.9898126554937658\n",
      "2 fold: ls 0.06859895677056699 0.07604575140279582 auc 0.9911791488165622 0.9882979899288058\n",
      "3 fold: ls 0.06624366975362299 0.07344371244669526 auc 0.9919044505742478 0.9889407578945081\n",
      "4 fold: ls 0.06403349394702863 0.07781019961697962 auc 0.9925579331931659 0.9879740233319305\n",
      "5 fold: ls 0.06665320517626346 0.07634931967659432 auc 0.9918094754655887 0.9875849553489753\n",
      "6 fold: ls 0.059663750037699706 0.07771382783116287 auc 0.9937838104203613 0.987615734465884\n",
      "7 fold: ls 0.06898773870741054 0.07112686290016572 auc 0.9909941233989706 0.9900041629487766\n",
      "8 fold: ls 0.06517898126723994 0.07408314331698385 auc 0.992196902710258 0.9893888099411017\n",
      "9 fold: ls 0.06685298241200735 0.07786071593680313 auc 0.9916572507242072 0.9875706308429125\n",
      "toxic 0.05 0.6 4\n",
      "this class avg train 0.06584345333387323 avg val 0.07534026641745781\n",
      "this class auc train 0.9919943041312365 auc val 0.9884372775657082\n",
      "========================\n",
      "0 fold: ls 0.01641439941425308 0.021339098015713702 auc 0.9956385632908604 0.9910222021774908\n",
      "1 fold: ls 0.01567614702854039 0.02052471786389657 auc 0.9962175817985042 0.9918502342068617\n",
      "2 fold: ls 0.016225382821573275 0.021058778499901707 auc 0.9957836089354154 0.9912528484618306\n",
      "3 fold: ls 0.01593211313038579 0.019985680564048383 auc 0.9960158299874678 0.9925113147233827\n",
      "4 fold: ls 0.01650808128064217 0.021160357494396553 auc 0.9955595829402247 0.9910597860488671\n",
      "5 fold: ls 0.016149810895294346 0.01996756366198075 auc 0.9958292110666253 0.9922595886271728\n",
      "6 fold: ls 0.0166500920715016 0.01923575735761973 auc 0.9954850893066826 0.9928849638276196\n",
      "7 fold: ls 0.015557031090750607 0.02015251801364614 auc 0.9963209456963514 0.9921117893971589\n",
      "8 fold: ls 0.01663818595322929 0.021200745080901605 auc 0.9954726633289226 0.9911092903158509\n",
      "9 fold: ls 0.016820433838953184 0.019246058209665934 auc 0.9953595609724264 0.9929176107397193\n",
      "severe_toxic 0.05 0.6 4\n",
      "this class avg train 0.016257167752512375 avg val 0.02038712747617711\n",
      "this class auc train 0.9957682637323482 auc val 0.9918979628525953\n",
      "========================\n",
      "0 fold: ls 0.03320333032422011 0.03714097121225424 auc 0.9967204146054186 0.9956358744401641\n",
      "1 fold: ls 0.03386904552231826 0.03700768833773198 auc 0.996593670335637 0.9954000963941463\n",
      "2 fold: ls 0.03181929539875338 0.03883562726586743 auc 0.9969992497921429 0.9954122434148496\n",
      "3 fold: ls 0.03142797816300352 0.033663503225001494 auc 0.9970943378741725 0.9964415598247093\n",
      "4 fold: ls 0.03316079032624453 0.04199787607913919 auc 0.9967381675373453 0.9945379822767126\n",
      "5 fold: ls 0.03240161828483596 0.03761166028087289 auc 0.996878261515799 0.9955149871100516\n",
      "6 fold: ls 0.03410789140184931 0.03757866096381968 auc 0.9965526968516294 0.995490084293684\n",
      "7 fold: ls 0.03336165148582418 0.03816968452479574 auc 0.9966887235138087 0.995577087529484\n",
      "8 fold: ls 0.03283827794088806 0.039155689885056265 auc 0.9968009244918518 0.9950850611293661\n",
      "9 fold: ls 0.03217545604105509 0.03867366692870622 auc 0.9969315251745277 0.9953207990134955\n",
      "obscene 0.05 0.6 4\n",
      "this class avg train 0.03283653348889924 avg val 0.037983502870324516\n",
      "this class auc train 0.9967997971692333 auc val 0.9954415775426663\n",
      "========================\n",
      "0 fold: ls 0.003715838550460776 0.006557540487864144 auc 0.9994444578892291 0.9969280326838466\n",
      "1 fold: ls 0.0038235521512731056 0.006242855357900488 auc 0.9994045512418731 0.9968926775612822\n",
      "2 fold: ls 0.003558532799834726 0.007368791921087389 auc 0.9995281530271312 0.9944518646553531\n",
      "3 fold: ls 0.004226231820055335 0.006524146458159553 auc 0.9992292483634654 0.9921932291994049\n",
      "4 fold: ls 0.0039154895407424815 0.006846516429154642 auc 0.9993636176706766 0.9961879544073586\n",
      "5 fold: ls 0.003924927170200373 0.0070681501266598385 auc 0.9993356815884324 0.9959875961195969\n",
      "6 fold: ls 0.004189319785012446 0.006340158197101291 auc 0.9991781350781039 0.9949059232719425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 fold: ls 0.004046390228723681 0.007587375182373839 auc 0.9992289235252996 0.9955803318876107\n",
      "8 fold: ls 0.004159919337037268 0.007149154362142969 auc 0.9991459968825667 0.994068659115742\n",
      "9 fold: ls 0.004185500834274946 0.007513218775244712 auc 0.9991513442764995 0.981985307393246\n",
      "threat 0.05 0.6 4\n",
      "this class avg train 0.003974570221761514 avg val 0.006919790729768886\n",
      "this class auc train 0.9993010109543278 auc val 0.9939181576295384\n",
      "========================\n",
      "0 fold: ls 0.04524948614729985 0.04985945781407136 auc 0.9935072520136924 0.9915208014749923\n",
      "1 fold: ls 0.047340281582402284 0.05399877646745867 auc 0.9927434353516623 0.989749672911738\n",
      "2 fold: ls 0.04920656692774303 0.0552006652234015 auc 0.9921132304999343 0.9890238464910374\n",
      "3 fold: ls 0.04588021257164593 0.05168104062184838 auc 0.9932796101892793 0.9906169169045237\n",
      "4 fold: ls 0.0485989554701862 0.05498693575021149 auc 0.9923049369244654 0.9891843771678346\n",
      "5 fold: ls 0.04652055906626567 0.05261761278320113 auc 0.9930488084515422 0.9903987828502758\n",
      "6 fold: ls 0.046487125508338854 0.056366107822031525 auc 0.9930343879834358 0.989066416847344\n",
      "7 fold: ls 0.044918639762878416 0.05529401271508806 auc 0.9935750717551226 0.9895917265224342\n",
      "8 fold: ls 0.047267945408174916 0.052057582232733074 auc 0.992766551588143 0.9905378646663098\n",
      "9 fold: ls 0.047200757203123125 0.05467212680850909 auc 0.9927922865793578 0.9892539815913934\n",
      "insult 0.05 0.6 4\n",
      "this class avg train 0.046867052964805825 avg val 0.05367343182385542\n",
      "this class auc train 0.9929165571336634 auc val 0.9898944387427882\n",
      "========================\n",
      "0 fold: ls 0.01332434255689553 0.017238228851204993 auc 0.9967132866130142 0.9927329289744359\n",
      "1 fold: ls 0.013960396647539447 0.01785470260587202 auc 0.9962445937605123 0.9913187041324152\n",
      "2 fold: ls 0.012400679076138349 0.018106848902432846 auc 0.9973232962114597 0.9917859274315228\n",
      "3 fold: ls 0.013716064169271182 0.018222967886944906 auc 0.9964141855269065 0.9886592978109108\n",
      "4 fold: ls 0.013888260302149546 0.019102549415070426 auc 0.9962968976853198 0.988388918109028\n",
      "5 fold: ls 0.01365422290813989 0.016670298081623163 auc 0.9964956833670806 0.9934193769813673\n",
      "6 fold: ls 0.013898474624783384 0.016708664199506427 auc 0.9962848987423139 0.9916779572223426\n",
      "7 fold: ls 0.01363482161510244 0.018797179276852594 auc 0.9965157137878997 0.9869070200158973\n",
      "8 fold: ls 0.012305945646343772 0.01688380676150198 auc 0.9973805531375514 0.992675590721873\n",
      "9 fold: ls 0.013861767849036744 0.01689698466173989 auc 0.9964144852566532 0.991831057157309\n",
      "identity_hate 0.05 0.6 4\n",
      "this class avg train 0.01346449753954003 avg val 0.01764822306427492\n",
      "this class auc train 0.9966083594088712 auc val 0.9909396778557102\n",
      "========================\n",
      "all loss avg 0.029873879216898703 0.03532539039697644\n",
      "all auc avg 0.9955647154216134 0.9917548486981678\n",
      "=======================================================\n",
      "TEST PARAM DONE ------------------------------------------\n",
      "[0.9885061994212517, 0.9919602898500901, 0.9954837994448729, 0.9947656143646005, 0.9899135070799396, 0.9912511184214111]\n",
      "0.9919800880970278\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999288      0.341593  0.977367  0.160700  0.934043   \n",
      "1  0000247867823ef7  0.000209      0.000018  0.000061  0.000046  0.000068   \n",
      "2  00013b17ad220c46  0.000346      0.000020  0.000135  0.000050  0.000215   \n",
      "3  00017563c3f7919a  0.000051      0.000019  0.000058  0.000049  0.000067   \n",
      "4  00017695ad8997eb  0.001441      0.000029  0.000167  0.000066  0.000177   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.393533  \n",
      "1       0.000057  \n",
      "2       0.000067  \n",
      "3       0.000057  \n",
      "4       0.000067  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "# find best params for each column, early stopping = 30\n",
    "\n",
    "best_pred = np.zeros((153164,6))\n",
    "val_auc_res = [0,0,0,0,0,0]\n",
    "for lr in [0.095,0.075,0.05]:\n",
    "    for max_d in [3,4]:\n",
    "        for s_rate in [0.4,0.5,0.6]:\n",
    "            print('learning rate',lr,'max depth',max_d,'feature fraction',s_rate)\n",
    "            lgb_res,tmp_auc_res = simple_ens('lgb',k=10,rnd=666,lr=lr,\n",
    "                                 feature_fraction=s_rate,bagging_fraction=0.9,\n",
    "                                 bag_frec=3,met='binary_logloss',max_d=max_d)\n",
    "            # check for each cls\n",
    "            for i in range(6):\n",
    "                # find better params for this class\n",
    "                if tmp_auc_res[i] > val_auc_res[i]:\n",
    "                    val_auc_res[i] = tmp_auc_res[i]\n",
    "                    best_pred[:,i] = lgb_res[:,i]\n",
    "                    print('FIND BETTER PARAMS',lr,max_d,s_rate,list_classes[i])\n",
    "            print('TEST PARAM DONE ------------------------------------------')\n",
    "\n",
    "print(val_auc_res)\n",
    "print(np.mean(val_auc_res))\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = best_pred\n",
    "sample_submission.to_csv(\"../results/lgb_grid_search_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "                \n",
    "            \n",
    "# best auc params\n",
    "# toxic 0.05,4,0.5\n",
    "# severe toxic 0.075 3 0.5\n",
    "# obs 0.075 3 0.6\n",
    "# threat 0.095 3 0.5\n",
    "# insult 0.075 0.5 4\n",
    "# hate 0.05 0.5 3\n",
    "\n",
    "# TEST PARAM DONE ------------------------------------------\n",
    "# [0.9884873039634368, 0.9920148292218363, 0.9954573112511824, \n",
    "#  0.994769628570376, 0.9898761527824232, 0.9912880359235366]\n",
    "# 0.9919822102854652 PUB 9870"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "{'application': 'binary', 'max_depth': 4, 'feature_fraction': 0.5, 'metric': 'binary_logloss', 'lambda_l2': 1.0, 'data_random_seed': 2, 'learning_rate': 0.05}\n",
      "0 fold: ls 0.067264566402172 0.07774020899970588 auc 0.9916054949158537 0.987196464391135\n",
      "1 fold: ls 0.06580705500580764 0.07138156198895095 auc 0.9920510116182186 0.9898353510150018\n",
      "2 fold: ls 0.06850507679428305 0.07616401241238943 auc 0.9911718996568857 0.9882864836166422\n",
      "3 fold: ls 0.06625393858844372 0.07341956114133712 auc 0.9918871014931974 0.9889863301387463\n",
      "4 fold: ls 0.06440112525776383 0.07772024618725268 auc 0.9924275736109777 0.9879902968267318\n",
      "5 fold: ls 0.06824277558037303 0.07675832242927207 auc 0.9913147545822014 0.9873848230939658\n",
      "6 fold: ls 0.06493381779223659 0.07796881259891172 auc 0.99229972609751 0.9875248476773688\n",
      "7 fold: ls 0.06714251417653379 0.07084740200338364 auc 0.9916255379191474 0.9900778747500496\n",
      "8 fold: ls 0.05622430850044298 0.07364552087798697 auc 0.9947001677450342 0.9894573537563076\n",
      "9 fold: ls 0.06718024290722233 0.07761638640047204 auc 0.9915586933482863 0.9876685052457099\n",
      "toxic\n",
      "this class avg train 0.0655955421005279 avg val 0.07532620350396625\n",
      "this class auc train 0.9920641960987313 auc val 0.9884408330511659\n",
      "========================\n",
      "{'application': 'binary', 'max_depth': 3, 'feature_fraction': 0.5, 'metric': 'binary_logloss', 'lambda_l2': 1.0, 'data_random_seed': 2, 'learning_rate': 0.075}\n",
      "0 fold: ls 0.017973804533624026 0.021326542723046838 auc 0.9941837642493878 0.9910008387137611\n",
      "1 fold: ls 0.017719180757537027 0.020577488745439347 auc 0.994413691469735 0.9917105804532219\n",
      "2 fold: ls 0.018269765543342236 0.02098448189372382 auc 0.9940104574219009 0.9913284118242817\n",
      "3 fold: ls 0.01658619631601573 0.019667014080815712 auc 0.9954016197882783 0.9927099158121281\n",
      "4 fold: ls 0.018171460727000807 0.02099396158208288 auc 0.9940706116879646 0.9912267375617166\n",
      "5 fold: ls 0.018092225356101756 0.019953376471734702 auc 0.9941043904476756 0.9922368964784173\n",
      "6 fold: ls 0.01744004589968488 0.019093412403276312 auc 0.9946882349118508 0.9929757381685799\n",
      "7 fold: ls 0.017321416370523972 0.02014196800068831 auc 0.9947629940413494 0.9921468251077049\n",
      "8 fold: ls 0.018104520535729394 0.021053075877608653 auc 0.9941208129475299 0.9911741860069763\n",
      "9 fold: ls 0.017902928898862313 0.019175360282989207 auc 0.9942738968792939 0.9929299528650253\n",
      "severe_toxic\n",
      "this class avg train 0.017758154493842212 avg val 0.02029666820614058\n",
      "this class auc train 0.9944030473844967 auc val 0.9919440082991813\n",
      "========================\n",
      "{'application': 'binary', 'max_depth': 3, 'feature_fraction': 0.6, 'metric': 'binary_logloss', 'lambda_l2': 1.0, 'data_random_seed': 2, 'learning_rate': 0.075}\n",
      "0 fold: ls 0.035427750598728706 0.037094285331594104 auc 0.9962045699090782 0.9957005548340568\n",
      "1 fold: ls 0.0347595354257749 0.03686508401596794 auc 0.9963587742044904 0.9955924931590303\n",
      "2 fold: ls 0.0349237398148973 0.039015205964151485 auc 0.9963115320217543 0.995382798575371\n",
      "3 fold: ls 0.03508117436945474 0.033875678932859296 auc 0.996280128163055 0.9964773478343947\n",
      "4 fold: ls 0.03535825871180014 0.04212682518497048 auc 0.9962403692158199 0.9945271753941378\n",
      "5 fold: ls 0.03394272067969666 0.03752236896230555 auc 0.9965286666655578 0.9956232908680276\n",
      "6 fold: ls 0.036229318880440925 0.03762315899342537 auc 0.9960580129543805 0.9955098969117375\n",
      "7 fold: ls 0.03518100108757928 0.03831405844461443 auc 0.9962506146177559 0.9955304143264806\n",
      "8 fold: ls 0.0353194537592486 0.03895168252093478 auc 0.9962538566744462 0.9951581250528597\n",
      "9 fold: ls 0.035365585778138774 0.03870883599531895 auc 0.9962243726422831 0.9953144483276841\n",
      "obscene\n",
      "this class avg train 0.03515885391057601 avg val 0.03800971843461424\n",
      "this class auc train 0.9962710897068622 auc val 0.995481654528378\n",
      "========================\n",
      "{'application': 'binary', 'max_depth': 3, 'feature_fraction': 0.5, 'metric': 'binary_logloss', 'lambda_l2': 1.0, 'data_random_seed': 2, 'learning_rate': 0.095}\n",
      "0 fold: ls 0.004893688011262022 0.006616347668793322 auc 0.9986544946790326 0.9966805468258957\n",
      "1 fold: ls 0.005020634881746092 0.006254078912985664 auc 0.9985753960332759 0.9968389901529435\n",
      "2 fold: ls 0.004745393694196382 0.007281927516491683 auc 0.9987461484075754 0.9945068615126755\n",
      "3 fold: ls 0.005106185360703896 0.006611076645338569 auc 0.9985105601639264 0.9913302480776081\n",
      "4 fold: ls 0.005167780250831118 0.006741059846984108 auc 0.9982839368176774 0.9962416451903534\n",
      "5 fold: ls 0.004711588772261755 0.007005413188036009 auc 0.9987490725870372 0.9958527143964633\n",
      "6 fold: ls 0.005124836425801525 0.00635831499317704 auc 0.9983947472369264 0.9950931862467786\n",
      "7 fold: ls 0.005000321212352669 0.007544432654656426 auc 0.9985029670718049 0.9955881890753661\n",
      "8 fold: ls 0.004957366808860144 0.007157456916608041 auc 0.998548984656285 0.9943936457752403\n",
      "9 fold: ls 0.005139774891805221 0.0073685404931202745 auc 0.998394493584294 0.9893924621818508\n",
      "threat\n",
      "this class avg train 0.004986757030982082 avg val 0.006893864883619113\n",
      "this class auc train 0.9985360801237837 auc val 0.9945918489435174\n",
      "========================\n",
      "{'application': 'binary', 'max_depth': 4, 'feature_fraction': 0.5, 'metric': 'binary_logloss', 'lambda_l2': 1.0, 'data_random_seed': 2, 'learning_rate': 0.075}\n",
      "0 fold: ls 0.04548177242185399 0.04989953272550446 auc 0.9933959005724292 0.9914562203654689\n",
      "1 fold: ls 0.04895723207351132 0.05381707114238372 auc 0.9921790997626543 0.9898831014994195\n",
      "2 fold: ls 0.04920256680059794 0.05527010498663256 auc 0.9921052765303436 0.9886593647628065\n",
      "3 fold: ls 0.047170810842656515 0.05186502710201859 auc 0.9927990423610731 0.990533513580437\n",
      "4 fold: ls 0.04807829801901896 0.05494790776832441 auc 0.9924747794857385 0.9892640212991163\n",
      "5 fold: ls 0.047046115213610636 0.052657172428419566 auc 0.9928548287967857 0.9903986991904743\n",
      "6 fold: ls 0.047963815308160636 0.0564634075313574 auc 0.9925091518930228 0.9890665423370466\n",
      "7 fold: ls 0.04397629585083979 0.055452845525507694 auc 0.993893355345211 0.9895617382572278\n",
      "8 fold: ls 0.04479844102957869 0.05220488887119087 auc 0.993637289574051 0.990602364566335\n",
      "9 fold: ls 0.04817868848617051 0.05453889883276571 auc 0.9924317616725239 0.9894541825797832\n",
      "insult\n",
      "this class avg train 0.047085403604599896 avg val 0.05371168569141049\n",
      "this class auc train 0.9928280485993832 auc val 0.9898879748438114\n",
      "========================\n",
      "{'application': 'binary', 'max_depth': 3, 'feature_fraction': 0.5, 'metric': 'binary_logloss', 'lambda_l2': 1.0, 'data_random_seed': 2, 'learning_rate': 0.05}\n",
      "0 fold: ls 0.014779311249640109 0.0170782321389635 auc 0.9954688327964849 0.9928764140566955\n",
      "1 fold: ls 0.015263284244040241 0.01777565183537266 auc 0.9950840201889259 0.9910389082220091\n",
      "2 fold: ls 0.015239373283583938 0.017841343829550587 auc 0.99508483439836 0.9919769419472808\n",
      "3 fold: ls 0.014473959250423827 0.018017258114204463 auc 0.995746317038948 0.9895663925653204\n",
      "4 fold: ls 0.014778186100717948 0.01889345740550632 auc 0.9954653647644927 0.9888749738251822\n",
      "5 fold: ls 0.0140132304772859 0.016219286827367507 auc 0.9961311559128864 0.9938786477479022\n",
      "6 fold: ls 0.013996781801514436 0.01656485003689339 auc 0.9960786293317563 0.9902747669629308\n",
      "7 fold: ls 0.01533473853958492 0.018557430424020496 auc 0.9949775632348592 0.9882700158971025\n",
      "8 fold: ls 0.014045272141952562 0.016895160293909434 auc 0.9961162196945402 0.992675590721873\n",
      "9 fold: ls 0.014733057235745728 0.016798133168499776 auc 0.9955648508727722 0.9918581544909314\n",
      "identity_hate\n",
      "this class avg train 0.014665719432448963 avg val 0.017464080407428816\n",
      "this class auc train 0.9955717788234028 auc val 0.9911290806437227\n",
      "========================\n",
      "all loss avg 0.030875071762162844 0.035283703521196585\n",
      "all auc avg 0.9949457067894433 0.9919125667182961\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999314      0.343206  0.976587  0.159187  0.936899   \n",
      "1  0000247867823ef7  0.000242      0.000030  0.000096  0.000043  0.000075   \n",
      "2  00013b17ad220c46  0.000433      0.000031  0.000159  0.000046  0.000216   \n",
      "3  00017563c3f7919a  0.000075      0.000031  0.000092  0.000043  0.000075   \n",
      "4  00017695ad8997eb  0.001758      0.000040  0.000196  0.000072  0.000172   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.414668  \n",
      "1       0.000033  \n",
      "2       0.000047  \n",
      "3       0.000033  \n",
      "4       0.000046  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "def special_ens(model_name,k=3,rnd=233):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    params_list = [\n",
    "        [0.05,4,0.5],\n",
    "        [0.075,3,0.5],\n",
    "        [0.075,3,0.6],\n",
    "        [0.095,3,0.5],\n",
    "        [0.075,4,0.5],\n",
    "        [0.05,3,0.5],\n",
    "    ]\n",
    "    \n",
    "    for i in range(6):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        \n",
    "        # special params\n",
    "        params = {\n",
    "                'application': 'binary',\n",
    "                #'num_leaves': 8,\n",
    "                #'lambda_l1': 1,\n",
    "                'lambda_l2': 1.0,\n",
    "                'max_depth': params_list[i][1],\n",
    "                'metric': 'binary_logloss', # or auc\n",
    "                'data_random_seed': 2,\n",
    "                'learning_rate':params_list[i][0],\n",
    "                'feature_fraction': params_list[i][2],\n",
    "\n",
    "                }\n",
    "        print(params)\n",
    "            \n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = test_x\n",
    "            s_round = 30\n",
    "            # train for each class\n",
    "            d_train = lgb.Dataset(curr_x, curr_y[:,i])\n",
    "            d_valid = lgb.Dataset(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [d_train, d_valid]\n",
    "            model = lgb.train(params,\n",
    "                      train_set=d_train,\n",
    "                      num_boost_round=2000,\n",
    "                      valid_sets=watchlist,\n",
    "                      early_stopping_rounds=s_round,\n",
    "                      verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            try:\n",
    "                train_pred = model.predict(curr_x)\n",
    "                tmp_test_pred = model.predict(hold_out_x)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_auc_l = train_auc_l/k\n",
    "        val_auc_l = val_auc_l/k\n",
    "        print(list_classes[i])\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/6\n",
    "        all_val_loss_l += val_loss_l/6\n",
    "        all_train_auc_l += train_auc_l/6\n",
    "        all_val_auc_l += val_auc_l/6\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')\n",
    "\n",
    "lgb_res = special_ens('lgb',10,666)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = lgb_res\n",
    "sample_submission.to_csv(\"../results/lgb_log_csv_fold10_stratified_special.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# best params changed when base models changed\n",
    "# all loss avg 0.03111512578966158 0.03534320053008906 all auc avg 0.9948524214184179 0.9918450388634261"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
