{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/cnn2d_muse_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/cnn_glove_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/cnn_gru_glove_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/cnn_muse_adj_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/cnn_muse_adj_1_feat_de_fr.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/cudnn_gru_glove_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/cudnn_gru_glove_1_sample_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/gru_glove_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/gru_muse_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_glove_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 16) (153164, 16)\n",
      "file path ../features/tfidf_feat1.pkl\n",
      "(159571, 30) (153164, 30)\n",
      "file path ../features/tfidf_feat2.pkl\n",
      "(159571, 30) (153164, 30)\n",
      "(159571, 160)\n",
      "(159571, 160)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "#     if 'tfidf' in feat or 'lr' in feat or 'mnb' in feat:\n",
    "#         continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[list_classes].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 160)\n",
      "[     6     12     16 ..., 159541 159546 159554]\n",
      "(156512, 160) 15294\n"
     ]
    }
   ],
   "source": [
    "def aug_data_ratio(x,y,ratio=0.2):\n",
    "    print(x.shape)\n",
    "    neg_index = np.where(y[:,0]==0)[0]\n",
    "    print(neg_index)\n",
    "    data_cnt = len(neg_index)\n",
    "    add_cnt = int(data_cnt*ratio)\n",
    "    add_index = neg_index[:add_cnt]\n",
    "    add_x = np.concatenate([x,x[add_index]])\n",
    "    add_y = np.concatenate([y,y[add_index]])\n",
    "    print(add_x.shape,data_cnt)\n",
    "    return add_x,add_y\n",
    "\n",
    "def del_data_ratio(x,y,ratio=0.8):\n",
    "    print(x.shape)\n",
    "    pos_index = np.where(y[:,0]==1)[0]\n",
    "    neg_index = np.where(y[:,0]==0)[0]\n",
    "    print(pos_index)\n",
    "    data_cnt = len(pos_index)\n",
    "    add_cnt = int(data_cnt*ratio)\n",
    "    add_index = pos_index[:add_cnt]\n",
    "    add_x = np.concatenate([x[add_index],x[neg_index]])\n",
    "    add_y = np.concatenate([y[add_index],y[neg_index]])\n",
    "    print(add_x.shape,data_cnt)\n",
    "    return add_x,add_y\n",
    "\n",
    "# add neg data\n",
    "#train_x,train_y = aug_data_ratio(train_x,train_y)\n",
    "# del pos data\n",
    "train_x,train_y = del_data_ratio(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def simple_ens(model_name,k=3,rnd=233):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    cache_test_pred = np.zeros((153164,6))\n",
    "    single_best = 100\n",
    "    single_best_pred = None\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        d_test = xgb.DMatrix(test_x)\n",
    "        \n",
    "        # share params\n",
    "        params = {\n",
    "                'colsample_bytree': 0.9,\n",
    "                'subsample': 0.9,\n",
    "                'eta': 0.05,\n",
    "                'max_depth': 3,\n",
    "                'eval_metric':'logloss',\n",
    "                'objective':'binary:logistic',\n",
    "                'scale_pos_weight':0.9,\n",
    "                'colsample_bylevel':0.9,\n",
    "                'colsample_bytree':0.9,\n",
    "            \n",
    "                }\n",
    "        \n",
    "        # train for each class\n",
    "        for i in range(6):\n",
    "            d_train = xgb.DMatrix(curr_x, curr_y[:,i])\n",
    "            d_valid = xgb.DMatrix(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "            model = xgb.train(params, d_train, 1000, watchlist,\n",
    "                              early_stopping_rounds=50,\n",
    "                              verbose_eval=2000)\n",
    "            print(i)\n",
    "            try:\n",
    "                curr_train_loss = log_loss(curr_y[:,i],model.predict(d_train))\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],model.predict(d_valid))\n",
    "                print(curr_train_loss,curr_val_loss)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            \n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            cache_test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg 6 class\n",
    "        train_loss_l = train_loss_l/6\n",
    "        val_loss_l = val_loss_l/6\n",
    "        print('this fold avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        \n",
    "        # save best one fold result\n",
    "        if val_loss_l < single_best:\n",
    "            single_best = val_loss_l\n",
    "            single_best_pred = cache_test_pred\n",
    "            print('new single best')\n",
    "        \n",
    "        cache_test_pred = np.zeros((153164,6))\n",
    "        \n",
    "        # avg k fold\n",
    "        all_train_loss_l += train_loss_l/k\n",
    "        all_val_loss_l += val_loss_l/k\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all train avg',all_train_loss_l,'all val avg',all_val_loss_l)\n",
    "    return test_pred, single_best_pred\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.648585\tvalid-logloss:0.648662\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[537]\ttrain-logloss:0.058003\tvalid-logloss:0.070881\n",
      "\n",
      "0\n",
      "0.0569477864684 0.0709223552454\n",
      "[0]\ttrain-logloss:0.64543\tvalid-logloss:0.645384\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[183]\ttrain-logloss:0.014612\tvalid-logloss:0.016652\n",
      "\n",
      "1\n",
      "0.0136318514357 0.0166669946835\n",
      "[0]\ttrain-logloss:0.646546\tvalid-logloss:0.64657\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[238]\ttrain-logloss:0.03181\tvalid-logloss:0.03645\n",
      "\n",
      "2\n",
      "0.0306316968461 0.0364851378257\n",
      "[0]\ttrain-logloss:0.644684\tvalid-logloss:0.644723\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[196]\ttrain-logloss:0.003538\tvalid-logloss:0.007025\n",
      "\n",
      "3\n",
      "0.00290861044984 0.00707829579089\n",
      "[0]\ttrain-logloss:0.64728\tvalid-logloss:0.647297\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[235]\ttrain-logloss:0.044584\tvalid-logloss:0.047643\n",
      "\n",
      "4\n",
      "0.0433851704222 0.0476929273699\n",
      "[0]\ttrain-logloss:0.645202\tvalid-logloss:0.645192\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[175]\ttrain-logloss:0.012828\tvalid-logloss:0.015589\n",
      "\n",
      "5\n",
      "0.0119218181073 0.0156318778357\n",
      "this fold avg train 0.0265711556216 avg val 0.0324129314585\n",
      "new single best\n",
      "========================\n",
      "[0]\ttrain-logloss:0.648587\tvalid-logloss:0.648695\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[546]\ttrain-logloss:0.05732\tvalid-logloss:0.072507\n",
      "\n",
      "0\n",
      "0.0563548246312 0.0725616702954\n",
      "[0]\ttrain-logloss:0.645374\tvalid-logloss:0.645424\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[179]\ttrain-logloss:0.014029\tvalid-logloss:0.017761\n",
      "\n",
      "1\n",
      "0.0131275337953 0.0178223122085\n",
      "[0]\ttrain-logloss:0.646504\tvalid-logloss:0.646574\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[227]\ttrain-logloss:0.03183\tvalid-logloss:0.037404\n",
      "\n",
      "2\n",
      "0.0306402174064 0.0374617975898\n",
      "[0]\ttrain-logloss:0.644703\tvalid-logloss:0.644715\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[207]\ttrain-logloss:0.003824\tvalid-logloss:0.005914\n",
      "\n",
      "3\n",
      "0.00322460736976 0.00594763103826\n",
      "[0]\ttrain-logloss:0.64725\tvalid-logloss:0.647318\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[179]\ttrain-logloss:0.044992\tvalid-logloss:0.049746\n",
      "\n",
      "4\n",
      "0.0436700362452 0.0498616501067\n",
      "[0]\ttrain-logloss:0.645185\tvalid-logloss:0.645206\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[187]\ttrain-logloss:0.012529\tvalid-logloss:0.015998\n",
      "\n",
      "5\n",
      "0.0116237391389 0.0160678891509\n",
      "this fold avg train 0.0264401597645 avg val 0.0332871583983\n",
      "========================\n",
      "[0]\ttrain-logloss:0.648745\tvalid-logloss:0.64866\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[605]\ttrain-logloss:0.058039\tvalid-logloss:0.069361\n",
      "\n",
      "0\n",
      "0.0570609476699 0.069400717116\n",
      "[0]\ttrain-logloss:0.645393\tvalid-logloss:0.645444\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[231]\ttrain-logloss:0.013335\tvalid-logloss:0.017421\n",
      "\n",
      "1\n",
      "0.0123879035103 0.0175132320509\n",
      "[0]\ttrain-logloss:0.646506\tvalid-logloss:0.646525\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[316]\ttrain-logloss:0.030278\tvalid-logloss:0.036801\n",
      "\n",
      "2\n",
      "0.0292195533518 0.0368357338142\n",
      "[0]\ttrain-logloss:0.644693\tvalid-logloss:0.644715\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[198]\ttrain-logloss:0.003684\tvalid-logloss:0.006131\n",
      "\n",
      "3\n",
      "0.00306847508861 0.00615583045894\n",
      "[0]\ttrain-logloss:0.647253\tvalid-logloss:0.647282\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[181]\ttrain-logloss:0.045148\tvalid-logloss:0.049211\n",
      "\n",
      "4\n",
      "0.0438328619039 0.0492360126221\n",
      "[0]\ttrain-logloss:0.645189\tvalid-logloss:0.64524\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[187]\ttrain-logloss:0.012702\tvalid-logloss:0.01565\n",
      "\n",
      "5\n",
      "0.0117328004901 0.0157046749928\n",
      "this fold avg train 0.0262170903358 avg val 0.0324743668425\n",
      "========================\n",
      "all train avg 0.0264094685739 all val avg 0.0327248188998\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.998049      0.272274  0.977529  0.133257  0.933826   \n",
      "1  0000247867823ef7  0.000081      0.000024  0.000074  0.000023  0.000073   \n",
      "2  00013b17ad220c46  0.000475      0.000029  0.000359  0.000036  0.000337   \n",
      "3  00017563c3f7919a  0.000079      0.000036  0.000098  0.000032  0.000112   \n",
      "4  00017695ad8997eb  0.002113      0.000031  0.000573  0.000045  0.000282   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.479305  \n",
      "1       0.000047  \n",
      "2       0.000179  \n",
      "3       0.000058  \n",
      "4       0.000094  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "# xgb_res,b = simple_ens('xgb',k=3)\n",
    "# sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "# sample_submission[list_classes] = xgb_res\n",
    "# sample_submission.to_csv(\"../results/xgb_ens_sample_csv_fold3.gz\", index=False, compression='gzip')\n",
    "# print(sample_submission.head())\n",
    "# print('save done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.831708      0.226895  0.814608  0.111047  0.778188   \n",
      "1  0000247867823ef7  0.000068      0.000020  0.000062  0.000019  0.000061   \n",
      "2  00013b17ad220c46  0.000396      0.000024  0.000299  0.000030  0.000281   \n",
      "3  00017563c3f7919a  0.000066      0.000030  0.000082  0.000027  0.000093   \n",
      "4  00017695ad8997eb  0.001761      0.000026  0.000478  0.000037  0.000235   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.399420  \n",
      "1       0.000039  \n",
      "2       0.000149  \n",
      "3       0.000048  \n",
      "4       0.000078  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = xgb_res/1.2\n",
    "sample_submission.to_csv(\"../results/xgb_ens_sample_csv_fold3_div2.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.648624\tvalid-logloss:0.648698\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[567]\ttrain-logloss:0.059114\tvalid-logloss:0.070927\n",
      "\n",
      "0\n",
      "0.0581462623283 0.0709437131355\n",
      "[0]\ttrain-logloss:0.645408\tvalid-logloss:0.64541\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[196]\ttrain-logloss:0.014455\tvalid-logloss:0.016786\n",
      "\n",
      "1\n",
      "0.0136270849377 0.0168117832044\n",
      "[0]\ttrain-logloss:0.646534\tvalid-logloss:0.646514\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[396]\ttrain-logloss:0.029886\tvalid-logloss:0.035317\n",
      "\n",
      "2\n",
      "0.0289965224012 0.0353767543775\n",
      "[0]\ttrain-logloss:0.644705\tvalid-logloss:0.644729\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[234]\ttrain-logloss:0.003525\tvalid-logloss:0.006411\n",
      "\n",
      "3\n",
      "0.00300976430518 0.00649886212629\n",
      "[0]\ttrain-logloss:0.647274\tvalid-logloss:0.647314\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[437]\ttrain-logloss:0.041139\tvalid-logloss:0.047082\n",
      "\n",
      "4\n",
      "0.0402630939404 0.0471874033144\n",
      "[0]\ttrain-logloss:0.645186\tvalid-logloss:0.645218\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[192]\ttrain-logloss:0.012825\tvalid-logloss:0.016238\n",
      "\n",
      "5\n",
      "0.0119698259618 0.0163061746211\n",
      "this fold avg train 0.0260020923124 avg val 0.0321874484632\n",
      "new single best\n",
      "========================\n",
      "[0]\ttrain-logloss:0.648634\tvalid-logloss:0.64865\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[539]\ttrain-logloss:0.059374\tvalid-logloss:0.071812\n",
      "\n",
      "0\n",
      "0.058403523774 0.0718356771475\n",
      "[0]\ttrain-logloss:0.645417\tvalid-logloss:0.645361\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[221]\ttrain-logloss:0.014295\tvalid-logloss:0.016015\n",
      "\n",
      "1\n",
      "0.0134971682824 0.0160285255117\n",
      "[0]\ttrain-logloss:0.646517\tvalid-logloss:0.646502\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[182]\ttrain-logloss:0.033603\tvalid-logloss:0.037449\n",
      "\n",
      "2\n",
      "0.0324490999193 0.0375238866389\n",
      "[0]\ttrain-logloss:0.644696\tvalid-logloss:0.644741\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[179]\ttrain-logloss:0.003918\tvalid-logloss:0.007608\n",
      "\n",
      "3\n",
      "0.00338425218006 0.00764852623202\n",
      "[0]\ttrain-logloss:0.647282\tvalid-logloss:0.647256\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[188]\ttrain-logloss:0.045644\tvalid-logloss:0.048606\n",
      "\n",
      "4\n",
      "0.044551540306 0.0486154810234\n",
      "[0]\ttrain-logloss:0.645203\tvalid-logloss:0.645159\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[196]\ttrain-logloss:0.013016\tvalid-logloss:0.014872\n",
      "\n",
      "5\n",
      "0.0122615348114 0.0149189518654\n",
      "this fold avg train 0.0274245198789 avg val 0.0327618414032\n",
      "========================\n",
      "[0]\ttrain-logloss:0.648603\tvalid-logloss:0.648688\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[562]\ttrain-logloss:0.059341\tvalid-logloss:0.071383\n",
      "\n",
      "0\n",
      "0.0583736349415 0.0714112991455\n",
      "[0]\ttrain-logloss:0.645388\tvalid-logloss:0.645434\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[193]\ttrain-logloss:0.014245\tvalid-logloss:0.017858\n",
      "\n",
      "1\n",
      "0.0134588972586 0.0180106717108\n",
      "[0]\ttrain-logloss:0.646525\tvalid-logloss:0.646569\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[213]\ttrain-logloss:0.033152\tvalid-logloss:0.036232\n",
      "\n",
      "2\n",
      "0.0320885823094 0.036285608933\n",
      "[0]\ttrain-logloss:0.644708\tvalid-logloss:0.644695\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[213]\ttrain-logloss:0.003972\tvalid-logloss:0.005569\n",
      "\n",
      "3\n",
      "0.00342316470374 0.0055955283179\n",
      "[0]\ttrain-logloss:0.647267\tvalid-logloss:0.647331\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[229]\ttrain-logloss:0.04453\tvalid-logloss:0.050178\n",
      "\n",
      "4\n",
      "0.0434205216068 0.0502720205046\n",
      "[0]\ttrain-logloss:0.645198\tvalid-logloss:0.64521\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[176]\ttrain-logloss:0.012929\tvalid-logloss:0.0167\n",
      "\n",
      "5\n",
      "0.0121807820857 0.0167619195164\n",
      "this fold avg train 0.027157597151 avg val 0.033056174688\n",
      "========================\n",
      "[0]\ttrain-logloss:0.64864\tvalid-logloss:0.64867\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[663]\ttrain-logloss:0.057339\tvalid-logloss:0.071255\n",
      "\n",
      "0\n",
      "0.056458525638 0.0713089672799\n",
      "[0]\ttrain-logloss:0.645391\tvalid-logloss:0.645446\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[191]\ttrain-logloss:0.014374\tvalid-logloss:0.017642\n",
      "\n",
      "1\n",
      "0.0135801315247 0.01772382117\n",
      "[0]\ttrain-logloss:0.646491\tvalid-logloss:0.646623\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[251]\ttrain-logloss:0.031661\tvalid-logloss:0.03934\n",
      "\n",
      "2\n",
      "0.0306919759956 0.0394254299651\n",
      "[0]\ttrain-logloss:0.64471\tvalid-logloss:0.64469\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[240]\ttrain-logloss:0.003581\tvalid-logloss:0.005719\n",
      "\n",
      "3\n",
      "0.00304492469067 0.00574483500493\n",
      "[0]\ttrain-logloss:0.647289\tvalid-logloss:0.647256\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[235]\ttrain-logloss:0.044855\tvalid-logloss:0.047464\n",
      "\n",
      "4\n",
      "0.0437686071461 0.0475068271158\n",
      "[0]\ttrain-logloss:0.645203\tvalid-logloss:0.645215\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[187]\ttrain-logloss:0.013153\tvalid-logloss:0.015187\n",
      "\n",
      "5\n",
      "0.0123254767174 0.015216240386\n",
      "this fold avg train 0.0266449402854 avg val 0.0328210201536\n",
      "========================\n",
      "[0]\ttrain-logloss:0.648633\tvalid-logloss:0.648544\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[634]\ttrain-logloss:0.058733\tvalid-logloss:0.068082\n",
      "\n",
      "0\n",
      "0.0578896950893 0.0680926131742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.645401\tvalid-logloss:0.645484\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[204]\ttrain-logloss:0.014271\tvalid-logloss:0.017286\n",
      "\n",
      "1\n",
      "0.0134289526644 0.0173437518977\n",
      "[0]\ttrain-logloss:0.646525\tvalid-logloss:0.646489\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[271]\ttrain-logloss:0.032008\tvalid-logloss:0.035754\n",
      "\n",
      "2\n",
      "0.0310311683655 0.0358146133167\n",
      "[0]\ttrain-logloss:0.644696\tvalid-logloss:0.644727\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[217]\ttrain-logloss:0.003712\tvalid-logloss:0.006461\n",
      "\n",
      "3\n",
      "0.00315642284674 0.0065305210376\n",
      "[0]\ttrain-logloss:0.647232\tvalid-logloss:0.647342\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[217]\ttrain-logloss:0.044643\tvalid-logloss:0.050488\n",
      "\n",
      "4\n",
      "0.0435374140403 0.0505385097566\n",
      "[0]\ttrain-logloss:0.645193\tvalid-logloss:0.645255\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[186]\ttrain-logloss:0.013069\tvalid-logloss:0.01564\n",
      "\n",
      "5\n",
      "0.012236484551 0.0156716188913\n",
      "this fold avg train 0.0268800229262 avg val 0.0323319380123\n",
      "========================\n",
      "all train avg 0.0268218345108 all val avg 0.0326316845441\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.831753      0.231305  0.809532  0.124339  0.777301   \n",
      "1  0000247867823ef7  0.000063      0.000019  0.000053  0.000018  0.000048   \n",
      "2  00013b17ad220c46  0.000476      0.000023  0.000285  0.000022  0.000249   \n",
      "3  00017563c3f7919a  0.000079      0.000026  0.000071  0.000023  0.000071   \n",
      "4  00017695ad8997eb  0.001793      0.000024  0.000535  0.000026  0.000203   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.390787  \n",
      "1       0.000041  \n",
      "2       0.000205  \n",
      "3       0.000042  \n",
      "4       0.000099  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "xgb_res,b = simple_ens('xgb',k=5)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = xgb_res\n",
    "sample_submission.to_csv(\"../results/xgb_ens_sample_csv_fold5.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_res,b = simple_ens('xgb',k=5)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = xgb_res/1.2\n",
    "sample_submission.to_csv(\"../results/xgb_ens_sample_csv_fold5_div2.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.37754067  0.70812487  1.        ]\n",
      "1.6487212707\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import logit,expit\n",
    "\n",
    "# The logit function is defined as logit(p) = log(p/(1-p)). \n",
    "# Note that logit(0) = -inf, logit(1) = inf, and logit(p) for p<0 or p>1 yields nan.\n",
    "\n",
    "# The expit function, also known as the logistic function, \n",
    "# is defined as expit(x) = 1/(1+exp(-x)). It is the inverse of the logit function.\n",
    "\n",
    "\n",
    "\n",
    "def new_trans(x):\n",
    "    return expit(logit(x)-0.5)\n",
    "\n",
    "test_x = np.array([0,0.5,0.8,1])\n",
    "print(new_trans(test_x))\n",
    "\n",
    "div_num = np.sqrt(np.e)\n",
    "print(div_num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.996878      0.188993  0.953767  0.096143  0.893775   \n",
      "1  0000247867823ef7  0.000046      0.000014  0.000038  0.000013  0.000035   \n",
      "2  00013b17ad220c46  0.000346      0.000017  0.000207  0.000016  0.000181   \n",
      "3  00017563c3f7919a  0.000057      0.000019  0.000052  0.000017  0.000052   \n",
      "4  00017695ad8997eb  0.001306      0.000018  0.000390  0.000019  0.000148   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.348785  \n",
      "1       0.000030  \n",
      "2       0.000149  \n",
      "3       0.000031  \n",
      "4       0.000072  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "sample_submission[list_classes] = new_trans(xgb_res)\n",
    "sample_submission.to_csv(\"../results/xgb_ens_sample_csv_fold5_new_trans.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.998049</td>\n",
       "      <td>0.272274</td>\n",
       "      <td>0.977529</td>\n",
       "      <td>0.133257</td>\n",
       "      <td>0.933826</td>\n",
       "      <td>0.479305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000337</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.000094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.998049      0.272274  0.977529  0.133257  0.933826   \n",
       "1  0000247867823ef7  0.000081      0.000024  0.000074  0.000023  0.000073   \n",
       "2  00013b17ad220c46  0.000475      0.000029  0.000359  0.000036  0.000337   \n",
       "3  00017563c3f7919a  0.000079      0.000036  0.000098  0.000032  0.000112   \n",
       "4  00017695ad8997eb  0.002113      0.000031  0.000573  0.000045  0.000282   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.479305  \n",
       "1       0.000047  \n",
       "2       0.000179  \n",
       "3       0.000058  \n",
       "4       0.000094  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_3fold_res = pd.read_csv('../results/xgb_ens_sample_csv_fold3.gz')\n",
    "print(pre_3fold_res.head())\n",
    "\n",
    "pre_3fold_res[list_classes] = new_trans(pre_3fold_res[list_classes].values)\n",
    "pre_3fold_res.to_csv(\"../results/xgb_ens_sample_csv_fold3_new_trans.gz\", index=False, compression='gzip')\n",
    "print(pre_3fold_res.head())\n",
    "print('save done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
