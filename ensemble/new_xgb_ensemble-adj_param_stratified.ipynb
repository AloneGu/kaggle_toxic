{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/fasttext_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 36) (153164, 36)\n",
      "file path ../features/pool_gru_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "(159571, 276)\n",
      "(159571, 276)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(1800)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat or 'tfidf' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,c_bytree=0.9,s_sample=0.9,max_d=3,ev_metric='logloss'):\n",
    "    kf = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for i in range(6):\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        fold_cnt = 0\n",
    "        for train_index, test_index in kf.split(train_x,train_y[:,i]):\n",
    "            # x,y\n",
    "            curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "            hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "            d_test = xgb.DMatrix(test_x)\n",
    "\n",
    "            # share params\n",
    "            params = {\n",
    "                    'subsample': s_sample,\n",
    "                    'eta': lr,\n",
    "                    'max_depth': max_d,\n",
    "                    'eval_metric':'logloss',\n",
    "                    #'eval_metric':'auc',\n",
    "                    'objective':'binary:logistic',\n",
    "                    #'scale_pos_weight':0.9,\n",
    "                    'colsample_bytree':c_bytree\n",
    "\n",
    "                    }\n",
    "\n",
    "            d_train = xgb.DMatrix(curr_x, curr_y[:,i])\n",
    "            d_valid = xgb.DMatrix(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "            model = xgb.train(params, d_train, 1000, watchlist,\n",
    "                              early_stopping_rounds=50,\n",
    "                              verbose_eval=None)\n",
    "            print(fold_cnt,'fold: ',end='')\n",
    "            fold_cnt += 1\n",
    "            try:\n",
    "                train_pred = model.predict(d_train)\n",
    "                tmp_test_pred = model.predict(d_valid)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "            \n",
    "        # avg k fold\n",
    "        train_loss_l = train_loss_l/k\n",
    "        val_loss_l = val_loss_l/k\n",
    "        train_auc_l = train_auc_l/k\n",
    "        val_auc_l = val_auc_l/k\n",
    "        print('this class avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this class auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg 6 class\n",
    "        all_train_loss_l += train_loss_l/6\n",
    "        all_val_loss_l += val_loss_l/6\n",
    "        all_train_auc_l += train_auc_l/6\n",
    "        all_val_auc_l += val_auc_l/6\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.068601561542 0.0737398426855 auc 0.990874280415 0.988955525838\n",
      "1 fold: ls 0.0651319943182 0.0786973120727 auc 0.991944741433 0.987396737643\n",
      "2 fold: ls 0.0687204616737 0.07372641548 auc 0.990860430861 0.989178449312\n",
      "3 fold: ls 0.0678187672201 0.0755270718717 auc 0.991134513274 0.988437787092\n",
      "4 fold: ls 0.0666269968593 0.0818243455237 auc 0.991429194698 0.986807544664\n",
      "5 fold: ls 0.0697068937329 0.074512447024 auc 0.990538502129 0.987950950327\n",
      "6 fold: ls 0.0664468065448 0.0744595740503 auc 0.991513225075 0.988725731868\n",
      "7 fold: ls 0.0715642457541 0.0726869956477 auc 0.989974643687 0.98893180584\n",
      "8 fold: ls 0.0631764780234 0.0780034398012 auc 0.9925734494 0.986683595901\n",
      "9 fold: ls 0.0700498915094 0.0777344832045 auc 0.990353144628 0.987799427559\n",
      "this class avg train 0.0677844097178 avg val 0.0760911927361\n",
      "this class auc train 0.99111961256 auc val 0.988086755604\n",
      "========================\n",
      "0 fold: ls 0.0154216342693 0.0198842452237 auc 0.996260154923 0.992501819851\n",
      "1 fold: ls 0.0166421260716 0.0198977794046 auc 0.99528444812 0.992613780225\n",
      "2 fold: ls 0.015638569399 0.0210624344184 auc 0.996040873434 0.991239793012\n",
      "3 fold: ls 0.0166837775736 0.0197261002005 auc 0.995250305317 0.992573031396\n",
      "4 fold: ls 0.0158276563909 0.021020151808 auc 0.995937131464 0.991293597291\n",
      "5 fold: ls 0.0169012508279 0.0196083590011 auc 0.995082388387 0.992445106896\n",
      "6 fold: ls 0.0158207599271 0.0215966826253 auc 0.995917505496 0.990694833785\n",
      "7 fold: ls 0.0165944698333 0.021216210441 auc 0.995274748899 0.991108892183\n",
      "8 fold: ls 0.0161301998731 0.0195998268628 auc 0.995713576442 0.992300902607\n",
      "9 fold: ls 0.0169243110156 0.0201804451768 auc 0.995017489037 0.992177083221\n",
      "this class avg train 0.0162584755181 avg val 0.0203792235162\n",
      "this class auc train 0.995577862152 auc val 0.991894884047\n",
      "========================\n",
      "0 fold: ls 0.0349540220205 0.0368650910782 auc 0.996261115835 0.995595077243\n",
      "1 fold: ls 0.0352264252981 0.0395096463034 auc 0.996190115915 0.994807636515\n",
      "2 fold: ls 0.0324943290542 0.0399728154534 auc 0.996812969801 0.994951228069\n",
      "3 fold: ls 0.0351717371338 0.040459687498 auc 0.996204875802 0.994722756476\n",
      "4 fold: ls 0.0342778598847 0.0381760338197 auc 0.996416250066 0.994967164305\n",
      "5 fold: ls 0.0343694896333 0.0392166443335 auc 0.99637410623 0.995091678387\n",
      "6 fold: ls 0.0336265109902 0.041001504166 auc 0.996537223839 0.99481120846\n",
      "7 fold: ls 0.0322085014778 0.038686116608 auc 0.996872564952 0.994933216598\n",
      "8 fold: ls 0.0318023749454 0.0379866894088 auc 0.996973651758 0.995480373762\n",
      "9 fold: ls 0.0329725782184 0.0384616596504 auc 0.996706447939 0.995080570602\n",
      "this class avg train 0.0337103828656 avg val 0.0390335888319\n",
      "this class auc train 0.996534932214 auc val 0.995044091042\n",
      "========================\n",
      "0 fold: ls 0.00422089972848 0.00879264139257 auc 0.998910680088 0.985169180809\n",
      "1 fold: ls 0.00401475778066 0.00727184968547 auc 0.998945925275 0.995346218311\n",
      "2 fold: ls 0.00334577662308 0.00641174970164 auc 0.999427054563 0.99582416719\n",
      "3 fold: ls 0.00396576371955 0.00759716421879 auc 0.998809451881 0.993494248539\n",
      "4 fold: ls 0.00387003827775 0.00627752081549 auc 0.999122433454 0.996682957236\n",
      "5 fold: ls 0.00371757928781 0.00724864537386 auc 0.999094334952 0.995162591405\n",
      "6 fold: ls 0.00437601948754 0.00661188785475 auc 0.99885812888 0.988611006349\n",
      "7 fold: ls 0.00423007103717 0.00663687126202 auc 0.998795898009 0.995787237832\n",
      "8 fold: ls 0.00420329176724 0.00722807282962 auc 0.998747996834 0.996195115036\n",
      "9 fold: ls 0.00439642220777 0.00628487894854 auc 0.99864486505 0.993731635913\n",
      "this class avg train 0.0040340619917 avg val 0.00703612820827\n",
      "this class auc train 0.998935676898 auc val 0.993600435862\n",
      "========================\n",
      "0 fold: ls 0.0474664575834 0.0522220252885 auc 0.992535279616 0.990655314222\n",
      "1 fold: ls 0.048585190938 0.0518004396322 auc 0.992098669921 0.990670957574\n",
      "2 fold: ls 0.0489551169569 0.0556488254711 auc 0.99196825809 0.989382305111\n",
      "3 fold: ls 0.0463588673311 0.0554451417368 auc 0.99294339017 0.989014937309\n",
      "4 fold: ls 0.050052805155 0.0561804919064 auc 0.991588588431 0.987551546987\n",
      "5 fold: ls 0.046361168575 0.0541419349089 auc 0.99295565325 0.989934889249\n",
      "6 fold: ls 0.045796577067 0.0509946527547 auc 0.993157117207 0.99122174432\n",
      "7 fold: ls 0.0465721134684 0.0542415815577 auc 0.992840690327 0.989826606678\n",
      "8 fold: ls 0.049993409178 0.0556466944221 auc 0.991614259234 0.989078282188\n",
      "9 fold: ls 0.0483105380163 0.0539388192557 auc 0.99222664107 0.989578156414\n",
      "this class avg train 0.0478452244269 avg val 0.0540260606934\n",
      "this class auc train 0.992392854732 auc val 0.989691474005\n",
      "========================\n",
      "0 fold: ls 0.0144726610725 0.0187796407591 auc 0.995551982198 0.984158798528\n",
      "1 fold: ls 0.0139579508614 0.017432484346 auc 0.99568781623 0.992156746691\n",
      "2 fold: ls 0.012503255306 0.0183661611483 auc 0.996873018942 0.991488644277\n",
      "3 fold: ls 0.0141879321928 0.0178873838152 auc 0.995409403844 0.991742433516\n",
      "4 fold: ls 0.014512918489 0.0181100160994 auc 0.995321733218 0.990196830145\n",
      "5 fold: ls 0.0139636833844 0.0182915350104 auc 0.995770943412 0.987241123926\n",
      "6 fold: ls 0.0139849402491 0.0202493058316 auc 0.995699218788 0.986936827083\n",
      "7 fold: ls 0.0140968420719 0.0181092629804 auc 0.995641017311 0.990446383409\n",
      "8 fold: ls 0.0129804154932 0.0154060232583 auc 0.996618569439 0.993469542597\n",
      "9 fold: ls 0.0126813172265 0.0165701537881 auc 0.996848584808 0.993494833442\n",
      "this class avg train 0.0137341916347 avg val 0.0179201967037\n",
      "this class auc train 0.995942228819 auc val 0.990133216361\n",
      "========================\n",
      "all loss avg 0.0305611243591 0.0357477317816\n",
      "all auc avg 0.995083861229 0.991408476154\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.998922      0.317778  0.982763  0.139075  0.921297   \n",
      "1  0000247867823ef7  0.000377      0.000027  0.000068  0.000023  0.000051   \n",
      "2  00013b17ad220c46  0.000288      0.000030  0.000188  0.000029  0.000184   \n",
      "3  00017563c3f7919a  0.000101      0.000027  0.000054  0.000029  0.000048   \n",
      "4  00017695ad8997eb  0.001657      0.000032  0.000153  0.000030  0.000176   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.430607  \n",
      "1       0.000040  \n",
      "2       0.000061  \n",
      "3       0.000045  \n",
      "4       0.000072  \n",
      "save done\n",
      "CPU times: user 14h 11min 24s, sys: 1min 35s, total: 14h 13min\n",
      "Wall time: 1h 47min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_res = simple_ens('xgb',10,233,0.05,0.8,0.6)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = xgb_res\n",
    "sample_submission.to_csv(\"../results/xgb_adj_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "# all train avg 0.0321542340346 all val avg 0.0367885979049, PUB 9862, rnd 42, lr 0.03\n",
    "# all train avg 0.0318508428487 all val avg 0.0368012450966, rnd 233, lr 0.05, PUB unknown\n",
    "\n",
    "# fix lr, mnb bug, rm scale_pos_weight\n",
    "# all train avg 0.0304768900903 all val avg 0.0360563778853 PUB 9866\n",
    "\n",
    "# add many base models, rm tfidf\n",
    "# all loss avg 0.0307207945903 0.0357848161087 all auc avg 0.995053758756 0.991359127088\n",
    "\n",
    "# change to stratified\n",
    "# all loss avg 0.0305611243591 0.0357477317816 all auc avg 0.995083861229 0.991408476154 PUB 9866"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 fold: ls 0.0581707319832 0.079299253139 auc 0.994044010174 0.986362030257\n",
      "1 fold: ls 0.0557417940086 0.072703174966 auc 0.99465195427 0.989351587599\n",
      "2 fold: ls 0.0592292122913 0.0765654854344 auc 0.993757797896 0.988083809441\n",
      "3 fold: ls 0.0554030700013 0.0738393569151 auc 0.994778602506 0.988779669524\n",
      "4 fold: ls 0.0583258564483 0.0805349726548 auc 0.993994466964 0.98692961854\n",
      "5 fold: ls 0.0597083287706 0.0772826359638 auc 0.993642309058 0.987054910851\n",
      "6 fold: ls 0.0581324289317 0.0790129675379 auc 0.994009215437 0.986979798927\n",
      "7 fold: ls 0.0559847055899 0.0710982646455 auc 0.994558051209 0.989875869961\n",
      "8 fold: ls 0.0576388883271 0.0759073521115 auc 0.994067138296 0.98862644133\n",
      "9 fold: ls 0.0560594748054 0.0786050510029 auc 0.99461862321 0.987364138066\n",
      "this class avg train 0.0574394491157 avg val 0.0764848514371\n",
      "this class auc train 0.994212216902 auc val 0.98794078745\n",
      "========================\n",
      "0 fold: ls 0.00973054296903 0.0221639161096 auc 0.999522032621 0.990752785163\n",
      "1 fold: ls 0.0100197735047 0.0217125289761 auc 0.999466782156 0.991339093556\n",
      "2 fold: ls 0.0102035920422 0.021127328603 auc 0.999406498004 0.991392897835\n",
      "3 fold: ls 0.0096976575105 0.0206997651632 auc 0.999521172434 0.992271569186\n",
      "4 fold: ls 0.00954186530858 0.0216597160675 auc 0.999585696254 0.990972749715\n",
      "5 fold: ls 0.0104775066387 0.0199056567326 auc 0.999308384413 0.992405694217\n",
      "6 fold: ls 0.0102916714666 0.0197320129722 auc 0.999357446666 0.992411185469\n",
      "7 fold: ls 0.0100604144704 0.0205028186301 auc 0.999426573208 0.991942582841\n",
      "8 fold: ls 0.00975600483161 0.0214990552939 auc 0.999513993414 0.991174982273\n",
      "9 fold: ls 0.00989227200706 0.0189324823007 auc 0.999517549291 0.993231737735\n",
      "this class avg train 0.00996713007493 avg val 0.0207935280849\n",
      "this class auc train 0.999462612846 auc val 0.991789527799\n",
      "========================\n",
      "0 fold: ls 0.0237260826305 0.0381070404807 auc 0.998624933379 0.995507218402\n",
      "1 fold: ls 0.0242818613524 0.0391126152854 auc 0.998534002834 0.994720090897\n",
      "2 fold: ls 0.0247902223024 0.0404654142708 auc 0.998426873937 0.994935957474\n",
      "3 fold: ls 0.0269270962551 0.0354557546417 auc 0.998049371099 0.995754539674\n",
      "4 fold: ls 0.0244620041728 0.0439465330904 auc 0.998481817274 0.994175168603\n",
      "5 fold: ls 0.0224573691969 0.0392168130603 auc 0.998859870768 0.995052953725\n",
      "6 fold: ls 0.0238644360419 0.0385832333717 auc 0.998608457152 0.995031966445\n",
      "7 fold: ls 0.0252916951281 0.0397094146549 auc 0.998329677503 0.995122728597\n",
      "8 fold: ls 0.0241595742638 0.0399338603657 auc 0.998541135405 0.994917554449\n",
      "9 fold: ls 0.0266839950004 0.0407928037642 auc 0.998066006381 0.994462672394\n",
      "this class avg train 0.0246644336344 avg val 0.0395323482986\n",
      "this class auc train 0.998452214573 auc val 0.994968085066\n",
      "========================\n",
      "0 fold: ls 0.00141043694909 0.00694879832769 auc 0.999959443672 0.99693327048\n",
      "1 fold: ls 0.00169535727386 0.00690157296606 auc 0.999951411992 0.995452283679\n",
      "2 fold: ls 0.00172410173126 0.0078728013925 auc 0.999929168543 0.989028126964\n",
      "3 fold: ls 0.00176309000397 0.00707842890364 auc 0.999979072301 0.986058729859\n",
      "4 fold: ls 0.00156620470987 0.0074870366833 auc 0.999960077389 0.995200567813\n",
      "5 fold: ls 0.00157955697109 0.00725146176633 auc 0.999958834883 0.993781035892\n",
      "6 fold: ls 0.000966977629353 0.00665961226758 auc 0.999973249577 0.996409265196\n",
      "7 fold: ls 0.00178984056842 0.00802997519463 auc 0.999937817854 0.995208425001\n",
      "8 fold: ls 0.00167175815494 0.00738531690204 auc 0.999957334278 0.994238508111\n",
      "9 fold: ls 0.00176201407358 0.00764158094316 auc 0.999945537603 0.990586086024\n",
      "this class avg train 0.00159293380654 avg val 0.00732565853469\n",
      "this class auc train 0.999955194809 auc val 0.993289629902\n",
      "========================\n",
      "0 fold: ls 0.0385331468493 0.0504757595024 auc 0.99564443756 0.991142265827\n",
      "1 fold: ls 0.0402585670019 0.0549579469975 auc 0.99505597555 0.989125026351\n",
      "2 fold: ls 0.0337861201287 0.0561835439085 auc 0.997012567342 0.988996198749\n",
      "3 fold: ls 0.0399641251493 0.0527384820936 auc 0.995170477374 0.99002000174\n",
      "4 fold: ls 0.0382365480517 0.0556605921412 auc 0.9957042886 0.988969036838\n",
      "5 fold: ls 0.0364740887116 0.0534930076953 auc 0.996269834117 0.990176666077\n",
      "6 fold: ls 0.0386496390964 0.0570744782369 auc 0.995559438658 0.988709858772\n",
      "7 fold: ls 0.0321152906594 0.0569258160367 auc 0.997451558674 0.988961302824\n",
      "8 fold: ls 0.0393566250255 0.053681081467 auc 0.995382721279 0.989785728819\n",
      "9 fold: ls 0.0364663857827 0.0551195980381 auc 0.996229966096 0.989223239431\n",
      "this class avg train 0.0373840536457 avg val 0.0546310306117\n",
      "this class auc train 0.995948126525 auc val 0.989510932543\n",
      "========================\n",
      "0 fold: ls 0.00805475867201 0.0177951367665 auc 0.99936859031 0.992187685662\n",
      "1 fold: ls 0.00805385098792 0.019149678561 auc 0.99937814685 0.989223373541\n",
      "2 fold: ls 0.00777234662572 0.0185473446296 auc 0.999466626128 0.992335654653\n",
      "3 fold: ls 0.00791701384896 0.018775184584 auc 0.999413494099 0.988301930278\n",
      "4 fold: ls 0.0082930230729 0.020021779716 auc 0.999245052786 0.987759377311\n",
      "5 fold: ls 0.00882824006601 0.0182889698775 auc 0.99910387533 0.991482491713\n",
      "6 fold: ls 0.00815507636913 0.0172428433523 auc 0.999331103679 0.988280854831\n",
      "7 fold: ls 0.00836099665582 0.0203259381507 auc 0.999288218234 0.986631078835\n",
      "8 fold: ls 0.00742252535921 0.0173821795344 auc 0.999587250153 0.992781270323\n",
      "9 fold: ls 0.0088811185342 0.0172275424624 auc 0.999112791913 0.9906270323\n",
      "this class avg train 0.00817389501919 avg val 0.0184756597634\n",
      "this class auc train 0.999329514948 auc val 0.989961074945\n",
      "========================\n",
      "all loss avg 0.0232036492161 0.0362071794551\n",
      "all auc avg 0.997893313434 0.991243339617\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999566      0.286107  0.981693  0.049993  0.934799   \n",
      "1  0000247867823ef7  0.000230      0.000010  0.000039  0.000007  0.000021   \n",
      "2  00013b17ad220c46  0.000275      0.000010  0.000121  0.000011  0.000168   \n",
      "3  00017563c3f7919a  0.000074      0.000010  0.000028  0.000009  0.000020   \n",
      "4  00017695ad8997eb  0.001580      0.000010  0.000097  0.000010  0.000159   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.421509  \n",
      "1       0.000017  \n",
      "2       0.000036  \n",
      "3       0.000021  \n",
      "4       0.000037  \n",
      "save done\n",
      "CPU times: user 10h 7min 34s, sys: 1min 30s, total: 10h 9min 5s\n",
      "Wall time: 1h 17min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_res = simple_ens('xgb',10,666,0.095,0.7,0.7,5,'auc')\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = xgb_res\n",
    "sample_submission.to_csv(\"../results/xgb_adj2_fold10_stratified.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# test param from discussion/48836, feels overfitting\n",
    "# all loss avg 0.0232036492161 0.0362071794551 all auc avg 0.997893313434 0.991243339617"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
