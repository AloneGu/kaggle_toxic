{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/cnn2d_muse_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/cnn_glove_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/cnn_gru_glove_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/cnn_muse_adj_1_feat_de_fr.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_glove_1_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 16) (153164, 16)\n",
      "file path ../features/tfidf_feat1.pkl\n",
      "(159571, 30) (153164, 30)\n",
      "file path ../features/tfidf_feat2.pkl\n",
      "(159571, 30) (153164, 30)\n",
      "(159571, 130)\n",
      "(159571, 130)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "#     if 'tfidf' in feat or 'lr' in feat or 'mnb' in feat:\n",
    "#         continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def simple_ens(model_name,k=3,rnd=233):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    cache_test_pred = np.zeros((153164,6))\n",
    "    single_best = 100\n",
    "    single_best_pred = None\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        d_test = xgb.DMatrix(test_x)\n",
    "        \n",
    "        # share params\n",
    "        params = {\n",
    "                'colsample_bytree': 0.9,\n",
    "                'subsample': 0.9,\n",
    "                'eta': 0.05,\n",
    "                'max_depth': 3,\n",
    "                'eval_metric':'logloss',\n",
    "                'objective':'binary:logistic',\n",
    "                'scale_pos_weight':0.9,\n",
    "                'colsample_bylevel':0.9,\n",
    "                'colsample_bytree':0.9,\n",
    "            \n",
    "                }\n",
    "        \n",
    "        # train for each class\n",
    "        for i in range(6):\n",
    "            d_train = xgb.DMatrix(curr_x, curr_y[:,i])\n",
    "            d_valid = xgb.DMatrix(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "            model = xgb.train(params, d_train, 1000, watchlist,\n",
    "                              early_stopping_rounds=50,\n",
    "                              verbose_eval=2000)\n",
    "            print(i)\n",
    "            try:\n",
    "                curr_train_loss = log_loss(curr_y[:,i],model.predict(d_train))\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],model.predict(d_valid))\n",
    "                print(curr_train_loss,curr_val_loss)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            \n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            cache_test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "        # avg 6 class\n",
    "        train_loss_l = train_loss_l/6\n",
    "        val_loss_l = val_loss_l/6\n",
    "        print('this fold avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        \n",
    "        # save best one fold result\n",
    "        if val_loss_l < single_best:\n",
    "            single_best = val_loss_l\n",
    "            single_best_pred = cache_test_pred\n",
    "            print('new single best')\n",
    "        \n",
    "        cache_test_pred = np.zeros((153164,6))\n",
    "        \n",
    "        # avg k fold\n",
    "        all_train_loss_l += train_loss_l/k\n",
    "        all_val_loss_l += val_loss_l/k\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all train avg',all_train_loss_l,'all val avg',all_val_loss_l)\n",
    "    return test_pred, single_best_pred\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.649341\tvalid-logloss:0.649323\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[422]\ttrain-logloss:0.073838\tvalid-logloss:0.082913\n",
      "\n",
      "0\n",
      "0.0727191805302 0.0829826968503\n",
      "[0]\ttrain-logloss:0.64566\tvalid-logloss:0.645651\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[245]\ttrain-logloss:0.017244\tvalid-logloss:0.019948\n",
      "\n",
      "1\n",
      "0.0163529834544 0.0200283656077\n",
      "[0]\ttrain-logloss:0.646934\tvalid-logloss:0.646864\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[228]\ttrain-logloss:0.039476\tvalid-logloss:0.042388\n",
      "\n",
      "2\n",
      "0.0383527858328 0.0424263226836\n",
      "[0]\ttrain-logloss:0.644743\tvalid-logloss:0.644784\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[201]\ttrain-logloss:0.004697\tvalid-logloss:0.007799\n",
      "\n",
      "3\n",
      "0.00404129290103 0.00781349888071\n",
      "[0]\ttrain-logloss:0.647914\tvalid-logloss:0.647856\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[199]\ttrain-logloss:0.054281\tvalid-logloss:0.05668\n",
      "\n",
      "4\n",
      "0.0530311971002 0.0567101590252\n",
      "[0]\ttrain-logloss:0.6454\tvalid-logloss:0.645411\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[223]\ttrain-logloss:0.015375\tvalid-logloss:0.019722\n",
      "\n",
      "5\n",
      "0.0145124796778 0.0197801326093\n",
      "this fold avg train 0.033168319916 avg val 0.0382901959428\n",
      "new single best\n",
      "========================\n",
      "[0]\ttrain-logloss:0.6493\tvalid-logloss:0.64942\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[494]\ttrain-logloss:0.071734\tvalid-logloss:0.084205\n",
      "\n",
      "0\n",
      "0.0706283543662 0.0842092149244\n",
      "[0]\ttrain-logloss:0.645636\tvalid-logloss:0.645667\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[212]\ttrain-logloss:0.017322\tvalid-logloss:0.0213\n",
      "\n",
      "1\n",
      "0.0164499259631 0.0213730919342\n",
      "[0]\ttrain-logloss:0.646907\tvalid-logloss:0.646968\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[248]\ttrain-logloss:0.037932\tvalid-logloss:0.04384\n",
      "\n",
      "2\n",
      "0.0368741686326 0.0438712086887\n",
      "[0]\ttrain-logloss:0.644769\tvalid-logloss:0.644757\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[254]\ttrain-logloss:0.004416\tvalid-logloss:0.006857\n",
      "\n",
      "3\n",
      "0.00382951050986 0.00691435691181\n",
      "[0]\ttrain-logloss:0.64778\tvalid-logloss:0.647864\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[380]\ttrain-logloss:0.049719\tvalid-logloss:0.057694\n",
      "\n",
      "4\n",
      "0.0487870062818 0.0577908782144\n",
      "[0]\ttrain-logloss:0.64541\tvalid-logloss:0.645406\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[198]\ttrain-logloss:0.016439\tvalid-logloss:0.018277\n",
      "\n",
      "5\n",
      "0.0155153478794 0.0183336503887\n",
      "this fold avg train 0.0320140522722 avg val 0.0387487335104\n",
      "========================\n",
      "[0]\ttrain-logloss:0.649341\tvalid-logloss:0.649371\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[349]\ttrain-logloss:0.075358\tvalid-logloss:0.082836\n",
      "\n",
      "0\n",
      "0.0740904364658 0.0828428286266\n",
      "[0]\ttrain-logloss:0.645626\tvalid-logloss:0.64566\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[190]\ttrain-logloss:0.017757\tvalid-logloss:0.021356\n",
      "\n",
      "1\n",
      "0.0168198278424 0.0214022258275\n",
      "[0]\ttrain-logloss:0.646893\tvalid-logloss:0.647013\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[284]\ttrain-logloss:0.037042\tvalid-logloss:0.04419\n",
      "\n",
      "2\n",
      "0.0360355045074 0.0442480151672\n",
      "[0]\ttrain-logloss:0.644761\tvalid-logloss:0.644776\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[196]\ttrain-logloss:0.004746\tvalid-logloss:0.007609\n",
      "\n",
      "3\n",
      "0.00409660590198 0.0077008025579\n",
      "[0]\ttrain-logloss:0.647788\tvalid-logloss:0.647868\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[248]\ttrain-logloss:0.052224\tvalid-logloss:0.058324\n",
      "\n",
      "4\n",
      "0.0510216543328 0.0583910339262\n",
      "[0]\ttrain-logloss:0.645363\tvalid-logloss:0.645445\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[181]\ttrain-logloss:0.01609\tvalid-logloss:0.019596\n",
      "\n",
      "5\n",
      "0.0151516276792 0.01972404316\n",
      "this fold avg train 0.0328692761216 avg val 0.0390514915442\n",
      "========================\n",
      "all train avg 0.0326838827699 all val avg 0.0386968069991\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.997564      0.310391  0.978612  0.130990  0.944227   \n",
      "1  0000247867823ef7  0.000142      0.000028  0.000087  0.000032  0.000060   \n",
      "2  00013b17ad220c46  0.001485      0.000034  0.000493  0.000032  0.000302   \n",
      "3  00017563c3f7919a  0.000219      0.000035  0.000135  0.000029  0.000098   \n",
      "4  00017695ad8997eb  0.006291      0.000031  0.000498  0.000050  0.000245   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.553908  \n",
      "1       0.000046  \n",
      "2       0.000221  \n",
      "3       0.000068  \n",
      "4       0.000139  \n",
      "save done\n"
     ]
    }
   ],
   "source": [
    "xgb_res,b = simple_ens('xgb',k=3)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = xgb_res\n",
    "sample_submission.to_csv(\"../results/xgb_ens_new_csv_fold3.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "\n",
    "# sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "# sample_submission[list_classes] = b\n",
    "# sample_submission.to_csv(\"../results/xgb_ens_new_csv_fold5_single_best.gz\", index=False, compression='gzip')\n",
    "# print(sample_submission.head())\n",
    "# print('save done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.649447\tvalid-logloss:0.64944\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[514]\ttrain-logloss:0.073006\tvalid-logloss:0.082361\n",
      "\n",
      "0\n",
      "0.0720997554264 0.082372275441\n",
      "[0]\ttrain-logloss:0.645648\tvalid-logloss:0.645636\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[247]\ttrain-logloss:0.01755\tvalid-logloss:0.020255\n",
      "\n",
      "1\n",
      "0.0167831849085 0.020258152129\n",
      "[0]\ttrain-logloss:0.646929\tvalid-logloss:0.646859\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[280]\ttrain-logloss:0.038769\tvalid-logloss:0.041845\n",
      "\n",
      "2\n",
      "0.037846022558 0.0418762727749\n",
      "[0]\ttrain-logloss:0.644747\tvalid-logloss:0.644796\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[222]\ttrain-logloss:0.004756\tvalid-logloss:0.007492\n",
      "\n",
      "3\n",
      "0.004206548825 0.00752446251792\n",
      "[0]\ttrain-logloss:0.647866\tvalid-logloss:0.647814\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[314]\ttrain-logloss:0.052442\tvalid-logloss:0.056135\n",
      "\n",
      "4\n",
      "0.0514775408648 0.0561503232951\n",
      "[0]\ttrain-logloss:0.645392\tvalid-logloss:0.645375\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[181]\ttrain-logloss:0.016693\tvalid-logloss:0.019396\n",
      "\n",
      "5\n",
      "0.0158612006675 0.0194262848973\n",
      "this fold avg train 0.033045708875 avg val 0.0379346285092\n",
      "new single best\n",
      "========================\n",
      "[0]\ttrain-logloss:0.649374\tvalid-logloss:0.649333\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[461]\ttrain-logloss:0.074145\tvalid-logloss:0.082668\n",
      "\n",
      "0\n",
      "0.0732627400074 0.0827304056722\n",
      "[0]\ttrain-logloss:0.645656\tvalid-logloss:0.645638\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[225]\ttrain-logloss:0.018038\tvalid-logloss:0.019593\n",
      "\n",
      "1\n",
      "0.0172100911463 0.0196328293935\n",
      "[0]\ttrain-logloss:0.646907\tvalid-logloss:0.646925\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[223]\ttrain-logloss:0.039391\tvalid-logloss:0.043516\n",
      "\n",
      "2\n",
      "0.0383901032289 0.0435617450688\n",
      "[0]\ttrain-logloss:0.644761\tvalid-logloss:0.644775\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[178]\ttrain-logloss:0.005374\tvalid-logloss:0.007462\n",
      "\n",
      "3\n",
      "0.00475383302425 0.00750499225024\n",
      "[0]\ttrain-logloss:0.647845\tvalid-logloss:0.647795\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[272]\ttrain-logloss:0.052984\tvalid-logloss:0.056617\n",
      "\n",
      "4\n",
      "0.0520822442282 0.0566268638317\n",
      "[0]\ttrain-logloss:0.645404\tvalid-logloss:0.645368\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5cad4eb5f26e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxgb_res\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_ens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'xgb'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msample_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/sample_submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist_classes\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_res\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../results/xgb_ens_new_csv_fold5.gz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gzip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0a52a25b1bc4>\u001b[0m in \u001b[0;36msimple_ens\u001b[0;34m(model_name, k, rnd)\u001b[0m\n\u001b[1;32m     37\u001b[0m             model = xgb.train(params, d_train, 1000, watchlist,\n\u001b[1;32m     38\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                               verbose_eval=2000)\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/xgboost-0.6-py3.5.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 896\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    897\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_res,b = simple_ens('xgb',k=5)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = xgb_res\n",
    "sample_submission.to_csv(\"../results/xgb_ens_new_csv_fold5.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_res,b = simple_ens('xgb',k=6)\n",
    "# sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "# sample_submission[list_classes] = xgb_res\n",
    "# sample_submission.to_csv(\"../results/xgb_ens_new_csv_fold6.gz\", index=False, compression='gzip')\n",
    "# print(sample_submission.head())\n",
    "# print('save done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
