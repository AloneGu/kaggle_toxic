{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file path ../features/fasttext_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/fasttext_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/glove_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lr_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/lstm_attention_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat1.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/mnb_feat2.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/muse_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn2d_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cnn_v2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_cudnn_gru_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_gru_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/no_pretrained_lstm_v1_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/other_feat.pkl\n",
      "(159571, 36) (153164, 36)\n",
      "file path ../features/pool_gru_fasttext_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj1_10_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_fasttext_adj2_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "file path ../features/pool_gru_glove_4_feat.pkl\n",
      "(159571, 6) (153164, 6)\n",
      "(159571, 276)\n",
      "(159571, 276)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "\n",
    "# import time\n",
    "# print('sleeping')\n",
    "# time.sleep(1800)\n",
    "# print('sleep done =======================')\n",
    "\n",
    "# load feats\n",
    "train_x,test_x = [],[]\n",
    "for feat in sorted(glob.glob('../features/*.pkl')):\n",
    "    if '3_feat' in feat or 'tfidf' in feat:\n",
    "        continue\n",
    "    print('file path',feat)\n",
    "    a,b = pickle.load(open(feat,'rb'))\n",
    "    print(a.shape,b.shape)\n",
    "    train_x.append(a)\n",
    "    test_x.append(b)\n",
    "train_x = np.nan_to_num(np.hstack(train_x))\n",
    "test_x = np.nan_to_num(np.hstack(test_x))\n",
    "print(train_x.shape)\n",
    "    \n",
    "# load y\n",
    "train = pd.read_csv(\"../input/train.csv\")\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "train_y = train[list_classes].values.astype('int')\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def simple_ens(model_name,k=3,rnd=233,lr=0.05,c_bytree=0.9,s_sample=0.9):\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=rnd)\n",
    "    test_pred = np.zeros((153164,6))\n",
    "    all_train_loss_l,all_val_loss_l = 0,0\n",
    "    all_train_auc_l,all_val_auc_l = 0,0\n",
    "    \n",
    "    for train_index, test_index in kf.split(train_x):\n",
    "        # x,y\n",
    "        curr_x,curr_y = train_x[train_index],train_y[train_index]\n",
    "        hold_out_x,hold_out_y = train_x[test_index],train_y[test_index]\n",
    "        val_loss_l,train_loss_l = 0,0\n",
    "        val_auc_l,train_auc_l = 0,0\n",
    "        d_test = xgb.DMatrix(test_x)\n",
    "        \n",
    "        # share params\n",
    "        params = {\n",
    "                'subsample': s_sample,\n",
    "                'eta': lr,\n",
    "                'max_depth': 3,\n",
    "                'eval_metric':'logloss',\n",
    "                #'eval_metric':'auc',\n",
    "                'objective':'binary:logistic',\n",
    "                #'scale_pos_weight':0.9,\n",
    "                'colsample_bytree':c_bytree\n",
    "            \n",
    "                }\n",
    "        \n",
    "        # train for each class\n",
    "        for i in range(6):\n",
    "            d_train = xgb.DMatrix(curr_x, curr_y[:,i])\n",
    "            d_valid = xgb.DMatrix(hold_out_x, hold_out_y[:,i])\n",
    "            watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "            model = xgb.train(params, d_train, 1000, watchlist,\n",
    "                              early_stopping_rounds=50,\n",
    "                              verbose_eval=None)\n",
    "            print(i)\n",
    "            try:\n",
    "                train_pred = model.predict(d_train)\n",
    "                tmp_test_pred = model.predict(d_valid)\n",
    "                \n",
    "                curr_train_loss = log_loss(curr_y[:,i],train_pred)\n",
    "                curr_val_loss = log_loss(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                curr_train_auc = roc_auc_score(curr_y[:,i],train_pred)\n",
    "                curr_val_auc = roc_auc_score(hold_out_y[:,i],tmp_test_pred)\n",
    "                \n",
    "                print('ls',curr_train_loss,curr_val_loss,'auc',curr_train_auc,curr_val_auc)\n",
    "                val_loss_l += curr_val_loss\n",
    "                train_loss_l += curr_train_loss\n",
    "                val_auc_l += curr_val_auc\n",
    "                train_auc_l += curr_train_auc\n",
    "            except:\n",
    "                pass\n",
    "            curr_test_pred = model.predict(d_test)\n",
    "            test_pred[:,i] += curr_test_pred\n",
    "            \n",
    "            \n",
    "        # avg 6 class\n",
    "        train_loss_l = train_loss_l/6\n",
    "        val_loss_l = val_loss_l/6\n",
    "        train_auc_l = train_auc_l/6\n",
    "        val_auc_l = val_auc_l/6\n",
    "        print('this fold avg train',train_loss_l,'avg val',val_loss_l)\n",
    "        print('this fold auc train',train_auc_l,'auc val',val_auc_l)\n",
    "        \n",
    "        \n",
    "        # avg k fold\n",
    "        all_train_loss_l += train_loss_l/k\n",
    "        all_val_loss_l += val_loss_l/k\n",
    "        all_train_auc_l += train_auc_l/k\n",
    "        all_val_auc_l += val_auc_l/k\n",
    "        print('========================')\n",
    "    test_pred = test_pred/k\n",
    "    print('all loss avg',all_train_loss_l,all_val_loss_l)\n",
    "    print('all auc avg',all_train_auc_l,all_val_auc_l)\n",
    "    print('=======================================================')\n",
    "    return test_pred\n",
    "\n",
    "print('done')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0688003911772 0.074704226865 auc 0.990813728283 0.988837137781\n",
      "1\n",
      "ls 0.0166296795286 0.0206951787293 auc 0.995296202396 0.992008688248\n",
      "2\n",
      "ls 0.0338646588139 0.0400604727117 auc 0.996490287614 0.994652346205\n",
      "3\n",
      "ls 0.00373618224407 0.00690765057967 auc 0.999125975598 0.997928660186\n",
      "4\n",
      "ls 0.0495808672918 0.0563505278254 auc 0.991773050114 0.987942038823\n",
      "5\n",
      "ls 0.0124027476631 0.0195981944745 auc 0.996977594694 0.989235540239\n",
      "this fold avg train 0.0308357544531 avg val 0.0363860418642\n",
      "this fold auc train 0.995079473117 auc val 0.991767401914\n",
      "========================\n",
      "0\n",
      "ls 0.0690765581718 0.0773713140222 auc 0.990755527966 0.986864754851\n",
      "1\n",
      "ls 0.0165496768128 0.0192693533141 auc 0.995327154816 0.993383214571\n",
      "2\n",
      "ls 0.0348556682482 0.034944524965 auc 0.996315828998 0.996056369352\n",
      "3\n",
      "ls 0.00410681480011 0.00756393688232 auc 0.998832243967 0.993075987043\n",
      "4\n",
      "ls 0.0503002297735 0.0490632270101 auc 0.991559056988 0.991543706112\n",
      "5\n",
      "ls 0.0139601925387 0.0164958092669 auc 0.99595357695 0.988320073246\n",
      "this fold avg train 0.0314748567242 avg val 0.0341180275768\n",
      "this fold auc train 0.994790564948 auc val 0.991540684196\n",
      "========================\n",
      "0\n",
      "ls 0.067224639847 0.0725431446351 auc 0.991360200106 0.988458430242\n",
      "1\n",
      "ls 0.0159767797549 0.0184188681167 auc 0.995931487972 0.992426322492\n",
      "2\n",
      "ls 0.0337844348752 0.0388367614843 auc 0.996507489429 0.995546933904\n",
      "3\n",
      "ls 0.00425076024496 0.00804792821819 auc 0.999049974342 0.979074621236\n",
      "4\n",
      "ls 0.0483427397727 0.0540407397317 auc 0.992222751944 0.989252852392\n",
      "5\n",
      "ls 0.0134526294459 0.0190070885454 auc 0.99607950074 0.989808776102\n",
      "this fold avg train 0.0305053306568 avg val 0.0351490884552\n",
      "this fold auc train 0.995191900756 auc val 0.989094656061\n",
      "========================\n",
      "0\n",
      "ls 0.0652142282743 0.0806721307129 auc 0.991856910687 0.986578419637\n",
      "1\n",
      "ls 0.0159000906187 0.0197956419509 auc 0.995857110298 0.992854706804\n",
      "2\n",
      "ls 0.0339741124826 0.0413783898456 auc 0.996491200771 0.994181846527\n",
      "3\n",
      "ls 0.00414547316927 0.00655585291119 auc 0.998942744237 0.99439566278\n",
      "4\n",
      "ls 0.0452250691505 0.0536131583815 auc 0.993368878203 0.989244819438\n",
      "5\n",
      "ls 0.0125820553781 0.0151445997865 auc 0.997065753257 0.992624339627\n",
      "this fold avg train 0.0295068381789 avg val 0.0361932955981\n",
      "this fold auc train 0.995597099576 auc val 0.991646632469\n",
      "========================\n",
      "0\n",
      "ls 0.065047582589 0.0768795460961 auc 0.991966564966 0.988629383103\n",
      "1\n",
      "ls 0.0163271865104 0.0209456735407 auc 0.995506382855 0.991325360282\n",
      "2\n",
      "ls 0.0342255253468 0.0369642244576 auc 0.996430685043 0.995321506322\n",
      "3\n",
      "ls 0.00378562065883 0.00732645491289 auc 0.99909826297 0.996219059641\n",
      "4\n",
      "ls 0.0494884183866 0.0537117031802 auc 0.991771889728 0.990364427288\n",
      "5\n",
      "ls 0.0143270470579 0.0185655215317 auc 0.995610341831 0.986924143449\n",
      "this fold avg train 0.0305335634249 avg val 0.0357321872865\n",
      "this fold auc train 0.995064021232 auc val 0.991463980014\n",
      "========================\n",
      "0\n",
      "ls 0.0652691629637 0.0773682871142 auc 0.991897295898 0.987268979644\n",
      "1\n",
      "ls 0.0166666475602 0.0196096627027 auc 0.995309921679 0.991893220196\n",
      "2\n",
      "ls 0.0346616816263 0.0427492881321 auc 0.996308132275 0.993912603948\n",
      "3\n",
      "ls 0.00414871700379 0.00659230055071 auc 0.998910759176 0.995490042234\n",
      "4\n",
      "ls 0.048405829275 0.0567818728984 auc 0.992144640222 0.989112011053\n",
      "5\n",
      "ls 0.0139718768193 0.016794108281 auc 0.995728026331 0.99314139414\n",
      "this fold avg train 0.0305206525414 avg val 0.0366492532798\n",
      "this fold auc train 0.99504979593 auc val 0.991803041869\n",
      "========================\n",
      "0\n",
      "ls 0.0693585314141 0.0767321699775 auc 0.990668228007 0.987945699691\n",
      "1\n",
      "ls 0.0165805264291 0.0217962440165 auc 0.995231790734 0.99206846534\n",
      "2\n",
      "ls 0.0326562066561 0.0351740959377 auc 0.996800492356 0.996080735699\n",
      "3\n",
      "ls 0.00300449503361 0.00522457090214 auc 0.999660211527 0.99279702837\n",
      "4\n",
      "ls 0.0490024943947 0.0509049324216 auc 0.991967311877 0.991475637518\n",
      "5\n",
      "ls 0.0138983100794 0.0187091608522 auc 0.995678778943 0.993330374219\n",
      "this fold avg train 0.0307500940012 avg val 0.0347568623513\n",
      "this fold auc train 0.995001135574 auc val 0.99228299014\n",
      "========================\n",
      "0\n",
      "ls 0.0694250772384 0.0745140325762 auc 0.990628855579 0.988632231133\n",
      "1\n",
      "ls 0.0164940643943 0.0196998591929 auc 0.995408381475 0.99213177248\n",
      "2\n",
      "ls 0.0348571953406 0.0412251562455 auc 0.996288089876 0.994602214352\n",
      "3\n",
      "ls 0.00387433346108 0.00596311543787 auc 0.999098201263 0.995792539328\n",
      "4\n",
      "ls 0.0495643253763 0.0568785721885 auc 0.991767514636 0.988470486297\n",
      "5\n",
      "ls 0.0141713512387 0.0172822895515 auc 0.995552310448 0.993420937063\n",
      "this fold avg train 0.0313977245082 avg val 0.0359271708654\n",
      "this fold auc train 0.994790558879 auc val 0.992175030109\n",
      "========================\n",
      "0\n",
      "ls 0.0676094729868 0.0774118691907 auc 0.991258430321 0.987474022821\n",
      "1\n",
      "ls 0.0166189402938 0.0209639275882 auc 0.995311451468 0.990805625432\n",
      "2\n",
      "ls 0.0342561440833 0.0420469286992 auc 0.99642756675 0.994131694487\n",
      "3\n",
      "ls 0.00421894185008 0.00896958265422 auc 0.998735988319 0.992749641399\n",
      "4\n",
      "ls 0.0490846877137 0.0532140888538 auc 0.991950886711 0.989744175419\n",
      "5\n",
      "ls 0.0145870439325 0.0189894139523 auc 0.995398850542 0.984790914313\n",
      "this fold avg train 0.0310625384767 avg val 0.0369326351564\n",
      "this fold auc train 0.994847195685 auc val 0.989949345645\n",
      "========================\n",
      "0\n",
      "ls 0.068667384599 0.073404704159 auc 0.990830825398 0.989783860604\n",
      "1\n",
      "ls 0.0164404099552 0.0222772354344 auc 0.995397343874 0.990047556498\n",
      "2\n",
      "ls 0.0343760191212 0.0378712957002 auc 0.996370538818 0.995633518003\n",
      "3\n",
      "ls 0.00360870000938 0.00688392949553 auc 0.999259087815 0.996743120736\n",
      "4\n",
      "ls 0.0475185247692 0.0570682757823 auc 0.992454415409 0.989518786267\n",
      "5\n",
      "ls 0.0131125191747 0.0185161513456 auc 0.996442839869 0.989478208651\n",
      "this fold avg train 0.0306205929381 avg val 0.0360035986528\n",
      "this fold auc train 0.995125841864 auc val 0.99186750846\n",
      "========================\n",
      "all loss avg 0.0307207945903 0.0357848161087\n",
      "all auc avg 0.995053758756 0.991359127088\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999331      0.322576  0.983401  0.136337  0.924753   \n",
      "1  0000247867823ef7  0.000358      0.000023  0.000061  0.000018  0.000051   \n",
      "2  00013b17ad220c46  0.000295      0.000024  0.000206  0.000023  0.000208   \n",
      "3  00017563c3f7919a  0.000087      0.000024  0.000046  0.000022  0.000046   \n",
      "4  00017695ad8997eb  0.002055      0.000026  0.000159  0.000022  0.000213   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.470877  \n",
      "1       0.000035  \n",
      "2       0.000056  \n",
      "3       0.000041  \n",
      "4       0.000063  \n",
      "save done\n",
      "CPU times: user 13h 58min 35s, sys: 42.3 s, total: 13h 59min 18s\n",
      "Wall time: 1h 45min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_res = simple_ens('xgb',10,233,0.05,0.8,0.7)\n",
    "sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "sample_submission[list_classes] = xgb_res\n",
    "sample_submission.to_csv(\"../results/xgb_adj_fold10.gz\", index=False, compression='gzip')\n",
    "print(sample_submission.head())\n",
    "print('save done')\n",
    "# all train avg 0.0321542340346 all val avg 0.0367885979049, PUB 9862, rnd 42, lr 0.03\n",
    "# all train avg 0.0318508428487 all val avg 0.0368012450966, rnd 233, lr 0.05, PUB unknown\n",
    "\n",
    "# fix lr, mnb bug, rm scale_pos_weight\n",
    "# all train avg 0.0304768900903 all val avg 0.0360563778853 PUB 9866\n",
    "\n",
    "# add many base models, rm tfidf\n",
    "# all loss avg 0.0307207945903 0.0357848161087 all auc avg 0.995053758756 0.991359127088"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0665750156779 0.0761578797365 auc 0.991626428172 0.987886995545\n",
      "1\n",
      "ls 0.0163873100813 0.0198899219435 auc 0.995469910995 0.99281797154\n",
      "2\n",
      "ls 0.0342686766459 0.0375387753073 auc 0.996433475328 0.995171177562\n",
      "3\n",
      "ls 0.00409166777748 0.00718869480271 auc 0.998813588977 0.996021432506\n",
      "4\n",
      "ls 0.0482071097314 0.0527547465068 auc 0.992332088584 0.989513439385\n",
      "5\n",
      "ls 0.014102401981 0.0181316152242 auc 0.99571170767 0.988437461404\n",
      "this fold avg train 0.0306053636492 avg val 0.0352769389202\n",
      "this fold auc train 0.995064533288 auc val 0.99164141299\n",
      "========================\n",
      "0\n",
      "ls 0.0674609998606 0.076736927229 auc 0.991307231248 0.987385551355\n",
      "1\n",
      "ls 0.0153823007163 0.0192965524941 auc 0.996406703197 0.992463249362\n",
      "2\n",
      "ls 0.0310401216165 0.0399914139285 auc 0.997121892584 0.994906232623\n",
      "3\n",
      "ls 0.00416442953175 0.00734797032905 auc 0.999132953867 0.984149203632\n",
      "4\n",
      "ls 0.0436058692404 0.0536283504558 auc 0.993977448829 0.989316045983\n",
      "5\n",
      "ls 0.0125699032046 0.016762315523 auc 0.99702254955 0.991606056722\n",
      "this fold avg train 0.029037270695 avg val 0.0356272549932\n",
      "this fold auc train 0.995828129879 auc val 0.989971056613\n",
      "========================\n",
      "0\n",
      "ls 0.0680640758148 0.0773439527929 auc 0.991026657016 0.987887725381\n",
      "1\n",
      "ls 0.0151902572212 0.0202097777022 auc 0.996506967875 0.991717186611\n",
      "2\n",
      "ls 0.0347000162354 0.0397511822332 auc 0.996299321097 0.994631077141\n",
      "3\n",
      "ls 0.00407184573147 0.00697939606219 auc 0.999057001649 0.995945611619\n",
      "4\n",
      "ls 0.0463042286977 0.0551941537065 auc 0.992900261632 0.989740756615\n",
      "5\n",
      "ls 0.0135343898556 0.0177514236467 auc 0.996176364452 0.989970051656\n",
      "this fold avg train 0.0303108022594 avg val 0.0362049810239\n",
      "this fold auc train 0.995327762287 auc val 0.991648734837\n",
      "========================\n",
      "0\n",
      "ls 0.0682655741837 0.0758868754429 auc 0.991001839598 0.988248773638\n",
      "1\n",
      "ls 0.0159826788755 0.0207536909434 auc 0.995730834512 0.991968112218\n",
      "2\n",
      "ls 0.0339474099193 0.0383187017069 auc 0.996508121026 0.995332920993\n",
      "3\n",
      "ls 0.00344748232599 0.00579188944042 auc 0.999461887066 0.993480069265\n",
      "4\n",
      "ls 0.0471209041785 0.0539661702945 auc 0.99265708537 0.989971254099\n",
      "5\n",
      "ls 0.0137291354422 0.0180077195175 auc 0.995875916123 0.993245188138\n",
      "this fold avg train 0.0304155308209 avg val 0.0354541745576\n",
      "this fold auc train 0.995205947283 auc val 0.992041053059\n",
      "========================\n",
      "0\n",
      "ls 0.0668847004057 0.0750299351197 auc 0.991398995306 0.988833669535\n",
      "1\n",
      "ls 0.0153416593331 0.0214373293351 auc 0.996326968253 0.990737623962\n",
      "2\n",
      "ls 0.0342233256064 0.0401345062936 auc 0.996432577018 0.994821543505\n",
      "3\n",
      "ls 0.00395613445569 0.00833378428588 auc 0.998946241724 0.993106355428\n",
      "4\n",
      "ls 0.0468238071254 0.0550233231361 auc 0.992719325332 0.989765896395\n",
      "5\n",
      "ls 0.0139527275184 0.0187441977317 auc 0.995905506605 0.987675423343\n",
      "this fold avg train 0.0301970590741 avg val 0.0364505126503\n",
      "this fold auc train 0.99528826904 auc val 0.990823418695\n",
      "========================\n",
      "all loss avg 0.0301132052997 0.0358027724291\n",
      "all auc avg 0.995342928355 0.991225135239\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999213      0.319954  0.983567  0.152359  0.927819   \n",
      "1  0000247867823ef7  0.000327      0.000021  0.000063  0.000026  0.000035   \n",
      "2  00013b17ad220c46  0.000295      0.000021  0.000244  0.000029  0.000200   \n",
      "3  00017563c3f7919a  0.000096      0.000021  0.000059  0.000029  0.000039   \n",
      "4  00017695ad8997eb  0.001837      0.000024  0.000147  0.000030  0.000180   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.457039  \n",
      "1       0.000039  \n",
      "2       0.000054  \n",
      "3       0.000040  \n",
      "4       0.000070  \n",
      "save done\n",
      "0\n",
      "ls 0.0635045878123 0.0760326990181 auc 0.992450633889 0.987998632652\n",
      "1\n",
      "ls 0.0163079575495 0.019838923495 auc 0.995543022752 0.992863898031\n",
      "2\n",
      "ls 0.0333057983304 0.0374786110941 auc 0.996655286583 0.99525212126\n",
      "3\n",
      "ls 0.00374362151183 0.00725283069839 auc 0.99906270875 0.996063060892\n",
      "4\n",
      "ls 0.0487271037932 0.052631172871 auc 0.992136970085 0.989386206017\n",
      "5\n",
      "ls 0.0132564224789 0.0180733783486 auc 0.996400994184 0.988646895162\n",
      "this fold avg train 0.0298075819127 avg val 0.0352179359209\n",
      "this fold auc train 0.995374936041 auc val 0.991701802336\n",
      "========================\n",
      "0\n",
      "ls 0.0671741156366 0.0768694522662 auc 0.991359253515 0.987412725785\n",
      "1\n",
      "ls 0.0143353453498 0.01916131735 auc 0.997247637838 0.992580808807\n",
      "2\n",
      "ls 0.0313118092792 0.0398955912166 auc 0.997056417099 0.994930582347\n",
      "3\n",
      "ls 0.00398931902929 0.00730869343 auc 0.999202931396 0.985230418444\n",
      "4\n",
      "ls 0.0428728502285 0.0537116587562 auc 0.994231132101 0.989413148361\n",
      "5\n",
      "ls 0.0138847369334 0.0170306579007 auc 0.995916185733 0.991172717857\n",
      "this fold avg train 0.0289280294095 avg val 0.0356628951533\n",
      "this fold auc train 0.995835592947 auc val 0.990123400267\n",
      "========================\n",
      "0\n",
      "ls 0.0673760256071 0.0770678047269 auc 0.991253356874 0.987945917955\n",
      "1\n",
      "ls 0.0144973252083 0.0201231624569 auc 0.997016465244 0.991801971033\n",
      "2\n",
      "ls 0.0346814648037 0.0397918779355 auc 0.996306968839 0.994553758355\n",
      "3\n",
      "ls 0.00394249503454 0.00701579822742 auc 0.999059436539 0.995816895569\n",
      "4\n",
      "ls 0.0471959286396 0.0552656301794 auc 0.992577603921 0.989725508665\n",
      "5\n",
      "ls 0.0137319232439 0.0178813295052 auc 0.995941142301 0.989392606741\n",
      "this fold avg train 0.0302375270895 avg val 0.0361909338386\n",
      "this fold auc train 0.995359162286 auc val 0.991539443053\n",
      "========================\n",
      "0\n",
      "ls 0.0691182077079 0.0756133378652 auc 0.990674794996 0.988345422796\n",
      "1\n",
      "ls 0.0151152937148 0.0208525794339 auc 0.996414043385 0.992046998513\n",
      "2\n",
      "ls 0.0318600234514 0.0383183972346 auc 0.996980225061 0.995310697693\n",
      "3\n",
      "ls 0.00294959096073 0.0057617231715 auc 0.999736667104 0.993295022409\n",
      "4\n",
      "ls 0.0484676298874 0.0538727008922 auc 0.992121833418 0.990010149609\n",
      "5\n",
      "ls 0.0122361414001 0.0178763804198 auc 0.996973358844 0.993309921708\n",
      "this fold avg train 0.0299578145204 avg val 0.0353825198362\n",
      "this fold auc train 0.995483487135 auc val 0.992053035455\n",
      "========================\n",
      "0\n",
      "ls 0.067131880511 0.075261382916 auc 0.991270299556 0.988839951685\n",
      "1\n",
      "ls 0.0159491666382 0.0215593481498 auc 0.995829697479 0.99062646134\n",
      "2\n",
      "ls 0.0333998088723 0.0401174310142 auc 0.996620308444 0.994880002312\n",
      "3\n",
      "ls 0.00399233317621 0.00818327611812 auc 0.998812685272 0.994515069367\n",
      "4\n",
      "ls 0.0459738492796 0.0550738552948 auc 0.993019151729 0.989761411251\n",
      "5\n",
      "ls 0.014010933316 0.0188034468394 auc 0.99575631958 0.987330581029\n",
      "this fold avg train 0.0300763286322 avg val 0.0364997900554\n",
      "this fold auc train 0.99521807701 auc val 0.990992246164\n",
      "========================\n",
      "all loss avg 0.0298014563128 0.0357908149609\n",
      "all auc avg 0.995454251084 0.991281985455\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999008      0.303697  0.982336  0.111006  0.926274   \n",
      "1  0000247867823ef7  0.000293      0.000021  0.000070  0.000022  0.000046   \n",
      "2  00013b17ad220c46  0.000263      0.000021  0.000217  0.000025  0.000158   \n",
      "3  00017563c3f7919a  0.000095      0.000022  0.000055  0.000025  0.000050   \n",
      "4  00017695ad8997eb  0.001707      0.000024  0.000176  0.000022  0.000164   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.466437  \n",
      "1       0.000042  \n",
      "2       0.000063  \n",
      "3       0.000046  \n",
      "4       0.000065  \n",
      "save done\n",
      "0\n",
      "ls 0.0676012144644 0.0761543090831 auc 0.991272513831 0.987823597686\n",
      "1\n",
      "ls 0.0156125437061 0.0199191053796 auc 0.996131734773 0.992799715047\n",
      "2\n",
      "ls 0.0350261157211 0.0376915735868 auc 0.996255292604 0.995163314688\n",
      "3\n",
      "ls 0.00405064530814 0.00712825073095 auc 0.998868901741 0.996332044309\n",
      "4\n",
      "ls 0.0482530286885 0.0527276235136 auc 0.992327643828 0.989694521856\n",
      "5\n",
      "ls 0.0127604300553 0.0180192363092 auc 0.996768106569 0.989063488827\n",
      "this fold avg train 0.0305506629906 avg val 0.0352733497672\n",
      "this fold auc train 0.995270698891 auc val 0.991812780402\n",
      "========================\n",
      "0\n",
      "ls 0.0676188521629 0.0766223205607 auc 0.991227797167 0.987442596388\n",
      "1\n",
      "ls 0.0155699820805 0.0192332712575 auc 0.996223594386 0.992517122074\n",
      "2\n",
      "ls 0.0310271854802 0.0398075233304 auc 0.997132103064 0.994942172815\n",
      "3\n",
      "ls 0.00409187585932 0.00735230442211 auc 0.999180730922 0.985688279819\n",
      "4\n",
      "ls 0.0437457345075 0.0537407479963 auc 0.993929579171 0.989262370429\n",
      "5\n",
      "ls 0.0123070863627 0.0168106707267 auc 0.997238781923 0.991560544036\n",
      "this fold avg train 0.0290601194089 avg val 0.0355944730489\n",
      "this fold auc train 0.995822097772 auc val 0.99023551426\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0648620828829 0.0770121625557 auc 0.9920419623 0.987971177276\n",
      "1\n",
      "ls 0.0163507488206 0.0202962117058 auc 0.995562250222 0.991602553568\n",
      "2\n",
      "ls 0.034290959001 0.0397462369322 auc 0.996408713352 0.99453241697\n",
      "3\n",
      "ls 0.00400138206974 0.0069788981694 auc 0.999078465516 0.995851999947\n",
      "4\n",
      "ls 0.0467626184651 0.0552638677063 auc 0.9927059462 0.98972093428\n",
      "5\n",
      "ls 0.0127191866095 0.0178063163112 auc 0.996780636655 0.989668161296\n",
      "this fold avg train 0.0298311629748 avg val 0.0361839488968\n",
      "this fold auc train 0.995429662374 auc val 0.991557873889\n",
      "========================\n",
      "0\n",
      "ls 0.0679972458843 0.0758108258332 auc 0.991090393626 0.988259537639\n",
      "1\n",
      "ls 0.0156394861139 0.0208225065684 auc 0.996011486015 0.991833524847\n",
      "2\n",
      "ls 0.034029352773 0.0383744679531 auc 0.996494711034 0.995313400924\n",
      "3\n",
      "ls 0.00289462327357 0.00591125855699 auc 0.999707246879 0.993299266603\n",
      "4\n",
      "ls 0.0477379059667 0.0539052156935 auc 0.992427640308 0.990005079895\n",
      "5\n",
      "ls 0.0137195629287 0.017960740094 auc 0.99583930867 0.993195119131\n",
      "this fold avg train 0.0303363628234 avg val 0.0354641691165\n",
      "this fold auc train 0.995261797756 auc val 0.991984321506\n",
      "========================\n",
      "0\n",
      "ls 0.0643680360877 0.0750607896649 auc 0.99217825936 0.988850971832\n",
      "1\n",
      "ls 0.0154049168105 0.0213957242548 auc 0.996261129385 0.990748004515\n",
      "2\n",
      "ls 0.0343599746979 0.0401398455421 auc 0.996401443002 0.994806802396\n",
      "3\n",
      "ls 0.00397910059059 0.0083030868759 auc 0.998890377332 0.992964581572\n",
      "4\n",
      "ls 0.0449350170341 0.0550180078853 auc 0.993406741205 0.989811154659\n",
      "5\n",
      "ls 0.0139811212443 0.0187356856382 auc 0.995821101592 0.987287593609\n",
      "this fold avg train 0.0295046944109 avg val 0.0364421899769\n",
      "this fold auc train 0.995493175313 auc val 0.99074485143\n",
      "========================\n",
      "all loss avg 0.0298566005217 0.0357916261613\n",
      "all auc avg 0.995455486421 0.991267068298\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999414      0.315966  0.981826  0.126545  0.931602   \n",
      "1  0000247867823ef7  0.000301      0.000021  0.000068  0.000023  0.000036   \n",
      "2  00013b17ad220c46  0.000314      0.000020  0.000225  0.000032  0.000168   \n",
      "3  00017563c3f7919a  0.000080      0.000021  0.000056  0.000026  0.000035   \n",
      "4  00017695ad8997eb  0.001850      0.000023  0.000160  0.000028  0.000162   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.450778  \n",
      "1       0.000033  \n",
      "2       0.000046  \n",
      "3       0.000037  \n",
      "4       0.000061  \n",
      "save done\n",
      "0\n",
      "ls 0.0681615246248 0.0762330777611 auc 0.991013757662 0.987855703673\n",
      "1\n",
      "ls 0.0163600899241 0.0198130154349 auc 0.995480430762 0.992895561637\n",
      "2\n",
      "ls 0.0350709141815 0.0375553710959 auc 0.996231831002 0.995172384932\n",
      "3\n",
      "ls 0.00387996421385 0.00734639208047 auc 0.99894761361 0.996146608771\n",
      "4\n",
      "ls 0.0495996236173 0.0525774259459 auc 0.991816535245 0.989526445133\n",
      "5\n",
      "ls 0.0134090748773 0.0179184685229 auc 0.996284350066 0.987405611197\n",
      "this fold avg train 0.0310801985731 avg val 0.0352406251402\n",
      "this fold auc train 0.994962419725 auc val 0.991500385891\n",
      "========================\n",
      "0\n",
      "ls 0.0673176079337 0.0767806275971 auc 0.991316411441 0.987442147984\n",
      "1\n",
      "ls 0.0149247078891 0.0191688391099 auc 0.996748089807 0.992602629343\n",
      "2\n",
      "ls 0.0336499272781 0.040015686093 auc 0.9965319295 0.994877110354\n",
      "3\n",
      "ls 0.00403836272249 0.00729201794813 auc 0.999179544169 0.986550677347\n",
      "4\n",
      "ls 0.0487345455596 0.0538115904069 auc 0.992168460403 0.989286732877\n",
      "5\n",
      "ls 0.0138608388547 0.0169922427044 auc 0.995920172443 0.991305745625\n",
      "this fold avg train 0.030420998373 avg val 0.0356768339766\n",
      "this fold auc train 0.99531076796 auc val 0.990344173922\n",
      "========================\n",
      "0\n",
      "ls 0.0676616041256 0.0770437035298 auc 0.991145849601 0.987892751384\n",
      "1\n",
      "ls 0.0146390721036 0.0200504462572 auc 0.996887804852 0.991868221662\n",
      "2\n",
      "ls 0.0338666715727 0.0397679152679 auc 0.99648257205 0.994618987578\n",
      "3\n",
      "ls 0.00380893642791 0.00705932941299 auc 0.999169743223 0.995916859462\n",
      "4\n",
      "ls 0.0468606634906 0.0552614347377 auc 0.992696539373 0.98968137203\n",
      "5\n",
      "ls 0.0139362979057 0.0178695684048 auc 0.995787320517 0.989371559683\n",
      "this fold avg train 0.030128874271 avg val 0.0361753996017\n",
      "this fold auc train 0.995361638269 auc val 0.991558291967\n",
      "========================\n",
      "0\n",
      "ls 0.0693105144776 0.0757128603996 auc 0.990637875863 0.988354939125\n",
      "1\n",
      "ls 0.015625411084 0.0206602957823 auc 0.996036989506 0.9921306915\n",
      "2\n",
      "ls 0.0330719403678 0.0384324443207 auc 0.996707931682 0.995256672254\n",
      "3\n",
      "ls 0.00259759283593 0.00569506118889 auc 0.999832251227 0.993297568926\n",
      "4\n",
      "ls 0.0483849648796 0.0540592519208 auc 0.992181253242 0.989919424586\n",
      "5\n",
      "ls 0.0137332879726 0.0179471465621 auc 0.995717787687 0.993194071662\n",
      "this fold avg train 0.0304539519362 avg val 0.0354178433624\n",
      "this fold auc train 0.995185681534 auc val 0.992025561342\n",
      "========================\n",
      "0\n",
      "ls 0.0657707664381 0.0751562624726 auc 0.991711683801 0.988804452815\n",
      "1\n",
      "ls 0.0160116997918 0.0215419481191 auc 0.995797001965 0.990638555188\n",
      "2\n",
      "ls 0.0337014064968 0.04008934954 auc 0.996541979093 0.994840621379\n",
      "3\n",
      "ls 0.00403014607496 0.00820525973716 auc 0.998700914023 0.994370675461\n",
      "4\n",
      "ls 0.0479306741194 0.0550121198583 auc 0.992282565247 0.989746654006\n",
      "5\n",
      "ls 0.0142620624853 0.0187371668099 auc 0.995563338899 0.987940835997\n",
      "this fold avg train 0.0302844592344 avg val 0.0364570177562\n",
      "this fold auc train 0.995099580505 auc val 0.991056965808\n",
      "========================\n",
      "all loss avg 0.0304736964775 0.0357935439674\n",
      "all auc avg 0.995184017599 0.991297075786\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999186      0.312151  0.980133  0.107494  0.922061   \n",
      "1  0000247867823ef7  0.000322      0.000022  0.000075  0.000022  0.000058   \n",
      "2  00013b17ad220c46  0.000311      0.000023  0.000225  0.000026  0.000159   \n",
      "3  00017563c3f7919a  0.000089      0.000022  0.000067  0.000027  0.000057   \n",
      "4  00017695ad8997eb  0.001716      0.000024  0.000161  0.000026  0.000169   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.455698  \n",
      "1       0.000047  \n",
      "2       0.000065  \n",
      "3       0.000050  \n",
      "4       0.000072  \n",
      "save done\n",
      "0\n",
      "ls 0.0659698570436 0.0760964705129 auc 0.991756345474 0.987859172267\n",
      "1\n",
      "ls 0.0166557286859 0.0199401288693 auc 0.995239103032 0.992781743811\n",
      "2\n",
      "ls 0.0349757226394 0.0376471139492 auc 0.996274634343 0.995149844028\n",
      "3\n",
      "ls 0.00374929572754 0.00736157134974 auc 0.999077253565 0.996135255575\n",
      "4\n",
      "ls 0.0484459972672 0.052761416493 auc 0.992263216028 0.989714279975\n",
      "5\n",
      "ls 0.013857873483 0.0180866995465 auc 0.99591157104 0.989292310167\n",
      "this fold avg train 0.0306090791411 avg val 0.0353155667868\n",
      "this fold auc train 0.99508702058 auc val 0.99182210097\n",
      "========================\n",
      "0\n",
      "ls 0.0667191514949 0.0764959493701 auc 0.99150114028 0.987526804353\n",
      "1\n",
      "ls 0.0156105308518 0.0193526139753 auc 0.996219144527 0.992397683348\n",
      "2\n",
      "ls 0.0299467641745 0.0398655046415 auc 0.997379261502 0.99496997046\n",
      "3\n",
      "ls 0.00419681963435 0.00725256148662 auc 0.999109157415 0.983334949249\n",
      "4\n",
      "ls 0.0456534687959 0.0538811991762 auc 0.99325135203 0.989180380586\n",
      "5\n",
      "ls 0.0126301616177 0.0168467652785 auc 0.996965899577 0.991450514699\n",
      "this fold avg train 0.0291261494282 avg val 0.0356157656547\n",
      "this fold auc train 0.995737659222 auc val 0.989810050449\n",
      "========================\n",
      "0\n",
      "ls 0.06451396489 0.0770358944649 auc 0.992149566061 0.988020296059\n",
      "1\n",
      "ls 0.0148015089132 0.0202942038863 auc 0.996802507116 0.991551764832\n",
      "2\n",
      "ls 0.03464460505 0.0397175574402 auc 0.996319988267 0.994668823015\n",
      "3\n",
      "ls 0.00406895896166 0.00695111308437 auc 0.998989837544 0.995773767335\n",
      "4\n",
      "ls 0.0469354911418 0.0552719622094 auc 0.992682928616 0.989731092712\n",
      "5\n",
      "ls 0.0142630943412 0.0178229362539 auc 0.995590611552 0.989685322743\n",
      "this fold avg train 0.0298712705496 avg val 0.0361822778898\n",
      "this fold auc train 0.995422573193 auc val 0.991571844449\n",
      "========================\n",
      "0\n",
      "ls 0.0685331788837 0.0757324412026 auc 0.990908521309 0.988317214082\n",
      "1\n",
      "ls 0.0157927327171 0.0207647616258 auc 0.995859263138 0.991995727134\n",
      "2\n",
      "ls 0.0333969674207 0.0384288103793 auc 0.996643580361 0.995297103185\n",
      "3\n",
      "ls 0.00385246637594 0.00582639023509 auc 0.999242494857 0.993286534021\n",
      "4\n",
      "ls 0.0485534383148 0.0538850620348 auc 0.992123962057 0.989987751447\n",
      "5\n",
      "ls 0.0138142024602 0.017935696882 auc 0.995753313394 0.993240055541\n",
      "this fold avg train 0.0306571643621 avg val 0.0354288603933\n",
      "this fold auc train 0.995088522519 auc val 0.992020730901\n",
      "========================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0655694227549 0.075029316998 auc 0.991812029537 0.988854043476\n",
      "1\n",
      "ls 0.0154181233544 0.0214299999779 auc 0.99623260343 0.990656897525\n",
      "2\n",
      "ls 0.0339094849149 0.0401384598942 auc 0.996502249621 0.994872865126\n",
      "3\n",
      "ls 0.00403462620568 0.0082312128291 auc 0.998890313633 0.993621923187\n",
      "4\n",
      "ls 0.0486888371432 0.0550464602165 auc 0.99202927332 0.989717566672\n",
      "5\n",
      "ls 0.0140438010077 0.0187380120163 auc 0.995793815671 0.987769440992\n",
      "this fold avg train 0.0302773825635 avg val 0.0364355769887\n",
      "this fold auc train 0.995210047535 auc val 0.990915456163\n",
      "========================\n",
      "all loss avg 0.0301082092089 0.0357956095426\n",
      "all auc avg 0.99530916461 0.991228036587\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999384      0.313022  0.978869  0.132661  0.924628   \n",
      "1  0000247867823ef7  0.000374      0.000020  0.000062  0.000022  0.000044   \n",
      "2  00013b17ad220c46  0.000317      0.000023  0.000202  0.000026  0.000139   \n",
      "3  00017563c3f7919a  0.000087      0.000021  0.000051  0.000026  0.000042   \n",
      "4  00017695ad8997eb  0.001726      0.000024  0.000147  0.000029  0.000159   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.459591  \n",
      "1       0.000040  \n",
      "2       0.000059  \n",
      "3       0.000047  \n",
      "4       0.000070  \n",
      "save done\n",
      "0\n",
      "ls 0.0662118492546 0.0759138650883 auc 0.991650351769 0.987983210311\n",
      "1\n",
      "ls 0.0165997844875 0.0198371441996 auc 0.995278426775 0.99288900071\n",
      "2\n",
      "ls 0.033500990602 0.0375577844556 auc 0.996603790421 0.995166647429\n",
      "3\n",
      "ls 0.00388187528103 0.00739430957268 auc 0.99893663599 0.996010079309\n",
      "4\n",
      "ls 0.0486952265433 0.0527814142979 auc 0.99214432351 0.989212151959\n",
      "5\n",
      "ls 0.0134618972369 0.0179071003797 auc 0.996209609991 0.989010711519\n",
      "this fold avg train 0.0303919372342 avg val 0.0352319363323\n",
      "this fold auc train 0.995137189743 auc val 0.991711966873\n",
      "========================\n",
      "0\n",
      "ls 0.0674468487765 0.0769413737151 auc 0.991296016266 0.987325080056\n",
      "1\n",
      "ls 0.0167627675367 0.0192764880744 auc 0.995314114146 0.992533200364\n",
      "2\n",
      "ls 0.0313260219643 0.0399431019125 auc 0.997062745808 0.994913070026\n",
      "3\n",
      "ls 0.00408455542961 0.00737191545291 auc 0.99913575706 0.983816547869\n",
      "4\n",
      "ls 0.0474229389411 0.0536880293348 auc 0.992628339571 0.989334372103\n",
      "5\n",
      "ls 0.0127920484634 0.0169062945624 auc 0.99672451362 0.991275000354\n",
      "this fold avg train 0.0299725301853 avg val 0.0356878671754\n",
      "this fold auc train 0.995360247745 auc val 0.989866211795\n",
      "========================\n",
      "0\n",
      "ls 0.0677998757758 0.0769948087292 auc 0.99107617796 0.987964610864\n",
      "1\n",
      "ls 0.0146961431556 0.0202011622199 auc 0.996863659107 0.991775245509\n",
      "2\n",
      "ls 0.0349283416593 0.0396904634128 auc 0.996251275673 0.994578559454\n",
      "3\n",
      "ls 0.00372214445371 0.00704539196053 auc 0.999207637487 0.996009133825\n",
      "4\n",
      "ls 0.0467683531792 0.0552593660427 auc 0.992729339874 0.989695239423\n",
      "5\n",
      "ls 0.0138889339885 0.0178769520877 auc 0.995769408812 0.989871292385\n",
      "this fold avg train 0.0303006320354 avg val 0.0361780240755\n",
      "this fold auc train 0.995316249819 auc val 0.991649013577\n",
      "========================\n",
      "0\n",
      "ls 0.0661665580411 0.0755053082679 auc 0.991593886155 0.988414713924\n",
      "1\n",
      "ls 0.0151907149471 0.02088243382 auc 0.996386032591 0.991908641188\n",
      "2\n",
      "ls 0.0325584860745 0.0384539320685 auc 0.996821656907 0.995211285401\n",
      "3\n",
      "ls 0.0036485764178 0.00579725621158 auc 0.999295178942 0.993888785142\n",
      "4\n",
      "ls 0.0480428399437 0.0539414850952 auc 0.992285779262 0.990001152944\n",
      "5\n",
      "ls 0.0131402114552 0.0181163635467 auc 0.996248889472 0.993108493463\n",
      "this fold avg train 0.0297912311466 avg val 0.0354494631683\n",
      "this fold auc train 0.995438570555 auc val 0.992088845344\n",
      "========================\n",
      "0\n",
      "ls 0.066630827307 0.0752178859581 auc 0.991473472584 0.988759239107\n",
      "1\n",
      "ls 0.0153873648724 0.0215709388578 auc 0.996288219159 0.990578690639\n",
      "2\n",
      "ls 0.0337100492452 0.0402488051687 auc 0.996542358485 0.994822185269\n",
      "3\n",
      "ls 0.00398899635113 0.00828274713425 auc 0.9987144183 0.994064711759\n",
      "4\n",
      "ls 0.0486783046658 0.0550975118143 auc 0.992014614201 0.98969081853\n",
      "5\n",
      "ls 0.0136605474618 0.0187708462644 auc 0.995956232875 0.988225384987\n",
      "this fold avg train 0.0303426816506 avg val 0.0365314558663\n",
      "this fold auc train 0.995164885934 auc val 0.991023505049\n",
      "========================\n",
      "all loss avg 0.0301598024504 0.0358157493235\n",
      "all auc avg 0.995283428759 0.991267908527\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
      "0  00001cee341fdb12  0.999252      0.324963  0.980203  0.123485  0.923852   \n",
      "1  0000247867823ef7  0.000258      0.000024  0.000069  0.000024  0.000051   \n",
      "2  00013b17ad220c46  0.000275      0.000025  0.000181  0.000030  0.000154   \n",
      "3  00017563c3f7919a  0.000086      0.000024  0.000052  0.000030  0.000050   \n",
      "4  00017695ad8997eb  0.001698      0.000025  0.000141  0.000027  0.000177   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.452317  \n",
      "1       0.000039  \n",
      "2       0.000052  \n",
      "3       0.000038  \n",
      "4       0.000061  \n",
      "save done\n",
      "0\n",
      "ls 0.0638576653558 0.0874349302134 auc 0.991903333459 0.984614157002\n",
      "1\n",
      "ls 0.0102219746507 0.026139350472 auc 0.998356584109 0.9903420297\n",
      "2\n",
      "ls 0.0277771313925 0.0459068924335 auc 0.997603439811 0.993459725242\n",
      "3\n",
      "ls 0.000917224902148 0.0122348595806 auc 0.99998959568 0.985830920051\n",
      "4\n",
      "ls 0.0426963106478 0.0626560407815 auc 0.993945973022 0.985977638523\n",
      "5\n",
      "ls 0.00838907504447 0.0251697216253 auc 0.99862992347 0.978138705944\n",
      "this fold avg train 0.0256432303322 avg val 0.0432569658511\n",
      "this fold auc train 0.996738141592 auc val 0.986393862744\n",
      "========================\n",
      "0\n",
      "ls 0.0645303135354 0.0900633370224 auc 0.991916081943 0.983960383165\n",
      "1\n",
      "ls 0.010385894023 0.0278102433293 auc 0.998453877466 0.987988368923\n",
      "2\n",
      "ls 0.026776110909 0.0500934424832 auc 0.997773359322 0.993041920387\n",
      "3\n",
      "ls 0.000847430772083 0.0115825868656 auc 0.999998854169 0.981290871525\n",
      "4\n",
      "ls 0.042707887818 0.0635582788233 auc 0.993924522015 0.986279197346\n",
      "5\n",
      "ls 0.00815993901026 0.0246827742225 auc 0.998798224611 0.98497524582\n",
      "this fold avg train 0.0255679293446 avg val 0.0446317771244\n",
      "this fold auc train 0.996810819921 auc val 0.986255997861\n",
      "========================\n",
      "0\n",
      "ls 0.0635804405214 0.0877342936525 auc 0.991969328981 0.984799015803\n",
      "1\n",
      "ls 0.0104292646285 0.0260801786602 auc 0.998386816261 0.98955200956\n",
      "2\n",
      "ls 0.0274562605576 0.0494643845943 auc 0.997661726833 0.991492241503\n",
      "3\n",
      "ls 0.000890695096895 0.0112022567159 auc 0.999929817859 0.989269427765\n",
      "4\n",
      "ls 0.0419742965459 0.065964145403 auc 0.9939992077 0.986441161982\n",
      "5\n",
      "ls 0.00836924369815 0.0253898651104 auc 0.998626363045 0.983079352912\n",
      "this fold avg train 0.0254500335081 avg val 0.0443058540227\n",
      "this fold auc train 0.996762210113 auc val 0.987438868254\n",
      "========================\n",
      "0\n",
      "ls 0.0647828996724 0.0868709975162 auc 0.99150968332 0.985767263135\n",
      "1\n",
      "ls 0.00963145130133 0.0278506397838 auc 0.998635102975 0.988898615371\n",
      "2\n",
      "ls 0.0276309972105 0.0478325119034 auc 0.997618109121 0.993342001302\n",
      "3\n",
      "ls 0.00118711911172 0.00908568752107 auc 0.999980120681 0.984743820454\n",
      "4\n",
      "ls 0.0419940504048 0.0643429928047 auc 0.993941687174 0.987222804304\n",
      "5\n",
      "ls 0.00859611294993 0.023555537745 auc 0.998468536883 0.98851010556\n",
      "this fold avg train 0.0256371051084 avg val 0.0432563945457\n",
      "this fold auc train 0.996692206692 auc val 0.988080768354\n",
      "========================\n",
      "0\n",
      "ls 0.0644071322829 0.0852489478383 auc 0.991703780824 0.986066318466\n",
      "1\n",
      "ls 0.00994807797083 0.0286291715972 auc 0.9985858928 0.988532008385\n",
      "2\n",
      "ls 0.0272712453354 0.0481648151665 auc 0.997718602412 0.993392025379\n",
      "3\n",
      "ls 0.000827910601713 0.0143439892653 auc 0.999998959576 0.965330906584\n",
      "4\n",
      "ls 0.0424588187823 0.0636896337813 auc 0.993842109794 0.987166749932\n",
      "5\n",
      "ls 0.00820452161905 0.0265171456953 auc 0.998720077216 0.977783990153\n",
      "this fold avg train 0.0255196177654 avg val 0.0444322838907\n",
      "this fold auc train 0.996761570437 auc val 0.98304533315\n",
      "========================\n",
      "all loss avg 0.0255635832117 0.0439766550869\n",
      "all auc avg 0.996752989751 0.986242966073\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic       obscene        threat  \\\n",
      "0  00001cee341fdb12  0.999068  1.824383e-01  9.746769e-01  4.061123e-02   \n",
      "1  0000247867823ef7  0.000113  8.439905e-07  2.576351e-06  3.590669e-07   \n",
      "2  00013b17ad220c46  0.000173  7.432014e-07  8.987218e-05  1.350186e-07   \n",
      "3  00017563c3f7919a  0.000005  1.897342e-06  4.663085e-07  1.118621e-06   \n",
      "4  00017695ad8997eb  0.000555  1.144020e-06  4.119044e-06  7.722649e-08   \n",
      "\n",
      "     insult  identity_hate  \n",
      "0  0.946936       0.276420  \n",
      "1  0.000002       0.000001  \n",
      "2  0.000043       0.000005  \n",
      "3  0.000004       0.000006  \n",
      "4  0.000075       0.000006  \n",
      "save done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ls 0.0659480664292 0.0896616715203 auc 0.991334830052 0.984396736399\n",
      "1\n",
      "ls 0.011365636614 0.0292182783341 auc 0.997809098543 0.989205277724\n",
      "2\n",
      "ls 0.0292838397293 0.0474111150983 auc 0.997309554392 0.993171652687\n",
      "3\n",
      "ls 0.00108575596091 0.0117842957439 auc 0.999984743869 0.98839907125\n",
      "4\n",
      "ls 0.0438587187553 0.0639806780687 auc 0.993517942889 0.985972075248\n",
      "5\n",
      "ls 0.00963964685593 0.0258900280954 auc 0.998073702553 0.984780628311\n",
      "this fold avg train 0.0268636107241 avg val 0.0446576778101\n",
      "this fold auc train 0.99633831205 auc val 0.98765424027\n",
      "========================\n",
      "0\n",
      "ls 0.0668148704501 0.089896752682 auc 0.991113161706 0.983967390914\n",
      "1\n",
      "ls 0.0115524855302 0.0286877927733 auc 0.997808895897 0.988921327361\n",
      "2\n",
      "ls 0.0287949271997 0.0507323964351 auc 0.997422160099 0.992796358294\n",
      "3\n",
      "ls 0.00104678666293 0.0129383824252 auc 0.999986270491 0.966244968373\n",
      "4\n",
      "ls 0.0446109629791 0.0642405104202 auc 0.993269181987 0.985929524562\n",
      "5\n",
      "ls 0.00919779579349 0.0252962894179 auc 0.998223889648 0.981026173062\n",
      "this fold avg train 0.0270029714359 avg val 0.0452986873589\n",
      "this fold auc train 0.996303926638 auc val 0.983147623761\n",
      "========================\n",
      "0\n",
      "ls nan 0.0906835121163 auc 0.991491839595 0.98411089185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1694: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ls 0.0110852329951 0.0297741121803 auc 0.99797113594 0.987860314593\n",
      "2\n",
      "ls 0.0284831601306 0.0522454280627 auc 0.997449266605 0.991916338352\n",
      "3\n",
      "ls 0.00111544330953 0.0124349224073 auc 0.999965072619 0.974526258074\n",
      "4\n",
      "ls 0.043882326232 0.0667330890139 auc 0.993468513533 0.986124890645\n",
      "5\n",
      "ls 0.00926427845864 0.0275307150999 auc 0.997962400556 0.975058589072\n",
      "this fold avg train nan avg val 0.0465669631467\n",
      "this fold auc train 0.996384704808 auc val 0.983266213764\n",
      "========================\n",
      "0\n",
      "ls 0.0660304231778 0.0897520094895 auc 0.99137981012 0.984625207191\n",
      "1\n",
      "ls 0.0109147994024 0.0294694210582 auc 0.997947815806 0.989253273828\n",
      "2\n",
      "ls 0.0290199351442 0.0492604851987 auc 0.997387246677 0.992534577603\n",
      "3\n",
      "ls 0.00127927780145 0.00977813980592 auc 0.999945205439 0.96638173978\n",
      "4\n",
      "ls 0.0435554708895 0.0643282787451 auc 0.993488868585 0.98707898234\n",
      "5\n",
      "ls 0.00913571594984 0.0267469820793 auc 0.998113838604 0.986169641338\n",
      "this fold avg train 0.0266559370609 avg val 0.0448892193961\n",
      "this fold auc train 0.996377130872 auc val 0.984340570347\n",
      "========================\n",
      "0\n",
      "ls 0.0665293200547 0.0869395698351 auc 0.991104818493 0.985596879094\n",
      "1\n",
      "ls 0.0110597897181 0.0313453285981 auc 0.997967192137 0.986953257276\n",
      "2\n",
      "ls 0.0287893081103 0.0513996447006 auc 0.997426593454 0.992204490928\n",
      "3\n",
      "ls 0.00103250071617 0.01440366565 auc 0.999974244201 0.97385480494\n",
      "4\n",
      "ls 0.0436496255692 0.0676036298317 auc 0.993475253159 0.985525319171\n",
      "5\n",
      "ls 0.00875870428837 0.0288331303324 auc 0.998340342858 0.979518962445\n",
      "this fold avg train 0.0266365414095 avg val 0.0467541614913\n",
      "this fold auc train 0.996381407384 auc val 0.983942285642\n",
      "========================\n",
      "all loss avg nan 0.0456333418406\n",
      "all auc avg 0.99635709635 0.984470186757\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene        threat    insult  \\\n",
      "0  00001cee341fdb12  0.999197      0.277298  0.995383  3.199673e-02  0.920445   \n",
      "1  0000247867823ef7  0.000088      0.000002  0.000002  8.859524e-07  0.000009   \n",
      "2  00013b17ad220c46  0.000033      0.000003  0.000239  7.597645e-07  0.000005   \n",
      "3  00017563c3f7919a  0.000004      0.000002  0.000001  7.924343e-06  0.000010   \n",
      "4  00017695ad8997eb  0.000518      0.000001  0.000006  2.462928e-06  0.000034   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.352673  \n",
      "1       0.000003  \n",
      "2       0.000075  \n",
      "3       0.000002  \n",
      "4       0.000007  \n",
      "save done\n",
      "0\n",
      "ls 0.0643942121079 0.0882655999974 auc 0.991776733359 0.984413018721\n",
      "1\n",
      "ls 0.0105546717057 0.0265104423431 auc 0.998241562551 0.990111636556\n",
      "2\n",
      "ls 0.0277135245354 0.0456838535798 auc 0.997622353425 0.993796222324\n",
      "3\n",
      "ls 0.000866461980678 0.0113173443537 auc 0.999975284431 0.98662011274\n",
      "4\n",
      "ls 0.0421528408098 0.0619840299589 auc 0.99410422017 0.986796862585\n",
      "5\n",
      "ls 0.00851361138399 0.0254578942103 auc 0.998558529345 0.97997250793\n",
      "this fold avg train 0.0256992204206 avg val 0.0432031940739\n",
      "this fold auc train 0.99671311388 auc val 0.986951726809\n",
      "========================\n",
      "0\n",
      "ls 0.0638376883941 0.0881515392801 auc 0.991995295189 0.984088126556\n",
      "1\n",
      "ls 0.0109604576807 0.0266647856927 auc 0.998166908995 0.989198208043\n",
      "2\n",
      "ls 0.0273315020465 0.0485740376106 auc 0.997664642154 0.993144569081\n",
      "3\n",
      "ls 0.000834022683048 0.0118144133924 auc 0.999999263394 0.96493106169\n",
      "4\n",
      "ls 0.0426623943578 0.0619334254988 auc 0.993958355393 0.986423884666\n",
      "5\n",
      "ls 0.00836136159477 0.0235817037449 auc 0.998724156101 0.985881989238\n",
      "this fold avg train 0.0256645711261 avg val 0.0434533175366\n",
      "this fold auc train 0.996751436871 auc val 0.983944639879\n",
      "========================\n",
      "0\n",
      "ls 0.0640461976395 0.0881110274439 auc 0.99197826971 0.984708930033\n",
      "1\n",
      "ls 0.0106059392883 0.0280550656714 auc 0.998290719396 0.988947562166\n",
      "2\n",
      "ls 0.0276509205536 0.0488054463085 auc 0.997589704058 0.992537677797\n",
      "3\n",
      "ls 0.00105443069078 0.010315557026 auc 0.999959609462 0.988338325956\n",
      "4\n",
      "ls 0.0421069005136 0.0643034219536 auc 0.994003208818 0.98726578762\n",
      "5\n",
      "ls 0.00833103555246 0.0251462219714 auc 0.998624586443 0.983189769014\n",
      "this fold avg train 0.0256325707064 avg val 0.0441227900625\n",
      "this fold auc train 0.996741016314 auc val 0.987498008764\n",
      "========================\n",
      "0\n",
      "ls 0.0643824255972 0.0861142270599 auc 0.991820914185 0.985763174176\n",
      "1\n",
      "ls 0.0100109129181 0.028482065737 auc 0.998516053173 0.988499565701\n",
      "2\n",
      "ls 0.0278870561121 0.0464350952157 auc 0.997585956098 0.993715105918\n",
      "3\n",
      "ls 0.0009596284951 0.00877732959408 auc 0.999995691517 0.98436820929\n",
      "4\n",
      "ls 0.0421638395506 0.0642119691904 auc 0.99401885985 0.986966970752\n",
      "5\n",
      "ls 0.00840085599236 0.023898734328 auc 0.998625454622 0.987370564284\n",
      "this fold avg train 0.0256341197776 avg val 0.0429865701875\n",
      "this fold auc train 0.996760488241 auc val 0.987780598353\n",
      "========================\n",
      "0\n",
      "ls 0.064643501962 0.0853479705117 auc 0.991790964067 0.985883002989\n",
      "1\n",
      "ls 0.0103447867737 0.0298369466172 auc 0.998408986168 0.98701725389\n",
      "2\n",
      "ls 0.0278535549693 0.0482999654921 auc 0.997620334468 0.993348832761\n",
      "3\n",
      "ls 0.000833170305968 0.0145948856965 auc 0.999985455299 0.962128913482\n",
      "4\n",
      "ls 0.0422623396504 0.0645336896463 auc 0.994010708759 0.986752123218\n",
      "5\n",
      "ls 0.00850842175682 0.0269031080382 auc 0.998581636625 0.977447634388\n",
      "this fold avg train 0.0257409625697 avg val 0.044919427667\n",
      "this fold auc train 0.996733014231 auc val 0.982096293455\n",
      "========================\n",
      "all loss avg 0.0256742889201 0.0437370599055\n",
      "all auc avg 0.996739813907 0.985654253452\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene        threat    insult  \\\n",
      "0  00001cee341fdb12  0.999884      0.176672  0.997651  3.710162e-02  0.973974   \n",
      "1  0000247867823ef7  0.000016      0.000002  0.000003  5.636704e-07  0.000003   \n",
      "2  00013b17ad220c46  0.000046      0.000003  0.000023  1.400265e-06  0.000653   \n",
      "3  00017563c3f7919a  0.000005      0.000003  0.000007  3.177247e-06  0.000004   \n",
      "4  00017695ad8997eb  0.000668      0.000001  0.000007  2.670336e-07  0.000053   \n",
      "\n",
      "   identity_hate  \n",
      "0   4.707869e-01  \n",
      "1   1.767763e-07  \n",
      "2   2.669105e-05  \n",
      "3   8.831308e-07  \n",
      "4   2.018450e-05  \n",
      "save done\n",
      "0\n",
      "ls 0.0660885355999 0.0890215590191 auc 0.991267086357 0.983967439208\n",
      "1\n",
      "ls 0.010908324633 0.0286136140639 auc 0.998032775257 0.989743749195\n",
      "2\n",
      "ls nan 0.0473885069125 auc 0.997274593103 0.992769239176\n",
      "3\n",
      "ls 0.0010728014445 0.0129553701214 auc 0.99997084667 0.966065878813\n",
      "4\n",
      "ls 0.0443758836752 0.0630796533418 auc 0.993334369814 0.986827524298\n",
      "5\n",
      "ls 0.00941373878913 0.025965009728 auc 0.998143368284 0.978707647707\n",
      "this fold avg train nan avg val 0.0445039521978\n",
      "this fold auc train 0.996337173247 auc val 0.983013579733\n",
      "========================\n",
      "0\n",
      "ls nan nan auc 0.991602130863 0.984528827172\n",
      "1\n",
      "ls 0.0113436291771 0.0260736026046 auc 0.997835319426 0.989897718063\n",
      "2\n",
      "ls 0.0288538883789 0.0511798503124 auc 0.997361536829 0.992603722761\n",
      "3\n",
      "ls 0.00104935439707 0.0119604124578 auc 0.99998868492 0.987117027963\n",
      "4\n",
      "ls 0.0439425452421 0.0663450157298 auc 0.993466100708 0.985426261959\n",
      "5\n",
      "ls 0.00934335065087 0.0236871532309 auc 0.998053393888 0.980811985039\n",
      "this fold avg train nan avg val nan\n",
      "this fold auc train 0.996384527772 auc val 0.986730923826\n",
      "========================\n",
      "0\n",
      "ls 0.0648874392203 0.0891899986433 auc 0.991590292624 0.985011833877\n",
      "1\n",
      "ls 0.0109932769897 0.0296054017475 auc 0.997981593558 0.988128491406\n",
      "2\n",
      "ls 0.028183529822 0.0510713862138 auc 0.99748031119 0.992704230004\n",
      "3\n",
      "ls 0.00106353007022 0.0115561026032 auc 0.999979456889 0.989713414553\n",
      "4\n",
      "ls 0.0437174889628 0.0669318416135 auc 0.993503115718 0.98596437506\n",
      "5\n",
      "ls 0.0095623686899 0.0253781540719 auc 0.9979919419 0.984209957676\n",
      "this fold avg train 0.0264012722925 avg val 0.0456221474822\n",
      "this fold auc train 0.996421118647 auc val 0.987622050429\n",
      "========================\n",
      "0\n",
      "ls 0.0665791585072 0.0889004655072 auc 0.991316385624 0.985098766512\n",
      "1\n",
      "ls 0.010573581363 0.0293184733966 auc 0.998147975944 0.98931839979\n",
      "2\n",
      "ls 0.0295066662054 0.0492921322784 auc 0.9973082893 0.993079298198\n",
      "3\n",
      "ls 0.00142996481863 0.00966352334552 auc 0.999945283245 0.972643623523\n",
      "4\n",
      "ls 0.0438638084825 0.0649812788903 auc 0.993335125801 0.987323606422\n",
      "5\n",
      "ls 0.00923857183931 0.0248319747634 auc 0.998201173527 0.989203110898\n",
      "this fold avg train 0.0268652918693 avg val 0.0444979746969\n",
      "this fold auc train 0.996375705573 auc val 0.986111134224\n",
      "========================\n",
      "0\n",
      "ls 0.0659768196677 0.0889801839082 auc 0.991202842441 0.98521189604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "ls 0.0107851947281 0.0305644904976 auc 0.99812318303 0.986706845118\n",
      "2\n",
      "ls 0.0287186033717 0.050194339736 auc 0.997397915984 0.99252948572\n",
      "3\n",
      "ls 0.000974526671925 0.0155254061487 auc 0.999979807284 0.969474080129\n",
      "4\n",
      "ls 0.0436709823405 0.0653016473617 auc 0.993537720367 0.986386772073\n",
      "5\n",
      "ls 0.00896179480279 0.0282501227712 auc 0.998346880331 0.97921172719\n",
      "this fold avg train 0.0265146535971 avg val 0.0464693650706\n",
      "this fold auc train 0.996431391573 auc val 0.983253467712\n",
      "========================\n",
      "all loss avg nan nan\n",
      "all auc avg 0.996389983363 0.985346231185\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene        threat    insult  \\\n",
      "0  00001cee341fdb12  0.999890  2.800859e-01  0.996744  7.826273e-02  0.878981   \n",
      "1  0000247867823ef7  0.000025  4.344897e-06  0.000002  1.448181e-06  0.000008   \n",
      "2  00013b17ad220c46  0.000038  5.759779e-07  0.000026  1.659680e-06  0.000013   \n",
      "3  00017563c3f7919a  0.000028  1.512231e-06  0.000007  4.402440e-06  0.000003   \n",
      "4  00017695ad8997eb  0.000280  4.358912e-07  0.000008  7.759699e-08  0.000043   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.197764  \n",
      "1       0.000005  \n",
      "2       0.000002  \n",
      "3       0.000004  \n",
      "4       0.000011  \n",
      "save done\n",
      "0\n",
      "ls 0.0647222697326 0.0854835309517 auc 0.991775280032 0.985255634641\n",
      "1\n",
      "ls 0.0100060724649 0.0271169050345 auc 0.998458854055 0.990091193087\n",
      "2\n",
      "ls 0.0277868104375 0.0457651104609 auc 0.997610546804 0.994081630682\n",
      "3\n",
      "ls 0.00105720704123 0.0109971055752 auc 0.999949974329 0.994218312065\n",
      "4\n",
      "ls 0.0431339997317 0.0618567375843 auc 0.993775175934 0.986797425282\n",
      "5\n",
      "ls 0.00871420153294 0.0258097725929 auc 0.998558633256 0.978577858615\n",
      "this fold avg train 0.0259034268235 avg val 0.0428381936999\n",
      "this fold auc train 0.996688077402 auc val 0.988170342395\n",
      "========================\n",
      "0\n",
      "ls 0.0639669155493 0.0881736287913 auc 0.991944938714 0.984451833912\n",
      "1\n",
      "ls 0.0107857026629 0.0268278427349 auc 0.998227096943 0.989082423474\n",
      "2\n",
      "ls 0.0270701927774 0.0477546415527 auc 0.997730020839 0.993229461958\n",
      "3\n",
      "ls 0.00100534065419 0.0103955244177 auc 0.999982137315 0.976044271634\n",
      "4\n",
      "ls 0.0427379076777 0.0619026342113 auc 0.993931968118 0.986058111387\n",
      "5\n",
      "ls 0.00883609641176 0.0232913298112 auc 0.998417732189 0.983033815078\n",
      "this fold avg train 0.0257336926222 avg val 0.0430576002532\n",
      "this fold auc train 0.99670564902 auc val 0.985316652907\n",
      "========================\n",
      "0\n",
      "ls 0.0637022468638 0.0884794545387 auc 0.991906120604 0.984617129575\n",
      "1\n",
      "ls 0.0101544477545 0.0276144713214 auc 0.998499724078 0.98895964497\n",
      "2\n",
      "ls 0.0277889883855 0.0485338535681 auc 0.997582029345 0.993078151276\n",
      "3\n",
      "ls 0.00107553059139 0.011604252921 auc 0.999962913956 0.985873330035\n",
      "4\n",
      "ls 0.0424667236164 0.0631392013796 auc 0.993914603359 0.987267003335\n",
      "5\n",
      "ls 0.00886805844828 0.0255007254651 auc 0.998500668429 0.979324234025\n",
      "this fold avg train 0.0256759992767 avg val 0.0441453265323\n",
      "this fold auc train 0.996727676628 auc val 0.986519915536\n",
      "========================\n",
      "0\n",
      "ls 0.0642501329913 0.0867687990794 auc 0.991859734421 0.98551400287\n",
      "1\n",
      "ls 0.0103099640818 0.028189797431 auc 0.998338405356 0.986957560116\n",
      "2\n",
      "ls 0.0283054612831 0.0464174654717 auc 0.997505397646 0.99339545867\n",
      "3\n",
      "ls 0.00119132761587 0.00875919939705 auc 0.999986987021 0.981480459731\n",
      "4\n",
      "ls 0.0423947634283 0.0633873462572 auc 0.99393472423 0.987220477223\n",
      "5\n",
      "ls 0.0088220501941 0.0241956196171 auc 0.998331549072 0.987615462483\n",
      "this fold avg train 0.0258789499324 avg val 0.0429530378756\n",
      "this fold auc train 0.996659466291 auc val 0.987030570182\n",
      "========================\n",
      "0\n",
      "ls 0.0640505953185 0.0852549931581 auc 0.991930341111 0.985993776572\n",
      "1\n",
      "ls 0.0103538372778 0.0292382543115 auc 0.998362595972 0.987103220995\n",
      "2\n",
      "ls 0.0277345061146 0.0486044578957 auc 0.99759807601 0.993304259379\n",
      "3\n",
      "ls 0.00091726215493 0.015021405029 auc 0.999980338112 0.970197796363\n",
      "4\n",
      "ls 0.0424910819206 0.0646645946737 auc 0.99391105375 0.985978420494\n",
      "5\n",
      "ls 0.00850784623388 0.0255058655244 auc 0.998623757986 0.97905924665\n",
      "this fold avg train 0.0256758548367 avg val 0.0447149284321\n",
      "this fold auc train 0.99673436049 auc val 0.983606120075\n",
      "========================\n",
      "all loss avg 0.0257735846983 0.0435418173586\n",
      "all auc avg 0.996703045966 0.986128720219\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic   obscene        threat    insult  \\\n",
      "0  00001cee341fdb12  0.999774      0.196757  0.998668  8.860155e-02  0.928514   \n",
      "1  0000247867823ef7  0.000039      0.000003  0.000006  2.170587e-06  0.000009   \n",
      "2  00013b17ad220c46  0.000158      0.000002  0.000036  1.686411e-06  0.000015   \n",
      "3  00017563c3f7919a  0.000009      0.000003  0.000002  2.309845e-06  0.000003   \n",
      "4  00017695ad8997eb  0.000443      0.000004  0.000065  9.164519e-08  0.000015   \n",
      "\n",
      "   identity_hate  \n",
      "0       0.415044  \n",
      "1       0.000003  \n",
      "2       0.000004  \n",
      "3       0.000005  \n",
      "4       0.000003  \n",
      "save done\n",
      "0\n",
      "ls 0.0664270442102 0.0873835145356 auc 0.99131289494 0.984685162835\n",
      "1\n",
      "ls 0.0108773848899 0.0288871426498 auc 0.998006065204 0.989386321284\n",
      "2\n",
      "ls 0.0293809849458 0.0461697786844 auc 0.997300332962 0.993610856067\n",
      "3\n",
      "ls 0.00121903119332 0.0131776172138 auc 0.999945143752 0.990111366121\n",
      "4\n",
      "ls 0.0444448885096 0.0642256568081 auc 0.993343246298 0.986280008877\n",
      "5\n",
      "ls 0.00956549845334 0.024375145256 auc 0.998108758828 0.978823614171\n",
      "this fold avg train 0.026985805367 avg val 0.0440364758579\n",
      "this fold auc train 0.996336073664 auc val 0.987149554893\n",
      "========================\n",
      "0\n",
      "ls 0.0657920424947 0.0886813040865 auc 0.991580102352 0.984415214255\n",
      "1\n",
      "ls 0.0117377085213 0.0269964480986 auc 0.997765279311 0.986001447255\n",
      "2\n",
      "ls 0.0289201766077 0.0509942386314 auc 0.997386402589 0.992719432648\n",
      "3\n",
      "ls 0.000980449525249 0.0121699720011 auc 0.999980132111 0.962175200931\n",
      "4\n",
      "ls 0.0444498904713 0.0645690466652 auc 0.993378045287 0.985488264607\n",
      "5\n",
      "ls 0.00964026712146 0.0233596774334 auc 0.997958289784 0.985377294714\n",
      "this fold avg train 0.0269200891236 avg val 0.0444617811527\n",
      "this fold auc train 0.996341375239 auc val 0.982696142401\n",
      "========================\n",
      "0\n",
      "ls 0.065961258927 0.0911526973995 auc 0.991237089102 0.984223369758\n",
      "1\n",
      "ls 0.0111308586852 0.0288547891344 auc 0.99794867929 0.986432393383\n",
      "2\n",
      "ls 0.0289490322082 0.0507398038214 auc 0.997339668997 0.992693015087\n",
      "3\n",
      "ls 0.00119676603478 0.0117244755646 auc 0.999955343288 0.973640959118\n",
      "4\n",
      "ls 0.0440019627526 0.0656560586794 auc 0.99334149774 0.986269107407\n",
      "5\n",
      "ls 0.00917253630941 0.0243732031491 auc 0.998113777736 0.983252046718\n",
      "this fold avg train 0.0267354024862 avg val 0.0454168379581\n",
      "this fold auc train 0.996322676025 auc val 0.984418481912\n",
      "========================\n",
      "0\n",
      "ls 0.0667555764511 0.0874781306355 auc 0.991170096605 0.985227656631\n",
      "1\n",
      "ls 0.0111109010821 0.0296941720071 auc 0.997906822331 0.989048753804\n",
      "2\n",
      "ls 0.0291587617374 0.04732317909 auc 0.997288085295 0.993612236233\n",
      "3\n",
      "ls 0.00138323851505 0.010655705399 auc 0.999928107669 0.983938272443\n",
      "4\n",
      "ls 0.0439886707674 0.0653280621866 auc 0.993428334009 0.986469120695\n",
      "5\n",
      "ls 0.0092110195137 0.0250888579059 auc 0.998284292504 0.98755282385\n",
      "this fold avg train 0.0269346946778 avg val 0.044261351204\n",
      "this fold auc train 0.996334289736 auc val 0.987641477276\n",
      "========================\n",
      "0\n",
      "ls 0.0662960376287 0.0891357258938 auc 0.991335482919 0.98537632063\n",
      "1\n",
      "ls 0.01119308917 0.0321976657278 auc 0.997913426457 0.986021224704\n",
      "2\n",
      "ls 0.029025030493 0.0515171542748 auc 0.997406972963 0.992613012191\n",
      "3\n",
      "ls 0.0010236682328 0.0156193311445 auc 0.999951864471 0.967035395139\n",
      "4\n",
      "ls 0.0439497543497 0.0665067745011 auc 0.993434031137 0.986029964062\n",
      "5\n",
      "ls 0.00895420363238 0.0285367632415 auc 0.998156281082 0.976310104041\n",
      "this fold avg train 0.0267402972511 avg val 0.0472522357972\n",
      "this fold auc train 0.996366343172 auc val 0.982231003461\n",
      "========================\n",
      "all loss avg 0.0268632577811 0.045085736394\n",
      "all auc avg 0.996340151567 0.984827331989\n",
      "=======================================================\n",
      "                 id     toxic  severe_toxic       obscene        threat  \\\n",
      "0  00001cee341fdb12  0.999724      0.429921  9.951458e-01  2.520426e-02   \n",
      "1  0000247867823ef7  0.000237      0.000004  1.163358e-06  4.059949e-07   \n",
      "2  00013b17ad220c46  0.000061      0.000002  3.277798e-05  6.418063e-07   \n",
      "3  00017563c3f7919a  0.000006      0.000003  2.348799e-07  3.752447e-06   \n",
      "4  00017695ad8997eb  0.000562      0.000002  1.064853e-03  2.227507e-06   \n",
      "\n",
      "     insult  identity_hate  \n",
      "0  0.952485   4.396430e-01  \n",
      "1  0.000004   7.754212e-07  \n",
      "2  0.000116   5.814604e-06  \n",
      "3  0.000006   4.732341e-06  \n",
      "4  0.000052   6.714020e-07  \n",
      "save done\n",
      "CPU times: user 1d 15h 51min 12s, sys: 4min 47s, total: 1d 15h 56min\n",
      "Wall time: 5h 2min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# adj lr, colsample_bytree, sample\n",
    "for lr in [0.05,0.075]:\n",
    "    for c1 in [0.8,0.7,0.6]:\n",
    "        for c2 in [0.7,0.6]:\n",
    "            xgb_res = simple_ens('xgb',5,233,lr,c1,c2)\n",
    "            sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n",
    "            sample_submission[list_classes] = xgb_res\n",
    "            fname = \"../results/xgb_adj_fold5_{}_{}_{}.gz\".format(lr,c1,c2)\n",
    "            sample_submission.to_csv(fname, index=False, compression='gzip')\n",
    "            print(sample_submission.head())\n",
    "            print('save done')\n",
    "\n",
    "# no rm, 0.0699781296574 0.0780951434931, 0.0161680844181 0.0199438522849,\n",
    "# final, all train avg 0.031309680463 all val avg 0.0368863155994\n",
    "# rm muse and pretrain, not good\n",
    "# rm gru_v1, 0.0687157498068 0.0780051849506, 0.0152173938614 0.0200296896045\n",
    "# rm tfidf, 0.072673329496 0.0787288243817, 0.0169421114344 0.0199760695638, not good\n",
    "# only rm no pretrain, not good,\n",
    "# test rm gru_v1, lstm_v1, all train avg 0.0313024384367 all val avg 0.0369036640753\n",
    "# rm cnn2d, 0.0704654561461 0.0780916497355, 0.0170009305396 0.0200476295259\n",
    "# 1st fold, this fold avg train 0.0318658486615 avg val 0.0362271742281\n",
    "\n",
    "# adj params\n",
    "# col sample by tree: 0.9 all train avg 0.031309680463 all val avg 0.0368863155994\n",
    "\n",
    "\n",
    "# adj lr, colsample_bytree, sample\n",
    "#   0.05  0.7  0.7 all train avg 0.031149993004 all val avg 0.0368516540068\n",
    "#   0.05  0.7  0.8 all train avg 0.0311077763624 all val avg 0.036855567286\n",
    "#   0.05  0.7  0.9 all train avg 0.0312078560147 all val avg 0.0368798432732\n",
    "#   0.05  0.8  0.7 all train avg 0.0309175391583 all val avg 0.0368485662838\n",
    "#   0.05  0.8  0.8 all train avg 0.0314143017087 all val avg 0.0368859121266\n",
    "#   0.05  0.8  0.9 all train avg 0.0312955837465 all val avg 0.0368866903553\n",
    "#   0.05  0.9  0.7 all train avg 0.0311044998336 all val avg 0.0368667306586\n",
    "#   0.05  0.9  0.8 all train avg 0.0311835661273 all val avg 0.0368992582647\n",
    "#   0.05  0.9  0.9 all train avg 0.0313585027516 all val avg 0.0368996796111\n",
    "#    0.1  0.7  0.7 all train avg 0.0306404949681 all val avg 0.0370501103027\n",
    "#    0.1  0.7  0.8 all train avg 0.0307017678518 all val avg 0.037048645753\n",
    "#    0.1  0.7  0.9 all train avg 0.030880668966 all val avg 0.0370266615654\n",
    "#    0.1  0.8  0.7 all train avg 0.0307153292658 all val avg 0.0370698994366\n",
    "#    0.1  0.8  0.8 all train avg 0.0308616897847 all val avg 0.0370446456042\n",
    "# large lr is worse\n",
    "\n",
    "# adj lr, colsample_bytree, sample\n",
    "#   0.03  0.8  0.7 all train avg 0.0320478053971 all val avg 0.036823783635\n",
    "#   0.05  0.8  0.7 all train avg 0.0309175391583 all val avg 0.0368485662838\n",
    "\n",
    "# fix lr, mnb bug, rm scale_pos_weight\n",
    "# all train avg 0.0299882438015 all val avg 0.0360842600203\n",
    "# 0\n",
    "# 0.0635105397429 0.0763360044684\n",
    "# 1\n",
    "# 0.0162476813928 0.0198345568551\n",
    "# 2\n",
    "# 0.0353173073883 0.0380803762678\n",
    "# 3\n",
    "# 0.00364481098573 0.00719515731424\n",
    "# 4\n",
    "# 0.0494110049729 0.0531263392106\n",
    "# 5\n",
    "# 0.0140568534717 0.0182191483172\n",
    "# 1st fold avg train 0.0303646996591 avg val 0.0354652637389\n",
    "\n",
    "# improve lr mnb feat (changed word, char tfidf params)\n",
    "# all train avg 0.0306645437303 all val avg 0.0362385982181, worse\n",
    "\n",
    "# add 2 feats, all train avg 0.0303858812518 all val avg 0.0360233929721\n",
    "\n",
    "# 0.05 0.8 0.7 all loss avg 0.0301132052997 0.0358027724291 all auc avg 0.995342928355 0.991225135239\n",
    "# 0.05 0.8 0.6 all loss avg 0.0298014563128 0.0357908149609 all auc avg 0.995454251084 0.991281985455\n",
    "# 0.05 0.7 0.7 all loss avg 0.0298566005217 0.0357916261613 all auc avg 0.995455486421 0.991267068298\n",
    "# 0.05 0.7 0.6 all loss avg 0.0304736964775 0.0357935439674 all auc avg 0.995184017599 0.991297075786\n",
    "# 0.05 0.6 0.7 all loss avg 0.0301082092089 0.0357956095426 all auc avg 0.99530916461 0.991228036587\n",
    "# 0.05 0.6 0.6 all loss avg 0.0301598024504 0.0358157493235 all auc avg 0.995283428759 0.991267908527\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
